{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.distributions import Normal\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "from miv.data.merror_funcs import get_merror_func\n",
    "from miv.util import dotdict, make_dotdict\n",
    "from miv.data.data_class import TrainDataSet, TestDataSet, ZTestDataSet, TrainDataSetTorch\n",
    "from itertools import product\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def psi(t: np.ndarray) -> np.ndarray:\n",
    "    out = 2 * ((t - 5) ** 4 / 600 + np.exp(-4 * (t - 5) ** 2) + t / 10 - 2)\n",
    "    return out\n",
    "\n",
    "\n",
    "def f_demand(p: np.ndarray, t: np.ndarray, s: np.ndarray) -> np.ndarray:\n",
    "    return 100 + (10 + p) * s * psi(t) - 2 * p\n",
    "\n",
    "\n",
    "def generate_test_demand_design() -> TestDataSet:\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    -------\n",
    "    test_data : TestDataSet\n",
    "        Uniformly sampled from (p,t,s).\n",
    "    \"\"\"\n",
    "    price = np.linspace(10, 25, 20)\n",
    "    time = np.linspace(0.0, 10, 20)\n",
    "    emotion = np.array([1, 2, 3, 4, 5, 6, 7])\n",
    "    data = []\n",
    "    target = []\n",
    "    for p, t, s in product(price, time, emotion):\n",
    "        data.append([p, t, s])\n",
    "        target.append(f(p, t, s))\n",
    "    features = np.array(data)\n",
    "    targets: np.ndarray = np.array(target)[:, np.newaxis]\n",
    "    test_data = TestDataSet(X_all=features[:, 0:1],\n",
    "                            Y_struct=targets,\n",
    "                            covariate=features[:, 1:])\n",
    "    # breakpoint()\n",
    "    return test_data\n",
    "\n",
    "\n",
    "def generate_train_demand_design(data_size: int,\n",
    "                                 rho: float,\n",
    "                                 merror_func_str: str,\n",
    "                                 m_scale: float,\n",
    "                                 n_scale: float,\n",
    "                                 bias: float,\n",
    "                                 rand_seed: int = 42) -> TrainDataSet:\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_size : int\n",
    "        size of data\n",
    "    rho : float\n",
    "        parameter for confounding\n",
    "    merror_func_str: str\n",
    "        parameter for choosing a measurement error mechanism\n",
    "    m_scale: float\n",
    "        chooses the error spread in M\n",
    "    n_scale: float\n",
    "        chooses the error spread in N\n",
    "    bias: float\n",
    "        chooses the bias level in N\n",
    "    rand_seed : int\n",
    "        random seed\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_data : TrainDataSet\n",
    "    \"\"\"\n",
    "    merror_func = get_merror_func(merror_func_str)\n",
    "    rng = default_rng(seed=rand_seed)\n",
    "    emotion = rng.choice(list(range(1, 8)), data_size)\n",
    "    time = rng.uniform(0, 10, data_size)\n",
    "    cost = rng.normal(0, 1.0, data_size)\n",
    "\n",
    "    noise_price = rng.normal(0, 1.0, data_size)\n",
    "    Z = np.c_[cost, time, emotion]\n",
    "\n",
    "\n",
    "    noise_demand = rho * noise_price + rng.normal(0, np.sqrt(1 - rho ** 2), data_size)\n",
    "    price = 25 + (cost + 3) * psi(time) + noise_price\n",
    "\n",
    "    X_hidden = price[:, np.newaxis]\n",
    "    X_obs = None\n",
    "    covariate = np.c_[time, emotion]\n",
    "    M, N = merror_func(X_hidden=X_hidden, scale_m=m_scale, scale_n=n_scale, bias=bias)\n",
    "\n",
    "\n",
    "    structure: np.ndarray = f_demand(price, time, emotion).astype(float)\n",
    "    outcome: np.ndarray = (structure + noise_demand).astype(float)\n",
    "\n",
    "\n",
    "    train_data = TrainDataSet(X_hidden=X_hidden,\n",
    "                              X_obs=X_obs,\n",
    "                              covariate=covariate,\n",
    "                              M=M,\n",
    "                              N=N,\n",
    "                              Z=Z,\n",
    "                              Y_struct=structure[:, np.newaxis],\n",
    "                              Y=outcome[:, np.newaxis])\n",
    "    \n",
    "    train_data_torch = TrainDataSetTorch.from_numpy(train_data)\n",
    "\n",
    "    return train_data_torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# data\n",
    "\n",
    "def f_sigmoid(x: np.ndarray) -> np.ndarray:\n",
    "    return np.log(np.abs(16 * x - 8) + 1) * np.sign(x - 0.5)\n",
    "\n",
    "def generate_train_sigmoid_cp_design(data_size: int,\n",
    "                                  merror_func_str: str,\n",
    "                                  m_scale: float,\n",
    "                                  n_scale: float,\n",
    "                                  bias: float,\n",
    "                                  rand_seed: int = 42):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_size : int\n",
    "        size of data\n",
    "    merror_func_str: str\n",
    "        parameter for choosing a measurement error mechanism\n",
    "    m_scale: float\n",
    "        chooses the error spread in M\n",
    "    n_scale: float\n",
    "        chooses the error spread in N\n",
    "    bias: float\n",
    "        chooses the bias level in N\n",
    "    rand_seed : int\n",
    "        random seed\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_data : TrainDataSet\n",
    "    \"\"\"\n",
    "    merror_func = get_merror_func(merror_func_str)\n",
    "    rng = default_rng(seed=rand_seed)\n",
    "    mu = np.zeros((3,))\n",
    "    sigma = np.array([[1, 0.5, 0], [0.5, 1, 0], [0, 0, 1]])\n",
    "    # sigma = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "    # sigma = np.array([[1, 0.5, 0],\n",
    "    #                   [0.5, 1, 0],\n",
    "    #                     [0, 0, 1]])\n",
    "    utw = rng.multivariate_normal(mu, sigma, size=data_size)\n",
    "    u = utw[:, 0:1]\n",
    "    z = stats.norm.cdf(utw[:, 2])[:, np.newaxis]\n",
    "    x = stats.norm.cdf(utw[:, 1] + utw[:, 2] / np.sqrt(2))[:, np.newaxis]\n",
    "#     x = z + rng.normal(0, 0.1, data_size)[:, np.newaxis]\n",
    "    structural = f_sigmoid(x)\n",
    "#     outcome = f(x) + rng.normal(0, 0.1, data_size)[:, np.newaxis]\n",
    "    outcome = f_sigmoid(x) + u\n",
    "    M, N = merror_func(X_hidden=x, scale_m=m_scale, scale_n=n_scale, bias=bias)\n",
    "\n",
    "    train_data = dotdict({'X': torch.tensor(x), \n",
    "                          'M': torch.tensor(M), \n",
    "                          'N': torch.tensor(N), \n",
    "                          'Z': torch.tensor(z),\n",
    "                          'Y': torch.tensor(outcome),\n",
    "                          'Y_struct': torch.tensor(structural)})\n",
    "#     train_data = TrainDataSet(X=x,\n",
    "#                               X_obs=None,\n",
    "#                               covariate=None,\n",
    "#                               M=M,\n",
    "#                               N=N,\n",
    "#                               Z=z,\n",
    "#                               Y_struct=structural,\n",
    "#                               Y=outcome)\n",
    "    return train_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# data\n",
    "\n",
    "def f_linear(x: np.ndarray) -> np.ndarray:\n",
    "    return 4 * x - 2\n",
    "\n",
    "def generate_train_linear_cp_design(data_size: int,\n",
    "                                  merror_func_str: str,\n",
    "                                  m_scale: float,\n",
    "                                  n_scale: float,\n",
    "                                  bias: float,\n",
    "                                  rand_seed: int = 42):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_size : int\n",
    "        size of data\n",
    "    merror_func_str: str\n",
    "        parameter for choosing a measurement error mechanism\n",
    "    m_scale: float\n",
    "        chooses the error spread in M\n",
    "    n_scale: float\n",
    "        chooses the error spread in N\n",
    "    bias: float\n",
    "        chooses the bias level in N\n",
    "    rand_seed : int\n",
    "        random seed\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_data : TrainDataSet\n",
    "    \"\"\"\n",
    "    merror_func = get_merror_func(merror_func_str)\n",
    "    rng = default_rng(seed=rand_seed)\n",
    "    mu = np.zeros((3,))\n",
    "    sigma = np.array([[1, 0.5, 0], [0.5, 1, 0], [0, 0, 1]])\n",
    "    # sigma = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "    # sigma = np.array([[1, 0.5, 0],\n",
    "    #                   [0.5, 1, 0],\n",
    "    #                     [0, 0, 1]])\n",
    "    utw = rng.multivariate_normal(mu, sigma, size=data_size)\n",
    "    u = utw[:, 0:1]\n",
    "    z = stats.norm.cdf(utw[:, 2])[:, np.newaxis]\n",
    "    x = stats.norm.cdf(utw[:, 1] + utw[:, 2] / np.sqrt(2))[:, np.newaxis]\n",
    "#     x = z + rng.normal(0, 1., data_size)[:, np.newaxis]\n",
    "    structural = f_linear(x)\n",
    "#     outcome = f(x) + rng.normal(0, 0.1, data_size)[:, np.newaxis]\n",
    "    outcome = f_linear(x) + u\n",
    "    M, N = merror_func(X_hidden=x, scale_m=m_scale, scale_n=n_scale, bias=bias)\n",
    "\n",
    "    train_data = dotdict({'X': torch.tensor(x), \n",
    "                          'M': torch.tensor(M), \n",
    "                          'N': torch.tensor(N), \n",
    "                          'Z': torch.tensor(z),\n",
    "                          'Y': torch.tensor(outcome),\n",
    "                          'Y_struct': torch.tensor(structural)})\n",
    "#     train_data = TrainDataSet(X=x,\n",
    "#                               X_obs=None,\n",
    "#                               covariate=None,\n",
    "#                               M=M,\n",
    "#                               N=N,\n",
    "#                               Z=z,\n",
    "#                               Y_struct=structural,\n",
    "#                               Y=outcome)\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## specialised implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "##             U\n",
    "##           /  \\\n",
    "##          /    \\\n",
    "##   Z --> X --> Y\n",
    "##        / \\\n",
    "##       /   \\\n",
    "##      M    N\n",
    "\n",
    "## p({x}|{z}) = prod_i (p(x_i|z_i))\n",
    "\n",
    "# likelihood models\n",
    "class EncoderS(torch.nn.Module):\n",
    "    # q({x}|{m},{n},{z}) = gaussian(q0 + q1*{m} + q2*{n} + q3*{z}, \n",
    "    #                       exp(qq0 + qq1*{m} + qq2*{n} + qq3*{z})^2)\n",
    "    # H[q] = -E_q[log(q)] = log(prod(sigma)*(2*pi*e)**(B*0.5))\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.q1_q2_q3 = torch.nn.Parameter(torch.tensor([[0.], [0.], [1.]]).double())\n",
    "        self.q0 = torch.nn.Parameter(torch.tensor([[0.]]).double())\n",
    "        self.qq1_qq2_qq3 = torch.nn.Parameter(torch.tensor([[0.], [0.], [0.]]).double())\n",
    "        self.qq0 = torch.nn.Parameter(torch.log(torch.tensor([[0.1]])).double())\n",
    "        self.data = data\n",
    "        \n",
    "    def forward(self, idx):\n",
    "        B = idx.shape[0]\n",
    "        mnz = torch.cat([self.data.M[idx], self.data.N[idx], self.data.Z[idx]], axis=1)\n",
    "        q_mean = self.q0 + mnz.matmul(self.q1_q2_q3)\n",
    "        q_logscale = self.qq0 + mnz.matmul(self.qq1_qq2_qq3)\n",
    "        q_scale = torch.exp(q_logscale)\n",
    "        \n",
    "        H_q = torch.log(torch.prod(q_scale)*(2*torch.pi*torch.e)**(B*0.5))\n",
    "        \n",
    "        return q_mean, q_scale, H_q\n",
    "        \n",
    "\n",
    "class MDecoderS(torch.nn.Module):\n",
    "    # p(m|x) = gaussian(x, exp(mm0 + mm1 * x)^2)\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.mm1 = torch.nn.Parameter(torch.tensor([[0.]]).double())\n",
    "        self.mm0 = torch.nn.Parameter(torch.log(torch.tensor([[0.4]])).double())\n",
    "        self.data = data\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pmx_mean = x\n",
    "        pmx_logscale = self.mm0 + x.matmul(self.mm1)\n",
    "        pmx_scale = torch.exp(pmx_logscale)\n",
    "        \n",
    "        return pmx_mean, pmx_scale\n",
    "\n",
    "class NDecoderS(torch.nn.Module):\n",
    "    # p(n|x) = gaussian(x, exp(nn0 + nn1 * x)^2)\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.nn1 = torch.nn.Parameter(torch.tensor([[0.]]).double())\n",
    "        self.nn0 = torch.nn.Parameter(torch.log(torch.tensor([[0.4]])).double())\n",
    "        self.data = data\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pnx_mean = x\n",
    "        pnx_logscale = self.nn0 + x.matmul(self.nn1)\n",
    "        pnx_scale = torch.exp(pnx_logscale)\n",
    "        \n",
    "        return pnx_mean, pnx_scale\n",
    "\n",
    "class IVModelS(torch.nn.Module):\n",
    "    # p(x|z) = gaussian(z, exp(zz0 + zz1 * x)^2)\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "#         self.zz1 = torch.nn.Parameter(torch.tensor([[0.]]).double())\n",
    "        self.zz1 = torch.nn.Parameter(torch.tensor([[3.]]).double())\n",
    "#         self.zz0 = torch.nn.Parameter(torch.log(torch.tensor([[0.1]])).double())\n",
    "        self.zz0 = torch.nn.Parameter(torch.log(torch.tensor([[1.]])).double())\n",
    "        self.data = data\n",
    "        \n",
    "    def forward(self, idx):\n",
    "        z = self.data.Z[idx]\n",
    "        pxz_mean = z\n",
    "        pxz_logscale = self.zz0 + z.matmul(self.zz1)\n",
    "        pxz_scale = torch.exp(pxz_logscale)\n",
    "        \n",
    "        return pxz_mean, pxz_scale\n",
    "\n",
    "\n",
    "class LVMS(torch.nn.Module):\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.ivm = IVModelS(data)\n",
    "        self.ndecoder = NDecoderS(data)\n",
    "        self.mdecoder = MDecoderS(data)\n",
    "        self.encoder = EncoderS(data)\n",
    "    \n",
    "    \n",
    "    def loss(self, idx):\n",
    "    ### Free energy = E_q[log(p({m},{n},{x}|{z})) - log(q)] \n",
    "    ###             = E_q[log(p({m},{n},{x}|{z}))] + H_q({m},{n},{z})\n",
    "    ###             = E_q[sum_i{log(p(m_i, n_i, x_i|z_i))}] + H_q({m}, {n}, {z})\n",
    "    ###             = E_q[sum_i{log(p(m_i|x_i))} + sum_i{log(p(n_i|x_i))} + sum_i{log(p(x_i|z_i))}]\n",
    "    ###               + H_q({m},{n},{z})\n",
    "    ###             = sum_i{E_q[log(p(m_i|x_i))]} \n",
    "    ###               + sum_i{E_q[log(p(n_i|x_i))]} \n",
    "    ###               + sum_i{E_q[log(p(x_i|z_i))]} \n",
    "    ###               + H_q({m},{n},{z})\n",
    "    ### ELBO = - sum_i{E_q[log(p(m_i|x_i))]} \n",
    "    ###        - sum_i{E_q[log(p(n_i|x_i))]} \n",
    "    ###        - sum_i{E_q[log(p(x_i|z_i))]} \n",
    "    ###        - H_q({m},{n},{z})\n",
    "    \n",
    "        q_mean, q_scale, H_q = self.encoder(idx)\n",
    "        q_dist = torch.distributions.Normal(q_mean, q_scale)\n",
    "        x_samples_from_q = q_dist.rsample()\n",
    "\n",
    "        pmx_mean, pmx_scale = self.mdecoder(x_samples_from_q)\n",
    "        pmx_dist = torch.distributions.Normal(pmx_mean, pmx_scale)\n",
    "        sum_pmx = torch.sum(pmx_dist.log_prob(data.M[idx]))\n",
    "\n",
    "        pnx_mean, pnx_scale = self.ndecoder(x_samples_from_q)\n",
    "        pnx_dist = torch.distributions.Normal(pnx_mean, pnx_scale)\n",
    "        sum_pnx = torch.sum(pnx_dist.log_prob(data.N[idx]))\n",
    "\n",
    "        pxz_mean, pxz_scale = self.ivm(idx)\n",
    "        pxz_dist = torch.distributions.Normal(pxz_mean, pxz_scale)\n",
    "        sum_pxz = torch.sum(pxz_dist.log_prob(x_samples_from_q))\n",
    "\n",
    "        loss = -sum_pmx - sum_pnx - sum_pxz - H_q\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generalised implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for linear and sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##             U\n",
    "##           /  \\\n",
    "##          /    \\\n",
    "##   Z --> X --> Y\n",
    "##        / \\\n",
    "##       /   \\\n",
    "##      M    N Z --> X\n",
    "\n",
    "## p({x}|{z}) = prod_i (p(x_i|z_i))\n",
    "\n",
    "# likelihood models\n",
    "class Encoder(torch.nn.Module):\n",
    "    # q({x}|{m},{n},{z}) = gaussian(q0 + q1*{m} + q2*{n} + q3*{z}, \n",
    "    #                       exp(qq0 + qq1*{m} + qq2*{n} + qq3*{z})^2)\n",
    "    # H[q] = -E_q[log(q)] = log(prod(sigma)*(2*pi*e)**(B*0.5))\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.q_nonlinear = nn.Sequential(nn.Linear(3,6), nn.ReLU())\n",
    "#         self.q_mean_fc = nn.Linear(3, 1)\n",
    "#         self.q_logscale_fc = nn.Linear(3, 1)\n",
    "        self.q_mean_fc = nn.Linear(6, 1)\n",
    "        self.q_logscale_fc = nn.Linear(6, 1)\n",
    "        self.data = data\n",
    "        \n",
    "    def forward(self, idx):\n",
    "        B = idx.shape[0]\n",
    "        mnz = torch.cat([self.data.M[idx], self.data.N[idx], self.data.Z[idx]], axis=1)\n",
    "        q_feature = self.q_nonlinear(mnz)\n",
    "        q_mean = self.q_mean_fc(q_feature)\n",
    "#         q_mean = self.q_mean_fc(mnz.double())\n",
    "        q_logscale = self.q_logscale_fc(q_feature)\n",
    "#         q_logscale = self.q_logscale_fc(mnz)\n",
    "        q_scale = torch.exp(q_logscale)\n",
    "        \n",
    "        H_q = torch.log(torch.prod(q_scale)*(2*torch.pi*torch.e)**(B*0.5))\n",
    "        \n",
    "        return q_mean, q_scale, H_q\n",
    "        \n",
    "\n",
    "class MDecoder(torch.nn.Module):\n",
    "    # p(m|x) = gaussian(x, exp(mm0 + mm1 * x)^2)\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.m_logscale_fc = nn.Linear(1,1)\n",
    "#         self.mm1 = torch.nn.Parameter(torch.tensor([[0.]]).double())\n",
    "#         self.mm0 = torch.nn.Parameter(torch.log(torch.tensor([[0.4]])).double())\n",
    "        self.data = data\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pmx_mean = x\n",
    "        pmx_logscale = self.m_logscale_fc(x.double())\n",
    "#         pmx_logscale = self.mm0 + x.matmul(self.mm1)\n",
    "        pmx_scale = torch.exp(pmx_logscale)\n",
    "        \n",
    "        return pmx_mean, pmx_scale\n",
    "\n",
    "class NDecoder(torch.nn.Module):\n",
    "    # p(n|x) = gaussian(x, exp(nn0 + nn1 * x)^2)\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.n_logscale_fc = nn.Linear(1,1)\n",
    "#         self.nn1 = torch.nn.Parameter(torch.tensor([[0.]]).double())\n",
    "#         self.nn0 = torch.nn.Parameter(torch.log(torch.tensor([[0.4]])).double())\n",
    "        self.data = data\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pnx_mean = x\n",
    "        pnx_logscale = self.n_logscale_fc(x.double())\n",
    "#         pnx_logscale = self.nn0 + x.matmul(self.nn1)\n",
    "        pnx_scale = torch.exp(pnx_logscale)\n",
    "        \n",
    "        return pnx_mean, pnx_scale\n",
    "\n",
    "class IVModel(torch.nn.Module):\n",
    "    # p(x|z) = gaussian(z, exp(zz0 + zz1 * x)^2)\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.z_feature = nn.Sequential(nn.Linear(1, 4), nn.ReLU())\n",
    "        self.z_mean_fc = nn.Linear(4,1)\n",
    "        self.z_logscale_fc = nn.Linear(4,1)\n",
    "#         self.zz1 = torch.nn.Parameter(torch.tensor([[3.]]).double())\n",
    "#         self.zz0 = torch.nn.Parameter(torch.log(torch.tensor([[1.]])).double())\n",
    "        self.data = data\n",
    "        \n",
    "    def forward(self, idx):\n",
    "        z = self.data.Z[idx]\n",
    "        z_feature = self.z_feature(z)\n",
    "        pxz_mean = self.z_mean_fc(z_feature)\n",
    "        pxz_logscale = self.z_logscale_fc(z_feature)\n",
    "#         pxz_logscale = self.zz0 + z.matmul(self.zz1)\n",
    "        pxz_scale = torch.exp(pxz_logscale)\n",
    "        \n",
    "        return pxz_mean, pxz_scale\n",
    "    \n",
    "class ResponseModel(torch.nn.Module):\n",
    "    # y = f(x) + noise\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.response_net = nn.Sequential(nn.Linear(1, 3), \n",
    "                                          nn.ReLU(), \n",
    "                                          nn.Linear(3, 3),\n",
    "                                          nn.ReLU(),\n",
    "                                          nn.Linear(3, 1))\n",
    "        \n",
    "#         self.response_net = nn.Sequential(nn.Linear(1, 1))\n",
    "    def forward(self, x):\n",
    "        return self.response_net(x)\n",
    "        \n",
    "\n",
    "class LVM(torch.nn.Module):\n",
    "    def __init__(self, data, sample_size_from_pxz):\n",
    "        super().__init__()\n",
    "        self.ivm = IVModel(data)\n",
    "        self.ndecoder = NDecoder(data)\n",
    "        self.mdecoder = MDecoder(data)\n",
    "        self.encoder = Encoder(data)\n",
    "        self.response = ResponseModel()\n",
    "        self.data = data\n",
    "        self.sample_size_from_pxz = sample_size_from_pxz\n",
    "    \n",
    "    \n",
    "    def stage_1_loss(self, idx):\n",
    "    ### Free energy = E_q[log(p({m},{n},{x}|{z})) - log(q)] \n",
    "    ###             = E_q[log(p({m},{n},{x}|{z}))] + H_q({m},{n},{z})\n",
    "    ###             = E_q[sum_i{log(p(m_i, n_i, x_i|z_i))}] + H_q({m}, {n}, {z})\n",
    "    ###             = E_q[sum_i{log(p(m_i|x_i))} + sum_i{log(p(n_i|x_i))} + sum_i{log(p(x_i|z_i))}]\n",
    "    ###               + H_q({m},{n},{z})\n",
    "    ###             = sum_i{E_q[log(p(m_i|x_i))]} \n",
    "    ###               + sum_i{E_q[log(p(n_i|x_i))]} \n",
    "    ###               + sum_i{E_q[log(p(x_i|z_i))]} \n",
    "    ###               + H_q({m},{n},{z})\n",
    "    ### ELBO = - sum_i{E_q[log(p(m_i|x_i))]} \n",
    "    ###        - sum_i{E_q[log(p(n_i|x_i))]} \n",
    "    ###        - sum_i{E_q[log(p(x_i|z_i))]} \n",
    "    ###        - H_q({m},{n},{z})\n",
    "    \n",
    "        q_mean, q_scale, H_q = self.encoder(idx)\n",
    "        q_dist = torch.distributions.Normal(q_mean, q_scale)\n",
    "        x_samples_from_q = q_dist.rsample()\n",
    "\n",
    "        pmx_mean, pmx_scale = self.mdecoder(x_samples_from_q)\n",
    "        pmx_dist = torch.distributions.Normal(pmx_mean, pmx_scale)\n",
    "        sum_pmx = torch.sum(pmx_dist.log_prob(data.M[idx]))\n",
    "\n",
    "        pnx_mean, pnx_scale = self.ndecoder(x_samples_from_q)\n",
    "        pnx_dist = torch.distributions.Normal(pnx_mean, pnx_scale)\n",
    "        sum_pnx = torch.sum(pnx_dist.log_prob(data.N[idx]))\n",
    "\n",
    "        pxz_mean, pxz_scale = self.ivm(idx)\n",
    "        pxz_dist = torch.distributions.Normal(pxz_mean, pxz_scale)\n",
    "        sum_pxz = torch.sum(pxz_dist.log_prob(x_samples_from_q))\n",
    "\n",
    "        loss = -sum_pmx - sum_pnx - sum_pxz - H_q\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def stage_2_loss(self, idx):\n",
    "        # {Z, Y}\n",
    "        # E[Y|Z] = E[f(X)|Z] vs E[Y|X] = f(X)\n",
    "        # \n",
    "        with torch.no_grad():\n",
    "            pxz_mean, pxz_scale = self.ivm(idx)\n",
    "            pxz_dist = torch.distributions.Normal(pxz_mean, pxz_scale)\n",
    "#             breakpoint()\n",
    "            x_samples_from_z = pxz_dist.rsample(sample_shape=(self.sample_size_from_pxz,))\n",
    "#             x_samples_from_z = pxz_dist.rsample()\n",
    "            dim_x = x_samples_from_z.shape[-1]\n",
    "#             breakpoint()\n",
    "            \n",
    "        \n",
    "        preds = torch.mean(self.response(x_samples_from_z.reshape(-1,dim_x)).reshape(self.sample_size_from_pxz, -1), axis=0).reshape(-1,1)\n",
    "#         breakpoint()\n",
    "#         preds = self.response(x_samples_from_z)\n",
    "        stage_2_loss = torch.mean((self.data.Y[idx] - preds)**2)\n",
    "#         breakpoint()\n",
    "        \n",
    "        return stage_2_loss\n",
    "    \n",
    "    \n",
    "                 \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9766],\n",
      "         [3.0453],\n",
      "         [9.0313]],\n",
      "\n",
      "        [[1.0518],\n",
      "         [3.1712],\n",
      "         [9.0542]],\n",
      "\n",
      "        [[0.8681],\n",
      "         [2.8237],\n",
      "         [9.0467]]])\n"
     ]
    }
   ],
   "source": [
    "_dist = torch.distributions.Normal(torch.tensor([[1.], [3.], [9.]]), torch.tensor([[0.1], [0.1], [0.1]]))\n",
    "\n",
    "\n",
    "samples = _dist.rsample(sample_shape=(3,))\n",
    "print(samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### for demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# likelihood models\n",
    "# \n",
    "# X - {P, T, S}\n",
    "# Z - {E, T, S}\n",
    "# Y \n",
    "# M\n",
    "# N\n",
    "\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    # q({x}|{m},{n},{z}) = gaussian(q0 + q1*{m} + q2*{n} + q3*{z}, \n",
    "    #                       exp(qq0 + qq1*{m} + qq2*{n} + qq3*{z})^2)\n",
    "    # H[q] = -E_q[log(q)] = log(prod(sigma)*(2*pi*e)**(B*0.5))\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.q_nonlinear = nn.Sequential(nn.Linear(5,10), nn.ReLU())\n",
    "#         self.q_mean_fc = nn.Linear(3, 1)\n",
    "#         self.q_logscale_fc = nn.Linear(3, 1)\n",
    "        self.q_mean_fc = nn.Linear(10, 1)\n",
    "        self.q_logscale_fc = nn.Linear(10, 1)\n",
    "        self.data = data\n",
    "        \n",
    "    def forward(self, idx):\n",
    "        B = idx.shape[0]\n",
    "        mnz = torch.cat([self.data.M[idx], self.data.N[idx], self.data.Z[idx]], axis=1)\n",
    "        q_feature = self.q_nonlinear(mnz.double())\n",
    "        q_mean = self.q_mean_fc(q_feature)\n",
    "#         q_mean = self.q_mean_fc(mnz.double())\n",
    "        q_logscale = self.q_logscale_fc(q_feature)\n",
    "#         q_logscale = self.q_logscale_fc(mnz)\n",
    "        q_scale = torch.exp(q_logscale)\n",
    "        \n",
    "        H_q = torch.log(torch.prod(q_scale)*(2*torch.pi*torch.e)**(B*0.5))\n",
    "        \n",
    "        return q_mean, q_scale, H_q\n",
    "        \n",
    "\n",
    "class MDecoder(torch.nn.Module):\n",
    "    # p(m|x) = gaussian(x, exp(mm0 + mm1 * x)^2)\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.m_logscale_fc = nn.Linear(1,1)\n",
    "#         self.mm1 = torch.nn.Parameter(torch.tensor([[0.]]).double())\n",
    "#         self.mm0 = torch.nn.Parameter(torch.log(torch.tensor([[0.4]])).double())\n",
    "        self.data = data\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pmx_mean = x\n",
    "        pmx_logscale = self.m_logscale_fc(x.double())\n",
    "#         pmx_logscale = self.mm0 + x.matmul(self.mm1)\n",
    "        pmx_scale = torch.exp(pmx_logscale)\n",
    "        \n",
    "        return pmx_mean, pmx_scale\n",
    "\n",
    "class NDecoder(torch.nn.Module):\n",
    "    # p(n|x) = gaussian(x, exp(nn0 + nn1 * x)^2)\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.n_logscale_fc = nn.Linear(1,1)\n",
    "#         self.nn1 = torch.nn.Parameter(torch.tensor([[0.]]).double())\n",
    "#         self.nn0 = torch.nn.Parameter(torch.log(torch.tensor([[0.4]])).double())\n",
    "        self.data = data\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pnx_mean = x\n",
    "        pnx_logscale = self.n_logscale_fc(x.double())\n",
    "#         pnx_logscale = self.nn0 + x.matmul(self.nn1)\n",
    "        pnx_scale = torch.exp(pnx_logscale)\n",
    "        \n",
    "        return pnx_mean, pnx_scale\n",
    "\n",
    "class IVModel(torch.nn.Module):\n",
    "    # p(x|z) = gaussian(z, exp(zz0 + zz1 * x)^2)\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.z_feature = nn.Sequential(nn.Linear(3, 6), nn.ReLU(), nn.Linear(6,6), nn.ReLU())\n",
    "        self.z_mean_fc = nn.Linear(6,1)\n",
    "        self.z_logscale_fc = nn.Linear(6,1)\n",
    "#         self.zz1 = torch.nn.Parameter(torch.tensor([[3.]]).double())\n",
    "#         self.zz0 = torch.nn.Parameter(torch.log(torch.tensor([[1.]])).double())\n",
    "        self.data = data\n",
    "        \n",
    "    def forward(self, idx):\n",
    "        z = self.data.Z[idx]\n",
    "        z_feature = self.z_feature(z.double())\n",
    "        pxz_mean = self.z_mean_fc(z_feature)\n",
    "        pxz_logscale = self.z_logscale_fc(z_feature)\n",
    "#         pxz_logscale = self.zz0 + z.matmul(self.zz1)\n",
    "        pxz_scale = torch.exp(pxz_logscale)\n",
    "        \n",
    "        return pxz_mean, pxz_scale\n",
    "    \n",
    "class ResponseModel(torch.nn.Module):\n",
    "    # y = f(x) + noise\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.response_net = nn.Sequential(nn.Linear(3, 3), \n",
    "                                          nn.ReLU(), \n",
    "                                          nn.Linear(3, 3),\n",
    "                                          nn.ReLU(),\n",
    "                                          nn.Linear(3, 3),\n",
    "                                          nn.ReLU(),\n",
    "                                          nn.Linear(3, 1))\n",
    "        \n",
    "#         self.response_net = nn.Sequential(nn.Linear(1, 1))\n",
    "    def forward(self, x):\n",
    "        return self.response_net(x)\n",
    "        \n",
    "\n",
    "class LVM(torch.nn.Module):\n",
    "    def __init__(self, data, sample_size_from_pxz):\n",
    "        super().__init__()\n",
    "        self.ivm = IVModel(data)\n",
    "        self.ndecoder = NDecoder(data)\n",
    "        self.mdecoder = MDecoder(data)\n",
    "        self.encoder = Encoder(data)\n",
    "        self.response = ResponseModel()\n",
    "        self.data = data\n",
    "        self.sample_size_from_pxz = sample_size_from_pxz\n",
    "    \n",
    "    \n",
    "    def stage_1_loss(self, idx):\n",
    "    ### Free energy = E_q[log(p({m},{n},{x}|{z})) - log(q)] \n",
    "    ###             = E_q[log(p({m},{n},{x}|{z}))] + H_q({m},{n},{z})\n",
    "    ###             = E_q[sum_i{log(p(m_i, n_i, x_i|z_i))}] + H_q({m}, {n}, {z})\n",
    "    ###             = E_q[sum_i{log(p(m_i|x_i))} + sum_i{log(p(n_i|x_i))} + sum_i{log(p(x_i|z_i))}]\n",
    "    ###               + H_q({m},{n},{z})\n",
    "    ###             = sum_i{E_q[log(p(m_i|x_i))]} \n",
    "    ###               + sum_i{E_q[log(p(n_i|x_i))]} \n",
    "    ###               + sum_i{E_q[log(p(x_i|z_i))]} \n",
    "    ###               + H_q({m},{n},{z})\n",
    "    ### ELBO = - sum_i{E_q[log(p(m_i|x_i))]} \n",
    "    ###        - sum_i{E_q[log(p(n_i|x_i))]} \n",
    "    ###        - sum_i{E_q[log(p(x_i|z_i))]} \n",
    "    ###        - H_q({m},{n},{z})\n",
    "    \n",
    "        q_mean, q_scale, H_q = self.encoder(idx)\n",
    "        q_dist = torch.distributions.Normal(q_mean, q_scale)\n",
    "        x_samples_from_q = q_dist.rsample()\n",
    "\n",
    "        pmx_mean, pmx_scale = self.mdecoder(x_samples_from_q)\n",
    "        pmx_dist = torch.distributions.Normal(pmx_mean, pmx_scale)\n",
    "        sum_pmx = torch.sum(pmx_dist.log_prob(data.M[idx]))\n",
    "\n",
    "        pnx_mean, pnx_scale = self.ndecoder(x_samples_from_q)\n",
    "        pnx_dist = torch.distributions.Normal(pnx_mean, pnx_scale)\n",
    "        sum_pnx = torch.sum(pnx_dist.log_prob(data.N[idx]))\n",
    "\n",
    "        pxz_mean, pxz_scale = self.ivm(idx)\n",
    "        pxz_dist = torch.distributions.Normal(pxz_mean, pxz_scale)\n",
    "        sum_pxz = torch.sum(pxz_dist.log_prob(x_samples_from_q))\n",
    "\n",
    "        loss = -sum_pmx - sum_pnx - sum_pxz - H_q\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def stage_2_loss(self, idx):\n",
    "        # {Z, Y}\n",
    "        # E[Y|Z] = E[f(X)|Z] vs E[Y|X] = f(X)\n",
    "        # \n",
    "        with torch.no_grad():\n",
    "            pxz_mean, pxz_scale = self.ivm(idx)\n",
    "            pxz_dist = torch.distributions.Normal(pxz_mean, pxz_scale)\n",
    "#             breakpoint()\n",
    "            x_samples_from_z = pxz_dist.rsample(sample_shape=(self.sample_size_from_pxz,))\n",
    "#             x_samples_from_z = pxz_dist.rsample()\n",
    "            dim_x = x_samples_from_z.shape[-1]\n",
    "#             breakpoint()\n",
    "            \n",
    "        response_inp = torch.cat([x_samples_from_z.reshape(-1, dim_x), self.data.covariate[idx].repeat((self.sample_size_from_pxz, 1)).reshape(-1, self.data.covariate.shape[-1])], axis=-1)\n",
    "        preds = torch.mean(self.response(response_inp).reshape(self.sample_size_from_pxz, -1), axis=0).reshape(-1,1)\n",
    "#         preds = torch.mean(self.response(x_samples_from_z.reshape(-1,dim_x)).reshape(self.sample_size_from_pxz, -1), axis=0).reshape(-1,1)\n",
    "#         breakpoint()\n",
    "#         preds = self.response(x_samples_from_z)\n",
    "        stage_2_loss = torch.mean((self.data.Y[idx] - preds)**2)\n",
    "#         breakpoint()\n",
    "        \n",
    "        return stage_2_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1],\n",
       "        [2, 2],\n",
       "        [1, 1],\n",
       "        [2, 2],\n",
       "        [1, 1],\n",
       "        [2, 2]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = torch.tensor([[1,1], [2,2]])\n",
    "ts.repeat((3, 1)).reshape(-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0216],\n",
       "        [-0.9607],\n",
       "        [ 1.0900],\n",
       "        [-0.8440],\n",
       "        [ 1.1285],\n",
       "        [-0.9692]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pxz_dist = torch.distributions.Normal(torch.tensor([[1.], [-1.]]), torch.tensor([[0.1], [0.1]]))\n",
    "\n",
    "pxz_dist.rsample(sample_shape=(3,)).reshape(-1,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_batches(train_size, batch_size):\n",
    "    batches_idxes = []\n",
    "    idxes = np.arange(train_size)\n",
    "    np.random.shuffle(idxes)\n",
    "    batch_i = 0\n",
    "    while True:\n",
    "        batches_idxes.append(torch.tensor(idxes[batch_i * batch_size: (batch_i + 1) * batch_size]))\n",
    "        batch_i += 1\n",
    "        if batch_i * batch_size >= train_size:\n",
    "            break\n",
    "    return batches_idxes\n",
    "\n",
    "def train1(lvm, data, batch_size):\n",
    "    lvm.train()\n",
    "    lvm.double()\n",
    "    optimizer = optim.Adam(lvm.parameters(), lr=1e-3)\n",
    "    losses = []\n",
    "    step = 0\n",
    "    for ep in range(500):\n",
    "        running_loss = 0.0\n",
    "        batches_idx = split_into_batches(train_size=data.Z.shape[0], batch_size=batch_size)\n",
    "        for i, batch_idx in enumerate(batches_idx):\n",
    "            loss = lvm.stage_1_loss(batch_idx)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            if i % 1 == 0:\n",
    "                print('[epoch %d, batch %5d] loss: %.5f' % (\n",
    "                ep + 1, i + 1, running_loss / 1))\n",
    "                # breakpoint()\n",
    "                running_loss = 0.0\n",
    "                \n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            step += 1\n",
    "            \n",
    "    return lvm\n",
    "\n",
    "def train2(lvm, data, batch_size):\n",
    "    lvm.eval()\n",
    "    lvm.response.train()\n",
    "    lvm.double()\n",
    "    optimizer = optim.Adam(lvm.response.parameters(), lr=1e-3)\n",
    "    losses = []\n",
    "    step = 0\n",
    "    for ep in range(500):\n",
    "        running_loss = 0.0\n",
    "        batches_idx = split_into_batches(train_size=data.Z.shape[0], batch_size=batch_size)\n",
    "        for i, batch_idx in enumerate(batches_idx):\n",
    "            loss = lvm.stage_2_loss(batch_idx)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            if i % 1 == 0:\n",
    "                print('[epoch %d, batch %5d] loss: %.5f' % (\n",
    "                ep + 1, i + 1, running_loss / 1))\n",
    "                running_loss = 0.0\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            step += 1\n",
    "    return lvm\n",
    "                \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response_net_param:  Parameter containing:\n",
      "tensor([[ 0.4792],\n",
      "        [-0.3045],\n",
      "        [ 0.6838]], requires_grad=True)\n",
      "iv model param:  Parameter containing:\n",
      "tensor([[ 0.2548, -0.4975,  0.3106,  0.0813]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "sample_size_from_pxz = 100\n",
    "# data = generate_train_demand_design(data_size=2000,\n",
    "#                                     rho=0.5,\n",
    "#                                     merror_func_str='gaussian',\n",
    "#                                     m_scale=0.5,\n",
    "#                                     n_scale=0.5,\n",
    "#                                     bias=0.,\n",
    "#                                     rand_seed=43)\n",
    "# data = generate_train_sigmoid_cp_design(data_size=5000,\n",
    "#                                     merror_func_str='multi_gaussian',\n",
    "#                                     m_scale=2.,\n",
    "#                                     n_scale=2.,\n",
    "#                                     bias=0.,\n",
    "#                                     rand_seed=42)\n",
    "data = generate_train_linear_cp_design(data_size=2000,\n",
    "                                    merror_func_str='multi_gaussian',\n",
    "                                    m_scale=0.5,\n",
    "                                    n_scale=0.5,\n",
    "                                    bias=0.,\n",
    "                                    rand_seed=42)\n",
    "lvm = LVM(data, sample_size_from_pxz=sample_size_from_pxz)\n",
    "print('response_net_param: ', lvm.response.response_net[0].weight)\n",
    "print('iv model param: ', lvm.ivm.z_logscale_fc.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch     1] loss: 328.98280\n",
      "[epoch 1, batch     2] loss: 451.67255\n",
      "[epoch 1, batch     3] loss: 295.14862\n",
      "[epoch 1, batch     4] loss: 335.85696\n",
      "[epoch 1, batch     5] loss: 464.33262\n",
      "[epoch 1, batch     6] loss: 322.45301\n",
      "[epoch 1, batch     7] loss: 385.45179\n",
      "[epoch 1, batch     8] loss: 463.23160\n",
      "[epoch 1, batch     9] loss: 381.62150\n",
      "[epoch 1, batch    10] loss: 381.98455\n",
      "[epoch 1, batch    11] loss: 376.76001\n",
      "[epoch 1, batch    12] loss: 329.83562\n",
      "[epoch 1, batch    13] loss: 344.87010\n",
      "[epoch 1, batch    14] loss: 368.55592\n",
      "[epoch 1, batch    15] loss: 305.64975\n",
      "[epoch 1, batch    16] loss: 287.59984\n",
      "[epoch 1, batch    17] loss: 339.71026\n",
      "[epoch 1, batch    18] loss: 313.53086\n",
      "[epoch 1, batch    19] loss: 320.76592\n",
      "[epoch 1, batch    20] loss: 330.14734\n",
      "[epoch 1, batch    21] loss: 291.63823\n",
      "[epoch 1, batch    22] loss: 473.70319\n",
      "[epoch 1, batch    23] loss: 370.20755\n",
      "[epoch 1, batch    24] loss: 450.41538\n",
      "[epoch 1, batch    25] loss: 312.43690\n",
      "[epoch 1, batch    26] loss: 305.70923\n",
      "[epoch 1, batch    27] loss: 285.95720\n",
      "[epoch 1, batch    28] loss: 363.45824\n",
      "[epoch 1, batch    29] loss: 327.80428\n",
      "[epoch 1, batch    30] loss: 282.31711\n",
      "[epoch 1, batch    31] loss: 251.33230\n",
      "[epoch 1, batch    32] loss: 79.31698\n",
      "[epoch 2, batch     1] loss: 322.31494\n",
      "[epoch 2, batch     2] loss: 330.03355\n",
      "[epoch 2, batch     3] loss: 279.56645\n",
      "[epoch 2, batch     4] loss: 254.42965\n",
      "[epoch 2, batch     5] loss: 351.18248\n",
      "[epoch 2, batch     6] loss: 278.62227\n",
      "[epoch 2, batch     7] loss: 397.64144\n",
      "[epoch 2, batch     8] loss: 348.21116\n",
      "[epoch 2, batch     9] loss: 276.73711\n",
      "[epoch 2, batch    10] loss: 367.54607\n",
      "[epoch 2, batch    11] loss: 284.83435\n",
      "[epoch 2, batch    12] loss: 305.82469\n",
      "[epoch 2, batch    13] loss: 301.30080\n",
      "[epoch 2, batch    14] loss: 273.03984\n",
      "[epoch 2, batch    15] loss: 286.63473\n",
      "[epoch 2, batch    16] loss: 352.46741\n",
      "[epoch 2, batch    17] loss: 303.22041\n",
      "[epoch 2, batch    18] loss: 298.98992\n",
      "[epoch 2, batch    19] loss: 267.91066\n",
      "[epoch 2, batch    20] loss: 301.31538\n",
      "[epoch 2, batch    21] loss: 277.19534\n",
      "[epoch 2, batch    22] loss: 260.44320\n",
      "[epoch 2, batch    23] loss: 260.53321\n",
      "[epoch 2, batch    24] loss: 340.66385\n",
      "[epoch 2, batch    25] loss: 307.73464\n",
      "[epoch 2, batch    26] loss: 295.21196\n",
      "[epoch 2, batch    27] loss: 245.49306\n",
      "[epoch 2, batch    28] loss: 299.06073\n",
      "[epoch 2, batch    29] loss: 265.77146\n",
      "[epoch 2, batch    30] loss: 304.34236\n",
      "[epoch 2, batch    31] loss: 290.67400\n",
      "[epoch 2, batch    32] loss: 70.89371\n",
      "[epoch 3, batch     1] loss: 270.63949\n",
      "[epoch 3, batch     2] loss: 269.40355\n",
      "[epoch 3, batch     3] loss: 252.73668\n",
      "[epoch 3, batch     4] loss: 274.85705\n",
      "[epoch 3, batch     5] loss: 278.68587\n",
      "[epoch 3, batch     6] loss: 333.39455\n",
      "[epoch 3, batch     7] loss: 268.38817\n",
      "[epoch 3, batch     8] loss: 261.22824\n",
      "[epoch 3, batch     9] loss: 291.89718\n",
      "[epoch 3, batch    10] loss: 329.33173\n",
      "[epoch 3, batch    11] loss: 240.73352\n",
      "[epoch 3, batch    12] loss: 251.08483\n",
      "[epoch 3, batch    13] loss: 270.88734\n",
      "[epoch 3, batch    14] loss: 257.49057\n",
      "[epoch 3, batch    15] loss: 229.44170\n",
      "[epoch 3, batch    16] loss: 258.88673\n",
      "[epoch 3, batch    17] loss: 269.89945\n",
      "[epoch 3, batch    18] loss: 254.35522\n",
      "[epoch 3, batch    19] loss: 247.88020\n",
      "[epoch 3, batch    20] loss: 260.00402\n",
      "[epoch 3, batch    21] loss: 306.67042\n",
      "[epoch 3, batch    22] loss: 239.57141\n",
      "[epoch 3, batch    23] loss: 251.99843\n",
      "[epoch 3, batch    24] loss: 307.72329\n",
      "[epoch 3, batch    25] loss: 228.97396\n",
      "[epoch 3, batch    26] loss: 250.95076\n",
      "[epoch 3, batch    27] loss: 237.37113\n",
      "[epoch 3, batch    28] loss: 243.51778\n",
      "[epoch 3, batch    29] loss: 261.09624\n",
      "[epoch 3, batch    30] loss: 259.33946\n",
      "[epoch 3, batch    31] loss: 215.73687\n",
      "[epoch 3, batch    32] loss: 71.80020\n",
      "[epoch 4, batch     1] loss: 233.05249\n",
      "[epoch 4, batch     2] loss: 247.94284\n",
      "[epoch 4, batch     3] loss: 236.10111\n",
      "[epoch 4, batch     4] loss: 279.94246\n",
      "[epoch 4, batch     5] loss: 234.91306\n",
      "[epoch 4, batch     6] loss: 208.13236\n",
      "[epoch 4, batch     7] loss: 240.58123\n",
      "[epoch 4, batch     8] loss: 253.16915\n",
      "[epoch 4, batch     9] loss: 256.46523\n",
      "[epoch 4, batch    10] loss: 212.72292\n",
      "[epoch 4, batch    11] loss: 240.19581\n",
      "[epoch 4, batch    12] loss: 265.26247\n",
      "[epoch 4, batch    13] loss: 247.54431\n",
      "[epoch 4, batch    14] loss: 218.65247\n",
      "[epoch 4, batch    15] loss: 242.52392\n",
      "[epoch 4, batch    16] loss: 228.16977\n",
      "[epoch 4, batch    17] loss: 259.93768\n",
      "[epoch 4, batch    18] loss: 199.21206\n",
      "[epoch 4, batch    19] loss: 234.11486\n",
      "[epoch 4, batch    20] loss: 199.95953\n",
      "[epoch 4, batch    21] loss: 221.39938\n",
      "[epoch 4, batch    22] loss: 234.20459\n",
      "[epoch 4, batch    23] loss: 206.67149\n",
      "[epoch 4, batch    24] loss: 205.30243\n",
      "[epoch 4, batch    25] loss: 250.47690\n",
      "[epoch 4, batch    26] loss: 221.01446\n",
      "[epoch 4, batch    27] loss: 191.91780\n",
      "[epoch 4, batch    28] loss: 242.14088\n",
      "[epoch 4, batch    29] loss: 199.30712\n",
      "[epoch 4, batch    30] loss: 221.38757\n",
      "[epoch 4, batch    31] loss: 238.27617\n",
      "[epoch 4, batch    32] loss: 41.33885\n",
      "[epoch 5, batch     1] loss: 198.89567\n",
      "[epoch 5, batch     2] loss: 217.74326\n",
      "[epoch 5, batch     3] loss: 215.97134\n",
      "[epoch 5, batch     4] loss: 256.81480\n",
      "[epoch 5, batch     5] loss: 238.48827\n",
      "[epoch 5, batch     6] loss: 193.10686\n",
      "[epoch 5, batch     7] loss: 232.73741\n",
      "[epoch 5, batch     8] loss: 294.05444\n",
      "[epoch 5, batch     9] loss: 210.02009\n",
      "[epoch 5, batch    10] loss: 207.52311\n",
      "[epoch 5, batch    11] loss: 235.32487\n",
      "[epoch 5, batch    12] loss: 296.49991\n",
      "[epoch 5, batch    13] loss: 182.03710\n",
      "[epoch 5, batch    14] loss: 217.67835\n",
      "[epoch 5, batch    15] loss: 196.39553\n",
      "[epoch 5, batch    16] loss: 184.42893\n",
      "[epoch 5, batch    17] loss: 182.74326\n",
      "[epoch 5, batch    18] loss: 220.36313\n",
      "[epoch 5, batch    19] loss: 218.31221\n",
      "[epoch 5, batch    20] loss: 224.99523\n",
      "[epoch 5, batch    21] loss: 267.61895\n",
      "[epoch 5, batch    22] loss: 209.90440\n",
      "[epoch 5, batch    23] loss: 198.76611\n",
      "[epoch 5, batch    24] loss: 195.87956\n",
      "[epoch 5, batch    25] loss: 248.24090\n",
      "[epoch 5, batch    26] loss: 227.27492\n",
      "[epoch 5, batch    27] loss: 207.24918\n",
      "[epoch 5, batch    28] loss: 209.05435\n",
      "[epoch 5, batch    29] loss: 199.42398\n",
      "[epoch 5, batch    30] loss: 229.07053\n",
      "[epoch 5, batch    31] loss: 185.05384\n",
      "[epoch 5, batch    32] loss: 50.49649\n",
      "[epoch 6, batch     1] loss: 198.19361\n",
      "[epoch 6, batch     2] loss: 208.35153\n",
      "[epoch 6, batch     3] loss: 203.60305\n",
      "[epoch 6, batch     4] loss: 199.72312\n",
      "[epoch 6, batch     5] loss: 189.94742\n",
      "[epoch 6, batch     6] loss: 200.53671\n",
      "[epoch 6, batch     7] loss: 211.49394\n",
      "[epoch 6, batch     8] loss: 165.16075\n",
      "[epoch 6, batch     9] loss: 208.06208\n",
      "[epoch 6, batch    10] loss: 187.84175\n",
      "[epoch 6, batch    11] loss: 197.74424\n",
      "[epoch 6, batch    12] loss: 190.18195\n",
      "[epoch 6, batch    13] loss: 205.15950\n",
      "[epoch 6, batch    14] loss: 194.00186\n",
      "[epoch 6, batch    15] loss: 168.45976\n",
      "[epoch 6, batch    16] loss: 245.97435\n",
      "[epoch 6, batch    17] loss: 216.66469\n",
      "[epoch 6, batch    18] loss: 191.70105\n",
      "[epoch 6, batch    19] loss: 171.48762\n",
      "[epoch 6, batch    20] loss: 205.04245\n",
      "[epoch 6, batch    21] loss: 201.66573\n",
      "[epoch 6, batch    22] loss: 219.47664\n",
      "[epoch 6, batch    23] loss: 197.53251\n",
      "[epoch 6, batch    24] loss: 169.92491\n",
      "[epoch 6, batch    25] loss: 190.44216\n",
      "[epoch 6, batch    26] loss: 189.25449\n",
      "[epoch 6, batch    27] loss: 205.85425\n",
      "[epoch 6, batch    28] loss: 185.22376\n",
      "[epoch 6, batch    29] loss: 187.51844\n",
      "[epoch 6, batch    30] loss: 179.87076\n",
      "[epoch 6, batch    31] loss: 191.24526\n",
      "[epoch 6, batch    32] loss: 47.16832\n",
      "[epoch 7, batch     1] loss: 175.43222\n",
      "[epoch 7, batch     2] loss: 186.76596\n",
      "[epoch 7, batch     3] loss: 197.28382\n",
      "[epoch 7, batch     4] loss: 208.35799\n",
      "[epoch 7, batch     5] loss: 190.28090\n",
      "[epoch 7, batch     6] loss: 196.78349\n",
      "[epoch 7, batch     7] loss: 171.81412\n",
      "[epoch 7, batch     8] loss: 169.66158\n",
      "[epoch 7, batch     9] loss: 185.83327\n",
      "[epoch 7, batch    10] loss: 197.69420\n",
      "[epoch 7, batch    11] loss: 217.69657\n",
      "[epoch 7, batch    12] loss: 161.77159\n",
      "[epoch 7, batch    13] loss: 220.12888\n",
      "[epoch 7, batch    14] loss: 166.81184\n",
      "[epoch 7, batch    15] loss: 215.61544\n",
      "[epoch 7, batch    16] loss: 182.79046\n",
      "[epoch 7, batch    17] loss: 233.18776\n",
      "[epoch 7, batch    18] loss: 222.64851\n",
      "[epoch 7, batch    19] loss: 191.67510\n",
      "[epoch 7, batch    20] loss: 193.42417\n",
      "[epoch 7, batch    21] loss: 182.31514\n",
      "[epoch 7, batch    22] loss: 194.17516\n",
      "[epoch 7, batch    23] loss: 217.37521\n",
      "[epoch 7, batch    24] loss: 193.26258\n",
      "[epoch 7, batch    25] loss: 179.63716\n",
      "[epoch 7, batch    26] loss: 185.40259\n",
      "[epoch 7, batch    27] loss: 191.21967\n",
      "[epoch 7, batch    28] loss: 160.98402\n",
      "[epoch 7, batch    29] loss: 192.55975\n",
      "[epoch 7, batch    30] loss: 196.65664\n",
      "[epoch 7, batch    31] loss: 204.03271\n",
      "[epoch 7, batch    32] loss: 47.26297\n",
      "[epoch 8, batch     1] loss: 180.74559\n",
      "[epoch 8, batch     2] loss: 183.12132\n",
      "[epoch 8, batch     3] loss: 185.05224\n",
      "[epoch 8, batch     4] loss: 167.31426\n",
      "[epoch 8, batch     5] loss: 178.66892\n",
      "[epoch 8, batch     6] loss: 190.24998\n",
      "[epoch 8, batch     7] loss: 200.55947\n",
      "[epoch 8, batch     8] loss: 191.81314\n",
      "[epoch 8, batch     9] loss: 186.01251\n",
      "[epoch 8, batch    10] loss: 173.79070\n",
      "[epoch 8, batch    11] loss: 181.44111\n",
      "[epoch 8, batch    12] loss: 166.88325\n",
      "[epoch 8, batch    13] loss: 186.53011\n",
      "[epoch 8, batch    14] loss: 219.41287\n",
      "[epoch 8, batch    15] loss: 180.18636\n",
      "[epoch 8, batch    16] loss: 181.45348\n",
      "[epoch 8, batch    17] loss: 186.54357\n",
      "[epoch 8, batch    18] loss: 194.08167\n",
      "[epoch 8, batch    19] loss: 156.69964\n",
      "[epoch 8, batch    20] loss: 197.90709\n",
      "[epoch 8, batch    21] loss: 181.90715\n",
      "[epoch 8, batch    22] loss: 236.70752\n",
      "[epoch 8, batch    23] loss: 215.75737\n",
      "[epoch 8, batch    24] loss: 200.84657\n",
      "[epoch 8, batch    25] loss: 178.70658\n",
      "[epoch 8, batch    26] loss: 188.10214\n",
      "[epoch 8, batch    27] loss: 186.94915\n",
      "[epoch 8, batch    28] loss: 171.31050\n",
      "[epoch 8, batch    29] loss: 212.18333\n",
      "[epoch 8, batch    30] loss: 190.22185\n",
      "[epoch 8, batch    31] loss: 187.74179\n",
      "[epoch 8, batch    32] loss: 42.96296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 9, batch     1] loss: 179.31062\n",
      "[epoch 9, batch     2] loss: 169.39988\n",
      "[epoch 9, batch     3] loss: 179.96758\n",
      "[epoch 9, batch     4] loss: 181.41918\n",
      "[epoch 9, batch     5] loss: 178.95029\n",
      "[epoch 9, batch     6] loss: 170.97267\n",
      "[epoch 9, batch     7] loss: 197.09220\n",
      "[epoch 9, batch     8] loss: 194.42088\n",
      "[epoch 9, batch     9] loss: 182.02467\n",
      "[epoch 9, batch    10] loss: 168.40394\n",
      "[epoch 9, batch    11] loss: 163.00574\n",
      "[epoch 9, batch    12] loss: 179.94803\n",
      "[epoch 9, batch    13] loss: 167.21373\n",
      "[epoch 9, batch    14] loss: 177.93657\n",
      "[epoch 9, batch    15] loss: 203.78248\n",
      "[epoch 9, batch    16] loss: 222.23206\n",
      "[epoch 9, batch    17] loss: 186.95493\n",
      "[epoch 9, batch    18] loss: 175.03579\n",
      "[epoch 9, batch    19] loss: 150.39819\n",
      "[epoch 9, batch    20] loss: 187.35696\n",
      "[epoch 9, batch    21] loss: 152.15805\n",
      "[epoch 9, batch    22] loss: 171.90439\n",
      "[epoch 9, batch    23] loss: 175.95027\n",
      "[epoch 9, batch    24] loss: 174.47231\n",
      "[epoch 9, batch    25] loss: 179.44826\n",
      "[epoch 9, batch    26] loss: 177.70292\n",
      "[epoch 9, batch    27] loss: 190.56593\n",
      "[epoch 9, batch    28] loss: 168.93740\n",
      "[epoch 9, batch    29] loss: 179.69829\n",
      "[epoch 9, batch    30] loss: 172.78665\n",
      "[epoch 9, batch    31] loss: 169.65829\n",
      "[epoch 9, batch    32] loss: 59.65843\n",
      "[epoch 10, batch     1] loss: 173.71171\n",
      "[epoch 10, batch     2] loss: 175.11924\n",
      "[epoch 10, batch     3] loss: 173.21537\n",
      "[epoch 10, batch     4] loss: 193.37944\n",
      "[epoch 10, batch     5] loss: 160.45544\n",
      "[epoch 10, batch     6] loss: 174.03543\n",
      "[epoch 10, batch     7] loss: 186.83383\n",
      "[epoch 10, batch     8] loss: 172.34279\n",
      "[epoch 10, batch     9] loss: 175.82349\n",
      "[epoch 10, batch    10] loss: 176.90700\n",
      "[epoch 10, batch    11] loss: 201.45275\n",
      "[epoch 10, batch    12] loss: 174.79530\n",
      "[epoch 10, batch    13] loss: 178.78328\n",
      "[epoch 10, batch    14] loss: 176.96963\n",
      "[epoch 10, batch    15] loss: 184.28995\n",
      "[epoch 10, batch    16] loss: 166.75766\n",
      "[epoch 10, batch    17] loss: 179.14848\n",
      "[epoch 10, batch    18] loss: 191.85919\n",
      "[epoch 10, batch    19] loss: 177.69320\n",
      "[epoch 10, batch    20] loss: 184.87419\n",
      "[epoch 10, batch    21] loss: 160.35119\n",
      "[epoch 10, batch    22] loss: 177.08018\n",
      "[epoch 10, batch    23] loss: 162.42688\n",
      "[epoch 10, batch    24] loss: 192.46154\n",
      "[epoch 10, batch    25] loss: 186.35431\n",
      "[epoch 10, batch    26] loss: 165.14890\n",
      "[epoch 10, batch    27] loss: 164.96792\n",
      "[epoch 10, batch    28] loss: 171.13470\n",
      "[epoch 10, batch    29] loss: 195.97467\n",
      "[epoch 10, batch    30] loss: 193.29653\n",
      "[epoch 10, batch    31] loss: 191.32668\n",
      "[epoch 10, batch    32] loss: 36.53221\n",
      "[epoch 11, batch     1] loss: 160.44434\n",
      "[epoch 11, batch     2] loss: 187.39047\n",
      "[epoch 11, batch     3] loss: 177.52115\n",
      "[epoch 11, batch     4] loss: 185.69376\n",
      "[epoch 11, batch     5] loss: 161.61480\n",
      "[epoch 11, batch     6] loss: 165.52857\n",
      "[epoch 11, batch     7] loss: 163.96474\n",
      "[epoch 11, batch     8] loss: 184.09182\n",
      "[epoch 11, batch     9] loss: 204.46639\n",
      "[epoch 11, batch    10] loss: 166.58452\n",
      "[epoch 11, batch    11] loss: 160.12697\n",
      "[epoch 11, batch    12] loss: 162.62971\n",
      "[epoch 11, batch    13] loss: 194.06632\n",
      "[epoch 11, batch    14] loss: 185.55580\n",
      "[epoch 11, batch    15] loss: 188.01909\n",
      "[epoch 11, batch    16] loss: 194.99149\n",
      "[epoch 11, batch    17] loss: 175.74745\n",
      "[epoch 11, batch    18] loss: 181.77205\n",
      "[epoch 11, batch    19] loss: 185.92459\n",
      "[epoch 11, batch    20] loss: 156.03813\n",
      "[epoch 11, batch    21] loss: 186.38339\n",
      "[epoch 11, batch    22] loss: 176.68541\n",
      "[epoch 11, batch    23] loss: 195.42536\n",
      "[epoch 11, batch    24] loss: 205.16909\n",
      "[epoch 11, batch    25] loss: 186.27627\n",
      "[epoch 11, batch    26] loss: 156.23256\n",
      "[epoch 11, batch    27] loss: 174.16816\n",
      "[epoch 11, batch    28] loss: 171.43334\n",
      "[epoch 11, batch    29] loss: 157.44854\n",
      "[epoch 11, batch    30] loss: 159.58688\n",
      "[epoch 11, batch    31] loss: 186.94070\n",
      "[epoch 11, batch    32] loss: 39.16651\n",
      "[epoch 12, batch     1] loss: 183.47280\n",
      "[epoch 12, batch     2] loss: 186.07480\n",
      "[epoch 12, batch     3] loss: 189.77857\n",
      "[epoch 12, batch     4] loss: 146.86349\n",
      "[epoch 12, batch     5] loss: 183.81775\n",
      "[epoch 12, batch     6] loss: 144.98730\n",
      "[epoch 12, batch     7] loss: 171.31852\n",
      "[epoch 12, batch     8] loss: 174.44371\n",
      "[epoch 12, batch     9] loss: 172.88376\n",
      "[epoch 12, batch    10] loss: 165.80626\n",
      "[epoch 12, batch    11] loss: 156.09518\n",
      "[epoch 12, batch    12] loss: 183.45559\n",
      "[epoch 12, batch    13] loss: 183.53455\n",
      "[epoch 12, batch    14] loss: 163.04040\n",
      "[epoch 12, batch    15] loss: 172.64202\n",
      "[epoch 12, batch    16] loss: 160.38992\n",
      "[epoch 12, batch    17] loss: 180.31808\n",
      "[epoch 12, batch    18] loss: 173.11462\n",
      "[epoch 12, batch    19] loss: 172.50324\n",
      "[epoch 12, batch    20] loss: 173.53898\n",
      "[epoch 12, batch    21] loss: 173.33593\n",
      "[epoch 12, batch    22] loss: 158.95204\n",
      "[epoch 12, batch    23] loss: 163.64179\n",
      "[epoch 12, batch    24] loss: 177.18215\n",
      "[epoch 12, batch    25] loss: 168.70993\n",
      "[epoch 12, batch    26] loss: 179.68736\n",
      "[epoch 12, batch    27] loss: 151.34079\n",
      "[epoch 12, batch    28] loss: 168.06490\n",
      "[epoch 12, batch    29] loss: 187.18657\n",
      "[epoch 12, batch    30] loss: 176.25328\n",
      "[epoch 12, batch    31] loss: 169.74855\n",
      "[epoch 12, batch    32] loss: 54.73906\n",
      "[epoch 13, batch     1] loss: 179.41228\n",
      "[epoch 13, batch     2] loss: 180.41022\n",
      "[epoch 13, batch     3] loss: 198.41457\n",
      "[epoch 13, batch     4] loss: 179.31881\n",
      "[epoch 13, batch     5] loss: 166.02025\n",
      "[epoch 13, batch     6] loss: 185.62378\n",
      "[epoch 13, batch     7] loss: 172.65894\n",
      "[epoch 13, batch     8] loss: 157.37246\n",
      "[epoch 13, batch     9] loss: 159.05980\n",
      "[epoch 13, batch    10] loss: 186.74010\n",
      "[epoch 13, batch    11] loss: 172.59991\n",
      "[epoch 13, batch    12] loss: 183.27752\n",
      "[epoch 13, batch    13] loss: 171.24820\n",
      "[epoch 13, batch    14] loss: 152.02351\n",
      "[epoch 13, batch    15] loss: 222.06778\n",
      "[epoch 13, batch    16] loss: 159.77913\n",
      "[epoch 13, batch    17] loss: 177.30865\n",
      "[epoch 13, batch    18] loss: 159.49717\n",
      "[epoch 13, batch    19] loss: 183.55888\n",
      "[epoch 13, batch    20] loss: 159.67213\n",
      "[epoch 13, batch    21] loss: 164.83819\n",
      "[epoch 13, batch    22] loss: 172.22355\n",
      "[epoch 13, batch    23] loss: 164.16143\n",
      "[epoch 13, batch    24] loss: 181.23986\n",
      "[epoch 13, batch    25] loss: 164.31314\n",
      "[epoch 13, batch    26] loss: 184.95811\n",
      "[epoch 13, batch    27] loss: 164.27405\n",
      "[epoch 13, batch    28] loss: 186.93158\n",
      "[epoch 13, batch    29] loss: 191.09285\n",
      "[epoch 13, batch    30] loss: 163.52441\n",
      "[epoch 13, batch    31] loss: 153.10952\n",
      "[epoch 13, batch    32] loss: 43.64856\n",
      "[epoch 14, batch     1] loss: 178.62515\n",
      "[epoch 14, batch     2] loss: 194.17831\n",
      "[epoch 14, batch     3] loss: 169.88732\n",
      "[epoch 14, batch     4] loss: 162.86178\n",
      "[epoch 14, batch     5] loss: 155.58407\n",
      "[epoch 14, batch     6] loss: 171.98551\n",
      "[epoch 14, batch     7] loss: 160.34141\n",
      "[epoch 14, batch     8] loss: 172.51126\n",
      "[epoch 14, batch     9] loss: 178.67278\n",
      "[epoch 14, batch    10] loss: 151.66903\n",
      "[epoch 14, batch    11] loss: 185.47614\n",
      "[epoch 14, batch    12] loss: 168.66811\n",
      "[epoch 14, batch    13] loss: 170.85164\n",
      "[epoch 14, batch    14] loss: 184.54245\n",
      "[epoch 14, batch    15] loss: 169.36929\n",
      "[epoch 14, batch    16] loss: 165.07139\n",
      "[epoch 14, batch    17] loss: 162.37607\n",
      "[epoch 14, batch    18] loss: 165.08923\n",
      "[epoch 14, batch    19] loss: 191.02611\n",
      "[epoch 14, batch    20] loss: 177.86730\n",
      "[epoch 14, batch    21] loss: 156.20787\n",
      "[epoch 14, batch    22] loss: 162.12338\n",
      "[epoch 14, batch    23] loss: 178.63526\n",
      "[epoch 14, batch    24] loss: 164.86941\n",
      "[epoch 14, batch    25] loss: 174.22906\n",
      "[epoch 14, batch    26] loss: 161.52774\n",
      "[epoch 14, batch    27] loss: 157.80093\n",
      "[epoch 14, batch    28] loss: 155.38389\n",
      "[epoch 14, batch    29] loss: 170.89668\n",
      "[epoch 14, batch    30] loss: 181.88532\n",
      "[epoch 14, batch    31] loss: 154.10243\n",
      "[epoch 14, batch    32] loss: 42.10619\n",
      "[epoch 15, batch     1] loss: 155.32782\n",
      "[epoch 15, batch     2] loss: 173.57710\n",
      "[epoch 15, batch     3] loss: 146.89119\n",
      "[epoch 15, batch     4] loss: 157.55974\n",
      "[epoch 15, batch     5] loss: 195.22640\n",
      "[epoch 15, batch     6] loss: 174.75783\n",
      "[epoch 15, batch     7] loss: 163.52741\n",
      "[epoch 15, batch     8] loss: 163.53345\n",
      "[epoch 15, batch     9] loss: 166.88713\n",
      "[epoch 15, batch    10] loss: 172.51252\n",
      "[epoch 15, batch    11] loss: 179.31709\n",
      "[epoch 15, batch    12] loss: 167.19182\n",
      "[epoch 15, batch    13] loss: 169.51735\n",
      "[epoch 15, batch    14] loss: 152.56500\n",
      "[epoch 15, batch    15] loss: 154.36208\n",
      "[epoch 15, batch    16] loss: 163.66297\n",
      "[epoch 15, batch    17] loss: 176.13734\n",
      "[epoch 15, batch    18] loss: 162.22987\n",
      "[epoch 15, batch    19] loss: 161.48542\n",
      "[epoch 15, batch    20] loss: 160.81029\n",
      "[epoch 15, batch    21] loss: 194.81348\n",
      "[epoch 15, batch    22] loss: 157.70486\n",
      "[epoch 15, batch    23] loss: 167.01790\n",
      "[epoch 15, batch    24] loss: 159.91107\n",
      "[epoch 15, batch    25] loss: 160.29426\n",
      "[epoch 15, batch    26] loss: 185.40163\n",
      "[epoch 15, batch    27] loss: 159.73677\n",
      "[epoch 15, batch    28] loss: 167.89003\n",
      "[epoch 15, batch    29] loss: 174.26010\n",
      "[epoch 15, batch    30] loss: 171.26410\n",
      "[epoch 15, batch    31] loss: 167.32101\n",
      "[epoch 15, batch    32] loss: 44.22846\n",
      "[epoch 16, batch     1] loss: 174.40426\n",
      "[epoch 16, batch     2] loss: 160.26424\n",
      "[epoch 16, batch     3] loss: 157.57352\n",
      "[epoch 16, batch     4] loss: 166.28301\n",
      "[epoch 16, batch     5] loss: 179.85179\n",
      "[epoch 16, batch     6] loss: 157.54954\n",
      "[epoch 16, batch     7] loss: 191.51726\n",
      "[epoch 16, batch     8] loss: 152.09744\n",
      "[epoch 16, batch     9] loss: 181.34641\n",
      "[epoch 16, batch    10] loss: 170.27063\n",
      "[epoch 16, batch    11] loss: 169.39440\n",
      "[epoch 16, batch    12] loss: 165.92277\n",
      "[epoch 16, batch    13] loss: 172.54361\n",
      "[epoch 16, batch    14] loss: 151.73921\n",
      "[epoch 16, batch    15] loss: 160.69297\n",
      "[epoch 16, batch    16] loss: 161.54550\n",
      "[epoch 16, batch    17] loss: 164.43789\n",
      "[epoch 16, batch    18] loss: 162.89900\n",
      "[epoch 16, batch    19] loss: 167.61900\n",
      "[epoch 16, batch    20] loss: 139.59075\n",
      "[epoch 16, batch    21] loss: 191.10205\n",
      "[epoch 16, batch    22] loss: 177.23555\n",
      "[epoch 16, batch    23] loss: 158.52009\n",
      "[epoch 16, batch    24] loss: 183.75211\n",
      "[epoch 16, batch    25] loss: 157.46435\n",
      "[epoch 16, batch    26] loss: 155.85818\n",
      "[epoch 16, batch    27] loss: 176.05576\n",
      "[epoch 16, batch    28] loss: 166.49695\n",
      "[epoch 16, batch    29] loss: 151.04934\n",
      "[epoch 16, batch    30] loss: 154.35166\n",
      "[epoch 16, batch    31] loss: 150.17710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 16, batch    32] loss: 46.08204\n",
      "[epoch 17, batch     1] loss: 152.39716\n",
      "[epoch 17, batch     2] loss: 170.74635\n",
      "[epoch 17, batch     3] loss: 162.23126\n",
      "[epoch 17, batch     4] loss: 178.00025\n",
      "[epoch 17, batch     5] loss: 171.91591\n",
      "[epoch 17, batch     6] loss: 147.30515\n",
      "[epoch 17, batch     7] loss: 154.17505\n",
      "[epoch 17, batch     8] loss: 162.85499\n",
      "[epoch 17, batch     9] loss: 153.14414\n",
      "[epoch 17, batch    10] loss: 152.34759\n",
      "[epoch 17, batch    11] loss: 168.32783\n",
      "[epoch 17, batch    12] loss: 162.41005\n",
      "[epoch 17, batch    13] loss: 144.44046\n",
      "[epoch 17, batch    14] loss: 154.16828\n",
      "[epoch 17, batch    15] loss: 172.49707\n",
      "[epoch 17, batch    16] loss: 162.61975\n",
      "[epoch 17, batch    17] loss: 172.41284\n",
      "[epoch 17, batch    18] loss: 154.30650\n",
      "[epoch 17, batch    19] loss: 144.59153\n",
      "[epoch 17, batch    20] loss: 171.51104\n",
      "[epoch 17, batch    21] loss: 174.98397\n",
      "[epoch 17, batch    22] loss: 173.10338\n",
      "[epoch 17, batch    23] loss: 146.06170\n",
      "[epoch 17, batch    24] loss: 154.50641\n",
      "[epoch 17, batch    25] loss: 163.30299\n",
      "[epoch 17, batch    26] loss: 164.72888\n",
      "[epoch 17, batch    27] loss: 171.93884\n",
      "[epoch 17, batch    28] loss: 169.99631\n",
      "[epoch 17, batch    29] loss: 165.62758\n",
      "[epoch 17, batch    30] loss: 148.45810\n",
      "[epoch 17, batch    31] loss: 169.86571\n",
      "[epoch 17, batch    32] loss: 35.08992\n",
      "[epoch 18, batch     1] loss: 172.31619\n",
      "[epoch 18, batch     2] loss: 153.16003\n",
      "[epoch 18, batch     3] loss: 156.18751\n",
      "[epoch 18, batch     4] loss: 155.84651\n",
      "[epoch 18, batch     5] loss: 165.62066\n",
      "[epoch 18, batch     6] loss: 156.69246\n",
      "[epoch 18, batch     7] loss: 152.66593\n",
      "[epoch 18, batch     8] loss: 176.99410\n",
      "[epoch 18, batch     9] loss: 163.78773\n",
      "[epoch 18, batch    10] loss: 175.79925\n",
      "[epoch 18, batch    11] loss: 148.78811\n",
      "[epoch 18, batch    12] loss: 193.15702\n",
      "[epoch 18, batch    13] loss: 162.88066\n",
      "[epoch 18, batch    14] loss: 157.95012\n",
      "[epoch 18, batch    15] loss: 158.30293\n",
      "[epoch 18, batch    16] loss: 139.34832\n",
      "[epoch 18, batch    17] loss: 160.23120\n",
      "[epoch 18, batch    18] loss: 155.13276\n",
      "[epoch 18, batch    19] loss: 155.76526\n",
      "[epoch 18, batch    20] loss: 167.38393\n",
      "[epoch 18, batch    21] loss: 172.39688\n",
      "[epoch 18, batch    22] loss: 171.65001\n",
      "[epoch 18, batch    23] loss: 171.02527\n",
      "[epoch 18, batch    24] loss: 159.30195\n",
      "[epoch 18, batch    25] loss: 155.05800\n",
      "[epoch 18, batch    26] loss: 164.44041\n",
      "[epoch 18, batch    27] loss: 143.86718\n",
      "[epoch 18, batch    28] loss: 155.86739\n",
      "[epoch 18, batch    29] loss: 168.70681\n",
      "[epoch 18, batch    30] loss: 154.92347\n",
      "[epoch 18, batch    31] loss: 160.76241\n",
      "[epoch 18, batch    32] loss: 36.50428\n",
      "[epoch 19, batch     1] loss: 177.88130\n",
      "[epoch 19, batch     2] loss: 141.94988\n",
      "[epoch 19, batch     3] loss: 153.20236\n",
      "[epoch 19, batch     4] loss: 155.29482\n",
      "[epoch 19, batch     5] loss: 168.24874\n",
      "[epoch 19, batch     6] loss: 163.71586\n",
      "[epoch 19, batch     7] loss: 147.76468\n",
      "[epoch 19, batch     8] loss: 152.81474\n",
      "[epoch 19, batch     9] loss: 158.29748\n",
      "[epoch 19, batch    10] loss: 158.48333\n",
      "[epoch 19, batch    11] loss: 148.48545\n",
      "[epoch 19, batch    12] loss: 166.10261\n",
      "[epoch 19, batch    13] loss: 170.69897\n",
      "[epoch 19, batch    14] loss: 161.50061\n",
      "[epoch 19, batch    15] loss: 155.77760\n",
      "[epoch 19, batch    16] loss: 160.70477\n",
      "[epoch 19, batch    17] loss: 158.75513\n",
      "[epoch 19, batch    18] loss: 151.45479\n",
      "[epoch 19, batch    19] loss: 171.34359\n",
      "[epoch 19, batch    20] loss: 148.21451\n",
      "[epoch 19, batch    21] loss: 160.22223\n",
      "[epoch 19, batch    22] loss: 166.22847\n",
      "[epoch 19, batch    23] loss: 152.22809\n",
      "[epoch 19, batch    24] loss: 130.24405\n",
      "[epoch 19, batch    25] loss: 152.79752\n",
      "[epoch 19, batch    26] loss: 159.16504\n",
      "[epoch 19, batch    27] loss: 184.11751\n",
      "[epoch 19, batch    28] loss: 155.19702\n",
      "[epoch 19, batch    29] loss: 151.25501\n",
      "[epoch 19, batch    30] loss: 153.02162\n",
      "[epoch 19, batch    31] loss: 170.25094\n",
      "[epoch 19, batch    32] loss: 46.97868\n",
      "[epoch 20, batch     1] loss: 158.16832\n",
      "[epoch 20, batch     2] loss: 155.75866\n",
      "[epoch 20, batch     3] loss: 157.62521\n",
      "[epoch 20, batch     4] loss: 153.55627\n",
      "[epoch 20, batch     5] loss: 154.40911\n",
      "[epoch 20, batch     6] loss: 156.04671\n",
      "[epoch 20, batch     7] loss: 143.14171\n",
      "[epoch 20, batch     8] loss: 159.93879\n",
      "[epoch 20, batch     9] loss: 177.88115\n",
      "[epoch 20, batch    10] loss: 168.73043\n",
      "[epoch 20, batch    11] loss: 187.01463\n",
      "[epoch 20, batch    12] loss: 154.10112\n",
      "[epoch 20, batch    13] loss: 143.54514\n",
      "[epoch 20, batch    14] loss: 164.71392\n",
      "[epoch 20, batch    15] loss: 166.36567\n",
      "[epoch 20, batch    16] loss: 157.50292\n",
      "[epoch 20, batch    17] loss: 152.56822\n",
      "[epoch 20, batch    18] loss: 154.43882\n",
      "[epoch 20, batch    19] loss: 154.22348\n",
      "[epoch 20, batch    20] loss: 156.79871\n",
      "[epoch 20, batch    21] loss: 136.31217\n",
      "[epoch 20, batch    22] loss: 157.49465\n",
      "[epoch 20, batch    23] loss: 154.08160\n",
      "[epoch 20, batch    24] loss: 161.64283\n",
      "[epoch 20, batch    25] loss: 163.13127\n",
      "[epoch 20, batch    26] loss: 149.27276\n",
      "[epoch 20, batch    27] loss: 151.32840\n",
      "[epoch 20, batch    28] loss: 145.00922\n",
      "[epoch 20, batch    29] loss: 143.91601\n",
      "[epoch 20, batch    30] loss: 155.83270\n",
      "[epoch 20, batch    31] loss: 156.87432\n",
      "[epoch 20, batch    32] loss: 39.14259\n",
      "[epoch 21, batch     1] loss: 163.01412\n",
      "[epoch 21, batch     2] loss: 166.71940\n",
      "[epoch 21, batch     3] loss: 159.08829\n",
      "[epoch 21, batch     4] loss: 156.41891\n",
      "[epoch 21, batch     5] loss: 163.00071\n",
      "[epoch 21, batch     6] loss: 144.89522\n",
      "[epoch 21, batch     7] loss: 142.99586\n",
      "[epoch 21, batch     8] loss: 150.63840\n",
      "[epoch 21, batch     9] loss: 164.29709\n",
      "[epoch 21, batch    10] loss: 182.33158\n",
      "[epoch 21, batch    11] loss: 159.29335\n",
      "[epoch 21, batch    12] loss: 168.65745\n",
      "[epoch 21, batch    13] loss: 161.95725\n",
      "[epoch 21, batch    14] loss: 154.92411\n",
      "[epoch 21, batch    15] loss: 154.80699\n",
      "[epoch 21, batch    16] loss: 147.19768\n",
      "[epoch 21, batch    17] loss: 157.64085\n",
      "[epoch 21, batch    18] loss: 142.48794\n",
      "[epoch 21, batch    19] loss: 139.81401\n",
      "[epoch 21, batch    20] loss: 153.38580\n",
      "[epoch 21, batch    21] loss: 157.95146\n",
      "[epoch 21, batch    22] loss: 147.96012\n",
      "[epoch 21, batch    23] loss: 188.70472\n",
      "[epoch 21, batch    24] loss: 171.87946\n",
      "[epoch 21, batch    25] loss: 147.62726\n",
      "[epoch 21, batch    26] loss: 166.56154\n",
      "[epoch 21, batch    27] loss: 169.23108\n",
      "[epoch 21, batch    28] loss: 153.65951\n",
      "[epoch 21, batch    29] loss: 168.88439\n",
      "[epoch 21, batch    30] loss: 151.20822\n",
      "[epoch 21, batch    31] loss: 153.30775\n",
      "[epoch 21, batch    32] loss: 36.13572\n",
      "[epoch 22, batch     1] loss: 156.94714\n",
      "[epoch 22, batch     2] loss: 167.80264\n",
      "[epoch 22, batch     3] loss: 150.87020\n",
      "[epoch 22, batch     4] loss: 142.55074\n",
      "[epoch 22, batch     5] loss: 157.03261\n",
      "[epoch 22, batch     6] loss: 162.51539\n",
      "[epoch 22, batch     7] loss: 163.24676\n",
      "[epoch 22, batch     8] loss: 155.56817\n",
      "[epoch 22, batch     9] loss: 157.24241\n",
      "[epoch 22, batch    10] loss: 152.65774\n",
      "[epoch 22, batch    11] loss: 155.19323\n",
      "[epoch 22, batch    12] loss: 151.36853\n",
      "[epoch 22, batch    13] loss: 159.24696\n",
      "[epoch 22, batch    14] loss: 145.96384\n",
      "[epoch 22, batch    15] loss: 157.73220\n",
      "[epoch 22, batch    16] loss: 152.51745\n",
      "[epoch 22, batch    17] loss: 161.21327\n",
      "[epoch 22, batch    18] loss: 152.62059\n",
      "[epoch 22, batch    19] loss: 180.50698\n",
      "[epoch 22, batch    20] loss: 151.39069\n",
      "[epoch 22, batch    21] loss: 144.17298\n",
      "[epoch 22, batch    22] loss: 159.72906\n",
      "[epoch 22, batch    23] loss: 153.62880\n",
      "[epoch 22, batch    24] loss: 140.95030\n",
      "[epoch 22, batch    25] loss: 145.57916\n",
      "[epoch 22, batch    26] loss: 154.45510\n",
      "[epoch 22, batch    27] loss: 154.32780\n",
      "[epoch 22, batch    28] loss: 147.84133\n",
      "[epoch 22, batch    29] loss: 150.60412\n",
      "[epoch 22, batch    30] loss: 137.52033\n",
      "[epoch 22, batch    31] loss: 174.49387\n",
      "[epoch 22, batch    32] loss: 40.42781\n",
      "[epoch 23, batch     1] loss: 144.21249\n",
      "[epoch 23, batch     2] loss: 146.27181\n",
      "[epoch 23, batch     3] loss: 141.33694\n",
      "[epoch 23, batch     4] loss: 158.82391\n",
      "[epoch 23, batch     5] loss: 147.16754\n",
      "[epoch 23, batch     6] loss: 155.90956\n",
      "[epoch 23, batch     7] loss: 170.35696\n",
      "[epoch 23, batch     8] loss: 154.87592\n",
      "[epoch 23, batch     9] loss: 157.56242\n",
      "[epoch 23, batch    10] loss: 152.84814\n",
      "[epoch 23, batch    11] loss: 145.62475\n",
      "[epoch 23, batch    12] loss: 146.94582\n",
      "[epoch 23, batch    13] loss: 150.57024\n",
      "[epoch 23, batch    14] loss: 146.20911\n",
      "[epoch 23, batch    15] loss: 149.32581\n",
      "[epoch 23, batch    16] loss: 147.63842\n",
      "[epoch 23, batch    17] loss: 157.25482\n",
      "[epoch 23, batch    18] loss: 146.10824\n",
      "[epoch 23, batch    19] loss: 144.01696\n",
      "[epoch 23, batch    20] loss: 144.42247\n",
      "[epoch 23, batch    21] loss: 164.64364\n",
      "[epoch 23, batch    22] loss: 148.62923\n",
      "[epoch 23, batch    23] loss: 142.32621\n",
      "[epoch 23, batch    24] loss: 144.84165\n",
      "[epoch 23, batch    25] loss: 142.43697\n",
      "[epoch 23, batch    26] loss: 152.27776\n",
      "[epoch 23, batch    27] loss: 160.37000\n",
      "[epoch 23, batch    28] loss: 158.94636\n",
      "[epoch 23, batch    29] loss: 155.05191\n",
      "[epoch 23, batch    30] loss: 141.23311\n",
      "[epoch 23, batch    31] loss: 153.08478\n",
      "[epoch 23, batch    32] loss: 40.10032\n",
      "[epoch 24, batch     1] loss: 171.75851\n",
      "[epoch 24, batch     2] loss: 142.09611\n",
      "[epoch 24, batch     3] loss: 164.97701\n",
      "[epoch 24, batch     4] loss: 145.39016\n",
      "[epoch 24, batch     5] loss: 144.67020\n",
      "[epoch 24, batch     6] loss: 145.61157\n",
      "[epoch 24, batch     7] loss: 165.88950\n",
      "[epoch 24, batch     8] loss: 147.13887\n",
      "[epoch 24, batch     9] loss: 140.93674\n",
      "[epoch 24, batch    10] loss: 145.16936\n",
      "[epoch 24, batch    11] loss: 163.38994\n",
      "[epoch 24, batch    12] loss: 125.22290\n",
      "[epoch 24, batch    13] loss: 146.95738\n",
      "[epoch 24, batch    14] loss: 148.27939\n",
      "[epoch 24, batch    15] loss: 147.41735\n",
      "[epoch 24, batch    16] loss: 152.94098\n",
      "[epoch 24, batch    17] loss: 145.04573\n",
      "[epoch 24, batch    18] loss: 159.72906\n",
      "[epoch 24, batch    19] loss: 144.29183\n",
      "[epoch 24, batch    20] loss: 150.08671\n",
      "[epoch 24, batch    21] loss: 144.62339\n",
      "[epoch 24, batch    22] loss: 151.84712\n",
      "[epoch 24, batch    23] loss: 146.52328\n",
      "[epoch 24, batch    24] loss: 142.53678\n",
      "[epoch 24, batch    25] loss: 148.33451\n",
      "[epoch 24, batch    26] loss: 159.31927\n",
      "[epoch 24, batch    27] loss: 144.82748\n",
      "[epoch 24, batch    28] loss: 147.14559\n",
      "[epoch 24, batch    29] loss: 152.86883\n",
      "[epoch 24, batch    30] loss: 152.68047\n",
      "[epoch 24, batch    31] loss: 145.53073\n",
      "[epoch 24, batch    32] loss: 40.47245\n",
      "[epoch 25, batch     1] loss: 155.76160\n",
      "[epoch 25, batch     2] loss: 154.86083\n",
      "[epoch 25, batch     3] loss: 138.64019\n",
      "[epoch 25, batch     4] loss: 148.18564\n",
      "[epoch 25, batch     5] loss: 148.51643\n",
      "[epoch 25, batch     6] loss: 143.60929\n",
      "[epoch 25, batch     7] loss: 142.55328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 25, batch     8] loss: 153.98856\n",
      "[epoch 25, batch     9] loss: 132.38552\n",
      "[epoch 25, batch    10] loss: 153.67775\n",
      "[epoch 25, batch    11] loss: 143.52911\n",
      "[epoch 25, batch    12] loss: 154.22716\n",
      "[epoch 25, batch    13] loss: 155.81539\n",
      "[epoch 25, batch    14] loss: 159.81532\n",
      "[epoch 25, batch    15] loss: 131.74616\n",
      "[epoch 25, batch    16] loss: 149.60429\n",
      "[epoch 25, batch    17] loss: 139.78836\n",
      "[epoch 25, batch    18] loss: 133.42427\n",
      "[epoch 25, batch    19] loss: 148.94233\n",
      "[epoch 25, batch    20] loss: 140.80424\n",
      "[epoch 25, batch    21] loss: 143.91237\n",
      "[epoch 25, batch    22] loss: 147.47915\n",
      "[epoch 25, batch    23] loss: 166.93929\n",
      "[epoch 25, batch    24] loss: 143.76895\n",
      "[epoch 25, batch    25] loss: 150.12151\n",
      "[epoch 25, batch    26] loss: 159.29065\n",
      "[epoch 25, batch    27] loss: 141.38006\n",
      "[epoch 25, batch    28] loss: 150.33588\n",
      "[epoch 25, batch    29] loss: 166.16542\n",
      "[epoch 25, batch    30] loss: 139.50396\n",
      "[epoch 25, batch    31] loss: 156.97691\n",
      "[epoch 25, batch    32] loss: 32.48273\n",
      "[epoch 26, batch     1] loss: 141.91241\n",
      "[epoch 26, batch     2] loss: 147.32626\n",
      "[epoch 26, batch     3] loss: 150.15282\n",
      "[epoch 26, batch     4] loss: 162.42958\n",
      "[epoch 26, batch     5] loss: 143.31050\n",
      "[epoch 26, batch     6] loss: 150.65193\n",
      "[epoch 26, batch     7] loss: 136.62229\n",
      "[epoch 26, batch     8] loss: 151.34762\n",
      "[epoch 26, batch     9] loss: 138.39513\n",
      "[epoch 26, batch    10] loss: 146.84230\n",
      "[epoch 26, batch    11] loss: 157.48582\n",
      "[epoch 26, batch    12] loss: 160.45951\n",
      "[epoch 26, batch    13] loss: 142.59474\n",
      "[epoch 26, batch    14] loss: 133.68843\n",
      "[epoch 26, batch    15] loss: 136.21998\n",
      "[epoch 26, batch    16] loss: 147.63660\n",
      "[epoch 26, batch    17] loss: 150.81369\n",
      "[epoch 26, batch    18] loss: 156.12900\n",
      "[epoch 26, batch    19] loss: 134.56816\n",
      "[epoch 26, batch    20] loss: 126.04571\n",
      "[epoch 26, batch    21] loss: 140.82602\n",
      "[epoch 26, batch    22] loss: 126.34778\n",
      "[epoch 26, batch    23] loss: 164.32976\n",
      "[epoch 26, batch    24] loss: 170.43518\n",
      "[epoch 26, batch    25] loss: 139.93438\n",
      "[epoch 26, batch    26] loss: 153.54426\n",
      "[epoch 26, batch    27] loss: 143.45007\n",
      "[epoch 26, batch    28] loss: 150.64441\n",
      "[epoch 26, batch    29] loss: 141.94063\n",
      "[epoch 26, batch    30] loss: 153.95902\n",
      "[epoch 26, batch    31] loss: 138.55765\n",
      "[epoch 26, batch    32] loss: 40.86176\n",
      "[epoch 27, batch     1] loss: 146.38718\n",
      "[epoch 27, batch     2] loss: 142.09217\n",
      "[epoch 27, batch     3] loss: 171.43275\n",
      "[epoch 27, batch     4] loss: 144.80800\n",
      "[epoch 27, batch     5] loss: 163.29631\n",
      "[epoch 27, batch     6] loss: 144.15610\n",
      "[epoch 27, batch     7] loss: 140.74975\n",
      "[epoch 27, batch     8] loss: 134.11962\n",
      "[epoch 27, batch     9] loss: 146.64209\n",
      "[epoch 27, batch    10] loss: 144.46698\n",
      "[epoch 27, batch    11] loss: 145.23553\n",
      "[epoch 27, batch    12] loss: 131.44450\n",
      "[epoch 27, batch    13] loss: 154.02863\n",
      "[epoch 27, batch    14] loss: 169.49372\n",
      "[epoch 27, batch    15] loss: 142.63959\n",
      "[epoch 27, batch    16] loss: 140.62815\n",
      "[epoch 27, batch    17] loss: 165.22542\n",
      "[epoch 27, batch    18] loss: 144.59865\n",
      "[epoch 27, batch    19] loss: 150.19986\n",
      "[epoch 27, batch    20] loss: 135.57319\n",
      "[epoch 27, batch    21] loss: 130.18100\n",
      "[epoch 27, batch    22] loss: 141.41513\n",
      "[epoch 27, batch    23] loss: 144.80482\n",
      "[epoch 27, batch    24] loss: 155.84223\n",
      "[epoch 27, batch    25] loss: 158.44007\n",
      "[epoch 27, batch    26] loss: 133.46403\n",
      "[epoch 27, batch    27] loss: 147.68005\n",
      "[epoch 27, batch    28] loss: 141.38988\n",
      "[epoch 27, batch    29] loss: 145.44322\n",
      "[epoch 27, batch    30] loss: 135.40429\n",
      "[epoch 27, batch    31] loss: 145.32129\n",
      "[epoch 27, batch    32] loss: 34.97517\n",
      "[epoch 28, batch     1] loss: 144.37516\n",
      "[epoch 28, batch     2] loss: 152.78574\n",
      "[epoch 28, batch     3] loss: 156.06543\n",
      "[epoch 28, batch     4] loss: 153.41538\n",
      "[epoch 28, batch     5] loss: 146.90387\n",
      "[epoch 28, batch     6] loss: 150.69198\n",
      "[epoch 28, batch     7] loss: 159.83437\n",
      "[epoch 28, batch     8] loss: 136.25722\n",
      "[epoch 28, batch     9] loss: 149.74386\n",
      "[epoch 28, batch    10] loss: 133.73925\n",
      "[epoch 28, batch    11] loss: 147.73568\n",
      "[epoch 28, batch    12] loss: 149.71844\n",
      "[epoch 28, batch    13] loss: 134.20400\n",
      "[epoch 28, batch    14] loss: 148.73623\n",
      "[epoch 28, batch    15] loss: 134.03831\n",
      "[epoch 28, batch    16] loss: 149.60023\n",
      "[epoch 28, batch    17] loss: 144.72206\n",
      "[epoch 28, batch    18] loss: 153.09969\n",
      "[epoch 28, batch    19] loss: 136.40807\n",
      "[epoch 28, batch    20] loss: 147.36353\n",
      "[epoch 28, batch    21] loss: 147.71942\n",
      "[epoch 28, batch    22] loss: 140.58711\n",
      "[epoch 28, batch    23] loss: 160.18483\n",
      "[epoch 28, batch    24] loss: 147.46087\n",
      "[epoch 28, batch    25] loss: 138.73209\n",
      "[epoch 28, batch    26] loss: 124.04921\n",
      "[epoch 28, batch    27] loss: 141.56303\n",
      "[epoch 28, batch    28] loss: 138.24700\n",
      "[epoch 28, batch    29] loss: 158.39596\n",
      "[epoch 28, batch    30] loss: 145.05207\n",
      "[epoch 28, batch    31] loss: 155.64741\n",
      "[epoch 28, batch    32] loss: 33.23009\n",
      "[epoch 29, batch     1] loss: 147.81961\n",
      "[epoch 29, batch     2] loss: 133.09986\n",
      "[epoch 29, batch     3] loss: 139.58270\n",
      "[epoch 29, batch     4] loss: 137.44956\n",
      "[epoch 29, batch     5] loss: 145.06667\n",
      "[epoch 29, batch     6] loss: 140.02684\n",
      "[epoch 29, batch     7] loss: 151.12062\n",
      "[epoch 29, batch     8] loss: 140.38470\n",
      "[epoch 29, batch     9] loss: 130.17524\n",
      "[epoch 29, batch    10] loss: 122.76790\n",
      "[epoch 29, batch    11] loss: 158.35777\n",
      "[epoch 29, batch    12] loss: 154.25526\n",
      "[epoch 29, batch    13] loss: 150.51929\n",
      "[epoch 29, batch    14] loss: 144.51767\n",
      "[epoch 29, batch    15] loss: 155.39471\n",
      "[epoch 29, batch    16] loss: 145.87380\n",
      "[epoch 29, batch    17] loss: 141.54594\n",
      "[epoch 29, batch    18] loss: 141.61460\n",
      "[epoch 29, batch    19] loss: 150.86065\n",
      "[epoch 29, batch    20] loss: 148.34668\n",
      "[epoch 29, batch    21] loss: 154.97372\n",
      "[epoch 29, batch    22] loss: 150.76307\n",
      "[epoch 29, batch    23] loss: 165.63529\n",
      "[epoch 29, batch    24] loss: 128.55799\n",
      "[epoch 29, batch    25] loss: 153.71263\n",
      "[epoch 29, batch    26] loss: 150.91282\n",
      "[epoch 29, batch    27] loss: 136.38120\n",
      "[epoch 29, batch    28] loss: 131.64690\n",
      "[epoch 29, batch    29] loss: 132.89695\n",
      "[epoch 29, batch    30] loss: 147.29611\n",
      "[epoch 29, batch    31] loss: 153.90195\n",
      "[epoch 29, batch    32] loss: 37.58596\n",
      "[epoch 30, batch     1] loss: 128.48653\n",
      "[epoch 30, batch     2] loss: 149.92895\n",
      "[epoch 30, batch     3] loss: 143.89140\n",
      "[epoch 30, batch     4] loss: 139.68210\n",
      "[epoch 30, batch     5] loss: 148.73370\n",
      "[epoch 30, batch     6] loss: 153.74272\n",
      "[epoch 30, batch     7] loss: 147.29241\n",
      "[epoch 30, batch     8] loss: 142.68599\n",
      "[epoch 30, batch     9] loss: 138.78501\n",
      "[epoch 30, batch    10] loss: 150.42994\n",
      "[epoch 30, batch    11] loss: 144.08632\n",
      "[epoch 30, batch    12] loss: 155.89714\n",
      "[epoch 30, batch    13] loss: 157.64066\n",
      "[epoch 30, batch    14] loss: 145.42839\n",
      "[epoch 30, batch    15] loss: 149.99583\n",
      "[epoch 30, batch    16] loss: 138.62837\n",
      "[epoch 30, batch    17] loss: 150.21699\n",
      "[epoch 30, batch    18] loss: 148.57554\n",
      "[epoch 30, batch    19] loss: 139.45360\n",
      "[epoch 30, batch    20] loss: 147.72733\n",
      "[epoch 30, batch    21] loss: 132.46431\n",
      "[epoch 30, batch    22] loss: 142.73937\n",
      "[epoch 30, batch    23] loss: 137.00553\n",
      "[epoch 30, batch    24] loss: 141.77459\n",
      "[epoch 30, batch    25] loss: 135.47723\n",
      "[epoch 30, batch    26] loss: 138.87107\n",
      "[epoch 30, batch    27] loss: 164.12418\n",
      "[epoch 30, batch    28] loss: 138.97947\n",
      "[epoch 30, batch    29] loss: 148.52309\n",
      "[epoch 30, batch    30] loss: 155.89666\n",
      "[epoch 30, batch    31] loss: 145.56275\n",
      "[epoch 30, batch    32] loss: 32.85102\n",
      "[epoch 31, batch     1] loss: 134.76999\n",
      "[epoch 31, batch     2] loss: 146.35748\n",
      "[epoch 31, batch     3] loss: 151.96636\n",
      "[epoch 31, batch     4] loss: 124.72101\n",
      "[epoch 31, batch     5] loss: 149.24812\n",
      "[epoch 31, batch     6] loss: 140.78332\n",
      "[epoch 31, batch     7] loss: 142.56157\n",
      "[epoch 31, batch     8] loss: 146.36338\n",
      "[epoch 31, batch     9] loss: 139.57497\n",
      "[epoch 31, batch    10] loss: 126.76244\n",
      "[epoch 31, batch    11] loss: 154.20024\n",
      "[epoch 31, batch    12] loss: 131.92670\n",
      "[epoch 31, batch    13] loss: 160.29365\n",
      "[epoch 31, batch    14] loss: 133.83423\n",
      "[epoch 31, batch    15] loss: 139.71597\n",
      "[epoch 31, batch    16] loss: 146.84336\n",
      "[epoch 31, batch    17] loss: 142.74376\n",
      "[epoch 31, batch    18] loss: 148.96282\n",
      "[epoch 31, batch    19] loss: 139.49405\n",
      "[epoch 31, batch    20] loss: 128.08985\n",
      "[epoch 31, batch    21] loss: 145.85519\n",
      "[epoch 31, batch    22] loss: 142.79878\n",
      "[epoch 31, batch    23] loss: 146.73180\n",
      "[epoch 31, batch    24] loss: 141.69516\n",
      "[epoch 31, batch    25] loss: 139.45538\n",
      "[epoch 31, batch    26] loss: 134.95853\n",
      "[epoch 31, batch    27] loss: 162.52294\n",
      "[epoch 31, batch    28] loss: 131.22664\n",
      "[epoch 31, batch    29] loss: 144.18894\n",
      "[epoch 31, batch    30] loss: 146.94746\n",
      "[epoch 31, batch    31] loss: 157.98686\n",
      "[epoch 31, batch    32] loss: 37.26789\n",
      "[epoch 32, batch     1] loss: 151.31892\n",
      "[epoch 32, batch     2] loss: 133.25546\n",
      "[epoch 32, batch     3] loss: 139.33001\n",
      "[epoch 32, batch     4] loss: 144.69235\n",
      "[epoch 32, batch     5] loss: 144.79255\n",
      "[epoch 32, batch     6] loss: 140.52527\n",
      "[epoch 32, batch     7] loss: 142.87386\n",
      "[epoch 32, batch     8] loss: 158.53997\n",
      "[epoch 32, batch     9] loss: 142.28940\n",
      "[epoch 32, batch    10] loss: 142.22787\n",
      "[epoch 32, batch    11] loss: 137.19855\n",
      "[epoch 32, batch    12] loss: 139.47515\n",
      "[epoch 32, batch    13] loss: 135.04011\n",
      "[epoch 32, batch    14] loss: 127.65298\n",
      "[epoch 32, batch    15] loss: 150.74093\n",
      "[epoch 32, batch    16] loss: 129.89770\n",
      "[epoch 32, batch    17] loss: 161.07862\n",
      "[epoch 32, batch    18] loss: 130.72590\n",
      "[epoch 32, batch    19] loss: 128.59550\n",
      "[epoch 32, batch    20] loss: 138.42881\n",
      "[epoch 32, batch    21] loss: 132.76461\n",
      "[epoch 32, batch    22] loss: 134.00385\n",
      "[epoch 32, batch    23] loss: 138.90997\n",
      "[epoch 32, batch    24] loss: 146.39482\n",
      "[epoch 32, batch    25] loss: 136.56345\n",
      "[epoch 32, batch    26] loss: 132.90542\n",
      "[epoch 32, batch    27] loss: 138.20246\n",
      "[epoch 32, batch    28] loss: 142.46830\n",
      "[epoch 32, batch    29] loss: 152.45283\n",
      "[epoch 32, batch    30] loss: 144.81184\n",
      "[epoch 32, batch    31] loss: 143.98403\n",
      "[epoch 32, batch    32] loss: 31.73699\n",
      "[epoch 33, batch     1] loss: 158.31757\n",
      "[epoch 33, batch     2] loss: 147.10842\n",
      "[epoch 33, batch     3] loss: 133.79921\n",
      "[epoch 33, batch     4] loss: 144.12591\n",
      "[epoch 33, batch     5] loss: 137.07315\n",
      "[epoch 33, batch     6] loss: 132.09544\n",
      "[epoch 33, batch     7] loss: 137.11529\n",
      "[epoch 33, batch     8] loss: 136.30343\n",
      "[epoch 33, batch     9] loss: 162.28988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 33, batch    10] loss: 148.99566\n",
      "[epoch 33, batch    11] loss: 136.61580\n",
      "[epoch 33, batch    12] loss: 146.82572\n",
      "[epoch 33, batch    13] loss: 148.72271\n",
      "[epoch 33, batch    14] loss: 126.17729\n",
      "[epoch 33, batch    15] loss: 142.38610\n",
      "[epoch 33, batch    16] loss: 136.06337\n",
      "[epoch 33, batch    17] loss: 150.40177\n",
      "[epoch 33, batch    18] loss: 143.18511\n",
      "[epoch 33, batch    19] loss: 135.71238\n",
      "[epoch 33, batch    20] loss: 143.44363\n",
      "[epoch 33, batch    21] loss: 150.25092\n",
      "[epoch 33, batch    22] loss: 118.65789\n",
      "[epoch 33, batch    23] loss: 146.92074\n",
      "[epoch 33, batch    24] loss: 134.56194\n",
      "[epoch 33, batch    25] loss: 142.88410\n",
      "[epoch 33, batch    26] loss: 141.83696\n",
      "[epoch 33, batch    27] loss: 139.23421\n",
      "[epoch 33, batch    28] loss: 140.81825\n",
      "[epoch 33, batch    29] loss: 153.17890\n",
      "[epoch 33, batch    30] loss: 136.36898\n",
      "[epoch 33, batch    31] loss: 144.28892\n",
      "[epoch 33, batch    32] loss: 35.82734\n",
      "[epoch 34, batch     1] loss: 146.88510\n",
      "[epoch 34, batch     2] loss: 150.33372\n",
      "[epoch 34, batch     3] loss: 147.67138\n",
      "[epoch 34, batch     4] loss: 134.79721\n",
      "[epoch 34, batch     5] loss: 133.58960\n",
      "[epoch 34, batch     6] loss: 144.99174\n",
      "[epoch 34, batch     7] loss: 148.02811\n",
      "[epoch 34, batch     8] loss: 152.23320\n",
      "[epoch 34, batch     9] loss: 129.40599\n",
      "[epoch 34, batch    10] loss: 142.18787\n",
      "[epoch 34, batch    11] loss: 126.22521\n",
      "[epoch 34, batch    12] loss: 156.37246\n",
      "[epoch 34, batch    13] loss: 134.12138\n",
      "[epoch 34, batch    14] loss: 138.26199\n",
      "[epoch 34, batch    15] loss: 129.76832\n",
      "[epoch 34, batch    16] loss: 127.35533\n",
      "[epoch 34, batch    17] loss: 137.85522\n",
      "[epoch 34, batch    18] loss: 151.14232\n",
      "[epoch 34, batch    19] loss: 132.04505\n",
      "[epoch 34, batch    20] loss: 133.69216\n",
      "[epoch 34, batch    21] loss: 132.76325\n",
      "[epoch 34, batch    22] loss: 153.05604\n",
      "[epoch 34, batch    23] loss: 129.64296\n",
      "[epoch 34, batch    24] loss: 153.10517\n",
      "[epoch 34, batch    25] loss: 126.16960\n",
      "[epoch 34, batch    26] loss: 149.62401\n",
      "[epoch 34, batch    27] loss: 151.88548\n",
      "[epoch 34, batch    28] loss: 133.38394\n",
      "[epoch 34, batch    29] loss: 137.55056\n",
      "[epoch 34, batch    30] loss: 137.19177\n",
      "[epoch 34, batch    31] loss: 149.55553\n",
      "[epoch 34, batch    32] loss: 30.06992\n",
      "[epoch 35, batch     1] loss: 148.81753\n",
      "[epoch 35, batch     2] loss: 141.81119\n",
      "[epoch 35, batch     3] loss: 138.70864\n",
      "[epoch 35, batch     4] loss: 139.24108\n",
      "[epoch 35, batch     5] loss: 129.96621\n",
      "[epoch 35, batch     6] loss: 137.95475\n",
      "[epoch 35, batch     7] loss: 119.45543\n",
      "[epoch 35, batch     8] loss: 160.53199\n",
      "[epoch 35, batch     9] loss: 134.16975\n",
      "[epoch 35, batch    10] loss: 138.55177\n",
      "[epoch 35, batch    11] loss: 134.40985\n",
      "[epoch 35, batch    12] loss: 146.69104\n",
      "[epoch 35, batch    13] loss: 133.53078\n",
      "[epoch 35, batch    14] loss: 125.26966\n",
      "[epoch 35, batch    15] loss: 130.00802\n",
      "[epoch 35, batch    16] loss: 136.31743\n",
      "[epoch 35, batch    17] loss: 153.47795\n",
      "[epoch 35, batch    18] loss: 142.04349\n",
      "[epoch 35, batch    19] loss: 139.39417\n",
      "[epoch 35, batch    20] loss: 152.52148\n",
      "[epoch 35, batch    21] loss: 137.01034\n",
      "[epoch 35, batch    22] loss: 126.48679\n",
      "[epoch 35, batch    23] loss: 136.14086\n",
      "[epoch 35, batch    24] loss: 139.06018\n",
      "[epoch 35, batch    25] loss: 145.84784\n",
      "[epoch 35, batch    26] loss: 152.80715\n",
      "[epoch 35, batch    27] loss: 158.33867\n",
      "[epoch 35, batch    28] loss: 148.44127\n",
      "[epoch 35, batch    29] loss: 151.23079\n",
      "[epoch 35, batch    30] loss: 135.21376\n",
      "[epoch 35, batch    31] loss: 147.40906\n",
      "[epoch 35, batch    32] loss: 39.29811\n",
      "[epoch 36, batch     1] loss: 147.85830\n",
      "[epoch 36, batch     2] loss: 150.26250\n",
      "[epoch 36, batch     3] loss: 144.80908\n",
      "[epoch 36, batch     4] loss: 135.65262\n",
      "[epoch 36, batch     5] loss: 140.95626\n",
      "[epoch 36, batch     6] loss: 148.27843\n",
      "[epoch 36, batch     7] loss: 136.34614\n",
      "[epoch 36, batch     8] loss: 137.53043\n",
      "[epoch 36, batch     9] loss: 131.53281\n",
      "[epoch 36, batch    10] loss: 142.03718\n",
      "[epoch 36, batch    11] loss: 150.49375\n",
      "[epoch 36, batch    12] loss: 141.43769\n",
      "[epoch 36, batch    13] loss: 151.15406\n",
      "[epoch 36, batch    14] loss: 133.66534\n",
      "[epoch 36, batch    15] loss: 123.00596\n",
      "[epoch 36, batch    16] loss: 146.85146\n",
      "[epoch 36, batch    17] loss: 147.61701\n",
      "[epoch 36, batch    18] loss: 141.25274\n",
      "[epoch 36, batch    19] loss: 142.67827\n",
      "[epoch 36, batch    20] loss: 141.21428\n",
      "[epoch 36, batch    21] loss: 157.50604\n",
      "[epoch 36, batch    22] loss: 161.32166\n",
      "[epoch 36, batch    23] loss: 140.01990\n",
      "[epoch 36, batch    24] loss: 145.78797\n",
      "[epoch 36, batch    25] loss: 136.95685\n",
      "[epoch 36, batch    26] loss: 139.08731\n",
      "[epoch 36, batch    27] loss: 135.93645\n",
      "[epoch 36, batch    28] loss: 157.37943\n",
      "[epoch 36, batch    29] loss: 141.87640\n",
      "[epoch 36, batch    30] loss: 147.79483\n",
      "[epoch 36, batch    31] loss: 136.28501\n",
      "[epoch 36, batch    32] loss: 30.32955\n",
      "[epoch 37, batch     1] loss: 139.92138\n",
      "[epoch 37, batch     2] loss: 149.13812\n",
      "[epoch 37, batch     3] loss: 142.77853\n",
      "[epoch 37, batch     4] loss: 130.63930\n",
      "[epoch 37, batch     5] loss: 137.56471\n",
      "[epoch 37, batch     6] loss: 133.46424\n",
      "[epoch 37, batch     7] loss: 126.74735\n",
      "[epoch 37, batch     8] loss: 135.92988\n",
      "[epoch 37, batch     9] loss: 146.75494\n",
      "[epoch 37, batch    10] loss: 131.10312\n",
      "[epoch 37, batch    11] loss: 141.13149\n",
      "[epoch 37, batch    12] loss: 141.80207\n",
      "[epoch 37, batch    13] loss: 132.15914\n",
      "[epoch 37, batch    14] loss: 144.47715\n",
      "[epoch 37, batch    15] loss: 145.60341\n",
      "[epoch 37, batch    16] loss: 143.28977\n",
      "[epoch 37, batch    17] loss: 139.92544\n",
      "[epoch 37, batch    18] loss: 147.12665\n",
      "[epoch 37, batch    19] loss: 137.47948\n",
      "[epoch 37, batch    20] loss: 141.10279\n",
      "[epoch 37, batch    21] loss: 142.96539\n",
      "[epoch 37, batch    22] loss: 141.27237\n",
      "[epoch 37, batch    23] loss: 138.75996\n",
      "[epoch 37, batch    24] loss: 143.47307\n",
      "[epoch 37, batch    25] loss: 144.88058\n",
      "[epoch 37, batch    26] loss: 146.26776\n",
      "[epoch 37, batch    27] loss: 135.42577\n",
      "[epoch 37, batch    28] loss: 132.66630\n",
      "[epoch 37, batch    29] loss: 144.44560\n",
      "[epoch 37, batch    30] loss: 131.67570\n",
      "[epoch 37, batch    31] loss: 126.78694\n",
      "[epoch 37, batch    32] loss: 36.22052\n",
      "[epoch 38, batch     1] loss: 143.96873\n",
      "[epoch 38, batch     2] loss: 133.75045\n",
      "[epoch 38, batch     3] loss: 129.35065\n",
      "[epoch 38, batch     4] loss: 130.96617\n",
      "[epoch 38, batch     5] loss: 144.70817\n",
      "[epoch 38, batch     6] loss: 125.18602\n",
      "[epoch 38, batch     7] loss: 132.65622\n",
      "[epoch 38, batch     8] loss: 151.77191\n",
      "[epoch 38, batch     9] loss: 127.96757\n",
      "[epoch 38, batch    10] loss: 127.71082\n",
      "[epoch 38, batch    11] loss: 134.63035\n",
      "[epoch 38, batch    12] loss: 142.27927\n",
      "[epoch 38, batch    13] loss: 142.64892\n",
      "[epoch 38, batch    14] loss: 139.35583\n",
      "[epoch 38, batch    15] loss: 135.18733\n",
      "[epoch 38, batch    16] loss: 150.66664\n",
      "[epoch 38, batch    17] loss: 133.41937\n",
      "[epoch 38, batch    18] loss: 147.70888\n",
      "[epoch 38, batch    19] loss: 146.59079\n",
      "[epoch 38, batch    20] loss: 129.86928\n",
      "[epoch 38, batch    21] loss: 142.02142\n",
      "[epoch 38, batch    22] loss: 137.39235\n",
      "[epoch 38, batch    23] loss: 142.94538\n",
      "[epoch 38, batch    24] loss: 137.97504\n",
      "[epoch 38, batch    25] loss: 143.04990\n",
      "[epoch 38, batch    26] loss: 141.68041\n",
      "[epoch 38, batch    27] loss: 123.07485\n",
      "[epoch 38, batch    28] loss: 152.11807\n",
      "[epoch 38, batch    29] loss: 137.27297\n",
      "[epoch 38, batch    30] loss: 131.33921\n",
      "[epoch 38, batch    31] loss: 137.21925\n",
      "[epoch 38, batch    32] loss: 41.25553\n",
      "[epoch 39, batch     1] loss: 143.87792\n",
      "[epoch 39, batch     2] loss: 133.92742\n",
      "[epoch 39, batch     3] loss: 136.28154\n",
      "[epoch 39, batch     4] loss: 135.16374\n",
      "[epoch 39, batch     5] loss: 134.17072\n",
      "[epoch 39, batch     6] loss: 135.63548\n",
      "[epoch 39, batch     7] loss: 129.15566\n",
      "[epoch 39, batch     8] loss: 153.84679\n",
      "[epoch 39, batch     9] loss: 133.49591\n",
      "[epoch 39, batch    10] loss: 131.74066\n",
      "[epoch 39, batch    11] loss: 131.70733\n",
      "[epoch 39, batch    12] loss: 134.58511\n",
      "[epoch 39, batch    13] loss: 131.00951\n",
      "[epoch 39, batch    14] loss: 149.42715\n",
      "[epoch 39, batch    15] loss: 125.88366\n",
      "[epoch 39, batch    16] loss: 140.25207\n",
      "[epoch 39, batch    17] loss: 139.96392\n",
      "[epoch 39, batch    18] loss: 143.38329\n",
      "[epoch 39, batch    19] loss: 156.80632\n",
      "[epoch 39, batch    20] loss: 141.53009\n",
      "[epoch 39, batch    21] loss: 149.37139\n",
      "[epoch 39, batch    22] loss: 153.27681\n",
      "[epoch 39, batch    23] loss: 134.31847\n",
      "[epoch 39, batch    24] loss: 136.15043\n",
      "[epoch 39, batch    25] loss: 128.76328\n",
      "[epoch 39, batch    26] loss: 139.35299\n",
      "[epoch 39, batch    27] loss: 151.66798\n",
      "[epoch 39, batch    28] loss: 135.93033\n",
      "[epoch 39, batch    29] loss: 132.25223\n",
      "[epoch 39, batch    30] loss: 122.07845\n",
      "[epoch 39, batch    31] loss: 144.29811\n",
      "[epoch 39, batch    32] loss: 34.59747\n",
      "[epoch 40, batch     1] loss: 155.78697\n",
      "[epoch 40, batch     2] loss: 150.78572\n",
      "[epoch 40, batch     3] loss: 130.56209\n",
      "[epoch 40, batch     4] loss: 131.93693\n",
      "[epoch 40, batch     5] loss: 146.62671\n",
      "[epoch 40, batch     6] loss: 149.42792\n",
      "[epoch 40, batch     7] loss: 126.03976\n",
      "[epoch 40, batch     8] loss: 154.83756\n",
      "[epoch 40, batch     9] loss: 144.86049\n",
      "[epoch 40, batch    10] loss: 154.15656\n",
      "[epoch 40, batch    11] loss: 156.24363\n",
      "[epoch 40, batch    12] loss: 141.55712\n",
      "[epoch 40, batch    13] loss: 132.57276\n",
      "[epoch 40, batch    14] loss: 152.02927\n",
      "[epoch 40, batch    15] loss: 121.96676\n",
      "[epoch 40, batch    16] loss: 133.75736\n",
      "[epoch 40, batch    17] loss: 129.49535\n",
      "[epoch 40, batch    18] loss: 146.99519\n",
      "[epoch 40, batch    19] loss: 138.15205\n",
      "[epoch 40, batch    20] loss: 146.42547\n",
      "[epoch 40, batch    21] loss: 147.09867\n",
      "[epoch 40, batch    22] loss: 132.40767\n",
      "[epoch 40, batch    23] loss: 133.96306\n",
      "[epoch 40, batch    24] loss: 143.75702\n",
      "[epoch 40, batch    25] loss: 138.58934\n",
      "[epoch 40, batch    26] loss: 155.01762\n",
      "[epoch 40, batch    27] loss: 146.87129\n",
      "[epoch 40, batch    28] loss: 127.35425\n",
      "[epoch 40, batch    29] loss: 134.75840\n",
      "[epoch 40, batch    30] loss: 147.65947\n",
      "[epoch 40, batch    31] loss: 143.30769\n",
      "[epoch 40, batch    32] loss: 32.27386\n",
      "[epoch 41, batch     1] loss: 159.58966\n",
      "[epoch 41, batch     2] loss: 148.63273\n",
      "[epoch 41, batch     3] loss: 136.78829\n",
      "[epoch 41, batch     4] loss: 136.21501\n",
      "[epoch 41, batch     5] loss: 125.67404\n",
      "[epoch 41, batch     6] loss: 130.76133\n",
      "[epoch 41, batch     7] loss: 127.30818\n",
      "[epoch 41, batch     8] loss: 137.54825\n",
      "[epoch 41, batch     9] loss: 138.47890\n",
      "[epoch 41, batch    10] loss: 132.22852\n",
      "[epoch 41, batch    11] loss: 145.66927\n",
      "[epoch 41, batch    12] loss: 143.68292\n",
      "[epoch 41, batch    13] loss: 143.23910\n",
      "[epoch 41, batch    14] loss: 128.54019\n",
      "[epoch 41, batch    15] loss: 126.13155\n",
      "[epoch 41, batch    16] loss: 139.04617\n",
      "[epoch 41, batch    17] loss: 133.83299\n",
      "[epoch 41, batch    18] loss: 142.61211\n",
      "[epoch 41, batch    19] loss: 143.91483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 41, batch    20] loss: 144.78162\n",
      "[epoch 41, batch    21] loss: 136.99029\n",
      "[epoch 41, batch    22] loss: 130.27779\n",
      "[epoch 41, batch    23] loss: 145.17067\n",
      "[epoch 41, batch    24] loss: 127.99052\n",
      "[epoch 41, batch    25] loss: 140.55754\n",
      "[epoch 41, batch    26] loss: 145.31979\n",
      "[epoch 41, batch    27] loss: 131.03895\n",
      "[epoch 41, batch    28] loss: 134.33580\n",
      "[epoch 41, batch    29] loss: 133.20811\n",
      "[epoch 41, batch    30] loss: 142.29444\n",
      "[epoch 41, batch    31] loss: 139.41602\n",
      "[epoch 41, batch    32] loss: 46.09837\n",
      "[epoch 42, batch     1] loss: 135.11754\n",
      "[epoch 42, batch     2] loss: 142.98427\n",
      "[epoch 42, batch     3] loss: 127.96172\n",
      "[epoch 42, batch     4] loss: 145.66412\n",
      "[epoch 42, batch     5] loss: 148.46501\n",
      "[epoch 42, batch     6] loss: 142.18044\n",
      "[epoch 42, batch     7] loss: 122.15760\n",
      "[epoch 42, batch     8] loss: 144.51793\n",
      "[epoch 42, batch     9] loss: 132.39845\n",
      "[epoch 42, batch    10] loss: 130.47108\n",
      "[epoch 42, batch    11] loss: 139.59507\n",
      "[epoch 42, batch    12] loss: 155.03840\n",
      "[epoch 42, batch    13] loss: 138.82737\n",
      "[epoch 42, batch    14] loss: 134.95797\n",
      "[epoch 42, batch    15] loss: 134.59726\n",
      "[epoch 42, batch    16] loss: 136.78126\n",
      "[epoch 42, batch    17] loss: 135.15317\n",
      "[epoch 42, batch    18] loss: 137.26581\n",
      "[epoch 42, batch    19] loss: 132.82643\n",
      "[epoch 42, batch    20] loss: 133.73473\n",
      "[epoch 42, batch    21] loss: 123.14129\n",
      "[epoch 42, batch    22] loss: 143.83984\n",
      "[epoch 42, batch    23] loss: 137.61590\n",
      "[epoch 42, batch    24] loss: 139.85276\n",
      "[epoch 42, batch    25] loss: 133.57118\n",
      "[epoch 42, batch    26] loss: 134.88309\n",
      "[epoch 42, batch    27] loss: 138.43931\n",
      "[epoch 42, batch    28] loss: 138.36080\n",
      "[epoch 42, batch    29] loss: 145.25445\n",
      "[epoch 42, batch    30] loss: 130.84084\n",
      "[epoch 42, batch    31] loss: 130.86689\n",
      "[epoch 42, batch    32] loss: 32.61761\n",
      "[epoch 43, batch     1] loss: 135.73123\n",
      "[epoch 43, batch     2] loss: 149.01702\n",
      "[epoch 43, batch     3] loss: 144.47077\n",
      "[epoch 43, batch     4] loss: 139.96670\n",
      "[epoch 43, batch     5] loss: 131.51888\n",
      "[epoch 43, batch     6] loss: 140.16960\n",
      "[epoch 43, batch     7] loss: 126.73420\n",
      "[epoch 43, batch     8] loss: 134.48545\n",
      "[epoch 43, batch     9] loss: 126.66505\n",
      "[epoch 43, batch    10] loss: 140.48300\n",
      "[epoch 43, batch    11] loss: 120.03387\n",
      "[epoch 43, batch    12] loss: 146.08066\n",
      "[epoch 43, batch    13] loss: 136.82776\n",
      "[epoch 43, batch    14] loss: 145.92944\n",
      "[epoch 43, batch    15] loss: 148.37002\n",
      "[epoch 43, batch    16] loss: 145.18085\n",
      "[epoch 43, batch    17] loss: 137.17802\n",
      "[epoch 43, batch    18] loss: 142.93708\n",
      "[epoch 43, batch    19] loss: 137.36917\n",
      "[epoch 43, batch    20] loss: 124.87557\n",
      "[epoch 43, batch    21] loss: 150.51766\n",
      "[epoch 43, batch    22] loss: 134.38517\n",
      "[epoch 43, batch    23] loss: 131.90771\n",
      "[epoch 43, batch    24] loss: 132.48735\n",
      "[epoch 43, batch    25] loss: 133.05869\n",
      "[epoch 43, batch    26] loss: 147.49883\n",
      "[epoch 43, batch    27] loss: 134.42506\n",
      "[epoch 43, batch    28] loss: 137.56851\n",
      "[epoch 43, batch    29] loss: 128.53780\n",
      "[epoch 43, batch    30] loss: 142.12587\n",
      "[epoch 43, batch    31] loss: 141.15984\n",
      "[epoch 43, batch    32] loss: 36.44497\n",
      "[epoch 44, batch     1] loss: 134.61761\n",
      "[epoch 44, batch     2] loss: 143.94878\n",
      "[epoch 44, batch     3] loss: 143.37177\n",
      "[epoch 44, batch     4] loss: 148.51157\n",
      "[epoch 44, batch     5] loss: 139.59987\n",
      "[epoch 44, batch     6] loss: 153.03910\n",
      "[epoch 44, batch     7] loss: 131.72317\n",
      "[epoch 44, batch     8] loss: 135.41214\n",
      "[epoch 44, batch     9] loss: 128.88081\n",
      "[epoch 44, batch    10] loss: 136.26621\n",
      "[epoch 44, batch    11] loss: 123.57272\n",
      "[epoch 44, batch    12] loss: 118.20041\n",
      "[epoch 44, batch    13] loss: 136.37079\n",
      "[epoch 44, batch    14] loss: 137.59257\n",
      "[epoch 44, batch    15] loss: 140.00490\n",
      "[epoch 44, batch    16] loss: 148.50871\n",
      "[epoch 44, batch    17] loss: 126.04426\n",
      "[epoch 44, batch    18] loss: 144.16370\n",
      "[epoch 44, batch    19] loss: 131.22575\n",
      "[epoch 44, batch    20] loss: 129.26430\n",
      "[epoch 44, batch    21] loss: 134.03035\n",
      "[epoch 44, batch    22] loss: 140.43624\n",
      "[epoch 44, batch    23] loss: 152.19380\n",
      "[epoch 44, batch    24] loss: 137.12322\n",
      "[epoch 44, batch    25] loss: 135.01501\n",
      "[epoch 44, batch    26] loss: 143.53681\n",
      "[epoch 44, batch    27] loss: 136.64739\n",
      "[epoch 44, batch    28] loss: 151.92907\n",
      "[epoch 44, batch    29] loss: 129.91262\n",
      "[epoch 44, batch    30] loss: 133.27217\n",
      "[epoch 44, batch    31] loss: 145.17395\n",
      "[epoch 44, batch    32] loss: 37.34875\n",
      "[epoch 45, batch     1] loss: 142.09087\n",
      "[epoch 45, batch     2] loss: 155.17521\n",
      "[epoch 45, batch     3] loss: 141.14411\n",
      "[epoch 45, batch     4] loss: 142.66531\n",
      "[epoch 45, batch     5] loss: 137.55677\n",
      "[epoch 45, batch     6] loss: 150.54318\n",
      "[epoch 45, batch     7] loss: 128.99808\n",
      "[epoch 45, batch     8] loss: 143.48561\n",
      "[epoch 45, batch     9] loss: 142.88062\n",
      "[epoch 45, batch    10] loss: 120.35848\n",
      "[epoch 45, batch    11] loss: 137.17626\n",
      "[epoch 45, batch    12] loss: 133.48561\n",
      "[epoch 45, batch    13] loss: 140.34174\n",
      "[epoch 45, batch    14] loss: 135.31852\n",
      "[epoch 45, batch    15] loss: 140.60147\n",
      "[epoch 45, batch    16] loss: 142.99717\n",
      "[epoch 45, batch    17] loss: 148.77213\n",
      "[epoch 45, batch    18] loss: 118.59215\n",
      "[epoch 45, batch    19] loss: 128.43321\n",
      "[epoch 45, batch    20] loss: 139.73371\n",
      "[epoch 45, batch    21] loss: 129.32108\n",
      "[epoch 45, batch    22] loss: 136.65973\n",
      "[epoch 45, batch    23] loss: 141.07165\n",
      "[epoch 45, batch    24] loss: 138.77654\n",
      "[epoch 45, batch    25] loss: 133.03324\n",
      "[epoch 45, batch    26] loss: 137.04529\n",
      "[epoch 45, batch    27] loss: 134.87927\n",
      "[epoch 45, batch    28] loss: 124.65853\n",
      "[epoch 45, batch    29] loss: 143.10534\n",
      "[epoch 45, batch    30] loss: 135.31950\n",
      "[epoch 45, batch    31] loss: 134.76289\n",
      "[epoch 45, batch    32] loss: 29.08038\n",
      "[epoch 46, batch     1] loss: 140.17194\n",
      "[epoch 46, batch     2] loss: 144.09433\n",
      "[epoch 46, batch     3] loss: 134.31409\n",
      "[epoch 46, batch     4] loss: 138.59298\n",
      "[epoch 46, batch     5] loss: 134.04345\n",
      "[epoch 46, batch     6] loss: 135.25156\n",
      "[epoch 46, batch     7] loss: 136.59165\n",
      "[epoch 46, batch     8] loss: 130.37085\n",
      "[epoch 46, batch     9] loss: 136.39154\n",
      "[epoch 46, batch    10] loss: 143.03601\n",
      "[epoch 46, batch    11] loss: 124.06472\n",
      "[epoch 46, batch    12] loss: 136.97549\n",
      "[epoch 46, batch    13] loss: 134.51870\n",
      "[epoch 46, batch    14] loss: 154.99207\n",
      "[epoch 46, batch    15] loss: 143.04579\n",
      "[epoch 46, batch    16] loss: 136.36264\n",
      "[epoch 46, batch    17] loss: 140.82369\n",
      "[epoch 46, batch    18] loss: 137.00934\n",
      "[epoch 46, batch    19] loss: 146.05110\n",
      "[epoch 46, batch    20] loss: 133.32606\n",
      "[epoch 46, batch    21] loss: 131.76450\n",
      "[epoch 46, batch    22] loss: 137.22055\n",
      "[epoch 46, batch    23] loss: 137.72631\n",
      "[epoch 46, batch    24] loss: 131.37471\n",
      "[epoch 46, batch    25] loss: 127.66203\n",
      "[epoch 46, batch    26] loss: 142.33811\n",
      "[epoch 46, batch    27] loss: 132.26097\n",
      "[epoch 46, batch    28] loss: 138.33303\n",
      "[epoch 46, batch    29] loss: 147.65853\n",
      "[epoch 46, batch    30] loss: 135.31221\n",
      "[epoch 46, batch    31] loss: 138.80196\n",
      "[epoch 46, batch    32] loss: 35.42201\n",
      "[epoch 47, batch     1] loss: 148.87683\n",
      "[epoch 47, batch     2] loss: 148.52401\n",
      "[epoch 47, batch     3] loss: 140.62594\n",
      "[epoch 47, batch     4] loss: 131.19187\n",
      "[epoch 47, batch     5] loss: 127.89690\n",
      "[epoch 47, batch     6] loss: 134.35770\n",
      "[epoch 47, batch     7] loss: 133.92532\n",
      "[epoch 47, batch     8] loss: 141.75388\n",
      "[epoch 47, batch     9] loss: 130.29062\n",
      "[epoch 47, batch    10] loss: 140.20592\n",
      "[epoch 47, batch    11] loss: 135.73667\n",
      "[epoch 47, batch    12] loss: 141.69143\n",
      "[epoch 47, batch    13] loss: 143.35287\n",
      "[epoch 47, batch    14] loss: 131.53888\n",
      "[epoch 47, batch    15] loss: 128.11453\n",
      "[epoch 47, batch    16] loss: 128.36406\n",
      "[epoch 47, batch    17] loss: 138.48776\n",
      "[epoch 47, batch    18] loss: 140.02572\n",
      "[epoch 47, batch    19] loss: 130.48320\n",
      "[epoch 47, batch    20] loss: 148.06012\n",
      "[epoch 47, batch    21] loss: 146.44594\n",
      "[epoch 47, batch    22] loss: 139.67963\n",
      "[epoch 47, batch    23] loss: 130.70883\n",
      "[epoch 47, batch    24] loss: 133.42629\n",
      "[epoch 47, batch    25] loss: 137.01675\n",
      "[epoch 47, batch    26] loss: 139.61637\n",
      "[epoch 47, batch    27] loss: 141.46167\n",
      "[epoch 47, batch    28] loss: 145.38291\n",
      "[epoch 47, batch    29] loss: 141.87580\n",
      "[epoch 47, batch    30] loss: 128.58649\n",
      "[epoch 47, batch    31] loss: 129.62663\n",
      "[epoch 47, batch    32] loss: 33.04806\n",
      "[epoch 48, batch     1] loss: 132.58823\n",
      "[epoch 48, batch     2] loss: 135.66678\n",
      "[epoch 48, batch     3] loss: 136.32078\n",
      "[epoch 48, batch     4] loss: 143.24651\n",
      "[epoch 48, batch     5] loss: 126.09707\n",
      "[epoch 48, batch     6] loss: 120.59883\n",
      "[epoch 48, batch     7] loss: 129.91935\n",
      "[epoch 48, batch     8] loss: 147.56052\n",
      "[epoch 48, batch     9] loss: 146.83872\n",
      "[epoch 48, batch    10] loss: 141.25566\n",
      "[epoch 48, batch    11] loss: 125.95310\n",
      "[epoch 48, batch    12] loss: 134.08957\n",
      "[epoch 48, batch    13] loss: 144.83099\n",
      "[epoch 48, batch    14] loss: 148.77731\n",
      "[epoch 48, batch    15] loss: 134.62525\n",
      "[epoch 48, batch    16] loss: 137.35326\n",
      "[epoch 48, batch    17] loss: 120.25858\n",
      "[epoch 48, batch    18] loss: 150.47647\n",
      "[epoch 48, batch    19] loss: 140.27203\n",
      "[epoch 48, batch    20] loss: 149.83539\n",
      "[epoch 48, batch    21] loss: 140.32289\n",
      "[epoch 48, batch    22] loss: 138.10530\n",
      "[epoch 48, batch    23] loss: 135.34951\n",
      "[epoch 48, batch    24] loss: 138.33321\n",
      "[epoch 48, batch    25] loss: 138.11197\n",
      "[epoch 48, batch    26] loss: 130.77178\n",
      "[epoch 48, batch    27] loss: 129.76838\n",
      "[epoch 48, batch    28] loss: 148.96049\n",
      "[epoch 48, batch    29] loss: 127.70074\n",
      "[epoch 48, batch    30] loss: 140.40731\n",
      "[epoch 48, batch    31] loss: 136.99807\n",
      "[epoch 48, batch    32] loss: 37.22942\n",
      "[epoch 49, batch     1] loss: 134.10262\n",
      "[epoch 49, batch     2] loss: 134.28593\n",
      "[epoch 49, batch     3] loss: 133.57644\n",
      "[epoch 49, batch     4] loss: 144.13172\n",
      "[epoch 49, batch     5] loss: 126.87208\n",
      "[epoch 49, batch     6] loss: 151.87114\n",
      "[epoch 49, batch     7] loss: 125.99607\n",
      "[epoch 49, batch     8] loss: 135.98236\n",
      "[epoch 49, batch     9] loss: 132.55854\n",
      "[epoch 49, batch    10] loss: 146.75684\n",
      "[epoch 49, batch    11] loss: 121.95400\n",
      "[epoch 49, batch    12] loss: 131.53528\n",
      "[epoch 49, batch    13] loss: 141.56003\n",
      "[epoch 49, batch    14] loss: 132.12286\n",
      "[epoch 49, batch    15] loss: 138.71682\n",
      "[epoch 49, batch    16] loss: 131.65453\n",
      "[epoch 49, batch    17] loss: 136.80811\n",
      "[epoch 49, batch    18] loss: 141.10791\n",
      "[epoch 49, batch    19] loss: 135.59551\n",
      "[epoch 49, batch    20] loss: 124.31643\n",
      "[epoch 49, batch    21] loss: 133.25041\n",
      "[epoch 49, batch    22] loss: 123.70680\n",
      "[epoch 49, batch    23] loss: 134.65367\n",
      "[epoch 49, batch    24] loss: 133.42824\n",
      "[epoch 49, batch    25] loss: 148.12262\n",
      "[epoch 49, batch    26] loss: 141.50769\n",
      "[epoch 49, batch    27] loss: 145.19404\n",
      "[epoch 49, batch    28] loss: 148.40922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 49, batch    29] loss: 138.67822\n",
      "[epoch 49, batch    30] loss: 132.26652\n",
      "[epoch 49, batch    31] loss: 138.39172\n",
      "[epoch 49, batch    32] loss: 31.41481\n",
      "[epoch 50, batch     1] loss: 139.42373\n",
      "[epoch 50, batch     2] loss: 142.66628\n",
      "[epoch 50, batch     3] loss: 143.42245\n",
      "[epoch 50, batch     4] loss: 132.92685\n",
      "[epoch 50, batch     5] loss: 135.45040\n",
      "[epoch 50, batch     6] loss: 142.10462\n",
      "[epoch 50, batch     7] loss: 138.38741\n",
      "[epoch 50, batch     8] loss: 143.83371\n",
      "[epoch 50, batch     9] loss: 138.55325\n",
      "[epoch 50, batch    10] loss: 137.85624\n",
      "[epoch 50, batch    11] loss: 138.40116\n",
      "[epoch 50, batch    12] loss: 138.19846\n",
      "[epoch 50, batch    13] loss: 132.53201\n",
      "[epoch 50, batch    14] loss: 136.65966\n",
      "[epoch 50, batch    15] loss: 132.07502\n",
      "[epoch 50, batch    16] loss: 139.62261\n",
      "[epoch 50, batch    17] loss: 140.53655\n",
      "[epoch 50, batch    18] loss: 135.16081\n",
      "[epoch 50, batch    19] loss: 139.16544\n",
      "[epoch 50, batch    20] loss: 136.17758\n",
      "[epoch 50, batch    21] loss: 127.54057\n",
      "[epoch 50, batch    22] loss: 135.21519\n",
      "[epoch 50, batch    23] loss: 118.63658\n",
      "[epoch 50, batch    24] loss: 139.56095\n",
      "[epoch 50, batch    25] loss: 132.62988\n",
      "[epoch 50, batch    26] loss: 132.26679\n",
      "[epoch 50, batch    27] loss: 134.71666\n",
      "[epoch 50, batch    28] loss: 133.61231\n",
      "[epoch 50, batch    29] loss: 136.70524\n",
      "[epoch 50, batch    30] loss: 136.24087\n",
      "[epoch 50, batch    31] loss: 138.69529\n",
      "[epoch 50, batch    32] loss: 28.64254\n",
      "[epoch 51, batch     1] loss: 136.12686\n",
      "[epoch 51, batch     2] loss: 127.68890\n",
      "[epoch 51, batch     3] loss: 135.08310\n",
      "[epoch 51, batch     4] loss: 147.15810\n",
      "[epoch 51, batch     5] loss: 137.72476\n",
      "[epoch 51, batch     6] loss: 132.29434\n",
      "[epoch 51, batch     7] loss: 147.33676\n",
      "[epoch 51, batch     8] loss: 129.53529\n",
      "[epoch 51, batch     9] loss: 136.84000\n",
      "[epoch 51, batch    10] loss: 133.71969\n",
      "[epoch 51, batch    11] loss: 147.83368\n",
      "[epoch 51, batch    12] loss: 132.62564\n",
      "[epoch 51, batch    13] loss: 130.06933\n",
      "[epoch 51, batch    14] loss: 118.66476\n",
      "[epoch 51, batch    15] loss: 130.48265\n",
      "[epoch 51, batch    16] loss: 137.80543\n",
      "[epoch 51, batch    17] loss: 139.26358\n",
      "[epoch 51, batch    18] loss: 134.84277\n",
      "[epoch 51, batch    19] loss: 140.28220\n",
      "[epoch 51, batch    20] loss: 142.67849\n",
      "[epoch 51, batch    21] loss: 128.86903\n",
      "[epoch 51, batch    22] loss: 128.65495\n",
      "[epoch 51, batch    23] loss: 131.97158\n",
      "[epoch 51, batch    24] loss: 136.95048\n",
      "[epoch 51, batch    25] loss: 140.80637\n",
      "[epoch 51, batch    26] loss: 138.87432\n",
      "[epoch 51, batch    27] loss: 118.02868\n",
      "[epoch 51, batch    28] loss: 156.70779\n",
      "[epoch 51, batch    29] loss: 132.79610\n",
      "[epoch 51, batch    30] loss: 142.61591\n",
      "[epoch 51, batch    31] loss: 137.93302\n",
      "[epoch 51, batch    32] loss: 24.66050\n",
      "[epoch 52, batch     1] loss: 138.71456\n",
      "[epoch 52, batch     2] loss: 131.78846\n",
      "[epoch 52, batch     3] loss: 151.38543\n",
      "[epoch 52, batch     4] loss: 130.62565\n",
      "[epoch 52, batch     5] loss: 139.70849\n",
      "[epoch 52, batch     6] loss: 133.75148\n",
      "[epoch 52, batch     7] loss: 135.51663\n",
      "[epoch 52, batch     8] loss: 139.63284\n",
      "[epoch 52, batch     9] loss: 139.59630\n",
      "[epoch 52, batch    10] loss: 143.77662\n",
      "[epoch 52, batch    11] loss: 135.21896\n",
      "[epoch 52, batch    12] loss: 134.90979\n",
      "[epoch 52, batch    13] loss: 130.12271\n",
      "[epoch 52, batch    14] loss: 134.97706\n",
      "[epoch 52, batch    15] loss: 136.79972\n",
      "[epoch 52, batch    16] loss: 141.40427\n",
      "[epoch 52, batch    17] loss: 145.04810\n",
      "[epoch 52, batch    18] loss: 145.20652\n",
      "[epoch 52, batch    19] loss: 128.18659\n",
      "[epoch 52, batch    20] loss: 121.12779\n",
      "[epoch 52, batch    21] loss: 145.07987\n",
      "[epoch 52, batch    22] loss: 138.97504\n",
      "[epoch 52, batch    23] loss: 123.56807\n",
      "[epoch 52, batch    24] loss: 133.85842\n",
      "[epoch 52, batch    25] loss: 136.53938\n",
      "[epoch 52, batch    26] loss: 132.21946\n",
      "[epoch 52, batch    27] loss: 133.52586\n",
      "[epoch 52, batch    28] loss: 137.94816\n",
      "[epoch 52, batch    29] loss: 116.53207\n",
      "[epoch 52, batch    30] loss: 131.86447\n",
      "[epoch 52, batch    31] loss: 134.08968\n",
      "[epoch 52, batch    32] loss: 38.94189\n",
      "[epoch 53, batch     1] loss: 135.22913\n",
      "[epoch 53, batch     2] loss: 149.01300\n",
      "[epoch 53, batch     3] loss: 156.12060\n",
      "[epoch 53, batch     4] loss: 132.50350\n",
      "[epoch 53, batch     5] loss: 129.72370\n",
      "[epoch 53, batch     6] loss: 149.64087\n",
      "[epoch 53, batch     7] loss: 138.69914\n",
      "[epoch 53, batch     8] loss: 132.05180\n",
      "[epoch 53, batch     9] loss: 135.78730\n",
      "[epoch 53, batch    10] loss: 140.49972\n",
      "[epoch 53, batch    11] loss: 143.75214\n",
      "[epoch 53, batch    12] loss: 142.22952\n",
      "[epoch 53, batch    13] loss: 131.68442\n",
      "[epoch 53, batch    14] loss: 139.22116\n",
      "[epoch 53, batch    15] loss: 140.17871\n",
      "[epoch 53, batch    16] loss: 132.15217\n",
      "[epoch 53, batch    17] loss: 148.30663\n",
      "[epoch 53, batch    18] loss: 136.68149\n",
      "[epoch 53, batch    19] loss: 137.65365\n",
      "[epoch 53, batch    20] loss: 127.28194\n",
      "[epoch 53, batch    21] loss: 135.60434\n",
      "[epoch 53, batch    22] loss: 148.61587\n",
      "[epoch 53, batch    23] loss: 131.93499\n",
      "[epoch 53, batch    24] loss: 117.00013\n",
      "[epoch 53, batch    25] loss: 135.63223\n",
      "[epoch 53, batch    26] loss: 140.19991\n",
      "[epoch 53, batch    27] loss: 128.52163\n",
      "[epoch 53, batch    28] loss: 146.73908\n",
      "[epoch 53, batch    29] loss: 129.88231\n",
      "[epoch 53, batch    30] loss: 138.44575\n",
      "[epoch 53, batch    31] loss: 130.18021\n",
      "[epoch 53, batch    32] loss: 31.01617\n",
      "[epoch 54, batch     1] loss: 141.79261\n",
      "[epoch 54, batch     2] loss: 144.64898\n",
      "[epoch 54, batch     3] loss: 142.72851\n",
      "[epoch 54, batch     4] loss: 125.80020\n",
      "[epoch 54, batch     5] loss: 140.45542\n",
      "[epoch 54, batch     6] loss: 138.08033\n",
      "[epoch 54, batch     7] loss: 131.05538\n",
      "[epoch 54, batch     8] loss: 141.00540\n",
      "[epoch 54, batch     9] loss: 128.50428\n",
      "[epoch 54, batch    10] loss: 150.25611\n",
      "[epoch 54, batch    11] loss: 138.02442\n",
      "[epoch 54, batch    12] loss: 137.76107\n",
      "[epoch 54, batch    13] loss: 154.25242\n",
      "[epoch 54, batch    14] loss: 136.94509\n",
      "[epoch 54, batch    15] loss: 125.01840\n",
      "[epoch 54, batch    16] loss: 119.61970\n",
      "[epoch 54, batch    17] loss: 140.93985\n",
      "[epoch 54, batch    18] loss: 125.85275\n",
      "[epoch 54, batch    19] loss: 130.64135\n",
      "[epoch 54, batch    20] loss: 150.74515\n",
      "[epoch 54, batch    21] loss: 125.30807\n",
      "[epoch 54, batch    22] loss: 124.24785\n",
      "[epoch 54, batch    23] loss: 131.11281\n",
      "[epoch 54, batch    24] loss: 141.49425\n",
      "[epoch 54, batch    25] loss: 138.11078\n",
      "[epoch 54, batch    26] loss: 152.14802\n",
      "[epoch 54, batch    27] loss: 138.59282\n",
      "[epoch 54, batch    28] loss: 153.94129\n",
      "[epoch 54, batch    29] loss: 137.84341\n",
      "[epoch 54, batch    30] loss: 136.89597\n",
      "[epoch 54, batch    31] loss: 129.57757\n",
      "[epoch 54, batch    32] loss: 38.85063\n",
      "[epoch 55, batch     1] loss: 140.06178\n",
      "[epoch 55, batch     2] loss: 124.37252\n",
      "[epoch 55, batch     3] loss: 133.22487\n",
      "[epoch 55, batch     4] loss: 138.52287\n",
      "[epoch 55, batch     5] loss: 169.98729\n",
      "[epoch 55, batch     6] loss: 143.60127\n",
      "[epoch 55, batch     7] loss: 129.14989\n",
      "[epoch 55, batch     8] loss: 141.36320\n",
      "[epoch 55, batch     9] loss: 134.59338\n",
      "[epoch 55, batch    10] loss: 143.57069\n",
      "[epoch 55, batch    11] loss: 135.70566\n",
      "[epoch 55, batch    12] loss: 124.10883\n",
      "[epoch 55, batch    13] loss: 137.78077\n",
      "[epoch 55, batch    14] loss: 147.23327\n",
      "[epoch 55, batch    15] loss: 134.89780\n",
      "[epoch 55, batch    16] loss: 142.45604\n",
      "[epoch 55, batch    17] loss: 128.96807\n",
      "[epoch 55, batch    18] loss: 136.25361\n",
      "[epoch 55, batch    19] loss: 126.92057\n",
      "[epoch 55, batch    20] loss: 148.18981\n",
      "[epoch 55, batch    21] loss: 131.60716\n",
      "[epoch 55, batch    22] loss: 130.65047\n",
      "[epoch 55, batch    23] loss: 152.27655\n",
      "[epoch 55, batch    24] loss: 139.45356\n",
      "[epoch 55, batch    25] loss: 126.37167\n",
      "[epoch 55, batch    26] loss: 129.61766\n",
      "[epoch 55, batch    27] loss: 124.19826\n",
      "[epoch 55, batch    28] loss: 132.65268\n",
      "[epoch 55, batch    29] loss: 136.72194\n",
      "[epoch 55, batch    30] loss: 129.22110\n",
      "[epoch 55, batch    31] loss: 134.62814\n",
      "[epoch 55, batch    32] loss: 36.59479\n",
      "[epoch 56, batch     1] loss: 146.41083\n",
      "[epoch 56, batch     2] loss: 138.15067\n",
      "[epoch 56, batch     3] loss: 127.36081\n",
      "[epoch 56, batch     4] loss: 140.93890\n",
      "[epoch 56, batch     5] loss: 152.43320\n",
      "[epoch 56, batch     6] loss: 118.14556\n",
      "[epoch 56, batch     7] loss: 139.11175\n",
      "[epoch 56, batch     8] loss: 143.44436\n",
      "[epoch 56, batch     9] loss: 128.14439\n",
      "[epoch 56, batch    10] loss: 130.30865\n",
      "[epoch 56, batch    11] loss: 133.68013\n",
      "[epoch 56, batch    12] loss: 125.56369\n",
      "[epoch 56, batch    13] loss: 142.06670\n",
      "[epoch 56, batch    14] loss: 132.37093\n",
      "[epoch 56, batch    15] loss: 130.07251\n",
      "[epoch 56, batch    16] loss: 135.72257\n",
      "[epoch 56, batch    17] loss: 122.17009\n",
      "[epoch 56, batch    18] loss: 130.23398\n",
      "[epoch 56, batch    19] loss: 132.31312\n",
      "[epoch 56, batch    20] loss: 132.74312\n",
      "[epoch 56, batch    21] loss: 123.56112\n",
      "[epoch 56, batch    22] loss: 142.91144\n",
      "[epoch 56, batch    23] loss: 142.43053\n",
      "[epoch 56, batch    24] loss: 146.49846\n",
      "[epoch 56, batch    25] loss: 141.41502\n",
      "[epoch 56, batch    26] loss: 136.13523\n",
      "[epoch 56, batch    27] loss: 131.68147\n",
      "[epoch 56, batch    28] loss: 129.30984\n",
      "[epoch 56, batch    29] loss: 138.67361\n",
      "[epoch 56, batch    30] loss: 146.70991\n",
      "[epoch 56, batch    31] loss: 125.93678\n",
      "[epoch 56, batch    32] loss: 32.70330\n",
      "[epoch 57, batch     1] loss: 142.65778\n",
      "[epoch 57, batch     2] loss: 139.45149\n",
      "[epoch 57, batch     3] loss: 118.60618\n",
      "[epoch 57, batch     4] loss: 133.23106\n",
      "[epoch 57, batch     5] loss: 129.84513\n",
      "[epoch 57, batch     6] loss: 127.78566\n",
      "[epoch 57, batch     7] loss: 139.32344\n",
      "[epoch 57, batch     8] loss: 128.62536\n",
      "[epoch 57, batch     9] loss: 132.05811\n",
      "[epoch 57, batch    10] loss: 140.93821\n",
      "[epoch 57, batch    11] loss: 128.76331\n",
      "[epoch 57, batch    12] loss: 140.59807\n",
      "[epoch 57, batch    13] loss: 145.88783\n",
      "[epoch 57, batch    14] loss: 142.17326\n",
      "[epoch 57, batch    15] loss: 131.86236\n",
      "[epoch 57, batch    16] loss: 136.63607\n",
      "[epoch 57, batch    17] loss: 150.93014\n",
      "[epoch 57, batch    18] loss: 142.01225\n",
      "[epoch 57, batch    19] loss: 127.38142\n",
      "[epoch 57, batch    20] loss: 142.60525\n",
      "[epoch 57, batch    21] loss: 149.85916\n",
      "[epoch 57, batch    22] loss: 141.34752\n",
      "[epoch 57, batch    23] loss: 136.34020\n",
      "[epoch 57, batch    24] loss: 128.11362\n",
      "[epoch 57, batch    25] loss: 139.27730\n",
      "[epoch 57, batch    26] loss: 142.74089\n",
      "[epoch 57, batch    27] loss: 130.69971\n",
      "[epoch 57, batch    28] loss: 135.44278\n",
      "[epoch 57, batch    29] loss: 131.86511\n",
      "[epoch 57, batch    30] loss: 133.52486\n",
      "[epoch 57, batch    31] loss: 131.75723\n",
      "[epoch 57, batch    32] loss: 35.44476\n",
      "[epoch 58, batch     1] loss: 138.00773\n",
      "[epoch 58, batch     2] loss: 134.10350\n",
      "[epoch 58, batch     3] loss: 133.84258\n",
      "[epoch 58, batch     4] loss: 134.47101\n",
      "[epoch 58, batch     5] loss: 130.43525\n",
      "[epoch 58, batch     6] loss: 130.72851\n",
      "[epoch 58, batch     7] loss: 146.05028\n",
      "[epoch 58, batch     8] loss: 137.64958\n",
      "[epoch 58, batch     9] loss: 135.13004\n",
      "[epoch 58, batch    10] loss: 142.59202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 58, batch    11] loss: 131.16768\n",
      "[epoch 58, batch    12] loss: 122.96738\n",
      "[epoch 58, batch    13] loss: 138.42108\n",
      "[epoch 58, batch    14] loss: 127.58016\n",
      "[epoch 58, batch    15] loss: 130.77126\n",
      "[epoch 58, batch    16] loss: 133.93850\n",
      "[epoch 58, batch    17] loss: 128.91053\n",
      "[epoch 58, batch    18] loss: 137.59552\n",
      "[epoch 58, batch    19] loss: 134.10848\n",
      "[epoch 58, batch    20] loss: 121.57823\n",
      "[epoch 58, batch    21] loss: 133.34726\n",
      "[epoch 58, batch    22] loss: 134.50368\n",
      "[epoch 58, batch    23] loss: 143.48304\n",
      "[epoch 58, batch    24] loss: 119.73234\n",
      "[epoch 58, batch    25] loss: 131.98128\n",
      "[epoch 58, batch    26] loss: 136.88063\n",
      "[epoch 58, batch    27] loss: 126.28279\n",
      "[epoch 58, batch    28] loss: 129.18768\n",
      "[epoch 58, batch    29] loss: 142.90619\n",
      "[epoch 58, batch    30] loss: 132.14344\n",
      "[epoch 58, batch    31] loss: 142.95887\n",
      "[epoch 58, batch    32] loss: 31.23584\n",
      "[epoch 59, batch     1] loss: 131.28567\n",
      "[epoch 59, batch     2] loss: 134.24936\n",
      "[epoch 59, batch     3] loss: 153.05989\n",
      "[epoch 59, batch     4] loss: 144.42536\n",
      "[epoch 59, batch     5] loss: 134.48318\n",
      "[epoch 59, batch     6] loss: 143.03525\n",
      "[epoch 59, batch     7] loss: 133.45703\n",
      "[epoch 59, batch     8] loss: 126.95348\n",
      "[epoch 59, batch     9] loss: 137.26316\n",
      "[epoch 59, batch    10] loss: 129.52491\n",
      "[epoch 59, batch    11] loss: 140.46049\n",
      "[epoch 59, batch    12] loss: 126.58529\n",
      "[epoch 59, batch    13] loss: 139.82630\n",
      "[epoch 59, batch    14] loss: 142.82616\n",
      "[epoch 59, batch    15] loss: 138.38591\n",
      "[epoch 59, batch    16] loss: 153.42025\n",
      "[epoch 59, batch    17] loss: 150.53776\n",
      "[epoch 59, batch    18] loss: 128.51625\n",
      "[epoch 59, batch    19] loss: 140.35366\n",
      "[epoch 59, batch    20] loss: 138.56554\n",
      "[epoch 59, batch    21] loss: 127.91021\n",
      "[epoch 59, batch    22] loss: 132.20420\n",
      "[epoch 59, batch    23] loss: 127.60924\n",
      "[epoch 59, batch    24] loss: 146.74931\n",
      "[epoch 59, batch    25] loss: 124.67127\n",
      "[epoch 59, batch    26] loss: 131.12617\n",
      "[epoch 59, batch    27] loss: 145.61660\n",
      "[epoch 59, batch    28] loss: 133.47750\n",
      "[epoch 59, batch    29] loss: 143.68889\n",
      "[epoch 59, batch    30] loss: 135.57870\n",
      "[epoch 59, batch    31] loss: 133.93248\n",
      "[epoch 59, batch    32] loss: 37.10714\n",
      "[epoch 60, batch     1] loss: 136.95778\n",
      "[epoch 60, batch     2] loss: 131.41359\n",
      "[epoch 60, batch     3] loss: 138.38319\n",
      "[epoch 60, batch     4] loss: 149.26076\n",
      "[epoch 60, batch     5] loss: 123.81264\n",
      "[epoch 60, batch     6] loss: 126.73055\n",
      "[epoch 60, batch     7] loss: 134.14657\n",
      "[epoch 60, batch     8] loss: 137.96871\n",
      "[epoch 60, batch     9] loss: 128.88121\n",
      "[epoch 60, batch    10] loss: 123.43144\n",
      "[epoch 60, batch    11] loss: 129.75653\n",
      "[epoch 60, batch    12] loss: 142.25375\n",
      "[epoch 60, batch    13] loss: 135.71692\n",
      "[epoch 60, batch    14] loss: 136.95895\n",
      "[epoch 60, batch    15] loss: 127.96708\n",
      "[epoch 60, batch    16] loss: 150.17420\n",
      "[epoch 60, batch    17] loss: 130.34826\n",
      "[epoch 60, batch    18] loss: 128.25045\n",
      "[epoch 60, batch    19] loss: 150.80941\n",
      "[epoch 60, batch    20] loss: 131.79872\n",
      "[epoch 60, batch    21] loss: 121.89934\n",
      "[epoch 60, batch    22] loss: 139.74537\n",
      "[epoch 60, batch    23] loss: 132.44153\n",
      "[epoch 60, batch    24] loss: 135.19058\n",
      "[epoch 60, batch    25] loss: 145.82745\n",
      "[epoch 60, batch    26] loss: 129.70919\n",
      "[epoch 60, batch    27] loss: 145.42066\n",
      "[epoch 60, batch    28] loss: 135.45885\n",
      "[epoch 60, batch    29] loss: 128.30775\n",
      "[epoch 60, batch    30] loss: 143.00035\n",
      "[epoch 60, batch    31] loss: 137.73231\n",
      "[epoch 60, batch    32] loss: 29.73890\n",
      "[epoch 61, batch     1] loss: 140.54696\n",
      "[epoch 61, batch     2] loss: 136.44812\n",
      "[epoch 61, batch     3] loss: 129.66679\n",
      "[epoch 61, batch     4] loss: 135.42954\n",
      "[epoch 61, batch     5] loss: 134.31744\n",
      "[epoch 61, batch     6] loss: 147.33795\n",
      "[epoch 61, batch     7] loss: 141.98166\n",
      "[epoch 61, batch     8] loss: 141.11583\n",
      "[epoch 61, batch     9] loss: 146.65195\n",
      "[epoch 61, batch    10] loss: 133.92396\n",
      "[epoch 61, batch    11] loss: 144.00217\n",
      "[epoch 61, batch    12] loss: 142.99551\n",
      "[epoch 61, batch    13] loss: 154.91224\n",
      "[epoch 61, batch    14] loss: 138.11364\n",
      "[epoch 61, batch    15] loss: 132.00769\n",
      "[epoch 61, batch    16] loss: 131.75083\n",
      "[epoch 61, batch    17] loss: 133.06786\n",
      "[epoch 61, batch    18] loss: 135.45831\n",
      "[epoch 61, batch    19] loss: 145.34671\n",
      "[epoch 61, batch    20] loss: 129.42826\n",
      "[epoch 61, batch    21] loss: 146.53168\n",
      "[epoch 61, batch    22] loss: 139.23324\n",
      "[epoch 61, batch    23] loss: 132.84182\n",
      "[epoch 61, batch    24] loss: 141.74161\n",
      "[epoch 61, batch    25] loss: 132.50275\n",
      "[epoch 61, batch    26] loss: 129.97935\n",
      "[epoch 61, batch    27] loss: 125.51589\n",
      "[epoch 61, batch    28] loss: 132.11322\n",
      "[epoch 61, batch    29] loss: 138.74570\n",
      "[epoch 61, batch    30] loss: 117.79746\n",
      "[epoch 61, batch    31] loss: 133.47180\n",
      "[epoch 61, batch    32] loss: 32.07973\n",
      "[epoch 62, batch     1] loss: 136.22848\n",
      "[epoch 62, batch     2] loss: 147.85730\n",
      "[epoch 62, batch     3] loss: 146.11956\n",
      "[epoch 62, batch     4] loss: 131.62106\n",
      "[epoch 62, batch     5] loss: 136.00222\n",
      "[epoch 62, batch     6] loss: 135.31358\n",
      "[epoch 62, batch     7] loss: 134.71694\n",
      "[epoch 62, batch     8] loss: 145.93856\n",
      "[epoch 62, batch     9] loss: 134.36150\n",
      "[epoch 62, batch    10] loss: 146.66817\n",
      "[epoch 62, batch    11] loss: 142.42273\n",
      "[epoch 62, batch    12] loss: 129.54838\n",
      "[epoch 62, batch    13] loss: 144.43652\n",
      "[epoch 62, batch    14] loss: 141.40776\n",
      "[epoch 62, batch    15] loss: 120.93500\n",
      "[epoch 62, batch    16] loss: 145.28519\n",
      "[epoch 62, batch    17] loss: 124.73475\n",
      "[epoch 62, batch    18] loss: 149.14475\n",
      "[epoch 62, batch    19] loss: 135.24184\n",
      "[epoch 62, batch    20] loss: 134.33387\n",
      "[epoch 62, batch    21] loss: 135.09551\n",
      "[epoch 62, batch    22] loss: 132.01721\n",
      "[epoch 62, batch    23] loss: 130.29006\n",
      "[epoch 62, batch    24] loss: 124.46534\n",
      "[epoch 62, batch    25] loss: 135.29354\n",
      "[epoch 62, batch    26] loss: 118.00872\n",
      "[epoch 62, batch    27] loss: 129.76505\n",
      "[epoch 62, batch    28] loss: 133.13806\n",
      "[epoch 62, batch    29] loss: 136.24940\n",
      "[epoch 62, batch    30] loss: 137.03346\n",
      "[epoch 62, batch    31] loss: 118.61761\n",
      "[epoch 62, batch    32] loss: 33.51019\n",
      "[epoch 63, batch     1] loss: 121.75182\n",
      "[epoch 63, batch     2] loss: 141.18199\n",
      "[epoch 63, batch     3] loss: 145.48456\n",
      "[epoch 63, batch     4] loss: 137.57985\n",
      "[epoch 63, batch     5] loss: 136.56259\n",
      "[epoch 63, batch     6] loss: 142.14045\n",
      "[epoch 63, batch     7] loss: 137.44785\n",
      "[epoch 63, batch     8] loss: 138.78533\n",
      "[epoch 63, batch     9] loss: 131.49869\n",
      "[epoch 63, batch    10] loss: 129.74443\n",
      "[epoch 63, batch    11] loss: 140.62747\n",
      "[epoch 63, batch    12] loss: 141.88859\n",
      "[epoch 63, batch    13] loss: 127.45776\n",
      "[epoch 63, batch    14] loss: 146.87096\n",
      "[epoch 63, batch    15] loss: 129.92460\n",
      "[epoch 63, batch    16] loss: 142.22578\n",
      "[epoch 63, batch    17] loss: 139.76721\n",
      "[epoch 63, batch    18] loss: 135.93080\n",
      "[epoch 63, batch    19] loss: 143.81014\n",
      "[epoch 63, batch    20] loss: 135.48908\n",
      "[epoch 63, batch    21] loss: 149.46294\n",
      "[epoch 63, batch    22] loss: 126.28667\n",
      "[epoch 63, batch    23] loss: 133.88175\n",
      "[epoch 63, batch    24] loss: 123.45196\n",
      "[epoch 63, batch    25] loss: 143.56301\n",
      "[epoch 63, batch    26] loss: 128.78148\n",
      "[epoch 63, batch    27] loss: 134.71088\n",
      "[epoch 63, batch    28] loss: 151.35743\n",
      "[epoch 63, batch    29] loss: 124.05050\n",
      "[epoch 63, batch    30] loss: 140.88789\n",
      "[epoch 63, batch    31] loss: 140.01514\n",
      "[epoch 63, batch    32] loss: 35.39356\n",
      "[epoch 64, batch     1] loss: 149.84226\n",
      "[epoch 64, batch     2] loss: 135.97774\n",
      "[epoch 64, batch     3] loss: 133.06818\n",
      "[epoch 64, batch     4] loss: 150.54686\n",
      "[epoch 64, batch     5] loss: 132.53748\n",
      "[epoch 64, batch     6] loss: 131.32636\n",
      "[epoch 64, batch     7] loss: 136.13569\n",
      "[epoch 64, batch     8] loss: 125.74844\n",
      "[epoch 64, batch     9] loss: 127.49977\n",
      "[epoch 64, batch    10] loss: 139.95867\n",
      "[epoch 64, batch    11] loss: 137.96875\n",
      "[epoch 64, batch    12] loss: 129.99912\n",
      "[epoch 64, batch    13] loss: 144.53998\n",
      "[epoch 64, batch    14] loss: 128.03717\n",
      "[epoch 64, batch    15] loss: 140.11901\n",
      "[epoch 64, batch    16] loss: 143.39967\n",
      "[epoch 64, batch    17] loss: 140.31285\n",
      "[epoch 64, batch    18] loss: 136.43833\n",
      "[epoch 64, batch    19] loss: 137.76092\n",
      "[epoch 64, batch    20] loss: 128.85273\n",
      "[epoch 64, batch    21] loss: 135.53052\n",
      "[epoch 64, batch    22] loss: 125.07865\n",
      "[epoch 64, batch    23] loss: 144.00473\n",
      "[epoch 64, batch    24] loss: 139.30810\n",
      "[epoch 64, batch    25] loss: 139.18100\n",
      "[epoch 64, batch    26] loss: 131.75332\n",
      "[epoch 64, batch    27] loss: 132.82516\n",
      "[epoch 64, batch    28] loss: 163.58598\n",
      "[epoch 64, batch    29] loss: 134.46872\n",
      "[epoch 64, batch    30] loss: 134.65909\n",
      "[epoch 64, batch    31] loss: 123.90750\n",
      "[epoch 64, batch    32] loss: 32.53321\n",
      "[epoch 65, batch     1] loss: 125.12493\n",
      "[epoch 65, batch     2] loss: 135.18287\n",
      "[epoch 65, batch     3] loss: 147.17957\n",
      "[epoch 65, batch     4] loss: 146.57141\n",
      "[epoch 65, batch     5] loss: 132.64857\n",
      "[epoch 65, batch     6] loss: 138.28755\n",
      "[epoch 65, batch     7] loss: 137.50816\n",
      "[epoch 65, batch     8] loss: 121.98958\n",
      "[epoch 65, batch     9] loss: 128.40325\n",
      "[epoch 65, batch    10] loss: 169.12839\n",
      "[epoch 65, batch    11] loss: 136.99057\n",
      "[epoch 65, batch    12] loss: 126.97473\n",
      "[epoch 65, batch    13] loss: 126.58947\n",
      "[epoch 65, batch    14] loss: 132.66352\n",
      "[epoch 65, batch    15] loss: 139.48836\n",
      "[epoch 65, batch    16] loss: 140.82310\n",
      "[epoch 65, batch    17] loss: 124.46151\n",
      "[epoch 65, batch    18] loss: 141.83006\n",
      "[epoch 65, batch    19] loss: 140.74383\n",
      "[epoch 65, batch    20] loss: 135.62938\n",
      "[epoch 65, batch    21] loss: 140.57001\n",
      "[epoch 65, batch    22] loss: 134.07256\n",
      "[epoch 65, batch    23] loss: 142.37112\n",
      "[epoch 65, batch    24] loss: 139.00687\n",
      "[epoch 65, batch    25] loss: 141.99241\n",
      "[epoch 65, batch    26] loss: 140.37408\n",
      "[epoch 65, batch    27] loss: 123.37321\n",
      "[epoch 65, batch    28] loss: 122.49881\n",
      "[epoch 65, batch    29] loss: 128.60329\n",
      "[epoch 65, batch    30] loss: 133.58870\n",
      "[epoch 65, batch    31] loss: 144.84409\n",
      "[epoch 65, batch    32] loss: 38.81969\n",
      "[epoch 66, batch     1] loss: 138.33092\n",
      "[epoch 66, batch     2] loss: 131.36300\n",
      "[epoch 66, batch     3] loss: 134.86826\n",
      "[epoch 66, batch     4] loss: 125.58211\n",
      "[epoch 66, batch     5] loss: 147.07645\n",
      "[epoch 66, batch     6] loss: 134.52851\n",
      "[epoch 66, batch     7] loss: 129.01951\n",
      "[epoch 66, batch     8] loss: 121.75974\n",
      "[epoch 66, batch     9] loss: 131.45939\n",
      "[epoch 66, batch    10] loss: 128.62905\n",
      "[epoch 66, batch    11] loss: 141.66012\n",
      "[epoch 66, batch    12] loss: 143.48416\n",
      "[epoch 66, batch    13] loss: 139.51718\n",
      "[epoch 66, batch    14] loss: 117.36714\n",
      "[epoch 66, batch    15] loss: 127.50762\n",
      "[epoch 66, batch    16] loss: 134.52353\n",
      "[epoch 66, batch    17] loss: 122.89100\n",
      "[epoch 66, batch    18] loss: 130.21198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 66, batch    19] loss: 138.68567\n",
      "[epoch 66, batch    20] loss: 132.85439\n",
      "[epoch 66, batch    21] loss: 131.13142\n",
      "[epoch 66, batch    22] loss: 132.52917\n",
      "[epoch 66, batch    23] loss: 144.95225\n",
      "[epoch 66, batch    24] loss: 136.84129\n",
      "[epoch 66, batch    25] loss: 123.44998\n",
      "[epoch 66, batch    26] loss: 137.17496\n",
      "[epoch 66, batch    27] loss: 144.49065\n",
      "[epoch 66, batch    28] loss: 139.44781\n",
      "[epoch 66, batch    29] loss: 138.14208\n",
      "[epoch 66, batch    30] loss: 149.91886\n",
      "[epoch 66, batch    31] loss: 126.28124\n",
      "[epoch 66, batch    32] loss: 34.76688\n",
      "[epoch 67, batch     1] loss: 129.82361\n",
      "[epoch 67, batch     2] loss: 127.76792\n",
      "[epoch 67, batch     3] loss: 135.34650\n",
      "[epoch 67, batch     4] loss: 123.09343\n",
      "[epoch 67, batch     5] loss: 126.27338\n",
      "[epoch 67, batch     6] loss: 137.76327\n",
      "[epoch 67, batch     7] loss: 135.06736\n",
      "[epoch 67, batch     8] loss: 118.72977\n",
      "[epoch 67, batch     9] loss: 133.41863\n",
      "[epoch 67, batch    10] loss: 141.63997\n",
      "[epoch 67, batch    11] loss: 146.40534\n",
      "[epoch 67, batch    12] loss: 134.37159\n",
      "[epoch 67, batch    13] loss: 128.90984\n",
      "[epoch 67, batch    14] loss: 149.67019\n",
      "[epoch 67, batch    15] loss: 137.15731\n",
      "[epoch 67, batch    16] loss: 123.84246\n",
      "[epoch 67, batch    17] loss: 131.45112\n",
      "[epoch 67, batch    18] loss: 138.90145\n",
      "[epoch 67, batch    19] loss: 126.93612\n",
      "[epoch 67, batch    20] loss: 132.42672\n",
      "[epoch 67, batch    21] loss: 143.41879\n",
      "[epoch 67, batch    22] loss: 139.44485\n",
      "[epoch 67, batch    23] loss: 134.15843\n",
      "[epoch 67, batch    24] loss: 132.54054\n",
      "[epoch 67, batch    25] loss: 127.66123\n",
      "[epoch 67, batch    26] loss: 128.24130\n",
      "[epoch 67, batch    27] loss: 138.15799\n",
      "[epoch 67, batch    28] loss: 131.36543\n",
      "[epoch 67, batch    29] loss: 138.75660\n",
      "[epoch 67, batch    30] loss: 136.02544\n",
      "[epoch 67, batch    31] loss: 141.55947\n",
      "[epoch 67, batch    32] loss: 30.50532\n",
      "[epoch 68, batch     1] loss: 154.77026\n",
      "[epoch 68, batch     2] loss: 133.39693\n",
      "[epoch 68, batch     3] loss: 136.82564\n",
      "[epoch 68, batch     4] loss: 138.04919\n",
      "[epoch 68, batch     5] loss: 134.30292\n",
      "[epoch 68, batch     6] loss: 133.67680\n",
      "[epoch 68, batch     7] loss: 134.13912\n",
      "[epoch 68, batch     8] loss: 122.15185\n",
      "[epoch 68, batch     9] loss: 120.12383\n",
      "[epoch 68, batch    10] loss: 127.22558\n",
      "[epoch 68, batch    11] loss: 138.56637\n",
      "[epoch 68, batch    12] loss: 129.72165\n",
      "[epoch 68, batch    13] loss: 134.17156\n",
      "[epoch 68, batch    14] loss: 146.13239\n",
      "[epoch 68, batch    15] loss: 143.00404\n",
      "[epoch 68, batch    16] loss: 128.05066\n",
      "[epoch 68, batch    17] loss: 151.57224\n",
      "[epoch 68, batch    18] loss: 122.93421\n",
      "[epoch 68, batch    19] loss: 129.08411\n",
      "[epoch 68, batch    20] loss: 143.85515\n",
      "[epoch 68, batch    21] loss: 141.06193\n",
      "[epoch 68, batch    22] loss: 142.23549\n",
      "[epoch 68, batch    23] loss: 132.81094\n",
      "[epoch 68, batch    24] loss: 143.11691\n",
      "[epoch 68, batch    25] loss: 130.15158\n",
      "[epoch 68, batch    26] loss: 152.01757\n",
      "[epoch 68, batch    27] loss: 136.19389\n",
      "[epoch 68, batch    28] loss: 134.76422\n",
      "[epoch 68, batch    29] loss: 137.71312\n",
      "[epoch 68, batch    30] loss: 125.54929\n",
      "[epoch 68, batch    31] loss: 139.96990\n",
      "[epoch 68, batch    32] loss: 40.19609\n",
      "[epoch 69, batch     1] loss: 128.17826\n",
      "[epoch 69, batch     2] loss: 133.07370\n",
      "[epoch 69, batch     3] loss: 132.96263\n",
      "[epoch 69, batch     4] loss: 146.39085\n",
      "[epoch 69, batch     5] loss: 149.86025\n",
      "[epoch 69, batch     6] loss: 138.04934\n",
      "[epoch 69, batch     7] loss: 143.73559\n",
      "[epoch 69, batch     8] loss: 143.50788\n",
      "[epoch 69, batch     9] loss: 124.44908\n",
      "[epoch 69, batch    10] loss: 133.50729\n",
      "[epoch 69, batch    11] loss: 132.79101\n",
      "[epoch 69, batch    12] loss: 141.45560\n",
      "[epoch 69, batch    13] loss: 125.28003\n",
      "[epoch 69, batch    14] loss: 139.05170\n",
      "[epoch 69, batch    15] loss: 144.92135\n",
      "[epoch 69, batch    16] loss: 136.97094\n",
      "[epoch 69, batch    17] loss: 131.39895\n",
      "[epoch 69, batch    18] loss: 139.94342\n",
      "[epoch 69, batch    19] loss: 140.86060\n",
      "[epoch 69, batch    20] loss: 132.17315\n",
      "[epoch 69, batch    21] loss: 129.22244\n",
      "[epoch 69, batch    22] loss: 142.51424\n",
      "[epoch 69, batch    23] loss: 135.96055\n",
      "[epoch 69, batch    24] loss: 141.97379\n",
      "[epoch 69, batch    25] loss: 127.69123\n",
      "[epoch 69, batch    26] loss: 127.26934\n",
      "[epoch 69, batch    27] loss: 126.63373\n",
      "[epoch 69, batch    28] loss: 126.25480\n",
      "[epoch 69, batch    29] loss: 121.86628\n",
      "[epoch 69, batch    30] loss: 141.36441\n",
      "[epoch 69, batch    31] loss: 137.02005\n",
      "[epoch 69, batch    32] loss: 38.16198\n",
      "[epoch 70, batch     1] loss: 125.24082\n",
      "[epoch 70, batch     2] loss: 126.08916\n",
      "[epoch 70, batch     3] loss: 135.69733\n",
      "[epoch 70, batch     4] loss: 138.04949\n",
      "[epoch 70, batch     5] loss: 120.76362\n",
      "[epoch 70, batch     6] loss: 125.97605\n",
      "[epoch 70, batch     7] loss: 136.18514\n",
      "[epoch 70, batch     8] loss: 137.14498\n",
      "[epoch 70, batch     9] loss: 140.52523\n",
      "[epoch 70, batch    10] loss: 151.90683\n",
      "[epoch 70, batch    11] loss: 134.20964\n",
      "[epoch 70, batch    12] loss: 130.46071\n",
      "[epoch 70, batch    13] loss: 130.89092\n",
      "[epoch 70, batch    14] loss: 128.54994\n",
      "[epoch 70, batch    15] loss: 138.99529\n",
      "[epoch 70, batch    16] loss: 134.14892\n",
      "[epoch 70, batch    17] loss: 147.70785\n",
      "[epoch 70, batch    18] loss: 137.56088\n",
      "[epoch 70, batch    19] loss: 145.73977\n",
      "[epoch 70, batch    20] loss: 138.97053\n",
      "[epoch 70, batch    21] loss: 136.34390\n",
      "[epoch 70, batch    22] loss: 127.86042\n",
      "[epoch 70, batch    23] loss: 137.79743\n",
      "[epoch 70, batch    24] loss: 145.28926\n",
      "[epoch 70, batch    25] loss: 129.78145\n",
      "[epoch 70, batch    26] loss: 141.12818\n",
      "[epoch 70, batch    27] loss: 136.81166\n",
      "[epoch 70, batch    28] loss: 147.90590\n",
      "[epoch 70, batch    29] loss: 133.45060\n",
      "[epoch 70, batch    30] loss: 142.83989\n",
      "[epoch 70, batch    31] loss: 137.30964\n",
      "[epoch 70, batch    32] loss: 41.84427\n",
      "[epoch 71, batch     1] loss: 130.96288\n",
      "[epoch 71, batch     2] loss: 121.16856\n",
      "[epoch 71, batch     3] loss: 120.91833\n",
      "[epoch 71, batch     4] loss: 123.83886\n",
      "[epoch 71, batch     5] loss: 143.25797\n",
      "[epoch 71, batch     6] loss: 127.93130\n",
      "[epoch 71, batch     7] loss: 143.92885\n",
      "[epoch 71, batch     8] loss: 126.88388\n",
      "[epoch 71, batch     9] loss: 135.20499\n",
      "[epoch 71, batch    10] loss: 145.61143\n",
      "[epoch 71, batch    11] loss: 129.22330\n",
      "[epoch 71, batch    12] loss: 138.39902\n",
      "[epoch 71, batch    13] loss: 139.86850\n",
      "[epoch 71, batch    14] loss: 128.67519\n",
      "[epoch 71, batch    15] loss: 133.51350\n",
      "[epoch 71, batch    16] loss: 133.57158\n",
      "[epoch 71, batch    17] loss: 129.36794\n",
      "[epoch 71, batch    18] loss: 124.86985\n",
      "[epoch 71, batch    19] loss: 143.52004\n",
      "[epoch 71, batch    20] loss: 125.35703\n",
      "[epoch 71, batch    21] loss: 132.28889\n",
      "[epoch 71, batch    22] loss: 122.85961\n",
      "[epoch 71, batch    23] loss: 136.21505\n",
      "[epoch 71, batch    24] loss: 127.23182\n",
      "[epoch 71, batch    25] loss: 130.22302\n",
      "[epoch 71, batch    26] loss: 140.61908\n",
      "[epoch 71, batch    27] loss: 139.81222\n",
      "[epoch 71, batch    28] loss: 138.22415\n",
      "[epoch 71, batch    29] loss: 139.81612\n",
      "[epoch 71, batch    30] loss: 132.00134\n",
      "[epoch 71, batch    31] loss: 123.92948\n",
      "[epoch 71, batch    32] loss: 35.46431\n",
      "[epoch 72, batch     1] loss: 136.79241\n",
      "[epoch 72, batch     2] loss: 131.30923\n",
      "[epoch 72, batch     3] loss: 143.61214\n",
      "[epoch 72, batch     4] loss: 122.49042\n",
      "[epoch 72, batch     5] loss: 136.94303\n",
      "[epoch 72, batch     6] loss: 130.41062\n",
      "[epoch 72, batch     7] loss: 131.67912\n",
      "[epoch 72, batch     8] loss: 142.03976\n",
      "[epoch 72, batch     9] loss: 144.83446\n",
      "[epoch 72, batch    10] loss: 131.57193\n",
      "[epoch 72, batch    11] loss: 126.13545\n",
      "[epoch 72, batch    12] loss: 157.77176\n",
      "[epoch 72, batch    13] loss: 138.47942\n",
      "[epoch 72, batch    14] loss: 138.38913\n",
      "[epoch 72, batch    15] loss: 127.10199\n",
      "[epoch 72, batch    16] loss: 123.61347\n",
      "[epoch 72, batch    17] loss: 131.76935\n",
      "[epoch 72, batch    18] loss: 145.13861\n",
      "[epoch 72, batch    19] loss: 150.12528\n",
      "[epoch 72, batch    20] loss: 136.49377\n",
      "[epoch 72, batch    21] loss: 128.17590\n",
      "[epoch 72, batch    22] loss: 130.50259\n",
      "[epoch 72, batch    23] loss: 127.24568\n",
      "[epoch 72, batch    24] loss: 141.26585\n",
      "[epoch 72, batch    25] loss: 134.69805\n",
      "[epoch 72, batch    26] loss: 125.85091\n",
      "[epoch 72, batch    27] loss: 133.56517\n",
      "[epoch 72, batch    28] loss: 137.49837\n",
      "[epoch 72, batch    29] loss: 139.54672\n",
      "[epoch 72, batch    30] loss: 133.93006\n",
      "[epoch 72, batch    31] loss: 126.52905\n",
      "[epoch 72, batch    32] loss: 24.20915\n",
      "[epoch 73, batch     1] loss: 137.71924\n",
      "[epoch 73, batch     2] loss: 133.12900\n",
      "[epoch 73, batch     3] loss: 136.65216\n",
      "[epoch 73, batch     4] loss: 135.42174\n",
      "[epoch 73, batch     5] loss: 134.36395\n",
      "[epoch 73, batch     6] loss: 125.87162\n",
      "[epoch 73, batch     7] loss: 140.30483\n",
      "[epoch 73, batch     8] loss: 141.29120\n",
      "[epoch 73, batch     9] loss: 141.10819\n",
      "[epoch 73, batch    10] loss: 128.82200\n",
      "[epoch 73, batch    11] loss: 131.95192\n",
      "[epoch 73, batch    12] loss: 129.14245\n",
      "[epoch 73, batch    13] loss: 134.02261\n",
      "[epoch 73, batch    14] loss: 138.21813\n",
      "[epoch 73, batch    15] loss: 132.93833\n",
      "[epoch 73, batch    16] loss: 153.12050\n",
      "[epoch 73, batch    17] loss: 147.79519\n",
      "[epoch 73, batch    18] loss: 138.28500\n",
      "[epoch 73, batch    19] loss: 124.65390\n",
      "[epoch 73, batch    20] loss: 132.29200\n",
      "[epoch 73, batch    21] loss: 127.92999\n",
      "[epoch 73, batch    22] loss: 145.65055\n",
      "[epoch 73, batch    23] loss: 155.85303\n",
      "[epoch 73, batch    24] loss: 141.08138\n",
      "[epoch 73, batch    25] loss: 132.11847\n",
      "[epoch 73, batch    26] loss: 125.04537\n",
      "[epoch 73, batch    27] loss: 139.93123\n",
      "[epoch 73, batch    28] loss: 148.05858\n",
      "[epoch 73, batch    29] loss: 140.87543\n",
      "[epoch 73, batch    30] loss: 126.56922\n",
      "[epoch 73, batch    31] loss: 135.34819\n",
      "[epoch 73, batch    32] loss: 34.08543\n",
      "[epoch 74, batch     1] loss: 130.14154\n",
      "[epoch 74, batch     2] loss: 130.57080\n",
      "[epoch 74, batch     3] loss: 129.44368\n",
      "[epoch 74, batch     4] loss: 145.63165\n",
      "[epoch 74, batch     5] loss: 135.21574\n",
      "[epoch 74, batch     6] loss: 129.68238\n",
      "[epoch 74, batch     7] loss: 141.15142\n",
      "[epoch 74, batch     8] loss: 142.70959\n",
      "[epoch 74, batch     9] loss: 131.38027\n",
      "[epoch 74, batch    10] loss: 134.39470\n",
      "[epoch 74, batch    11] loss: 136.93696\n",
      "[epoch 74, batch    12] loss: 147.81082\n",
      "[epoch 74, batch    13] loss: 127.94058\n",
      "[epoch 74, batch    14] loss: 141.63133\n",
      "[epoch 74, batch    15] loss: 134.35866\n",
      "[epoch 74, batch    16] loss: 127.30334\n",
      "[epoch 74, batch    17] loss: 130.59827\n",
      "[epoch 74, batch    18] loss: 145.97652\n",
      "[epoch 74, batch    19] loss: 126.26891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 74, batch    20] loss: 136.84207\n",
      "[epoch 74, batch    21] loss: 136.46977\n",
      "[epoch 74, batch    22] loss: 145.08590\n",
      "[epoch 74, batch    23] loss: 136.30484\n",
      "[epoch 74, batch    24] loss: 124.73372\n",
      "[epoch 74, batch    25] loss: 130.51197\n",
      "[epoch 74, batch    26] loss: 131.59572\n",
      "[epoch 74, batch    27] loss: 127.26060\n",
      "[epoch 74, batch    28] loss: 143.53596\n",
      "[epoch 74, batch    29] loss: 127.85158\n",
      "[epoch 74, batch    30] loss: 122.93476\n",
      "[epoch 74, batch    31] loss: 129.08418\n",
      "[epoch 74, batch    32] loss: 29.48013\n",
      "[epoch 75, batch     1] loss: 137.12474\n",
      "[epoch 75, batch     2] loss: 127.24697\n",
      "[epoch 75, batch     3] loss: 146.92520\n",
      "[epoch 75, batch     4] loss: 143.73721\n",
      "[epoch 75, batch     5] loss: 144.49712\n",
      "[epoch 75, batch     6] loss: 142.58895\n",
      "[epoch 75, batch     7] loss: 138.53330\n",
      "[epoch 75, batch     8] loss: 123.93287\n",
      "[epoch 75, batch     9] loss: 125.36270\n",
      "[epoch 75, batch    10] loss: 134.74958\n",
      "[epoch 75, batch    11] loss: 126.37684\n",
      "[epoch 75, batch    12] loss: 131.42980\n",
      "[epoch 75, batch    13] loss: 145.93010\n",
      "[epoch 75, batch    14] loss: 132.39192\n",
      "[epoch 75, batch    15] loss: 126.71883\n",
      "[epoch 75, batch    16] loss: 141.88162\n",
      "[epoch 75, batch    17] loss: 132.31869\n",
      "[epoch 75, batch    18] loss: 133.33572\n",
      "[epoch 75, batch    19] loss: 130.69194\n",
      "[epoch 75, batch    20] loss: 119.92097\n",
      "[epoch 75, batch    21] loss: 128.15641\n",
      "[epoch 75, batch    22] loss: 132.95011\n",
      "[epoch 75, batch    23] loss: 135.63078\n",
      "[epoch 75, batch    24] loss: 141.34181\n",
      "[epoch 75, batch    25] loss: 132.53356\n",
      "[epoch 75, batch    26] loss: 139.01565\n",
      "[epoch 75, batch    27] loss: 139.64000\n",
      "[epoch 75, batch    28] loss: 156.09818\n",
      "[epoch 75, batch    29] loss: 133.31171\n",
      "[epoch 75, batch    30] loss: 140.01941\n",
      "[epoch 75, batch    31] loss: 131.22072\n",
      "[epoch 75, batch    32] loss: 31.97240\n",
      "[epoch 76, batch     1] loss: 141.21405\n",
      "[epoch 76, batch     2] loss: 134.01099\n",
      "[epoch 76, batch     3] loss: 135.77047\n",
      "[epoch 76, batch     4] loss: 130.67676\n",
      "[epoch 76, batch     5] loss: 130.85280\n",
      "[epoch 76, batch     6] loss: 131.06160\n",
      "[epoch 76, batch     7] loss: 141.81142\n",
      "[epoch 76, batch     8] loss: 143.88019\n",
      "[epoch 76, batch     9] loss: 121.40864\n",
      "[epoch 76, batch    10] loss: 128.41501\n",
      "[epoch 76, batch    11] loss: 136.00011\n",
      "[epoch 76, batch    12] loss: 140.86271\n",
      "[epoch 76, batch    13] loss: 133.00742\n",
      "[epoch 76, batch    14] loss: 133.44826\n",
      "[epoch 76, batch    15] loss: 140.17999\n",
      "[epoch 76, batch    16] loss: 133.05736\n",
      "[epoch 76, batch    17] loss: 154.77996\n",
      "[epoch 76, batch    18] loss: 135.07176\n",
      "[epoch 76, batch    19] loss: 136.04186\n",
      "[epoch 76, batch    20] loss: 131.94039\n",
      "[epoch 76, batch    21] loss: 134.23824\n",
      "[epoch 76, batch    22] loss: 125.55785\n",
      "[epoch 76, batch    23] loss: 132.53970\n",
      "[epoch 76, batch    24] loss: 142.23296\n",
      "[epoch 76, batch    25] loss: 127.87281\n",
      "[epoch 76, batch    26] loss: 134.63491\n",
      "[epoch 76, batch    27] loss: 125.47444\n",
      "[epoch 76, batch    28] loss: 141.15874\n",
      "[epoch 76, batch    29] loss: 137.60119\n",
      "[epoch 76, batch    30] loss: 127.78793\n",
      "[epoch 76, batch    31] loss: 135.38920\n",
      "[epoch 76, batch    32] loss: 40.16612\n",
      "[epoch 77, batch     1] loss: 128.67825\n",
      "[epoch 77, batch     2] loss: 143.67118\n",
      "[epoch 77, batch     3] loss: 135.66755\n",
      "[epoch 77, batch     4] loss: 132.10940\n",
      "[epoch 77, batch     5] loss: 122.23739\n",
      "[epoch 77, batch     6] loss: 134.91122\n",
      "[epoch 77, batch     7] loss: 147.10620\n",
      "[epoch 77, batch     8] loss: 134.43302\n",
      "[epoch 77, batch     9] loss: 131.60364\n",
      "[epoch 77, batch    10] loss: 141.94978\n",
      "[epoch 77, batch    11] loss: 133.67951\n",
      "[epoch 77, batch    12] loss: 136.57220\n",
      "[epoch 77, batch    13] loss: 135.74577\n",
      "[epoch 77, batch    14] loss: 132.89643\n",
      "[epoch 77, batch    15] loss: 128.25606\n",
      "[epoch 77, batch    16] loss: 131.65432\n",
      "[epoch 77, batch    17] loss: 141.05507\n",
      "[epoch 77, batch    18] loss: 144.22542\n",
      "[epoch 77, batch    19] loss: 144.90811\n",
      "[epoch 77, batch    20] loss: 130.78651\n",
      "[epoch 77, batch    21] loss: 128.39468\n",
      "[epoch 77, batch    22] loss: 146.66079\n",
      "[epoch 77, batch    23] loss: 117.71376\n",
      "[epoch 77, batch    24] loss: 135.72030\n",
      "[epoch 77, batch    25] loss: 126.75406\n",
      "[epoch 77, batch    26] loss: 120.23778\n",
      "[epoch 77, batch    27] loss: 136.89907\n",
      "[epoch 77, batch    28] loss: 134.38525\n",
      "[epoch 77, batch    29] loss: 139.02566\n",
      "[epoch 77, batch    30] loss: 127.60303\n",
      "[epoch 77, batch    31] loss: 131.32782\n",
      "[epoch 77, batch    32] loss: 39.02373\n",
      "[epoch 78, batch     1] loss: 136.73575\n",
      "[epoch 78, batch     2] loss: 144.15167\n",
      "[epoch 78, batch     3] loss: 143.54834\n",
      "[epoch 78, batch     4] loss: 130.00438\n",
      "[epoch 78, batch     5] loss: 138.26379\n",
      "[epoch 78, batch     6] loss: 117.97249\n",
      "[epoch 78, batch     7] loss: 128.37420\n",
      "[epoch 78, batch     8] loss: 131.40348\n",
      "[epoch 78, batch     9] loss: 130.48790\n",
      "[epoch 78, batch    10] loss: 161.46835\n",
      "[epoch 78, batch    11] loss: 144.17226\n",
      "[epoch 78, batch    12] loss: 134.51588\n",
      "[epoch 78, batch    13] loss: 139.63142\n",
      "[epoch 78, batch    14] loss: 128.00519\n",
      "[epoch 78, batch    15] loss: 143.90259\n",
      "[epoch 78, batch    16] loss: 141.68087\n",
      "[epoch 78, batch    17] loss: 136.34347\n",
      "[epoch 78, batch    18] loss: 133.18072\n",
      "[epoch 78, batch    19] loss: 135.18288\n",
      "[epoch 78, batch    20] loss: 131.42727\n",
      "[epoch 78, batch    21] loss: 132.42047\n",
      "[epoch 78, batch    22] loss: 130.50630\n",
      "[epoch 78, batch    23] loss: 131.44019\n",
      "[epoch 78, batch    24] loss: 124.15046\n",
      "[epoch 78, batch    25] loss: 138.90423\n",
      "[epoch 78, batch    26] loss: 135.53424\n",
      "[epoch 78, batch    27] loss: 124.02311\n",
      "[epoch 78, batch    28] loss: 141.33664\n",
      "[epoch 78, batch    29] loss: 131.74070\n",
      "[epoch 78, batch    30] loss: 132.53346\n",
      "[epoch 78, batch    31] loss: 136.91690\n",
      "[epoch 78, batch    32] loss: 34.34012\n",
      "[epoch 79, batch     1] loss: 131.87295\n",
      "[epoch 79, batch     2] loss: 121.07332\n",
      "[epoch 79, batch     3] loss: 132.47731\n",
      "[epoch 79, batch     4] loss: 139.97487\n",
      "[epoch 79, batch     5] loss: 124.70193\n",
      "[epoch 79, batch     6] loss: 116.68778\n",
      "[epoch 79, batch     7] loss: 148.09290\n",
      "[epoch 79, batch     8] loss: 134.28495\n",
      "[epoch 79, batch     9] loss: 130.65905\n",
      "[epoch 79, batch    10] loss: 131.76589\n",
      "[epoch 79, batch    11] loss: 140.95378\n",
      "[epoch 79, batch    12] loss: 133.41661\n",
      "[epoch 79, batch    13] loss: 140.12770\n",
      "[epoch 79, batch    14] loss: 141.45933\n",
      "[epoch 79, batch    15] loss: 133.04259\n",
      "[epoch 79, batch    16] loss: 141.37876\n",
      "[epoch 79, batch    17] loss: 121.43753\n",
      "[epoch 79, batch    18] loss: 138.67229\n",
      "[epoch 79, batch    19] loss: 130.66548\n",
      "[epoch 79, batch    20] loss: 132.56156\n",
      "[epoch 79, batch    21] loss: 133.31348\n",
      "[epoch 79, batch    22] loss: 130.57496\n",
      "[epoch 79, batch    23] loss: 144.39208\n",
      "[epoch 79, batch    24] loss: 133.83867\n",
      "[epoch 79, batch    25] loss: 123.10956\n",
      "[epoch 79, batch    26] loss: 151.30438\n",
      "[epoch 79, batch    27] loss: 143.14624\n",
      "[epoch 79, batch    28] loss: 125.05913\n",
      "[epoch 79, batch    29] loss: 130.21804\n",
      "[epoch 79, batch    30] loss: 131.55920\n",
      "[epoch 79, batch    31] loss: 140.39902\n",
      "[epoch 79, batch    32] loss: 35.52889\n",
      "[epoch 80, batch     1] loss: 137.95590\n",
      "[epoch 80, batch     2] loss: 129.59441\n",
      "[epoch 80, batch     3] loss: 128.56596\n",
      "[epoch 80, batch     4] loss: 140.60931\n",
      "[epoch 80, batch     5] loss: 143.44434\n",
      "[epoch 80, batch     6] loss: 137.08427\n",
      "[epoch 80, batch     7] loss: 122.43498\n",
      "[epoch 80, batch     8] loss: 140.33313\n",
      "[epoch 80, batch     9] loss: 124.16371\n",
      "[epoch 80, batch    10] loss: 127.04543\n",
      "[epoch 80, batch    11] loss: 135.40246\n",
      "[epoch 80, batch    12] loss: 127.15055\n",
      "[epoch 80, batch    13] loss: 139.28087\n",
      "[epoch 80, batch    14] loss: 130.48169\n",
      "[epoch 80, batch    15] loss: 142.78419\n",
      "[epoch 80, batch    16] loss: 131.29496\n",
      "[epoch 80, batch    17] loss: 133.05087\n",
      "[epoch 80, batch    18] loss: 133.23729\n",
      "[epoch 80, batch    19] loss: 125.22999\n",
      "[epoch 80, batch    20] loss: 133.79787\n",
      "[epoch 80, batch    21] loss: 124.46320\n",
      "[epoch 80, batch    22] loss: 137.57399\n",
      "[epoch 80, batch    23] loss: 117.71794\n",
      "[epoch 80, batch    24] loss: 123.45985\n",
      "[epoch 80, batch    25] loss: 133.70317\n",
      "[epoch 80, batch    26] loss: 141.24774\n",
      "[epoch 80, batch    27] loss: 128.39391\n",
      "[epoch 80, batch    28] loss: 135.85642\n",
      "[epoch 80, batch    29] loss: 146.67947\n",
      "[epoch 80, batch    30] loss: 136.27549\n",
      "[epoch 80, batch    31] loss: 137.47561\n",
      "[epoch 80, batch    32] loss: 33.50025\n",
      "[epoch 81, batch     1] loss: 127.42375\n",
      "[epoch 81, batch     2] loss: 136.47898\n",
      "[epoch 81, batch     3] loss: 132.49450\n",
      "[epoch 81, batch     4] loss: 135.90455\n",
      "[epoch 81, batch     5] loss: 135.80938\n",
      "[epoch 81, batch     6] loss: 133.95311\n",
      "[epoch 81, batch     7] loss: 130.54690\n",
      "[epoch 81, batch     8] loss: 133.13535\n",
      "[epoch 81, batch     9] loss: 135.48474\n",
      "[epoch 81, batch    10] loss: 149.43688\n",
      "[epoch 81, batch    11] loss: 115.62234\n",
      "[epoch 81, batch    12] loss: 131.60710\n",
      "[epoch 81, batch    13] loss: 136.98700\n",
      "[epoch 81, batch    14] loss: 124.45249\n",
      "[epoch 81, batch    15] loss: 137.62207\n",
      "[epoch 81, batch    16] loss: 156.16846\n",
      "[epoch 81, batch    17] loss: 133.03455\n",
      "[epoch 81, batch    18] loss: 150.15814\n",
      "[epoch 81, batch    19] loss: 140.30129\n",
      "[epoch 81, batch    20] loss: 150.19751\n",
      "[epoch 81, batch    21] loss: 131.68525\n",
      "[epoch 81, batch    22] loss: 126.46147\n",
      "[epoch 81, batch    23] loss: 155.54379\n",
      "[epoch 81, batch    24] loss: 119.86733\n",
      "[epoch 81, batch    25] loss: 120.22539\n",
      "[epoch 81, batch    26] loss: 128.58049\n",
      "[epoch 81, batch    27] loss: 132.35724\n",
      "[epoch 81, batch    28] loss: 149.52612\n",
      "[epoch 81, batch    29] loss: 145.67025\n",
      "[epoch 81, batch    30] loss: 145.04935\n",
      "[epoch 81, batch    31] loss: 121.58383\n",
      "[epoch 81, batch    32] loss: 31.02203\n",
      "[epoch 82, batch     1] loss: 128.82023\n",
      "[epoch 82, batch     2] loss: 130.75657\n",
      "[epoch 82, batch     3] loss: 140.97719\n",
      "[epoch 82, batch     4] loss: 131.56275\n",
      "[epoch 82, batch     5] loss: 129.05848\n",
      "[epoch 82, batch     6] loss: 139.27189\n",
      "[epoch 82, batch     7] loss: 140.02144\n",
      "[epoch 82, batch     8] loss: 134.91745\n",
      "[epoch 82, batch     9] loss: 134.45374\n",
      "[epoch 82, batch    10] loss: 136.33265\n",
      "[epoch 82, batch    11] loss: 126.63510\n",
      "[epoch 82, batch    12] loss: 144.55125\n",
      "[epoch 82, batch    13] loss: 143.64177\n",
      "[epoch 82, batch    14] loss: 136.16141\n",
      "[epoch 82, batch    15] loss: 131.41553\n",
      "[epoch 82, batch    16] loss: 131.31404\n",
      "[epoch 82, batch    17] loss: 131.90656\n",
      "[epoch 82, batch    18] loss: 138.60149\n",
      "[epoch 82, batch    19] loss: 120.35386\n",
      "[epoch 82, batch    20] loss: 138.26293\n",
      "[epoch 82, batch    21] loss: 133.13308\n",
      "[epoch 82, batch    22] loss: 141.71686\n",
      "[epoch 82, batch    23] loss: 130.30225\n",
      "[epoch 82, batch    24] loss: 146.42241\n",
      "[epoch 82, batch    25] loss: 139.75280\n",
      "[epoch 82, batch    26] loss: 152.42332\n",
      "[epoch 82, batch    27] loss: 129.06156\n",
      "[epoch 82, batch    28] loss: 130.28300\n",
      "[epoch 82, batch    29] loss: 140.85294\n",
      "[epoch 82, batch    30] loss: 141.26896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 82, batch    31] loss: 134.44178\n",
      "[epoch 82, batch    32] loss: 25.90904\n",
      "[epoch 83, batch     1] loss: 134.67742\n",
      "[epoch 83, batch     2] loss: 151.80682\n",
      "[epoch 83, batch     3] loss: 127.54480\n",
      "[epoch 83, batch     4] loss: 138.80935\n",
      "[epoch 83, batch     5] loss: 141.68171\n",
      "[epoch 83, batch     6] loss: 129.21369\n",
      "[epoch 83, batch     7] loss: 134.84437\n",
      "[epoch 83, batch     8] loss: 138.00727\n",
      "[epoch 83, batch     9] loss: 127.55012\n",
      "[epoch 83, batch    10] loss: 133.48842\n",
      "[epoch 83, batch    11] loss: 149.47120\n",
      "[epoch 83, batch    12] loss: 131.02222\n",
      "[epoch 83, batch    13] loss: 130.23604\n",
      "[epoch 83, batch    14] loss: 121.05020\n",
      "[epoch 83, batch    15] loss: 149.11030\n",
      "[epoch 83, batch    16] loss: 130.36023\n",
      "[epoch 83, batch    17] loss: 141.88652\n",
      "[epoch 83, batch    18] loss: 144.04569\n",
      "[epoch 83, batch    19] loss: 129.58847\n",
      "[epoch 83, batch    20] loss: 141.72722\n",
      "[epoch 83, batch    21] loss: 140.49079\n",
      "[epoch 83, batch    22] loss: 143.42111\n",
      "[epoch 83, batch    23] loss: 131.21671\n",
      "[epoch 83, batch    24] loss: 138.20973\n",
      "[epoch 83, batch    25] loss: 144.00403\n",
      "[epoch 83, batch    26] loss: 142.95647\n",
      "[epoch 83, batch    27] loss: 119.09702\n",
      "[epoch 83, batch    28] loss: 132.44661\n",
      "[epoch 83, batch    29] loss: 136.70625\n",
      "[epoch 83, batch    30] loss: 131.37120\n",
      "[epoch 83, batch    31] loss: 137.43563\n",
      "[epoch 83, batch    32] loss: 27.57056\n",
      "[epoch 84, batch     1] loss: 133.01099\n",
      "[epoch 84, batch     2] loss: 134.45899\n",
      "[epoch 84, batch     3] loss: 132.75797\n",
      "[epoch 84, batch     4] loss: 140.05670\n",
      "[epoch 84, batch     5] loss: 128.95970\n",
      "[epoch 84, batch     6] loss: 137.43010\n",
      "[epoch 84, batch     7] loss: 137.26707\n",
      "[epoch 84, batch     8] loss: 134.86799\n",
      "[epoch 84, batch     9] loss: 141.69870\n",
      "[epoch 84, batch    10] loss: 134.74380\n",
      "[epoch 84, batch    11] loss: 137.42076\n",
      "[epoch 84, batch    12] loss: 126.90706\n",
      "[epoch 84, batch    13] loss: 130.86889\n",
      "[epoch 84, batch    14] loss: 141.44612\n",
      "[epoch 84, batch    15] loss: 126.37844\n",
      "[epoch 84, batch    16] loss: 138.93269\n",
      "[epoch 84, batch    17] loss: 138.32696\n",
      "[epoch 84, batch    18] loss: 134.88242\n",
      "[epoch 84, batch    19] loss: 152.88802\n",
      "[epoch 84, batch    20] loss: 119.27411\n",
      "[epoch 84, batch    21] loss: 136.39336\n",
      "[epoch 84, batch    22] loss: 149.65367\n",
      "[epoch 84, batch    23] loss: 127.09090\n",
      "[epoch 84, batch    24] loss: 121.35254\n",
      "[epoch 84, batch    25] loss: 133.34485\n",
      "[epoch 84, batch    26] loss: 134.23478\n",
      "[epoch 84, batch    27] loss: 133.93822\n",
      "[epoch 84, batch    28] loss: 148.26811\n",
      "[epoch 84, batch    29] loss: 133.63308\n",
      "[epoch 84, batch    30] loss: 140.88939\n",
      "[epoch 84, batch    31] loss: 135.12079\n",
      "[epoch 84, batch    32] loss: 30.96897\n",
      "[epoch 85, batch     1] loss: 129.65550\n",
      "[epoch 85, batch     2] loss: 128.84891\n",
      "[epoch 85, batch     3] loss: 132.05179\n",
      "[epoch 85, batch     4] loss: 151.21932\n",
      "[epoch 85, batch     5] loss: 131.65448\n",
      "[epoch 85, batch     6] loss: 133.51517\n",
      "[epoch 85, batch     7] loss: 132.75596\n",
      "[epoch 85, batch     8] loss: 138.14952\n",
      "[epoch 85, batch     9] loss: 128.64817\n",
      "[epoch 85, batch    10] loss: 131.00606\n",
      "[epoch 85, batch    11] loss: 136.81892\n",
      "[epoch 85, batch    12] loss: 133.08978\n",
      "[epoch 85, batch    13] loss: 128.44388\n",
      "[epoch 85, batch    14] loss: 148.30377\n",
      "[epoch 85, batch    15] loss: 136.70936\n",
      "[epoch 85, batch    16] loss: 137.83917\n",
      "[epoch 85, batch    17] loss: 135.79117\n",
      "[epoch 85, batch    18] loss: 131.83886\n",
      "[epoch 85, batch    19] loss: 127.41116\n",
      "[epoch 85, batch    20] loss: 137.96707\n",
      "[epoch 85, batch    21] loss: 143.19428\n",
      "[epoch 85, batch    22] loss: 139.60941\n",
      "[epoch 85, batch    23] loss: 130.74202\n",
      "[epoch 85, batch    24] loss: 129.31703\n",
      "[epoch 85, batch    25] loss: 127.49606\n",
      "[epoch 85, batch    26] loss: 144.96089\n",
      "[epoch 85, batch    27] loss: 133.09784\n",
      "[epoch 85, batch    28] loss: 122.95552\n",
      "[epoch 85, batch    29] loss: 127.57639\n",
      "[epoch 85, batch    30] loss: 141.78675\n",
      "[epoch 85, batch    31] loss: 128.79352\n",
      "[epoch 85, batch    32] loss: 29.40860\n",
      "[epoch 86, batch     1] loss: 136.36807\n",
      "[epoch 86, batch     2] loss: 132.43227\n",
      "[epoch 86, batch     3] loss: 136.10420\n",
      "[epoch 86, batch     4] loss: 125.13567\n",
      "[epoch 86, batch     5] loss: 136.10880\n",
      "[epoch 86, batch     6] loss: 130.23483\n",
      "[epoch 86, batch     7] loss: 142.89569\n",
      "[epoch 86, batch     8] loss: 136.04743\n",
      "[epoch 86, batch     9] loss: 123.64925\n",
      "[epoch 86, batch    10] loss: 153.68602\n",
      "[epoch 86, batch    11] loss: 137.06388\n",
      "[epoch 86, batch    12] loss: 148.16623\n",
      "[epoch 86, batch    13] loss: 141.21688\n",
      "[epoch 86, batch    14] loss: 132.92642\n",
      "[epoch 86, batch    15] loss: 122.47217\n",
      "[epoch 86, batch    16] loss: 136.37020\n",
      "[epoch 86, batch    17] loss: 125.92449\n",
      "[epoch 86, batch    18] loss: 145.63797\n",
      "[epoch 86, batch    19] loss: 135.03292\n",
      "[epoch 86, batch    20] loss: 126.62742\n",
      "[epoch 86, batch    21] loss: 124.69679\n",
      "[epoch 86, batch    22] loss: 142.89028\n",
      "[epoch 86, batch    23] loss: 129.68580\n",
      "[epoch 86, batch    24] loss: 131.96055\n",
      "[epoch 86, batch    25] loss: 136.06153\n",
      "[epoch 86, batch    26] loss: 132.85448\n",
      "[epoch 86, batch    27] loss: 122.05951\n",
      "[epoch 86, batch    28] loss: 125.29256\n",
      "[epoch 86, batch    29] loss: 134.13114\n",
      "[epoch 86, batch    30] loss: 138.52843\n",
      "[epoch 86, batch    31] loss: 135.94124\n",
      "[epoch 86, batch    32] loss: 45.02812\n",
      "[epoch 87, batch     1] loss: 137.79053\n",
      "[epoch 87, batch     2] loss: 137.15858\n",
      "[epoch 87, batch     3] loss: 142.19547\n",
      "[epoch 87, batch     4] loss: 136.49308\n",
      "[epoch 87, batch     5] loss: 137.54396\n",
      "[epoch 87, batch     6] loss: 146.50981\n",
      "[epoch 87, batch     7] loss: 133.58249\n",
      "[epoch 87, batch     8] loss: 127.56123\n",
      "[epoch 87, batch     9] loss: 131.27102\n",
      "[epoch 87, batch    10] loss: 141.18866\n",
      "[epoch 87, batch    11] loss: 128.21446\n",
      "[epoch 87, batch    12] loss: 128.08512\n",
      "[epoch 87, batch    13] loss: 152.64283\n",
      "[epoch 87, batch    14] loss: 135.07047\n",
      "[epoch 87, batch    15] loss: 137.98000\n",
      "[epoch 87, batch    16] loss: 138.29868\n",
      "[epoch 87, batch    17] loss: 146.24712\n",
      "[epoch 87, batch    18] loss: 136.36806\n",
      "[epoch 87, batch    19] loss: 119.59333\n",
      "[epoch 87, batch    20] loss: 137.58481\n",
      "[epoch 87, batch    21] loss: 151.59590\n",
      "[epoch 87, batch    22] loss: 127.72142\n",
      "[epoch 87, batch    23] loss: 137.58631\n",
      "[epoch 87, batch    24] loss: 134.07257\n",
      "[epoch 87, batch    25] loss: 128.32536\n",
      "[epoch 87, batch    26] loss: 132.09564\n",
      "[epoch 87, batch    27] loss: 137.78914\n",
      "[epoch 87, batch    28] loss: 131.99584\n",
      "[epoch 87, batch    29] loss: 143.01316\n",
      "[epoch 87, batch    30] loss: 129.07537\n",
      "[epoch 87, batch    31] loss: 135.97170\n",
      "[epoch 87, batch    32] loss: 36.72651\n",
      "[epoch 88, batch     1] loss: 128.50972\n",
      "[epoch 88, batch     2] loss: 129.44204\n",
      "[epoch 88, batch     3] loss: 141.49907\n",
      "[epoch 88, batch     4] loss: 138.60907\n",
      "[epoch 88, batch     5] loss: 134.83525\n",
      "[epoch 88, batch     6] loss: 132.21985\n",
      "[epoch 88, batch     7] loss: 137.18107\n",
      "[epoch 88, batch     8] loss: 132.99292\n",
      "[epoch 88, batch     9] loss: 140.94836\n",
      "[epoch 88, batch    10] loss: 119.58988\n",
      "[epoch 88, batch    11] loss: 125.69581\n",
      "[epoch 88, batch    12] loss: 133.73958\n",
      "[epoch 88, batch    13] loss: 139.98053\n",
      "[epoch 88, batch    14] loss: 134.78936\n",
      "[epoch 88, batch    15] loss: 131.23626\n",
      "[epoch 88, batch    16] loss: 132.52437\n",
      "[epoch 88, batch    17] loss: 132.61401\n",
      "[epoch 88, batch    18] loss: 137.46061\n",
      "[epoch 88, batch    19] loss: 134.85568\n",
      "[epoch 88, batch    20] loss: 134.76526\n",
      "[epoch 88, batch    21] loss: 133.88853\n",
      "[epoch 88, batch    22] loss: 125.37485\n",
      "[epoch 88, batch    23] loss: 136.49361\n",
      "[epoch 88, batch    24] loss: 123.62414\n",
      "[epoch 88, batch    25] loss: 122.09260\n",
      "[epoch 88, batch    26] loss: 124.76301\n",
      "[epoch 88, batch    27] loss: 128.48629\n",
      "[epoch 88, batch    28] loss: 135.67106\n",
      "[epoch 88, batch    29] loss: 124.70890\n",
      "[epoch 88, batch    30] loss: 123.17567\n",
      "[epoch 88, batch    31] loss: 140.57083\n",
      "[epoch 88, batch    32] loss: 40.25185\n",
      "[epoch 89, batch     1] loss: 127.75142\n",
      "[epoch 89, batch     2] loss: 132.05172\n",
      "[epoch 89, batch     3] loss: 136.90537\n",
      "[epoch 89, batch     4] loss: 132.52859\n",
      "[epoch 89, batch     5] loss: 139.67988\n",
      "[epoch 89, batch     6] loss: 140.61499\n",
      "[epoch 89, batch     7] loss: 134.50507\n",
      "[epoch 89, batch     8] loss: 142.47278\n",
      "[epoch 89, batch     9] loss: 136.63199\n",
      "[epoch 89, batch    10] loss: 138.43688\n",
      "[epoch 89, batch    11] loss: 138.73133\n",
      "[epoch 89, batch    12] loss: 136.68578\n",
      "[epoch 89, batch    13] loss: 134.11008\n",
      "[epoch 89, batch    14] loss: 124.70137\n",
      "[epoch 89, batch    15] loss: 143.39202\n",
      "[epoch 89, batch    16] loss: 130.93633\n",
      "[epoch 89, batch    17] loss: 141.95717\n",
      "[epoch 89, batch    18] loss: 130.31199\n",
      "[epoch 89, batch    19] loss: 129.73275\n",
      "[epoch 89, batch    20] loss: 135.07951\n",
      "[epoch 89, batch    21] loss: 135.12069\n",
      "[epoch 89, batch    22] loss: 141.58836\n",
      "[epoch 89, batch    23] loss: 129.42129\n",
      "[epoch 89, batch    24] loss: 124.17438\n",
      "[epoch 89, batch    25] loss: 130.97631\n",
      "[epoch 89, batch    26] loss: 140.21462\n",
      "[epoch 89, batch    27] loss: 134.52008\n",
      "[epoch 89, batch    28] loss: 144.44422\n",
      "[epoch 89, batch    29] loss: 138.57412\n",
      "[epoch 89, batch    30] loss: 128.29632\n",
      "[epoch 89, batch    31] loss: 132.76691\n",
      "[epoch 89, batch    32] loss: 31.77077\n",
      "[epoch 90, batch     1] loss: 128.21090\n",
      "[epoch 90, batch     2] loss: 128.62642\n",
      "[epoch 90, batch     3] loss: 128.34131\n",
      "[epoch 90, batch     4] loss: 140.07657\n",
      "[epoch 90, batch     5] loss: 145.55961\n",
      "[epoch 90, batch     6] loss: 123.28818\n",
      "[epoch 90, batch     7] loss: 122.69709\n",
      "[epoch 90, batch     8] loss: 133.90782\n",
      "[epoch 90, batch     9] loss: 123.73749\n",
      "[epoch 90, batch    10] loss: 148.37222\n",
      "[epoch 90, batch    11] loss: 138.96477\n",
      "[epoch 90, batch    12] loss: 121.23474\n",
      "[epoch 90, batch    13] loss: 124.20171\n",
      "[epoch 90, batch    14] loss: 139.12323\n",
      "[epoch 90, batch    15] loss: 134.88643\n",
      "[epoch 90, batch    16] loss: 128.27757\n",
      "[epoch 90, batch    17] loss: 133.61898\n",
      "[epoch 90, batch    18] loss: 136.91836\n",
      "[epoch 90, batch    19] loss: 125.34844\n",
      "[epoch 90, batch    20] loss: 132.16453\n",
      "[epoch 90, batch    21] loss: 148.52904\n",
      "[epoch 90, batch    22] loss: 137.45432\n",
      "[epoch 90, batch    23] loss: 146.36723\n",
      "[epoch 90, batch    24] loss: 147.45371\n",
      "[epoch 90, batch    25] loss: 123.78894\n",
      "[epoch 90, batch    26] loss: 139.26596\n",
      "[epoch 90, batch    27] loss: 129.32976\n",
      "[epoch 90, batch    28] loss: 138.49574\n",
      "[epoch 90, batch    29] loss: 130.63037\n",
      "[epoch 90, batch    30] loss: 147.29628\n",
      "[epoch 90, batch    31] loss: 137.07334\n",
      "[epoch 90, batch    32] loss: 31.98055\n",
      "[epoch 91, batch     1] loss: 126.20451\n",
      "[epoch 91, batch     2] loss: 140.99673\n",
      "[epoch 91, batch     3] loss: 138.69689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 91, batch     4] loss: 129.60501\n",
      "[epoch 91, batch     5] loss: 136.02374\n",
      "[epoch 91, batch     6] loss: 134.67862\n",
      "[epoch 91, batch     7] loss: 134.88381\n",
      "[epoch 91, batch     8] loss: 121.50902\n",
      "[epoch 91, batch     9] loss: 122.65996\n",
      "[epoch 91, batch    10] loss: 142.08273\n",
      "[epoch 91, batch    11] loss: 125.65981\n",
      "[epoch 91, batch    12] loss: 143.05269\n",
      "[epoch 91, batch    13] loss: 141.09181\n",
      "[epoch 91, batch    14] loss: 131.58366\n",
      "[epoch 91, batch    15] loss: 136.99638\n",
      "[epoch 91, batch    16] loss: 136.68104\n",
      "[epoch 91, batch    17] loss: 133.20302\n",
      "[epoch 91, batch    18] loss: 139.04278\n",
      "[epoch 91, batch    19] loss: 135.09864\n",
      "[epoch 91, batch    20] loss: 125.36705\n",
      "[epoch 91, batch    21] loss: 136.80176\n",
      "[epoch 91, batch    22] loss: 135.22546\n",
      "[epoch 91, batch    23] loss: 134.92282\n",
      "[epoch 91, batch    24] loss: 139.41867\n",
      "[epoch 91, batch    25] loss: 134.97296\n",
      "[epoch 91, batch    26] loss: 134.26739\n",
      "[epoch 91, batch    27] loss: 127.15562\n",
      "[epoch 91, batch    28] loss: 127.80357\n",
      "[epoch 91, batch    29] loss: 131.98210\n",
      "[epoch 91, batch    30] loss: 145.03593\n",
      "[epoch 91, batch    31] loss: 136.69708\n",
      "[epoch 91, batch    32] loss: 38.93780\n",
      "[epoch 92, batch     1] loss: 133.89261\n",
      "[epoch 92, batch     2] loss: 144.06489\n",
      "[epoch 92, batch     3] loss: 142.34934\n",
      "[epoch 92, batch     4] loss: 141.30025\n",
      "[epoch 92, batch     5] loss: 130.27532\n",
      "[epoch 92, batch     6] loss: 124.59070\n",
      "[epoch 92, batch     7] loss: 133.88997\n",
      "[epoch 92, batch     8] loss: 132.33936\n",
      "[epoch 92, batch     9] loss: 127.39880\n",
      "[epoch 92, batch    10] loss: 134.41826\n",
      "[epoch 92, batch    11] loss: 128.68620\n",
      "[epoch 92, batch    12] loss: 126.83121\n",
      "[epoch 92, batch    13] loss: 141.72046\n",
      "[epoch 92, batch    14] loss: 140.93152\n",
      "[epoch 92, batch    15] loss: 132.67460\n",
      "[epoch 92, batch    16] loss: 151.14404\n",
      "[epoch 92, batch    17] loss: 140.35605\n",
      "[epoch 92, batch    18] loss: 121.74947\n",
      "[epoch 92, batch    19] loss: 133.89499\n",
      "[epoch 92, batch    20] loss: 128.79607\n",
      "[epoch 92, batch    21] loss: 136.25703\n",
      "[epoch 92, batch    22] loss: 144.47543\n",
      "[epoch 92, batch    23] loss: 137.36560\n",
      "[epoch 92, batch    24] loss: 127.80896\n",
      "[epoch 92, batch    25] loss: 141.66569\n",
      "[epoch 92, batch    26] loss: 141.89467\n",
      "[epoch 92, batch    27] loss: 135.94650\n",
      "[epoch 92, batch    28] loss: 137.63318\n",
      "[epoch 92, batch    29] loss: 123.16335\n",
      "[epoch 92, batch    30] loss: 129.37497\n",
      "[epoch 92, batch    31] loss: 142.31956\n",
      "[epoch 92, batch    32] loss: 40.73445\n",
      "[epoch 93, batch     1] loss: 139.90696\n",
      "[epoch 93, batch     2] loss: 128.11278\n",
      "[epoch 93, batch     3] loss: 124.02679\n",
      "[epoch 93, batch     4] loss: 139.37571\n",
      "[epoch 93, batch     5] loss: 122.39884\n",
      "[epoch 93, batch     6] loss: 146.91707\n",
      "[epoch 93, batch     7] loss: 136.80004\n",
      "[epoch 93, batch     8] loss: 140.06295\n",
      "[epoch 93, batch     9] loss: 127.25665\n",
      "[epoch 93, batch    10] loss: 126.81568\n",
      "[epoch 93, batch    11] loss: 123.44005\n",
      "[epoch 93, batch    12] loss: 146.61601\n",
      "[epoch 93, batch    13] loss: 126.03945\n",
      "[epoch 93, batch    14] loss: 125.89247\n",
      "[epoch 93, batch    15] loss: 128.91290\n",
      "[epoch 93, batch    16] loss: 138.92445\n",
      "[epoch 93, batch    17] loss: 128.05823\n",
      "[epoch 93, batch    18] loss: 137.76657\n",
      "[epoch 93, batch    19] loss: 145.36584\n",
      "[epoch 93, batch    20] loss: 125.51896\n",
      "[epoch 93, batch    21] loss: 127.64137\n",
      "[epoch 93, batch    22] loss: 138.50412\n",
      "[epoch 93, batch    23] loss: 132.98412\n",
      "[epoch 93, batch    24] loss: 146.83871\n",
      "[epoch 93, batch    25] loss: 131.15606\n",
      "[epoch 93, batch    26] loss: 138.70595\n",
      "[epoch 93, batch    27] loss: 136.24216\n",
      "[epoch 93, batch    28] loss: 145.62901\n",
      "[epoch 93, batch    29] loss: 136.26404\n",
      "[epoch 93, batch    30] loss: 125.84765\n",
      "[epoch 93, batch    31] loss: 133.19268\n",
      "[epoch 93, batch    32] loss: 32.83676\n",
      "[epoch 94, batch     1] loss: 135.38821\n",
      "[epoch 94, batch     2] loss: 138.17814\n",
      "[epoch 94, batch     3] loss: 141.45047\n",
      "[epoch 94, batch     4] loss: 143.52848\n",
      "[epoch 94, batch     5] loss: 135.57409\n",
      "[epoch 94, batch     6] loss: 127.91490\n",
      "[epoch 94, batch     7] loss: 128.44410\n",
      "[epoch 94, batch     8] loss: 142.04500\n",
      "[epoch 94, batch     9] loss: 136.22050\n",
      "[epoch 94, batch    10] loss: 125.52773\n",
      "[epoch 94, batch    11] loss: 127.46950\n",
      "[epoch 94, batch    12] loss: 136.64818\n",
      "[epoch 94, batch    13] loss: 143.58451\n",
      "[epoch 94, batch    14] loss: 138.29521\n",
      "[epoch 94, batch    15] loss: 139.77186\n",
      "[epoch 94, batch    16] loss: 125.48895\n",
      "[epoch 94, batch    17] loss: 148.17678\n",
      "[epoch 94, batch    18] loss: 138.23408\n",
      "[epoch 94, batch    19] loss: 131.70715\n",
      "[epoch 94, batch    20] loss: 140.02291\n",
      "[epoch 94, batch    21] loss: 134.47656\n",
      "[epoch 94, batch    22] loss: 136.70367\n",
      "[epoch 94, batch    23] loss: 133.60630\n",
      "[epoch 94, batch    24] loss: 132.87434\n",
      "[epoch 94, batch    25] loss: 143.94079\n",
      "[epoch 94, batch    26] loss: 125.13101\n",
      "[epoch 94, batch    27] loss: 128.51702\n",
      "[epoch 94, batch    28] loss: 143.95841\n",
      "[epoch 94, batch    29] loss: 130.53113\n",
      "[epoch 94, batch    30] loss: 121.73956\n",
      "[epoch 94, batch    31] loss: 149.72918\n",
      "[epoch 94, batch    32] loss: 34.18524\n",
      "[epoch 95, batch     1] loss: 125.72666\n",
      "[epoch 95, batch     2] loss: 136.64389\n",
      "[epoch 95, batch     3] loss: 135.32427\n",
      "[epoch 95, batch     4] loss: 131.99393\n",
      "[epoch 95, batch     5] loss: 129.74197\n",
      "[epoch 95, batch     6] loss: 122.29464\n",
      "[epoch 95, batch     7] loss: 139.96672\n",
      "[epoch 95, batch     8] loss: 132.87247\n",
      "[epoch 95, batch     9] loss: 125.08913\n",
      "[epoch 95, batch    10] loss: 134.27389\n",
      "[epoch 95, batch    11] loss: 146.20032\n",
      "[epoch 95, batch    12] loss: 116.78598\n",
      "[epoch 95, batch    13] loss: 134.82672\n",
      "[epoch 95, batch    14] loss: 136.94752\n",
      "[epoch 95, batch    15] loss: 137.42577\n",
      "[epoch 95, batch    16] loss: 126.80002\n",
      "[epoch 95, batch    17] loss: 130.50244\n",
      "[epoch 95, batch    18] loss: 129.70017\n",
      "[epoch 95, batch    19] loss: 126.42506\n",
      "[epoch 95, batch    20] loss: 126.64300\n",
      "[epoch 95, batch    21] loss: 132.47278\n",
      "[epoch 95, batch    22] loss: 149.30415\n",
      "[epoch 95, batch    23] loss: 135.21116\n",
      "[epoch 95, batch    24] loss: 136.58349\n",
      "[epoch 95, batch    25] loss: 148.51465\n",
      "[epoch 95, batch    26] loss: 129.80337\n",
      "[epoch 95, batch    27] loss: 146.18110\n",
      "[epoch 95, batch    28] loss: 142.13395\n",
      "[epoch 95, batch    29] loss: 131.66399\n",
      "[epoch 95, batch    30] loss: 132.12253\n",
      "[epoch 95, batch    31] loss: 140.92686\n",
      "[epoch 95, batch    32] loss: 34.53709\n",
      "[epoch 96, batch     1] loss: 121.27612\n",
      "[epoch 96, batch     2] loss: 130.73777\n",
      "[epoch 96, batch     3] loss: 143.60099\n",
      "[epoch 96, batch     4] loss: 142.60136\n",
      "[epoch 96, batch     5] loss: 120.49787\n",
      "[epoch 96, batch     6] loss: 153.68948\n",
      "[epoch 96, batch     7] loss: 126.16173\n",
      "[epoch 96, batch     8] loss: 134.48579\n",
      "[epoch 96, batch     9] loss: 127.38593\n",
      "[epoch 96, batch    10] loss: 138.84468\n",
      "[epoch 96, batch    11] loss: 151.11879\n",
      "[epoch 96, batch    12] loss: 131.13241\n",
      "[epoch 96, batch    13] loss: 138.36518\n",
      "[epoch 96, batch    14] loss: 128.70890\n",
      "[epoch 96, batch    15] loss: 130.43990\n",
      "[epoch 96, batch    16] loss: 125.83898\n",
      "[epoch 96, batch    17] loss: 137.84203\n",
      "[epoch 96, batch    18] loss: 125.50284\n",
      "[epoch 96, batch    19] loss: 129.91020\n",
      "[epoch 96, batch    20] loss: 142.32195\n",
      "[epoch 96, batch    21] loss: 125.49886\n",
      "[epoch 96, batch    22] loss: 126.73558\n",
      "[epoch 96, batch    23] loss: 129.19125\n",
      "[epoch 96, batch    24] loss: 125.49963\n",
      "[epoch 96, batch    25] loss: 133.15981\n",
      "[epoch 96, batch    26] loss: 136.22238\n",
      "[epoch 96, batch    27] loss: 133.84273\n",
      "[epoch 96, batch    28] loss: 146.14438\n",
      "[epoch 96, batch    29] loss: 136.18759\n",
      "[epoch 96, batch    30] loss: 131.96988\n",
      "[epoch 96, batch    31] loss: 118.44887\n",
      "[epoch 96, batch    32] loss: 33.22418\n",
      "[epoch 97, batch     1] loss: 129.97537\n",
      "[epoch 97, batch     2] loss: 138.94319\n",
      "[epoch 97, batch     3] loss: 132.25300\n",
      "[epoch 97, batch     4] loss: 137.08011\n",
      "[epoch 97, batch     5] loss: 129.55873\n",
      "[epoch 97, batch     6] loss: 139.88555\n",
      "[epoch 97, batch     7] loss: 122.93906\n",
      "[epoch 97, batch     8] loss: 135.51179\n",
      "[epoch 97, batch     9] loss: 137.13579\n",
      "[epoch 97, batch    10] loss: 137.57233\n",
      "[epoch 97, batch    11] loss: 137.96477\n",
      "[epoch 97, batch    12] loss: 146.24698\n",
      "[epoch 97, batch    13] loss: 139.49636\n",
      "[epoch 97, batch    14] loss: 130.38820\n",
      "[epoch 97, batch    15] loss: 131.04990\n",
      "[epoch 97, batch    16] loss: 137.44543\n",
      "[epoch 97, batch    17] loss: 134.17796\n",
      "[epoch 97, batch    18] loss: 138.85844\n",
      "[epoch 97, batch    19] loss: 140.93793\n",
      "[epoch 97, batch    20] loss: 120.21574\n",
      "[epoch 97, batch    21] loss: 116.94544\n",
      "[epoch 97, batch    22] loss: 127.04390\n",
      "[epoch 97, batch    23] loss: 112.94623\n",
      "[epoch 97, batch    24] loss: 120.95430\n",
      "[epoch 97, batch    25] loss: 122.51310\n",
      "[epoch 97, batch    26] loss: 140.02731\n",
      "[epoch 97, batch    27] loss: 135.92223\n",
      "[epoch 97, batch    28] loss: 125.80244\n",
      "[epoch 97, batch    29] loss: 126.65165\n",
      "[epoch 97, batch    30] loss: 140.02257\n",
      "[epoch 97, batch    31] loss: 148.98708\n",
      "[epoch 97, batch    32] loss: 38.03799\n",
      "[epoch 98, batch     1] loss: 141.03131\n",
      "[epoch 98, batch     2] loss: 135.99665\n",
      "[epoch 98, batch     3] loss: 139.02852\n",
      "[epoch 98, batch     4] loss: 123.81167\n",
      "[epoch 98, batch     5] loss: 131.66241\n",
      "[epoch 98, batch     6] loss: 143.55528\n",
      "[epoch 98, batch     7] loss: 138.14410\n",
      "[epoch 98, batch     8] loss: 132.90986\n",
      "[epoch 98, batch     9] loss: 113.84938\n",
      "[epoch 98, batch    10] loss: 117.53773\n",
      "[epoch 98, batch    11] loss: 134.56425\n",
      "[epoch 98, batch    12] loss: 141.23864\n",
      "[epoch 98, batch    13] loss: 134.80695\n",
      "[epoch 98, batch    14] loss: 135.54007\n",
      "[epoch 98, batch    15] loss: 130.82324\n",
      "[epoch 98, batch    16] loss: 137.95883\n",
      "[epoch 98, batch    17] loss: 143.02702\n",
      "[epoch 98, batch    18] loss: 133.79129\n",
      "[epoch 98, batch    19] loss: 124.99880\n",
      "[epoch 98, batch    20] loss: 129.28001\n",
      "[epoch 98, batch    21] loss: 132.59311\n",
      "[epoch 98, batch    22] loss: 136.11796\n",
      "[epoch 98, batch    23] loss: 129.00141\n",
      "[epoch 98, batch    24] loss: 139.58528\n",
      "[epoch 98, batch    25] loss: 134.96335\n",
      "[epoch 98, batch    26] loss: 122.82651\n",
      "[epoch 98, batch    27] loss: 135.93982\n",
      "[epoch 98, batch    28] loss: 121.89788\n",
      "[epoch 98, batch    29] loss: 130.91532\n",
      "[epoch 98, batch    30] loss: 130.17048\n",
      "[epoch 98, batch    31] loss: 139.53852\n",
      "[epoch 98, batch    32] loss: 29.36272\n",
      "[epoch 99, batch     1] loss: 130.72198\n",
      "[epoch 99, batch     2] loss: 143.72324\n",
      "[epoch 99, batch     3] loss: 125.36523\n",
      "[epoch 99, batch     4] loss: 136.70176\n",
      "[epoch 99, batch     5] loss: 147.18891\n",
      "[epoch 99, batch     6] loss: 124.74854\n",
      "[epoch 99, batch     7] loss: 130.99964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 99, batch     8] loss: 145.27092\n",
      "[epoch 99, batch     9] loss: 148.29746\n",
      "[epoch 99, batch    10] loss: 132.15240\n",
      "[epoch 99, batch    11] loss: 128.99366\n",
      "[epoch 99, batch    12] loss: 139.47934\n",
      "[epoch 99, batch    13] loss: 121.78151\n",
      "[epoch 99, batch    14] loss: 142.24626\n",
      "[epoch 99, batch    15] loss: 136.00599\n",
      "[epoch 99, batch    16] loss: 134.78191\n",
      "[epoch 99, batch    17] loss: 153.88736\n",
      "[epoch 99, batch    18] loss: 139.79315\n",
      "[epoch 99, batch    19] loss: 139.54041\n",
      "[epoch 99, batch    20] loss: 132.47866\n",
      "[epoch 99, batch    21] loss: 138.11366\n",
      "[epoch 99, batch    22] loss: 128.79457\n",
      "[epoch 99, batch    23] loss: 128.94927\n",
      "[epoch 99, batch    24] loss: 138.07444\n",
      "[epoch 99, batch    25] loss: 125.30076\n",
      "[epoch 99, batch    26] loss: 122.62274\n",
      "[epoch 99, batch    27] loss: 138.79795\n",
      "[epoch 99, batch    28] loss: 136.91319\n",
      "[epoch 99, batch    29] loss: 132.93039\n",
      "[epoch 99, batch    30] loss: 130.83118\n",
      "[epoch 99, batch    31] loss: 142.29863\n",
      "[epoch 99, batch    32] loss: 31.58708\n",
      "[epoch 100, batch     1] loss: 140.11556\n",
      "[epoch 100, batch     2] loss: 138.15525\n",
      "[epoch 100, batch     3] loss: 128.51562\n",
      "[epoch 100, batch     4] loss: 135.05155\n",
      "[epoch 100, batch     5] loss: 137.28918\n",
      "[epoch 100, batch     6] loss: 133.79931\n",
      "[epoch 100, batch     7] loss: 129.19666\n",
      "[epoch 100, batch     8] loss: 128.74522\n",
      "[epoch 100, batch     9] loss: 140.56357\n",
      "[epoch 100, batch    10] loss: 130.45040\n",
      "[epoch 100, batch    11] loss: 127.20806\n",
      "[epoch 100, batch    12] loss: 142.70368\n",
      "[epoch 100, batch    13] loss: 125.99171\n",
      "[epoch 100, batch    14] loss: 132.66418\n",
      "[epoch 100, batch    15] loss: 136.57141\n",
      "[epoch 100, batch    16] loss: 129.29608\n",
      "[epoch 100, batch    17] loss: 133.38983\n",
      "[epoch 100, batch    18] loss: 155.05997\n",
      "[epoch 100, batch    19] loss: 133.47637\n",
      "[epoch 100, batch    20] loss: 131.83922\n",
      "[epoch 100, batch    21] loss: 128.68517\n",
      "[epoch 100, batch    22] loss: 139.77199\n",
      "[epoch 100, batch    23] loss: 131.24500\n",
      "[epoch 100, batch    24] loss: 135.46656\n",
      "[epoch 100, batch    25] loss: 134.13335\n",
      "[epoch 100, batch    26] loss: 136.46221\n",
      "[epoch 100, batch    27] loss: 148.30094\n",
      "[epoch 100, batch    28] loss: 130.90485\n",
      "[epoch 100, batch    29] loss: 140.28913\n",
      "[epoch 100, batch    30] loss: 136.43550\n",
      "[epoch 100, batch    31] loss: 121.74874\n",
      "[epoch 100, batch    32] loss: 28.29022\n",
      "[epoch 101, batch     1] loss: 125.42204\n",
      "[epoch 101, batch     2] loss: 135.73356\n",
      "[epoch 101, batch     3] loss: 137.80105\n",
      "[epoch 101, batch     4] loss: 132.95813\n",
      "[epoch 101, batch     5] loss: 135.26706\n",
      "[epoch 101, batch     6] loss: 131.01502\n",
      "[epoch 101, batch     7] loss: 136.75226\n",
      "[epoch 101, batch     8] loss: 142.54631\n",
      "[epoch 101, batch     9] loss: 135.62921\n",
      "[epoch 101, batch    10] loss: 136.27110\n",
      "[epoch 101, batch    11] loss: 135.00468\n",
      "[epoch 101, batch    12] loss: 130.14016\n",
      "[epoch 101, batch    13] loss: 145.59232\n",
      "[epoch 101, batch    14] loss: 137.36365\n",
      "[epoch 101, batch    15] loss: 131.21385\n",
      "[epoch 101, batch    16] loss: 136.97197\n",
      "[epoch 101, batch    17] loss: 129.02046\n",
      "[epoch 101, batch    18] loss: 131.80764\n",
      "[epoch 101, batch    19] loss: 127.76708\n",
      "[epoch 101, batch    20] loss: 132.03813\n",
      "[epoch 101, batch    21] loss: 130.52713\n",
      "[epoch 101, batch    22] loss: 143.02107\n",
      "[epoch 101, batch    23] loss: 130.66353\n",
      "[epoch 101, batch    24] loss: 131.98016\n",
      "[epoch 101, batch    25] loss: 138.82955\n",
      "[epoch 101, batch    26] loss: 126.96051\n",
      "[epoch 101, batch    27] loss: 138.31911\n",
      "[epoch 101, batch    28] loss: 147.61939\n",
      "[epoch 101, batch    29] loss: 133.32687\n",
      "[epoch 101, batch    30] loss: 140.94203\n",
      "[epoch 101, batch    31] loss: 139.74175\n",
      "[epoch 101, batch    32] loss: 26.47004\n",
      "[epoch 102, batch     1] loss: 131.76818\n",
      "[epoch 102, batch     2] loss: 156.68069\n",
      "[epoch 102, batch     3] loss: 134.56865\n",
      "[epoch 102, batch     4] loss: 145.68072\n",
      "[epoch 102, batch     5] loss: 130.39364\n",
      "[epoch 102, batch     6] loss: 139.82141\n",
      "[epoch 102, batch     7] loss: 137.06270\n",
      "[epoch 102, batch     8] loss: 127.67297\n",
      "[epoch 102, batch     9] loss: 130.20364\n",
      "[epoch 102, batch    10] loss: 138.99848\n",
      "[epoch 102, batch    11] loss: 127.86451\n",
      "[epoch 102, batch    12] loss: 128.31281\n",
      "[epoch 102, batch    13] loss: 137.37818\n",
      "[epoch 102, batch    14] loss: 129.17258\n",
      "[epoch 102, batch    15] loss: 138.90456\n",
      "[epoch 102, batch    16] loss: 136.91294\n",
      "[epoch 102, batch    17] loss: 124.12208\n",
      "[epoch 102, batch    18] loss: 123.31758\n",
      "[epoch 102, batch    19] loss: 140.09156\n",
      "[epoch 102, batch    20] loss: 135.40065\n",
      "[epoch 102, batch    21] loss: 123.17652\n",
      "[epoch 102, batch    22] loss: 129.43248\n",
      "[epoch 102, batch    23] loss: 127.36966\n",
      "[epoch 102, batch    24] loss: 123.54015\n",
      "[epoch 102, batch    25] loss: 133.60178\n",
      "[epoch 102, batch    26] loss: 133.95197\n",
      "[epoch 102, batch    27] loss: 134.28268\n",
      "[epoch 102, batch    28] loss: 132.49266\n",
      "[epoch 102, batch    29] loss: 129.71338\n",
      "[epoch 102, batch    30] loss: 136.48428\n",
      "[epoch 102, batch    31] loss: 137.75511\n",
      "[epoch 102, batch    32] loss: 41.37614\n",
      "[epoch 103, batch     1] loss: 128.97324\n",
      "[epoch 103, batch     2] loss: 131.64480\n",
      "[epoch 103, batch     3] loss: 138.94594\n",
      "[epoch 103, batch     4] loss: 131.09135\n",
      "[epoch 103, batch     5] loss: 140.76721\n",
      "[epoch 103, batch     6] loss: 140.87544\n",
      "[epoch 103, batch     7] loss: 132.18361\n",
      "[epoch 103, batch     8] loss: 133.51924\n",
      "[epoch 103, batch     9] loss: 146.53469\n",
      "[epoch 103, batch    10] loss: 123.64478\n",
      "[epoch 103, batch    11] loss: 133.08927\n",
      "[epoch 103, batch    12] loss: 141.73341\n",
      "[epoch 103, batch    13] loss: 127.47792\n",
      "[epoch 103, batch    14] loss: 132.13439\n",
      "[epoch 103, batch    15] loss: 134.53446\n",
      "[epoch 103, batch    16] loss: 136.90931\n",
      "[epoch 103, batch    17] loss: 131.96635\n",
      "[epoch 103, batch    18] loss: 141.92450\n",
      "[epoch 103, batch    19] loss: 139.72181\n",
      "[epoch 103, batch    20] loss: 138.61762\n",
      "[epoch 103, batch    21] loss: 122.63982\n",
      "[epoch 103, batch    22] loss: 123.04389\n",
      "[epoch 103, batch    23] loss: 129.94337\n",
      "[epoch 103, batch    24] loss: 145.24698\n",
      "[epoch 103, batch    25] loss: 133.35922\n",
      "[epoch 103, batch    26] loss: 125.30286\n",
      "[epoch 103, batch    27] loss: 150.58316\n",
      "[epoch 103, batch    28] loss: 154.79302\n",
      "[epoch 103, batch    29] loss: 131.56224\n",
      "[epoch 103, batch    30] loss: 132.24559\n",
      "[epoch 103, batch    31] loss: 148.06896\n",
      "[epoch 103, batch    32] loss: 32.91605\n",
      "[epoch 104, batch     1] loss: 125.70886\n",
      "[epoch 104, batch     2] loss: 125.21837\n",
      "[epoch 104, batch     3] loss: 126.32935\n",
      "[epoch 104, batch     4] loss: 133.73677\n",
      "[epoch 104, batch     5] loss: 140.23622\n",
      "[epoch 104, batch     6] loss: 131.22123\n",
      "[epoch 104, batch     7] loss: 137.78498\n",
      "[epoch 104, batch     8] loss: 137.10683\n",
      "[epoch 104, batch     9] loss: 127.39475\n",
      "[epoch 104, batch    10] loss: 136.73468\n",
      "[epoch 104, batch    11] loss: 127.54522\n",
      "[epoch 104, batch    12] loss: 140.22120\n",
      "[epoch 104, batch    13] loss: 124.45770\n",
      "[epoch 104, batch    14] loss: 124.47326\n",
      "[epoch 104, batch    15] loss: 133.09923\n",
      "[epoch 104, batch    16] loss: 126.87812\n",
      "[epoch 104, batch    17] loss: 133.12666\n",
      "[epoch 104, batch    18] loss: 141.22322\n",
      "[epoch 104, batch    19] loss: 146.22122\n",
      "[epoch 104, batch    20] loss: 141.57090\n",
      "[epoch 104, batch    21] loss: 138.19938\n",
      "[epoch 104, batch    22] loss: 148.03848\n",
      "[epoch 104, batch    23] loss: 135.89966\n",
      "[epoch 104, batch    24] loss: 130.32904\n",
      "[epoch 104, batch    25] loss: 136.11158\n",
      "[epoch 104, batch    26] loss: 122.69805\n",
      "[epoch 104, batch    27] loss: 139.98031\n",
      "[epoch 104, batch    28] loss: 145.17414\n",
      "[epoch 104, batch    29] loss: 142.55678\n",
      "[epoch 104, batch    30] loss: 136.07617\n",
      "[epoch 104, batch    31] loss: 130.59592\n",
      "[epoch 104, batch    32] loss: 37.58834\n",
      "[epoch 105, batch     1] loss: 132.54354\n",
      "[epoch 105, batch     2] loss: 124.51299\n",
      "[epoch 105, batch     3] loss: 134.10838\n",
      "[epoch 105, batch     4] loss: 137.15052\n",
      "[epoch 105, batch     5] loss: 131.01531\n",
      "[epoch 105, batch     6] loss: 146.56018\n",
      "[epoch 105, batch     7] loss: 125.08094\n",
      "[epoch 105, batch     8] loss: 136.33556\n",
      "[epoch 105, batch     9] loss: 147.65040\n",
      "[epoch 105, batch    10] loss: 135.38512\n",
      "[epoch 105, batch    11] loss: 133.96560\n",
      "[epoch 105, batch    12] loss: 133.44395\n",
      "[epoch 105, batch    13] loss: 127.29548\n",
      "[epoch 105, batch    14] loss: 142.33496\n",
      "[epoch 105, batch    15] loss: 126.70551\n",
      "[epoch 105, batch    16] loss: 135.35315\n",
      "[epoch 105, batch    17] loss: 126.62550\n",
      "[epoch 105, batch    18] loss: 122.49449\n",
      "[epoch 105, batch    19] loss: 135.23464\n",
      "[epoch 105, batch    20] loss: 142.68038\n",
      "[epoch 105, batch    21] loss: 137.38533\n",
      "[epoch 105, batch    22] loss: 131.62892\n",
      "[epoch 105, batch    23] loss: 133.62347\n",
      "[epoch 105, batch    24] loss: 129.52096\n",
      "[epoch 105, batch    25] loss: 121.59363\n",
      "[epoch 105, batch    26] loss: 138.21585\n",
      "[epoch 105, batch    27] loss: 132.49819\n",
      "[epoch 105, batch    28] loss: 119.47739\n",
      "[epoch 105, batch    29] loss: 137.13040\n",
      "[epoch 105, batch    30] loss: 132.54811\n",
      "[epoch 105, batch    31] loss: 140.34930\n",
      "[epoch 105, batch    32] loss: 33.06534\n",
      "[epoch 106, batch     1] loss: 149.79534\n",
      "[epoch 106, batch     2] loss: 138.36171\n",
      "[epoch 106, batch     3] loss: 135.19972\n",
      "[epoch 106, batch     4] loss: 133.98950\n",
      "[epoch 106, batch     5] loss: 132.88112\n",
      "[epoch 106, batch     6] loss: 126.43526\n",
      "[epoch 106, batch     7] loss: 134.91510\n",
      "[epoch 106, batch     8] loss: 127.98244\n",
      "[epoch 106, batch     9] loss: 129.25834\n",
      "[epoch 106, batch    10] loss: 141.20204\n",
      "[epoch 106, batch    11] loss: 141.97075\n",
      "[epoch 106, batch    12] loss: 133.76834\n",
      "[epoch 106, batch    13] loss: 133.39045\n",
      "[epoch 106, batch    14] loss: 125.42384\n",
      "[epoch 106, batch    15] loss: 131.81010\n",
      "[epoch 106, batch    16] loss: 133.11275\n",
      "[epoch 106, batch    17] loss: 141.84894\n",
      "[epoch 106, batch    18] loss: 117.98581\n",
      "[epoch 106, batch    19] loss: 139.10604\n",
      "[epoch 106, batch    20] loss: 147.64530\n",
      "[epoch 106, batch    21] loss: 124.32190\n",
      "[epoch 106, batch    22] loss: 124.37104\n",
      "[epoch 106, batch    23] loss: 130.83224\n",
      "[epoch 106, batch    24] loss: 126.38803\n",
      "[epoch 106, batch    25] loss: 130.82371\n",
      "[epoch 106, batch    26] loss: 140.73060\n",
      "[epoch 106, batch    27] loss: 120.12521\n",
      "[epoch 106, batch    28] loss: 124.84726\n",
      "[epoch 106, batch    29] loss: 137.06194\n",
      "[epoch 106, batch    30] loss: 128.11398\n",
      "[epoch 106, batch    31] loss: 128.52529\n",
      "[epoch 106, batch    32] loss: 38.27843\n",
      "[epoch 107, batch     1] loss: 139.08979\n",
      "[epoch 107, batch     2] loss: 134.66239\n",
      "[epoch 107, batch     3] loss: 137.22708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 107, batch     4] loss: 142.95371\n",
      "[epoch 107, batch     5] loss: 142.64461\n",
      "[epoch 107, batch     6] loss: 136.29816\n",
      "[epoch 107, batch     7] loss: 135.61702\n",
      "[epoch 107, batch     8] loss: 151.33855\n",
      "[epoch 107, batch     9] loss: 142.25214\n",
      "[epoch 107, batch    10] loss: 131.14600\n",
      "[epoch 107, batch    11] loss: 135.59910\n",
      "[epoch 107, batch    12] loss: 138.51719\n",
      "[epoch 107, batch    13] loss: 128.24241\n",
      "[epoch 107, batch    14] loss: 132.53609\n",
      "[epoch 107, batch    15] loss: 127.10262\n",
      "[epoch 107, batch    16] loss: 128.00908\n",
      "[epoch 107, batch    17] loss: 140.14648\n",
      "[epoch 107, batch    18] loss: 130.75264\n",
      "[epoch 107, batch    19] loss: 129.23528\n",
      "[epoch 107, batch    20] loss: 136.59754\n",
      "[epoch 107, batch    21] loss: 133.90531\n",
      "[epoch 107, batch    22] loss: 148.89746\n",
      "[epoch 107, batch    23] loss: 127.02879\n",
      "[epoch 107, batch    24] loss: 137.66850\n",
      "[epoch 107, batch    25] loss: 137.45654\n",
      "[epoch 107, batch    26] loss: 140.34036\n",
      "[epoch 107, batch    27] loss: 129.63055\n",
      "[epoch 107, batch    28] loss: 130.82233\n",
      "[epoch 107, batch    29] loss: 121.41949\n",
      "[epoch 107, batch    30] loss: 141.63711\n",
      "[epoch 107, batch    31] loss: 125.66758\n",
      "[epoch 107, batch    32] loss: 31.97043\n",
      "[epoch 108, batch     1] loss: 139.07480\n",
      "[epoch 108, batch     2] loss: 136.69214\n",
      "[epoch 108, batch     3] loss: 137.01301\n",
      "[epoch 108, batch     4] loss: 132.79384\n",
      "[epoch 108, batch     5] loss: 148.31809\n",
      "[epoch 108, batch     6] loss: 120.48888\n",
      "[epoch 108, batch     7] loss: 125.88072\n",
      "[epoch 108, batch     8] loss: 132.13941\n",
      "[epoch 108, batch     9] loss: 129.10284\n",
      "[epoch 108, batch    10] loss: 131.89427\n",
      "[epoch 108, batch    11] loss: 134.22043\n",
      "[epoch 108, batch    12] loss: 137.52154\n",
      "[epoch 108, batch    13] loss: 120.42764\n",
      "[epoch 108, batch    14] loss: 149.25218\n",
      "[epoch 108, batch    15] loss: 137.60115\n",
      "[epoch 108, batch    16] loss: 139.85370\n",
      "[epoch 108, batch    17] loss: 139.03584\n",
      "[epoch 108, batch    18] loss: 142.45718\n",
      "[epoch 108, batch    19] loss: 123.79394\n",
      "[epoch 108, batch    20] loss: 140.67871\n",
      "[epoch 108, batch    21] loss: 134.95996\n",
      "[epoch 108, batch    22] loss: 135.76163\n",
      "[epoch 108, batch    23] loss: 135.31838\n",
      "[epoch 108, batch    24] loss: 139.91953\n",
      "[epoch 108, batch    25] loss: 130.88434\n",
      "[epoch 108, batch    26] loss: 146.78409\n",
      "[epoch 108, batch    27] loss: 137.86485\n",
      "[epoch 108, batch    28] loss: 126.15459\n",
      "[epoch 108, batch    29] loss: 132.24529\n",
      "[epoch 108, batch    30] loss: 140.43759\n",
      "[epoch 108, batch    31] loss: 131.19454\n",
      "[epoch 108, batch    32] loss: 33.32818\n",
      "[epoch 109, batch     1] loss: 145.22297\n",
      "[epoch 109, batch     2] loss: 138.97821\n",
      "[epoch 109, batch     3] loss: 129.23207\n",
      "[epoch 109, batch     4] loss: 132.53302\n",
      "[epoch 109, batch     5] loss: 123.44394\n",
      "[epoch 109, batch     6] loss: 136.22688\n",
      "[epoch 109, batch     7] loss: 131.30922\n",
      "[epoch 109, batch     8] loss: 145.53286\n",
      "[epoch 109, batch     9] loss: 133.06196\n",
      "[epoch 109, batch    10] loss: 125.65874\n",
      "[epoch 109, batch    11] loss: 127.68340\n",
      "[epoch 109, batch    12] loss: 141.06012\n",
      "[epoch 109, batch    13] loss: 134.71516\n",
      "[epoch 109, batch    14] loss: 130.86852\n",
      "[epoch 109, batch    15] loss: 131.45232\n",
      "[epoch 109, batch    16] loss: 137.34372\n",
      "[epoch 109, batch    17] loss: 130.55281\n",
      "[epoch 109, batch    18] loss: 133.77093\n",
      "[epoch 109, batch    19] loss: 130.35845\n",
      "[epoch 109, batch    20] loss: 137.41052\n",
      "[epoch 109, batch    21] loss: 120.18245\n",
      "[epoch 109, batch    22] loss: 136.29620\n",
      "[epoch 109, batch    23] loss: 136.73540\n",
      "[epoch 109, batch    24] loss: 125.69429\n",
      "[epoch 109, batch    25] loss: 139.64143\n",
      "[epoch 109, batch    26] loss: 133.67719\n",
      "[epoch 109, batch    27] loss: 126.07373\n",
      "[epoch 109, batch    28] loss: 135.17386\n",
      "[epoch 109, batch    29] loss: 137.16885\n",
      "[epoch 109, batch    30] loss: 136.31327\n",
      "[epoch 109, batch    31] loss: 138.23270\n",
      "[epoch 109, batch    32] loss: 35.71353\n",
      "[epoch 110, batch     1] loss: 129.80784\n",
      "[epoch 110, batch     2] loss: 134.96747\n",
      "[epoch 110, batch     3] loss: 138.76623\n",
      "[epoch 110, batch     4] loss: 136.06611\n",
      "[epoch 110, batch     5] loss: 129.24112\n",
      "[epoch 110, batch     6] loss: 128.17304\n",
      "[epoch 110, batch     7] loss: 132.53942\n",
      "[epoch 110, batch     8] loss: 127.69872\n",
      "[epoch 110, batch     9] loss: 139.50514\n",
      "[epoch 110, batch    10] loss: 130.52095\n",
      "[epoch 110, batch    11] loss: 139.49817\n",
      "[epoch 110, batch    12] loss: 138.30458\n",
      "[epoch 110, batch    13] loss: 120.10002\n",
      "[epoch 110, batch    14] loss: 148.90204\n",
      "[epoch 110, batch    15] loss: 130.33197\n",
      "[epoch 110, batch    16] loss: 129.29334\n",
      "[epoch 110, batch    17] loss: 130.30804\n",
      "[epoch 110, batch    18] loss: 120.43234\n",
      "[epoch 110, batch    19] loss: 116.76253\n",
      "[epoch 110, batch    20] loss: 136.78530\n",
      "[epoch 110, batch    21] loss: 142.01878\n",
      "[epoch 110, batch    22] loss: 142.36592\n",
      "[epoch 110, batch    23] loss: 143.20356\n",
      "[epoch 110, batch    24] loss: 140.92054\n",
      "[epoch 110, batch    25] loss: 122.15048\n",
      "[epoch 110, batch    26] loss: 132.11511\n",
      "[epoch 110, batch    27] loss: 130.14402\n",
      "[epoch 110, batch    28] loss: 125.40056\n",
      "[epoch 110, batch    29] loss: 132.07466\n",
      "[epoch 110, batch    30] loss: 150.37226\n",
      "[epoch 110, batch    31] loss: 121.21758\n",
      "[epoch 110, batch    32] loss: 39.31578\n",
      "[epoch 111, batch     1] loss: 133.44394\n",
      "[epoch 111, batch     2] loss: 139.26072\n",
      "[epoch 111, batch     3] loss: 133.99728\n",
      "[epoch 111, batch     4] loss: 128.29937\n",
      "[epoch 111, batch     5] loss: 126.05985\n",
      "[epoch 111, batch     6] loss: 143.94067\n",
      "[epoch 111, batch     7] loss: 143.58706\n",
      "[epoch 111, batch     8] loss: 140.27568\n",
      "[epoch 111, batch     9] loss: 125.27573\n",
      "[epoch 111, batch    10] loss: 130.19402\n",
      "[epoch 111, batch    11] loss: 127.38777\n",
      "[epoch 111, batch    12] loss: 138.79897\n",
      "[epoch 111, batch    13] loss: 127.79922\n",
      "[epoch 111, batch    14] loss: 133.23599\n",
      "[epoch 111, batch    15] loss: 141.24066\n",
      "[epoch 111, batch    16] loss: 128.25130\n",
      "[epoch 111, batch    17] loss: 138.60567\n",
      "[epoch 111, batch    18] loss: 139.71203\n",
      "[epoch 111, batch    19] loss: 134.58120\n",
      "[epoch 111, batch    20] loss: 134.22014\n",
      "[epoch 111, batch    21] loss: 113.74129\n",
      "[epoch 111, batch    22] loss: 121.80864\n",
      "[epoch 111, batch    23] loss: 130.78788\n",
      "[epoch 111, batch    24] loss: 137.82108\n",
      "[epoch 111, batch    25] loss: 134.09058\n",
      "[epoch 111, batch    26] loss: 125.94379\n",
      "[epoch 111, batch    27] loss: 134.63800\n",
      "[epoch 111, batch    28] loss: 143.21248\n",
      "[epoch 111, batch    29] loss: 144.81966\n",
      "[epoch 111, batch    30] loss: 153.17515\n",
      "[epoch 111, batch    31] loss: 143.26342\n",
      "[epoch 111, batch    32] loss: 32.81233\n",
      "[epoch 112, batch     1] loss: 131.77887\n",
      "[epoch 112, batch     2] loss: 134.62466\n",
      "[epoch 112, batch     3] loss: 135.78101\n",
      "[epoch 112, batch     4] loss: 133.55344\n",
      "[epoch 112, batch     5] loss: 142.11169\n",
      "[epoch 112, batch     6] loss: 126.75993\n",
      "[epoch 112, batch     7] loss: 150.99602\n",
      "[epoch 112, batch     8] loss: 138.95286\n",
      "[epoch 112, batch     9] loss: 136.30259\n",
      "[epoch 112, batch    10] loss: 142.71656\n",
      "[epoch 112, batch    11] loss: 144.26642\n",
      "[epoch 112, batch    12] loss: 127.73572\n",
      "[epoch 112, batch    13] loss: 136.60816\n",
      "[epoch 112, batch    14] loss: 130.57409\n",
      "[epoch 112, batch    15] loss: 122.29929\n",
      "[epoch 112, batch    16] loss: 142.38001\n",
      "[epoch 112, batch    17] loss: 136.30031\n",
      "[epoch 112, batch    18] loss: 136.19125\n",
      "[epoch 112, batch    19] loss: 127.00647\n",
      "[epoch 112, batch    20] loss: 122.42043\n",
      "[epoch 112, batch    21] loss: 125.23066\n",
      "[epoch 112, batch    22] loss: 126.89090\n",
      "[epoch 112, batch    23] loss: 124.76162\n",
      "[epoch 112, batch    24] loss: 126.29621\n",
      "[epoch 112, batch    25] loss: 133.77784\n",
      "[epoch 112, batch    26] loss: 121.45182\n",
      "[epoch 112, batch    27] loss: 135.54158\n",
      "[epoch 112, batch    28] loss: 135.13795\n",
      "[epoch 112, batch    29] loss: 123.55823\n",
      "[epoch 112, batch    30] loss: 123.37685\n",
      "[epoch 112, batch    31] loss: 137.18194\n",
      "[epoch 112, batch    32] loss: 32.77261\n",
      "[epoch 113, batch     1] loss: 130.76375\n",
      "[epoch 113, batch     2] loss: 144.13843\n",
      "[epoch 113, batch     3] loss: 147.61377\n",
      "[epoch 113, batch     4] loss: 131.59542\n",
      "[epoch 113, batch     5] loss: 127.78751\n",
      "[epoch 113, batch     6] loss: 139.43574\n",
      "[epoch 113, batch     7] loss: 146.67355\n",
      "[epoch 113, batch     8] loss: 129.62294\n",
      "[epoch 113, batch     9] loss: 135.20847\n",
      "[epoch 113, batch    10] loss: 126.40947\n",
      "[epoch 113, batch    11] loss: 131.14351\n",
      "[epoch 113, batch    12] loss: 135.28591\n",
      "[epoch 113, batch    13] loss: 148.01908\n",
      "[epoch 113, batch    14] loss: 123.50682\n",
      "[epoch 113, batch    15] loss: 123.85936\n",
      "[epoch 113, batch    16] loss: 134.95117\n",
      "[epoch 113, batch    17] loss: 151.68441\n",
      "[epoch 113, batch    18] loss: 135.29406\n",
      "[epoch 113, batch    19] loss: 133.40027\n",
      "[epoch 113, batch    20] loss: 131.27447\n",
      "[epoch 113, batch    21] loss: 127.45265\n",
      "[epoch 113, batch    22] loss: 138.91762\n",
      "[epoch 113, batch    23] loss: 134.07293\n",
      "[epoch 113, batch    24] loss: 133.85955\n",
      "[epoch 113, batch    25] loss: 132.38776\n",
      "[epoch 113, batch    26] loss: 141.57485\n",
      "[epoch 113, batch    27] loss: 141.93673\n",
      "[epoch 113, batch    28] loss: 133.26648\n",
      "[epoch 113, batch    29] loss: 130.86641\n",
      "[epoch 113, batch    30] loss: 133.90768\n",
      "[epoch 113, batch    31] loss: 137.54884\n",
      "[epoch 113, batch    32] loss: 35.47472\n",
      "[epoch 114, batch     1] loss: 122.76181\n",
      "[epoch 114, batch     2] loss: 116.81765\n",
      "[epoch 114, batch     3] loss: 134.68324\n",
      "[epoch 114, batch     4] loss: 131.34876\n",
      "[epoch 114, batch     5] loss: 137.42674\n",
      "[epoch 114, batch     6] loss: 130.16094\n",
      "[epoch 114, batch     7] loss: 143.19282\n",
      "[epoch 114, batch     8] loss: 142.68530\n",
      "[epoch 114, batch     9] loss: 133.42207\n",
      "[epoch 114, batch    10] loss: 129.88681\n",
      "[epoch 114, batch    11] loss: 120.05563\n",
      "[epoch 114, batch    12] loss: 145.03864\n",
      "[epoch 114, batch    13] loss: 130.16641\n",
      "[epoch 114, batch    14] loss: 130.73726\n",
      "[epoch 114, batch    15] loss: 135.17824\n",
      "[epoch 114, batch    16] loss: 130.04662\n",
      "[epoch 114, batch    17] loss: 134.63790\n",
      "[epoch 114, batch    18] loss: 141.48684\n",
      "[epoch 114, batch    19] loss: 143.97854\n",
      "[epoch 114, batch    20] loss: 133.98202\n",
      "[epoch 114, batch    21] loss: 129.10858\n",
      "[epoch 114, batch    22] loss: 145.73733\n",
      "[epoch 114, batch    23] loss: 127.91714\n",
      "[epoch 114, batch    24] loss: 136.99795\n",
      "[epoch 114, batch    25] loss: 150.12810\n",
      "[epoch 114, batch    26] loss: 143.22372\n",
      "[epoch 114, batch    27] loss: 129.43565\n",
      "[epoch 114, batch    28] loss: 131.12455\n",
      "[epoch 114, batch    29] loss: 139.54994\n",
      "[epoch 114, batch    30] loss: 121.22406\n",
      "[epoch 114, batch    31] loss: 131.20885\n",
      "[epoch 114, batch    32] loss: 24.56314\n",
      "[epoch 115, batch     1] loss: 130.54542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 115, batch     2] loss: 133.74128\n",
      "[epoch 115, batch     3] loss: 141.63975\n",
      "[epoch 115, batch     4] loss: 133.74651\n",
      "[epoch 115, batch     5] loss: 129.76546\n",
      "[epoch 115, batch     6] loss: 145.07151\n",
      "[epoch 115, batch     7] loss: 128.10479\n",
      "[epoch 115, batch     8] loss: 132.82252\n",
      "[epoch 115, batch     9] loss: 136.10978\n",
      "[epoch 115, batch    10] loss: 124.52868\n",
      "[epoch 115, batch    11] loss: 134.07859\n",
      "[epoch 115, batch    12] loss: 151.91692\n",
      "[epoch 115, batch    13] loss: 141.94851\n",
      "[epoch 115, batch    14] loss: 138.29473\n",
      "[epoch 115, batch    15] loss: 134.73913\n",
      "[epoch 115, batch    16] loss: 151.48391\n",
      "[epoch 115, batch    17] loss: 151.45330\n",
      "[epoch 115, batch    18] loss: 131.11957\n",
      "[epoch 115, batch    19] loss: 119.23137\n",
      "[epoch 115, batch    20] loss: 137.64645\n",
      "[epoch 115, batch    21] loss: 127.12787\n",
      "[epoch 115, batch    22] loss: 131.50637\n",
      "[epoch 115, batch    23] loss: 128.33726\n",
      "[epoch 115, batch    24] loss: 138.05909\n",
      "[epoch 115, batch    25] loss: 131.83668\n",
      "[epoch 115, batch    26] loss: 144.30654\n",
      "[epoch 115, batch    27] loss: 134.86140\n",
      "[epoch 115, batch    28] loss: 131.26651\n",
      "[epoch 115, batch    29] loss: 122.94795\n",
      "[epoch 115, batch    30] loss: 120.65277\n",
      "[epoch 115, batch    31] loss: 138.44059\n",
      "[epoch 115, batch    32] loss: 37.24804\n",
      "[epoch 116, batch     1] loss: 141.98726\n",
      "[epoch 116, batch     2] loss: 136.84551\n",
      "[epoch 116, batch     3] loss: 133.20395\n",
      "[epoch 116, batch     4] loss: 137.71443\n",
      "[epoch 116, batch     5] loss: 132.14637\n",
      "[epoch 116, batch     6] loss: 124.82854\n",
      "[epoch 116, batch     7] loss: 130.32494\n",
      "[epoch 116, batch     8] loss: 128.78230\n",
      "[epoch 116, batch     9] loss: 129.64468\n",
      "[epoch 116, batch    10] loss: 132.21634\n",
      "[epoch 116, batch    11] loss: 133.61029\n",
      "[epoch 116, batch    12] loss: 133.49119\n",
      "[epoch 116, batch    13] loss: 130.15071\n",
      "[epoch 116, batch    14] loss: 141.58278\n",
      "[epoch 116, batch    15] loss: 127.49142\n",
      "[epoch 116, batch    16] loss: 132.40037\n",
      "[epoch 116, batch    17] loss: 125.50054\n",
      "[epoch 116, batch    18] loss: 130.91886\n",
      "[epoch 116, batch    19] loss: 121.02051\n",
      "[epoch 116, batch    20] loss: 144.83555\n",
      "[epoch 116, batch    21] loss: 144.44520\n",
      "[epoch 116, batch    22] loss: 129.89892\n",
      "[epoch 116, batch    23] loss: 146.90314\n",
      "[epoch 116, batch    24] loss: 141.07850\n",
      "[epoch 116, batch    25] loss: 129.30528\n",
      "[epoch 116, batch    26] loss: 141.84009\n",
      "[epoch 116, batch    27] loss: 137.80396\n",
      "[epoch 116, batch    28] loss: 126.04993\n",
      "[epoch 116, batch    29] loss: 131.58383\n",
      "[epoch 116, batch    30] loss: 139.49682\n",
      "[epoch 116, batch    31] loss: 131.00763\n",
      "[epoch 116, batch    32] loss: 35.25612\n",
      "[epoch 117, batch     1] loss: 134.35780\n",
      "[epoch 117, batch     2] loss: 135.16733\n",
      "[epoch 117, batch     3] loss: 136.70541\n",
      "[epoch 117, batch     4] loss: 142.28028\n",
      "[epoch 117, batch     5] loss: 131.96779\n",
      "[epoch 117, batch     6] loss: 139.09229\n",
      "[epoch 117, batch     7] loss: 143.98142\n",
      "[epoch 117, batch     8] loss: 138.51129\n",
      "[epoch 117, batch     9] loss: 129.45737\n",
      "[epoch 117, batch    10] loss: 123.07882\n",
      "[epoch 117, batch    11] loss: 130.31461\n",
      "[epoch 117, batch    12] loss: 122.71634\n",
      "[epoch 117, batch    13] loss: 132.08801\n",
      "[epoch 117, batch    14] loss: 130.47893\n",
      "[epoch 117, batch    15] loss: 134.31613\n",
      "[epoch 117, batch    16] loss: 128.45581\n",
      "[epoch 117, batch    17] loss: 122.36246\n",
      "[epoch 117, batch    18] loss: 135.76380\n",
      "[epoch 117, batch    19] loss: 134.89960\n",
      "[epoch 117, batch    20] loss: 148.53230\n",
      "[epoch 117, batch    21] loss: 134.56740\n",
      "[epoch 117, batch    22] loss: 135.24255\n",
      "[epoch 117, batch    23] loss: 133.38933\n",
      "[epoch 117, batch    24] loss: 119.17248\n",
      "[epoch 117, batch    25] loss: 140.77322\n",
      "[epoch 117, batch    26] loss: 134.40123\n",
      "[epoch 117, batch    27] loss: 122.13825\n",
      "[epoch 117, batch    28] loss: 127.88273\n",
      "[epoch 117, batch    29] loss: 137.56425\n",
      "[epoch 117, batch    30] loss: 131.36142\n",
      "[epoch 117, batch    31] loss: 138.97481\n",
      "[epoch 117, batch    32] loss: 48.25416\n",
      "[epoch 118, batch     1] loss: 138.00622\n",
      "[epoch 118, batch     2] loss: 135.78963\n",
      "[epoch 118, batch     3] loss: 141.01454\n",
      "[epoch 118, batch     4] loss: 125.61420\n",
      "[epoch 118, batch     5] loss: 138.77188\n",
      "[epoch 118, batch     6] loss: 118.31839\n",
      "[epoch 118, batch     7] loss: 135.05185\n",
      "[epoch 118, batch     8] loss: 137.30905\n",
      "[epoch 118, batch     9] loss: 143.63534\n",
      "[epoch 118, batch    10] loss: 134.53450\n",
      "[epoch 118, batch    11] loss: 126.77769\n",
      "[epoch 118, batch    12] loss: 137.00158\n",
      "[epoch 118, batch    13] loss: 137.62799\n",
      "[epoch 118, batch    14] loss: 128.35802\n",
      "[epoch 118, batch    15] loss: 121.71758\n",
      "[epoch 118, batch    16] loss: 138.06292\n",
      "[epoch 118, batch    17] loss: 145.42048\n",
      "[epoch 118, batch    18] loss: 123.25003\n",
      "[epoch 118, batch    19] loss: 135.01337\n",
      "[epoch 118, batch    20] loss: 136.70087\n",
      "[epoch 118, batch    21] loss: 136.19471\n",
      "[epoch 118, batch    22] loss: 133.69413\n",
      "[epoch 118, batch    23] loss: 125.92247\n",
      "[epoch 118, batch    24] loss: 127.79177\n",
      "[epoch 118, batch    25] loss: 123.79883\n",
      "[epoch 118, batch    26] loss: 129.22463\n",
      "[epoch 118, batch    27] loss: 142.29916\n",
      "[epoch 118, batch    28] loss: 131.24021\n",
      "[epoch 118, batch    29] loss: 135.61931\n",
      "[epoch 118, batch    30] loss: 133.54469\n",
      "[epoch 118, batch    31] loss: 127.32844\n",
      "[epoch 118, batch    32] loss: 30.67702\n",
      "[epoch 119, batch     1] loss: 136.53783\n",
      "[epoch 119, batch     2] loss: 130.94854\n",
      "[epoch 119, batch     3] loss: 151.27381\n",
      "[epoch 119, batch     4] loss: 138.59441\n",
      "[epoch 119, batch     5] loss: 132.30822\n",
      "[epoch 119, batch     6] loss: 122.72376\n",
      "[epoch 119, batch     7] loss: 149.85363\n",
      "[epoch 119, batch     8] loss: 123.41763\n",
      "[epoch 119, batch     9] loss: 134.81064\n",
      "[epoch 119, batch    10] loss: 127.55935\n",
      "[epoch 119, batch    11] loss: 135.66510\n",
      "[epoch 119, batch    12] loss: 126.27626\n",
      "[epoch 119, batch    13] loss: 134.78385\n",
      "[epoch 119, batch    14] loss: 130.97793\n",
      "[epoch 119, batch    15] loss: 129.36679\n",
      "[epoch 119, batch    16] loss: 137.43722\n",
      "[epoch 119, batch    17] loss: 142.50164\n",
      "[epoch 119, batch    18] loss: 132.80941\n",
      "[epoch 119, batch    19] loss: 129.87809\n",
      "[epoch 119, batch    20] loss: 132.22754\n",
      "[epoch 119, batch    21] loss: 128.86773\n",
      "[epoch 119, batch    22] loss: 130.88215\n",
      "[epoch 119, batch    23] loss: 132.87119\n",
      "[epoch 119, batch    24] loss: 143.58149\n",
      "[epoch 119, batch    25] loss: 127.89426\n",
      "[epoch 119, batch    26] loss: 134.85601\n",
      "[epoch 119, batch    27] loss: 126.17422\n",
      "[epoch 119, batch    28] loss: 145.93122\n",
      "[epoch 119, batch    29] loss: 133.34056\n",
      "[epoch 119, batch    30] loss: 125.46964\n",
      "[epoch 119, batch    31] loss: 127.63977\n",
      "[epoch 119, batch    32] loss: 32.15951\n",
      "[epoch 120, batch     1] loss: 126.07009\n",
      "[epoch 120, batch     2] loss: 139.36030\n",
      "[epoch 120, batch     3] loss: 120.91851\n",
      "[epoch 120, batch     4] loss: 135.07680\n",
      "[epoch 120, batch     5] loss: 139.60819\n",
      "[epoch 120, batch     6] loss: 127.56199\n",
      "[epoch 120, batch     7] loss: 133.31955\n",
      "[epoch 120, batch     8] loss: 141.03861\n",
      "[epoch 120, batch     9] loss: 134.72205\n",
      "[epoch 120, batch    10] loss: 135.42061\n",
      "[epoch 120, batch    11] loss: 142.66010\n",
      "[epoch 120, batch    12] loss: 137.84736\n",
      "[epoch 120, batch    13] loss: 133.33418\n",
      "[epoch 120, batch    14] loss: 137.29526\n",
      "[epoch 120, batch    15] loss: 129.40101\n",
      "[epoch 120, batch    16] loss: 132.84788\n",
      "[epoch 120, batch    17] loss: 139.11806\n",
      "[epoch 120, batch    18] loss: 134.88737\n",
      "[epoch 120, batch    19] loss: 136.85676\n",
      "[epoch 120, batch    20] loss: 141.28023\n",
      "[epoch 120, batch    21] loss: 134.84675\n",
      "[epoch 120, batch    22] loss: 123.48132\n",
      "[epoch 120, batch    23] loss: 140.14050\n",
      "[epoch 120, batch    24] loss: 131.15913\n",
      "[epoch 120, batch    25] loss: 137.75881\n",
      "[epoch 120, batch    26] loss: 134.58350\n",
      "[epoch 120, batch    27] loss: 130.72954\n",
      "[epoch 120, batch    28] loss: 128.72554\n",
      "[epoch 120, batch    29] loss: 130.38240\n",
      "[epoch 120, batch    30] loss: 143.27980\n",
      "[epoch 120, batch    31] loss: 140.65538\n",
      "[epoch 120, batch    32] loss: 30.71028\n",
      "[epoch 121, batch     1] loss: 137.66761\n",
      "[epoch 121, batch     2] loss: 132.88580\n",
      "[epoch 121, batch     3] loss: 128.95117\n",
      "[epoch 121, batch     4] loss: 131.69097\n",
      "[epoch 121, batch     5] loss: 121.81631\n",
      "[epoch 121, batch     6] loss: 140.43629\n",
      "[epoch 121, batch     7] loss: 140.41571\n",
      "[epoch 121, batch     8] loss: 126.48332\n",
      "[epoch 121, batch     9] loss: 126.46426\n",
      "[epoch 121, batch    10] loss: 134.96974\n",
      "[epoch 121, batch    11] loss: 130.51978\n",
      "[epoch 121, batch    12] loss: 136.40321\n",
      "[epoch 121, batch    13] loss: 126.57691\n",
      "[epoch 121, batch    14] loss: 126.35452\n",
      "[epoch 121, batch    15] loss: 130.89224\n",
      "[epoch 121, batch    16] loss: 143.17670\n",
      "[epoch 121, batch    17] loss: 146.80050\n",
      "[epoch 121, batch    18] loss: 133.36959\n",
      "[epoch 121, batch    19] loss: 137.54443\n",
      "[epoch 121, batch    20] loss: 140.29889\n",
      "[epoch 121, batch    21] loss: 125.93291\n",
      "[epoch 121, batch    22] loss: 139.08714\n",
      "[epoch 121, batch    23] loss: 143.76134\n",
      "[epoch 121, batch    24] loss: 130.80496\n",
      "[epoch 121, batch    25] loss: 143.43960\n",
      "[epoch 121, batch    26] loss: 133.84042\n",
      "[epoch 121, batch    27] loss: 131.45684\n",
      "[epoch 121, batch    28] loss: 129.46857\n",
      "[epoch 121, batch    29] loss: 126.08830\n",
      "[epoch 121, batch    30] loss: 128.00965\n",
      "[epoch 121, batch    31] loss: 130.37414\n",
      "[epoch 121, batch    32] loss: 32.22836\n",
      "[epoch 122, batch     1] loss: 125.75560\n",
      "[epoch 122, batch     2] loss: 126.40445\n",
      "[epoch 122, batch     3] loss: 138.46752\n",
      "[epoch 122, batch     4] loss: 136.20748\n",
      "[epoch 122, batch     5] loss: 127.29784\n",
      "[epoch 122, batch     6] loss: 129.35606\n",
      "[epoch 122, batch     7] loss: 133.14519\n",
      "[epoch 122, batch     8] loss: 147.72733\n",
      "[epoch 122, batch     9] loss: 136.77759\n",
      "[epoch 122, batch    10] loss: 129.76917\n",
      "[epoch 122, batch    11] loss: 135.02783\n",
      "[epoch 122, batch    12] loss: 133.89539\n",
      "[epoch 122, batch    13] loss: 136.82354\n",
      "[epoch 122, batch    14] loss: 127.00149\n",
      "[epoch 122, batch    15] loss: 144.91159\n",
      "[epoch 122, batch    16] loss: 130.63037\n",
      "[epoch 122, batch    17] loss: 140.55200\n",
      "[epoch 122, batch    18] loss: 140.54350\n",
      "[epoch 122, batch    19] loss: 134.33023\n",
      "[epoch 122, batch    20] loss: 118.71835\n",
      "[epoch 122, batch    21] loss: 141.12245\n",
      "[epoch 122, batch    22] loss: 142.33793\n",
      "[epoch 122, batch    23] loss: 126.09931\n",
      "[epoch 122, batch    24] loss: 133.26773\n",
      "[epoch 122, batch    25] loss: 141.77800\n",
      "[epoch 122, batch    26] loss: 128.97450\n",
      "[epoch 122, batch    27] loss: 135.92700\n",
      "[epoch 122, batch    28] loss: 132.31057\n",
      "[epoch 122, batch    29] loss: 136.75570\n",
      "[epoch 122, batch    30] loss: 132.67202\n",
      "[epoch 122, batch    31] loss: 127.45063\n",
      "[epoch 122, batch    32] loss: 31.17542\n",
      "[epoch 123, batch     1] loss: 122.35870\n",
      "[epoch 123, batch     2] loss: 132.39396\n",
      "[epoch 123, batch     3] loss: 139.86510\n",
      "[epoch 123, batch     4] loss: 142.93926\n",
      "[epoch 123, batch     5] loss: 141.26975\n",
      "[epoch 123, batch     6] loss: 131.51005\n",
      "[epoch 123, batch     7] loss: 138.83830\n",
      "[epoch 123, batch     8] loss: 136.78651\n",
      "[epoch 123, batch     9] loss: 134.52722\n",
      "[epoch 123, batch    10] loss: 139.33849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 123, batch    11] loss: 138.00783\n",
      "[epoch 123, batch    12] loss: 135.49650\n",
      "[epoch 123, batch    13] loss: 117.04891\n",
      "[epoch 123, batch    14] loss: 137.09887\n",
      "[epoch 123, batch    15] loss: 138.65246\n",
      "[epoch 123, batch    16] loss: 136.27972\n",
      "[epoch 123, batch    17] loss: 118.16005\n",
      "[epoch 123, batch    18] loss: 120.87959\n",
      "[epoch 123, batch    19] loss: 130.06243\n",
      "[epoch 123, batch    20] loss: 116.63868\n",
      "[epoch 123, batch    21] loss: 141.28213\n",
      "[epoch 123, batch    22] loss: 134.18777\n",
      "[epoch 123, batch    23] loss: 118.62430\n",
      "[epoch 123, batch    24] loss: 125.21171\n",
      "[epoch 123, batch    25] loss: 139.61908\n",
      "[epoch 123, batch    26] loss: 149.86342\n",
      "[epoch 123, batch    27] loss: 131.12044\n",
      "[epoch 123, batch    28] loss: 136.83552\n",
      "[epoch 123, batch    29] loss: 126.65168\n",
      "[epoch 123, batch    30] loss: 127.20395\n",
      "[epoch 123, batch    31] loss: 137.33368\n",
      "[epoch 123, batch    32] loss: 28.89620\n",
      "[epoch 124, batch     1] loss: 131.79651\n",
      "[epoch 124, batch     2] loss: 125.40503\n",
      "[epoch 124, batch     3] loss: 128.26133\n",
      "[epoch 124, batch     4] loss: 129.85399\n",
      "[epoch 124, batch     5] loss: 135.69709\n",
      "[epoch 124, batch     6] loss: 128.28089\n",
      "[epoch 124, batch     7] loss: 140.34997\n",
      "[epoch 124, batch     8] loss: 140.20448\n",
      "[epoch 124, batch     9] loss: 134.57360\n",
      "[epoch 124, batch    10] loss: 125.73425\n",
      "[epoch 124, batch    11] loss: 132.60068\n",
      "[epoch 124, batch    12] loss: 122.47740\n",
      "[epoch 124, batch    13] loss: 135.08424\n",
      "[epoch 124, batch    14] loss: 131.64955\n",
      "[epoch 124, batch    15] loss: 136.86951\n",
      "[epoch 124, batch    16] loss: 133.86549\n",
      "[epoch 124, batch    17] loss: 120.39589\n",
      "[epoch 124, batch    18] loss: 137.39139\n",
      "[epoch 124, batch    19] loss: 136.68414\n",
      "[epoch 124, batch    20] loss: 139.63807\n",
      "[epoch 124, batch    21] loss: 145.37077\n",
      "[epoch 124, batch    22] loss: 143.07627\n",
      "[epoch 124, batch    23] loss: 146.28619\n",
      "[epoch 124, batch    24] loss: 136.15637\n",
      "[epoch 124, batch    25] loss: 147.85592\n",
      "[epoch 124, batch    26] loss: 131.88311\n",
      "[epoch 124, batch    27] loss: 137.52272\n",
      "[epoch 124, batch    28] loss: 130.91914\n",
      "[epoch 124, batch    29] loss: 122.91050\n",
      "[epoch 124, batch    30] loss: 130.74411\n",
      "[epoch 124, batch    31] loss: 149.85194\n",
      "[epoch 124, batch    32] loss: 28.08296\n",
      "[epoch 125, batch     1] loss: 124.21388\n",
      "[epoch 125, batch     2] loss: 127.86643\n",
      "[epoch 125, batch     3] loss: 128.05256\n",
      "[epoch 125, batch     4] loss: 125.19782\n",
      "[epoch 125, batch     5] loss: 139.54515\n",
      "[epoch 125, batch     6] loss: 138.09948\n",
      "[epoch 125, batch     7] loss: 130.96969\n",
      "[epoch 125, batch     8] loss: 131.56849\n",
      "[epoch 125, batch     9] loss: 136.39296\n",
      "[epoch 125, batch    10] loss: 142.30059\n",
      "[epoch 125, batch    11] loss: 122.90059\n",
      "[epoch 125, batch    12] loss: 129.52912\n",
      "[epoch 125, batch    13] loss: 125.46886\n",
      "[epoch 125, batch    14] loss: 127.96052\n",
      "[epoch 125, batch    15] loss: 139.19152\n",
      "[epoch 125, batch    16] loss: 134.58478\n",
      "[epoch 125, batch    17] loss: 129.70181\n",
      "[epoch 125, batch    18] loss: 131.98236\n",
      "[epoch 125, batch    19] loss: 143.48438\n",
      "[epoch 125, batch    20] loss: 141.50342\n",
      "[epoch 125, batch    21] loss: 148.46041\n",
      "[epoch 125, batch    22] loss: 131.61745\n",
      "[epoch 125, batch    23] loss: 126.98153\n",
      "[epoch 125, batch    24] loss: 137.20517\n",
      "[epoch 125, batch    25] loss: 136.59256\n",
      "[epoch 125, batch    26] loss: 130.63053\n",
      "[epoch 125, batch    27] loss: 134.69305\n",
      "[epoch 125, batch    28] loss: 119.35992\n",
      "[epoch 125, batch    29] loss: 131.13177\n",
      "[epoch 125, batch    30] loss: 137.68792\n",
      "[epoch 125, batch    31] loss: 135.76929\n",
      "[epoch 125, batch    32] loss: 36.39726\n",
      "[epoch 126, batch     1] loss: 144.61600\n",
      "[epoch 126, batch     2] loss: 129.30225\n",
      "[epoch 126, batch     3] loss: 131.32758\n",
      "[epoch 126, batch     4] loss: 131.63299\n",
      "[epoch 126, batch     5] loss: 130.99891\n",
      "[epoch 126, batch     6] loss: 127.14530\n",
      "[epoch 126, batch     7] loss: 132.24424\n",
      "[epoch 126, batch     8] loss: 119.60790\n",
      "[epoch 126, batch     9] loss: 151.30826\n",
      "[epoch 126, batch    10] loss: 137.06790\n",
      "[epoch 126, batch    11] loss: 124.97979\n",
      "[epoch 126, batch    12] loss: 137.19314\n",
      "[epoch 126, batch    13] loss: 134.05597\n",
      "[epoch 126, batch    14] loss: 133.94349\n",
      "[epoch 126, batch    15] loss: 135.26371\n",
      "[epoch 126, batch    16] loss: 121.71092\n",
      "[epoch 126, batch    17] loss: 139.30100\n",
      "[epoch 126, batch    18] loss: 135.18653\n",
      "[epoch 126, batch    19] loss: 127.83434\n",
      "[epoch 126, batch    20] loss: 149.38347\n",
      "[epoch 126, batch    21] loss: 151.38480\n",
      "[epoch 126, batch    22] loss: 140.32920\n",
      "[epoch 126, batch    23] loss: 138.01037\n",
      "[epoch 126, batch    24] loss: 133.38675\n",
      "[epoch 126, batch    25] loss: 136.25744\n",
      "[epoch 126, batch    26] loss: 141.58112\n",
      "[epoch 126, batch    27] loss: 129.44804\n",
      "[epoch 126, batch    28] loss: 137.48037\n",
      "[epoch 126, batch    29] loss: 125.62818\n",
      "[epoch 126, batch    30] loss: 137.16019\n",
      "[epoch 126, batch    31] loss: 150.08644\n",
      "[epoch 126, batch    32] loss: 34.52027\n",
      "[epoch 127, batch     1] loss: 134.56908\n",
      "[epoch 127, batch     2] loss: 131.66697\n",
      "[epoch 127, batch     3] loss: 140.63469\n",
      "[epoch 127, batch     4] loss: 131.71460\n",
      "[epoch 127, batch     5] loss: 125.94476\n",
      "[epoch 127, batch     6] loss: 127.58788\n",
      "[epoch 127, batch     7] loss: 138.53422\n",
      "[epoch 127, batch     8] loss: 136.34661\n",
      "[epoch 127, batch     9] loss: 127.90253\n",
      "[epoch 127, batch    10] loss: 129.91217\n",
      "[epoch 127, batch    11] loss: 125.87483\n",
      "[epoch 127, batch    12] loss: 135.55672\n",
      "[epoch 127, batch    13] loss: 137.13091\n",
      "[epoch 127, batch    14] loss: 130.65447\n",
      "[epoch 127, batch    15] loss: 139.63606\n",
      "[epoch 127, batch    16] loss: 129.63441\n",
      "[epoch 127, batch    17] loss: 129.92899\n",
      "[epoch 127, batch    18] loss: 123.84920\n",
      "[epoch 127, batch    19] loss: 127.71654\n",
      "[epoch 127, batch    20] loss: 127.60250\n",
      "[epoch 127, batch    21] loss: 135.26244\n",
      "[epoch 127, batch    22] loss: 138.24764\n",
      "[epoch 127, batch    23] loss: 140.13649\n",
      "[epoch 127, batch    24] loss: 127.82101\n",
      "[epoch 127, batch    25] loss: 155.74936\n",
      "[epoch 127, batch    26] loss: 133.83666\n",
      "[epoch 127, batch    27] loss: 127.18358\n",
      "[epoch 127, batch    28] loss: 133.57106\n",
      "[epoch 127, batch    29] loss: 132.48779\n",
      "[epoch 127, batch    30] loss: 140.90457\n",
      "[epoch 127, batch    31] loss: 129.27753\n",
      "[epoch 127, batch    32] loss: 34.12851\n",
      "[epoch 128, batch     1] loss: 137.76124\n",
      "[epoch 128, batch     2] loss: 138.68791\n",
      "[epoch 128, batch     3] loss: 148.31944\n",
      "[epoch 128, batch     4] loss: 127.38369\n",
      "[epoch 128, batch     5] loss: 131.30850\n",
      "[epoch 128, batch     6] loss: 137.49583\n",
      "[epoch 128, batch     7] loss: 127.08347\n",
      "[epoch 128, batch     8] loss: 132.25041\n",
      "[epoch 128, batch     9] loss: 128.04032\n",
      "[epoch 128, batch    10] loss: 125.40551\n",
      "[epoch 128, batch    11] loss: 130.95122\n",
      "[epoch 128, batch    12] loss: 140.52998\n",
      "[epoch 128, batch    13] loss: 139.21989\n",
      "[epoch 128, batch    14] loss: 118.35374\n",
      "[epoch 128, batch    15] loss: 148.34899\n",
      "[epoch 128, batch    16] loss: 140.47821\n",
      "[epoch 128, batch    17] loss: 138.01323\n",
      "[epoch 128, batch    18] loss: 145.34365\n",
      "[epoch 128, batch    19] loss: 138.62382\n",
      "[epoch 128, batch    20] loss: 119.96092\n",
      "[epoch 128, batch    21] loss: 140.13080\n",
      "[epoch 128, batch    22] loss: 134.72478\n",
      "[epoch 128, batch    23] loss: 135.51981\n",
      "[epoch 128, batch    24] loss: 129.67830\n",
      "[epoch 128, batch    25] loss: 134.11780\n",
      "[epoch 128, batch    26] loss: 129.67480\n",
      "[epoch 128, batch    27] loss: 130.36658\n",
      "[epoch 128, batch    28] loss: 136.05658\n",
      "[epoch 128, batch    29] loss: 127.16816\n",
      "[epoch 128, batch    30] loss: 130.63886\n",
      "[epoch 128, batch    31] loss: 134.60492\n",
      "[epoch 128, batch    32] loss: 36.95850\n",
      "[epoch 129, batch     1] loss: 122.09950\n",
      "[epoch 129, batch     2] loss: 139.74420\n",
      "[epoch 129, batch     3] loss: 134.24409\n",
      "[epoch 129, batch     4] loss: 141.24219\n",
      "[epoch 129, batch     5] loss: 125.92720\n",
      "[epoch 129, batch     6] loss: 131.63613\n",
      "[epoch 129, batch     7] loss: 120.40490\n",
      "[epoch 129, batch     8] loss: 127.63271\n",
      "[epoch 129, batch     9] loss: 138.13963\n",
      "[epoch 129, batch    10] loss: 135.58611\n",
      "[epoch 129, batch    11] loss: 127.45554\n",
      "[epoch 129, batch    12] loss: 130.25832\n",
      "[epoch 129, batch    13] loss: 134.46259\n",
      "[epoch 129, batch    14] loss: 146.10344\n",
      "[epoch 129, batch    15] loss: 133.67594\n",
      "[epoch 129, batch    16] loss: 131.21374\n",
      "[epoch 129, batch    17] loss: 135.62717\n",
      "[epoch 129, batch    18] loss: 139.60152\n",
      "[epoch 129, batch    19] loss: 131.15718\n",
      "[epoch 129, batch    20] loss: 136.34240\n",
      "[epoch 129, batch    21] loss: 137.91993\n",
      "[epoch 129, batch    22] loss: 131.19384\n",
      "[epoch 129, batch    23] loss: 129.07990\n",
      "[epoch 129, batch    24] loss: 130.21728\n",
      "[epoch 129, batch    25] loss: 119.51194\n",
      "[epoch 129, batch    26] loss: 135.61405\n",
      "[epoch 129, batch    27] loss: 128.78399\n",
      "[epoch 129, batch    28] loss: 126.50070\n",
      "[epoch 129, batch    29] loss: 121.71216\n",
      "[epoch 129, batch    30] loss: 139.85657\n",
      "[epoch 129, batch    31] loss: 143.57835\n",
      "[epoch 129, batch    32] loss: 33.52245\n",
      "[epoch 130, batch     1] loss: 142.01346\n",
      "[epoch 130, batch     2] loss: 126.04002\n",
      "[epoch 130, batch     3] loss: 135.29970\n",
      "[epoch 130, batch     4] loss: 121.89938\n",
      "[epoch 130, batch     5] loss: 139.47536\n",
      "[epoch 130, batch     6] loss: 145.96879\n",
      "[epoch 130, batch     7] loss: 123.85984\n",
      "[epoch 130, batch     8] loss: 140.36749\n",
      "[epoch 130, batch     9] loss: 131.85219\n",
      "[epoch 130, batch    10] loss: 133.61082\n",
      "[epoch 130, batch    11] loss: 140.40914\n",
      "[epoch 130, batch    12] loss: 144.27884\n",
      "[epoch 130, batch    13] loss: 149.25210\n",
      "[epoch 130, batch    14] loss: 122.17338\n",
      "[epoch 130, batch    15] loss: 122.31877\n",
      "[epoch 130, batch    16] loss: 132.68466\n",
      "[epoch 130, batch    17] loss: 130.45106\n",
      "[epoch 130, batch    18] loss: 136.88710\n",
      "[epoch 130, batch    19] loss: 139.55510\n",
      "[epoch 130, batch    20] loss: 135.29095\n",
      "[epoch 130, batch    21] loss: 127.92529\n",
      "[epoch 130, batch    22] loss: 120.59367\n",
      "[epoch 130, batch    23] loss: 125.68777\n",
      "[epoch 130, batch    24] loss: 125.44003\n",
      "[epoch 130, batch    25] loss: 136.84196\n",
      "[epoch 130, batch    26] loss: 120.76413\n",
      "[epoch 130, batch    27] loss: 139.70100\n",
      "[epoch 130, batch    28] loss: 138.56575\n",
      "[epoch 130, batch    29] loss: 129.49221\n",
      "[epoch 130, batch    30] loss: 140.45218\n",
      "[epoch 130, batch    31] loss: 128.23689\n",
      "[epoch 130, batch    32] loss: 29.43293\n",
      "[epoch 131, batch     1] loss: 127.66292\n",
      "[epoch 131, batch     2] loss: 144.17384\n",
      "[epoch 131, batch     3] loss: 144.21526\n",
      "[epoch 131, batch     4] loss: 137.75887\n",
      "[epoch 131, batch     5] loss: 134.41250\n",
      "[epoch 131, batch     6] loss: 123.05003\n",
      "[epoch 131, batch     7] loss: 138.33646\n",
      "[epoch 131, batch     8] loss: 128.75701\n",
      "[epoch 131, batch     9] loss: 134.35105\n",
      "[epoch 131, batch    10] loss: 135.84558\n",
      "[epoch 131, batch    11] loss: 130.02569\n",
      "[epoch 131, batch    12] loss: 132.52161\n",
      "[epoch 131, batch    13] loss: 135.60767\n",
      "[epoch 131, batch    14] loss: 132.78515\n",
      "[epoch 131, batch    15] loss: 139.81729\n",
      "[epoch 131, batch    16] loss: 128.17719\n",
      "[epoch 131, batch    17] loss: 130.16583\n",
      "[epoch 131, batch    18] loss: 133.71324\n",
      "[epoch 131, batch    19] loss: 144.56829\n",
      "[epoch 131, batch    20] loss: 138.28877\n",
      "[epoch 131, batch    21] loss: 124.53815\n",
      "[epoch 131, batch    22] loss: 128.73223\n",
      "[epoch 131, batch    23] loss: 121.13416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 131, batch    24] loss: 136.75075\n",
      "[epoch 131, batch    25] loss: 129.29680\n",
      "[epoch 131, batch    26] loss: 133.40391\n",
      "[epoch 131, batch    27] loss: 139.29692\n",
      "[epoch 131, batch    28] loss: 129.05609\n",
      "[epoch 131, batch    29] loss: 122.73648\n",
      "[epoch 131, batch    30] loss: 125.91862\n",
      "[epoch 131, batch    31] loss: 132.18059\n",
      "[epoch 131, batch    32] loss: 31.04628\n",
      "[epoch 132, batch     1] loss: 139.68118\n",
      "[epoch 132, batch     2] loss: 140.44188\n",
      "[epoch 132, batch     3] loss: 125.80295\n",
      "[epoch 132, batch     4] loss: 134.55493\n",
      "[epoch 132, batch     5] loss: 124.31857\n",
      "[epoch 132, batch     6] loss: 140.87682\n",
      "[epoch 132, batch     7] loss: 117.32976\n",
      "[epoch 132, batch     8] loss: 131.83205\n",
      "[epoch 132, batch     9] loss: 123.56396\n",
      "[epoch 132, batch    10] loss: 130.98654\n",
      "[epoch 132, batch    11] loss: 123.13585\n",
      "[epoch 132, batch    12] loss: 126.82857\n",
      "[epoch 132, batch    13] loss: 137.67825\n",
      "[epoch 132, batch    14] loss: 127.01756\n",
      "[epoch 132, batch    15] loss: 151.24577\n",
      "[epoch 132, batch    16] loss: 129.52882\n",
      "[epoch 132, batch    17] loss: 134.70324\n",
      "[epoch 132, batch    18] loss: 128.32129\n",
      "[epoch 132, batch    19] loss: 122.15570\n",
      "[epoch 132, batch    20] loss: 125.67363\n",
      "[epoch 132, batch    21] loss: 131.25540\n",
      "[epoch 132, batch    22] loss: 137.47927\n",
      "[epoch 132, batch    23] loss: 133.44721\n",
      "[epoch 132, batch    24] loss: 134.40725\n",
      "[epoch 132, batch    25] loss: 130.47047\n",
      "[epoch 132, batch    26] loss: 139.48678\n",
      "[epoch 132, batch    27] loss: 138.41305\n",
      "[epoch 132, batch    28] loss: 145.80252\n",
      "[epoch 132, batch    29] loss: 132.86220\n",
      "[epoch 132, batch    30] loss: 126.59307\n",
      "[epoch 132, batch    31] loss: 130.72071\n",
      "[epoch 132, batch    32] loss: 35.92018\n",
      "[epoch 133, batch     1] loss: 132.59097\n",
      "[epoch 133, batch     2] loss: 123.40332\n",
      "[epoch 133, batch     3] loss: 133.42039\n",
      "[epoch 133, batch     4] loss: 138.05200\n",
      "[epoch 133, batch     5] loss: 137.25227\n",
      "[epoch 133, batch     6] loss: 127.61836\n",
      "[epoch 133, batch     7] loss: 143.51471\n",
      "[epoch 133, batch     8] loss: 131.84034\n",
      "[epoch 133, batch     9] loss: 147.35759\n",
      "[epoch 133, batch    10] loss: 130.52215\n",
      "[epoch 133, batch    11] loss: 133.16176\n",
      "[epoch 133, batch    12] loss: 139.48356\n",
      "[epoch 133, batch    13] loss: 127.14840\n",
      "[epoch 133, batch    14] loss: 137.68865\n",
      "[epoch 133, batch    15] loss: 122.56888\n",
      "[epoch 133, batch    16] loss: 129.69840\n",
      "[epoch 133, batch    17] loss: 132.69356\n",
      "[epoch 133, batch    18] loss: 137.72601\n",
      "[epoch 133, batch    19] loss: 134.62718\n",
      "[epoch 133, batch    20] loss: 121.50945\n",
      "[epoch 133, batch    21] loss: 132.89916\n",
      "[epoch 133, batch    22] loss: 137.07624\n",
      "[epoch 133, batch    23] loss: 133.42161\n",
      "[epoch 133, batch    24] loss: 130.20945\n",
      "[epoch 133, batch    25] loss: 131.36276\n",
      "[epoch 133, batch    26] loss: 143.94954\n",
      "[epoch 133, batch    27] loss: 137.82051\n",
      "[epoch 133, batch    28] loss: 145.13014\n",
      "[epoch 133, batch    29] loss: 131.14056\n",
      "[epoch 133, batch    30] loss: 128.22494\n",
      "[epoch 133, batch    31] loss: 135.88714\n",
      "[epoch 133, batch    32] loss: 35.91055\n",
      "[epoch 134, batch     1] loss: 140.81821\n",
      "[epoch 134, batch     2] loss: 125.85235\n",
      "[epoch 134, batch     3] loss: 128.23282\n",
      "[epoch 134, batch     4] loss: 126.33632\n",
      "[epoch 134, batch     5] loss: 134.20335\n",
      "[epoch 134, batch     6] loss: 123.20137\n",
      "[epoch 134, batch     7] loss: 140.62521\n",
      "[epoch 134, batch     8] loss: 133.86015\n",
      "[epoch 134, batch     9] loss: 146.76476\n",
      "[epoch 134, batch    10] loss: 136.06613\n",
      "[epoch 134, batch    11] loss: 142.54078\n",
      "[epoch 134, batch    12] loss: 127.89650\n",
      "[epoch 134, batch    13] loss: 132.01716\n",
      "[epoch 134, batch    14] loss: 132.80933\n",
      "[epoch 134, batch    15] loss: 119.64556\n",
      "[epoch 134, batch    16] loss: 140.93085\n",
      "[epoch 134, batch    17] loss: 135.20357\n",
      "[epoch 134, batch    18] loss: 138.89240\n",
      "[epoch 134, batch    19] loss: 144.26346\n",
      "[epoch 134, batch    20] loss: 117.08991\n",
      "[epoch 134, batch    21] loss: 127.79045\n",
      "[epoch 134, batch    22] loss: 123.77450\n",
      "[epoch 134, batch    23] loss: 126.86247\n",
      "[epoch 134, batch    24] loss: 136.62902\n",
      "[epoch 134, batch    25] loss: 138.30936\n",
      "[epoch 134, batch    26] loss: 149.26202\n",
      "[epoch 134, batch    27] loss: 128.16151\n",
      "[epoch 134, batch    28] loss: 133.65287\n",
      "[epoch 134, batch    29] loss: 136.40689\n",
      "[epoch 134, batch    30] loss: 128.20013\n",
      "[epoch 134, batch    31] loss: 131.73836\n",
      "[epoch 134, batch    32] loss: 40.23920\n",
      "[epoch 135, batch     1] loss: 132.00304\n",
      "[epoch 135, batch     2] loss: 117.58371\n",
      "[epoch 135, batch     3] loss: 128.50990\n",
      "[epoch 135, batch     4] loss: 138.77533\n",
      "[epoch 135, batch     5] loss: 118.03770\n",
      "[epoch 135, batch     6] loss: 140.11442\n",
      "[epoch 135, batch     7] loss: 132.05284\n",
      "[epoch 135, batch     8] loss: 137.79570\n",
      "[epoch 135, batch     9] loss: 130.57525\n",
      "[epoch 135, batch    10] loss: 135.25752\n",
      "[epoch 135, batch    11] loss: 133.88046\n",
      "[epoch 135, batch    12] loss: 133.87983\n",
      "[epoch 135, batch    13] loss: 127.10273\n",
      "[epoch 135, batch    14] loss: 137.70874\n",
      "[epoch 135, batch    15] loss: 129.57213\n",
      "[epoch 135, batch    16] loss: 135.04510\n",
      "[epoch 135, batch    17] loss: 134.60859\n",
      "[epoch 135, batch    18] loss: 143.80691\n",
      "[epoch 135, batch    19] loss: 132.58215\n",
      "[epoch 135, batch    20] loss: 137.60658\n",
      "[epoch 135, batch    21] loss: 147.31856\n",
      "[epoch 135, batch    22] loss: 141.29936\n",
      "[epoch 135, batch    23] loss: 137.73327\n",
      "[epoch 135, batch    24] loss: 145.87485\n",
      "[epoch 135, batch    25] loss: 140.17111\n",
      "[epoch 135, batch    26] loss: 130.31753\n",
      "[epoch 135, batch    27] loss: 136.03625\n",
      "[epoch 135, batch    28] loss: 133.48987\n",
      "[epoch 135, batch    29] loss: 121.70791\n",
      "[epoch 135, batch    30] loss: 128.53227\n",
      "[epoch 135, batch    31] loss: 125.02005\n",
      "[epoch 135, batch    32] loss: 36.52513\n",
      "[epoch 136, batch     1] loss: 128.27524\n",
      "[epoch 136, batch     2] loss: 130.03986\n",
      "[epoch 136, batch     3] loss: 131.57600\n",
      "[epoch 136, batch     4] loss: 132.22325\n",
      "[epoch 136, batch     5] loss: 134.64070\n",
      "[epoch 136, batch     6] loss: 128.12811\n",
      "[epoch 136, batch     7] loss: 127.47099\n",
      "[epoch 136, batch     8] loss: 115.36331\n",
      "[epoch 136, batch     9] loss: 134.45611\n",
      "[epoch 136, batch    10] loss: 121.62804\n",
      "[epoch 136, batch    11] loss: 133.45781\n",
      "[epoch 136, batch    12] loss: 124.28307\n",
      "[epoch 136, batch    13] loss: 145.03353\n",
      "[epoch 136, batch    14] loss: 122.68260\n",
      "[epoch 136, batch    15] loss: 140.10304\n",
      "[epoch 136, batch    16] loss: 144.07116\n",
      "[epoch 136, batch    17] loss: 141.15396\n",
      "[epoch 136, batch    18] loss: 130.37281\n",
      "[epoch 136, batch    19] loss: 135.36882\n",
      "[epoch 136, batch    20] loss: 133.99990\n",
      "[epoch 136, batch    21] loss: 113.22694\n",
      "[epoch 136, batch    22] loss: 138.24833\n",
      "[epoch 136, batch    23] loss: 130.46507\n",
      "[epoch 136, batch    24] loss: 142.00946\n",
      "[epoch 136, batch    25] loss: 139.84825\n",
      "[epoch 136, batch    26] loss: 131.63262\n",
      "[epoch 136, batch    27] loss: 151.09949\n",
      "[epoch 136, batch    28] loss: 125.23168\n",
      "[epoch 136, batch    29] loss: 135.06752\n",
      "[epoch 136, batch    30] loss: 151.10384\n",
      "[epoch 136, batch    31] loss: 138.10845\n",
      "[epoch 136, batch    32] loss: 31.54551\n",
      "[epoch 137, batch     1] loss: 121.90773\n",
      "[epoch 137, batch     2] loss: 129.48145\n",
      "[epoch 137, batch     3] loss: 144.47452\n",
      "[epoch 137, batch     4] loss: 127.71434\n",
      "[epoch 137, batch     5] loss: 137.31557\n",
      "[epoch 137, batch     6] loss: 134.75418\n",
      "[epoch 137, batch     7] loss: 139.78086\n",
      "[epoch 137, batch     8] loss: 131.14829\n",
      "[epoch 137, batch     9] loss: 132.20498\n",
      "[epoch 137, batch    10] loss: 135.76551\n",
      "[epoch 137, batch    11] loss: 137.68803\n",
      "[epoch 137, batch    12] loss: 127.93858\n",
      "[epoch 137, batch    13] loss: 149.79346\n",
      "[epoch 137, batch    14] loss: 130.23008\n",
      "[epoch 137, batch    15] loss: 150.44898\n",
      "[epoch 137, batch    16] loss: 134.29481\n",
      "[epoch 137, batch    17] loss: 136.27561\n",
      "[epoch 137, batch    18] loss: 136.15278\n",
      "[epoch 137, batch    19] loss: 140.40663\n",
      "[epoch 137, batch    20] loss: 125.52185\n",
      "[epoch 137, batch    21] loss: 134.46717\n",
      "[epoch 137, batch    22] loss: 141.61209\n",
      "[epoch 137, batch    23] loss: 137.27222\n",
      "[epoch 137, batch    24] loss: 133.44631\n",
      "[epoch 137, batch    25] loss: 140.07605\n",
      "[epoch 137, batch    26] loss: 133.14603\n",
      "[epoch 137, batch    27] loss: 120.25288\n",
      "[epoch 137, batch    28] loss: 121.04757\n",
      "[epoch 137, batch    29] loss: 125.80808\n",
      "[epoch 137, batch    30] loss: 133.70161\n",
      "[epoch 137, batch    31] loss: 144.55626\n",
      "[epoch 137, batch    32] loss: 27.40009\n",
      "[epoch 138, batch     1] loss: 121.93926\n",
      "[epoch 138, batch     2] loss: 129.83166\n",
      "[epoch 138, batch     3] loss: 140.87571\n",
      "[epoch 138, batch     4] loss: 135.82331\n",
      "[epoch 138, batch     5] loss: 131.82102\n",
      "[epoch 138, batch     6] loss: 134.76860\n",
      "[epoch 138, batch     7] loss: 141.63301\n",
      "[epoch 138, batch     8] loss: 130.97042\n",
      "[epoch 138, batch     9] loss: 139.63010\n",
      "[epoch 138, batch    10] loss: 136.30530\n",
      "[epoch 138, batch    11] loss: 140.43692\n",
      "[epoch 138, batch    12] loss: 125.78903\n",
      "[epoch 138, batch    13] loss: 136.50802\n",
      "[epoch 138, batch    14] loss: 130.04131\n",
      "[epoch 138, batch    15] loss: 141.22401\n",
      "[epoch 138, batch    16] loss: 140.21315\n",
      "[epoch 138, batch    17] loss: 135.60621\n",
      "[epoch 138, batch    18] loss: 131.89956\n",
      "[epoch 138, batch    19] loss: 132.73249\n",
      "[epoch 138, batch    20] loss: 125.67758\n",
      "[epoch 138, batch    21] loss: 116.09450\n",
      "[epoch 138, batch    22] loss: 130.41992\n",
      "[epoch 138, batch    23] loss: 128.52499\n",
      "[epoch 138, batch    24] loss: 136.16172\n",
      "[epoch 138, batch    25] loss: 124.72510\n",
      "[epoch 138, batch    26] loss: 133.46906\n",
      "[epoch 138, batch    27] loss: 138.39368\n",
      "[epoch 138, batch    28] loss: 135.68596\n",
      "[epoch 138, batch    29] loss: 142.07632\n",
      "[epoch 138, batch    30] loss: 133.40817\n",
      "[epoch 138, batch    31] loss: 137.40275\n",
      "[epoch 138, batch    32] loss: 37.79196\n",
      "[epoch 139, batch     1] loss: 129.56757\n",
      "[epoch 139, batch     2] loss: 136.26991\n",
      "[epoch 139, batch     3] loss: 138.18196\n",
      "[epoch 139, batch     4] loss: 130.95228\n",
      "[epoch 139, batch     5] loss: 126.64517\n",
      "[epoch 139, batch     6] loss: 126.65012\n",
      "[epoch 139, batch     7] loss: 144.69003\n",
      "[epoch 139, batch     8] loss: 133.11100\n",
      "[epoch 139, batch     9] loss: 133.82229\n",
      "[epoch 139, batch    10] loss: 133.62298\n",
      "[epoch 139, batch    11] loss: 140.08024\n",
      "[epoch 139, batch    12] loss: 148.05308\n",
      "[epoch 139, batch    13] loss: 135.20699\n",
      "[epoch 139, batch    14] loss: 138.03168\n",
      "[epoch 139, batch    15] loss: 142.61434\n",
      "[epoch 139, batch    16] loss: 135.83527\n",
      "[epoch 139, batch    17] loss: 121.53875\n",
      "[epoch 139, batch    18] loss: 134.33823\n",
      "[epoch 139, batch    19] loss: 132.44244\n",
      "[epoch 139, batch    20] loss: 134.92499\n",
      "[epoch 139, batch    21] loss: 148.41472\n",
      "[epoch 139, batch    22] loss: 134.34582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 139, batch    23] loss: 122.75044\n",
      "[epoch 139, batch    24] loss: 144.77880\n",
      "[epoch 139, batch    25] loss: 132.33606\n",
      "[epoch 139, batch    26] loss: 132.32525\n",
      "[epoch 139, batch    27] loss: 122.22853\n",
      "[epoch 139, batch    28] loss: 139.27617\n",
      "[epoch 139, batch    29] loss: 117.93016\n",
      "[epoch 139, batch    30] loss: 125.65563\n",
      "[epoch 139, batch    31] loss: 131.29217\n",
      "[epoch 139, batch    32] loss: 32.06840\n",
      "[epoch 140, batch     1] loss: 132.57051\n",
      "[epoch 140, batch     2] loss: 133.33441\n",
      "[epoch 140, batch     3] loss: 134.91468\n",
      "[epoch 140, batch     4] loss: 129.86275\n",
      "[epoch 140, batch     5] loss: 127.39888\n",
      "[epoch 140, batch     6] loss: 141.81961\n",
      "[epoch 140, batch     7] loss: 127.18640\n",
      "[epoch 140, batch     8] loss: 135.89064\n",
      "[epoch 140, batch     9] loss: 136.96398\n",
      "[epoch 140, batch    10] loss: 144.21155\n",
      "[epoch 140, batch    11] loss: 123.80656\n",
      "[epoch 140, batch    12] loss: 120.56949\n",
      "[epoch 140, batch    13] loss: 141.01961\n",
      "[epoch 140, batch    14] loss: 115.99311\n",
      "[epoch 140, batch    15] loss: 124.45222\n",
      "[epoch 140, batch    16] loss: 128.12772\n",
      "[epoch 140, batch    17] loss: 138.17294\n",
      "[epoch 140, batch    18] loss: 131.82375\n",
      "[epoch 140, batch    19] loss: 154.03007\n",
      "[epoch 140, batch    20] loss: 122.62764\n",
      "[epoch 140, batch    21] loss: 128.25090\n",
      "[epoch 140, batch    22] loss: 133.70472\n",
      "[epoch 140, batch    23] loss: 134.12410\n",
      "[epoch 140, batch    24] loss: 135.56781\n",
      "[epoch 140, batch    25] loss: 135.69726\n",
      "[epoch 140, batch    26] loss: 134.37159\n",
      "[epoch 140, batch    27] loss: 141.57430\n",
      "[epoch 140, batch    28] loss: 123.43472\n",
      "[epoch 140, batch    29] loss: 129.19932\n",
      "[epoch 140, batch    30] loss: 133.05205\n",
      "[epoch 140, batch    31] loss: 137.97353\n",
      "[epoch 140, batch    32] loss: 34.84103\n",
      "[epoch 141, batch     1] loss: 130.17731\n",
      "[epoch 141, batch     2] loss: 134.37097\n",
      "[epoch 141, batch     3] loss: 138.83561\n",
      "[epoch 141, batch     4] loss: 131.97769\n",
      "[epoch 141, batch     5] loss: 133.25876\n",
      "[epoch 141, batch     6] loss: 125.43066\n",
      "[epoch 141, batch     7] loss: 142.71156\n",
      "[epoch 141, batch     8] loss: 148.27216\n",
      "[epoch 141, batch     9] loss: 144.11863\n",
      "[epoch 141, batch    10] loss: 134.84588\n",
      "[epoch 141, batch    11] loss: 129.51180\n",
      "[epoch 141, batch    12] loss: 125.88908\n",
      "[epoch 141, batch    13] loss: 137.96322\n",
      "[epoch 141, batch    14] loss: 139.12163\n",
      "[epoch 141, batch    15] loss: 132.32663\n",
      "[epoch 141, batch    16] loss: 132.20021\n",
      "[epoch 141, batch    17] loss: 123.44156\n",
      "[epoch 141, batch    18] loss: 135.43888\n",
      "[epoch 141, batch    19] loss: 128.19316\n",
      "[epoch 141, batch    20] loss: 136.36372\n",
      "[epoch 141, batch    21] loss: 142.97506\n",
      "[epoch 141, batch    22] loss: 126.00734\n",
      "[epoch 141, batch    23] loss: 137.24160\n",
      "[epoch 141, batch    24] loss: 122.84684\n",
      "[epoch 141, batch    25] loss: 124.20758\n",
      "[epoch 141, batch    26] loss: 122.29008\n",
      "[epoch 141, batch    27] loss: 125.31697\n",
      "[epoch 141, batch    28] loss: 133.71933\n",
      "[epoch 141, batch    29] loss: 149.61369\n",
      "[epoch 141, batch    30] loss: 128.76876\n",
      "[epoch 141, batch    31] loss: 135.12495\n",
      "[epoch 141, batch    32] loss: 31.74300\n",
      "[epoch 142, batch     1] loss: 129.71458\n",
      "[epoch 142, batch     2] loss: 127.76643\n",
      "[epoch 142, batch     3] loss: 123.89012\n",
      "[epoch 142, batch     4] loss: 137.86846\n",
      "[epoch 142, batch     5] loss: 134.21865\n",
      "[epoch 142, batch     6] loss: 137.18694\n",
      "[epoch 142, batch     7] loss: 137.90391\n",
      "[epoch 142, batch     8] loss: 132.91138\n",
      "[epoch 142, batch     9] loss: 134.00746\n",
      "[epoch 142, batch    10] loss: 129.58518\n",
      "[epoch 142, batch    11] loss: 119.49914\n",
      "[epoch 142, batch    12] loss: 127.08012\n",
      "[epoch 142, batch    13] loss: 128.24415\n",
      "[epoch 142, batch    14] loss: 131.12249\n",
      "[epoch 142, batch    15] loss: 137.82427\n",
      "[epoch 142, batch    16] loss: 133.23877\n",
      "[epoch 142, batch    17] loss: 130.46200\n",
      "[epoch 142, batch    18] loss: 142.98256\n",
      "[epoch 142, batch    19] loss: 143.45670\n",
      "[epoch 142, batch    20] loss: 147.24448\n",
      "[epoch 142, batch    21] loss: 132.30087\n",
      "[epoch 142, batch    22] loss: 122.01660\n",
      "[epoch 142, batch    23] loss: 135.09968\n",
      "[epoch 142, batch    24] loss: 128.06096\n",
      "[epoch 142, batch    25] loss: 140.12276\n",
      "[epoch 142, batch    26] loss: 131.55108\n",
      "[epoch 142, batch    27] loss: 135.49421\n",
      "[epoch 142, batch    28] loss: 123.81029\n",
      "[epoch 142, batch    29] loss: 131.13090\n",
      "[epoch 142, batch    30] loss: 141.10740\n",
      "[epoch 142, batch    31] loss: 131.17299\n",
      "[epoch 142, batch    32] loss: 35.87051\n",
      "[epoch 143, batch     1] loss: 137.83391\n",
      "[epoch 143, batch     2] loss: 134.67880\n",
      "[epoch 143, batch     3] loss: 132.29691\n",
      "[epoch 143, batch     4] loss: 136.01937\n",
      "[epoch 143, batch     5] loss: 121.56487\n",
      "[epoch 143, batch     6] loss: 133.36133\n",
      "[epoch 143, batch     7] loss: 140.18398\n",
      "[epoch 143, batch     8] loss: 129.89622\n",
      "[epoch 143, batch     9] loss: 131.15963\n",
      "[epoch 143, batch    10] loss: 129.05651\n",
      "[epoch 143, batch    11] loss: 119.36421\n",
      "[epoch 143, batch    12] loss: 121.67287\n",
      "[epoch 143, batch    13] loss: 132.49890\n",
      "[epoch 143, batch    14] loss: 126.46016\n",
      "[epoch 143, batch    15] loss: 116.71735\n",
      "[epoch 143, batch    16] loss: 135.18452\n",
      "[epoch 143, batch    17] loss: 124.15248\n",
      "[epoch 143, batch    18] loss: 123.72245\n",
      "[epoch 143, batch    19] loss: 129.67477\n",
      "[epoch 143, batch    20] loss: 134.61910\n",
      "[epoch 143, batch    21] loss: 134.18721\n",
      "[epoch 143, batch    22] loss: 125.57261\n",
      "[epoch 143, batch    23] loss: 143.87374\n",
      "[epoch 143, batch    24] loss: 123.83682\n",
      "[epoch 143, batch    25] loss: 135.23134\n",
      "[epoch 143, batch    26] loss: 132.72226\n",
      "[epoch 143, batch    27] loss: 129.07832\n",
      "[epoch 143, batch    28] loss: 136.27331\n",
      "[epoch 143, batch    29] loss: 135.09963\n",
      "[epoch 143, batch    30] loss: 129.82752\n",
      "[epoch 143, batch    31] loss: 117.81775\n",
      "[epoch 143, batch    32] loss: 31.26701\n",
      "[epoch 144, batch     1] loss: 122.41470\n",
      "[epoch 144, batch     2] loss: 120.54642\n",
      "[epoch 144, batch     3] loss: 142.41733\n",
      "[epoch 144, batch     4] loss: 121.80480\n",
      "[epoch 144, batch     5] loss: 132.23153\n",
      "[epoch 144, batch     6] loss: 128.95861\n",
      "[epoch 144, batch     7] loss: 124.37219\n",
      "[epoch 144, batch     8] loss: 128.26462\n",
      "[epoch 144, batch     9] loss: 134.06970\n",
      "[epoch 144, batch    10] loss: 127.93586\n",
      "[epoch 144, batch    11] loss: 120.88184\n",
      "[epoch 144, batch    12] loss: 130.86833\n",
      "[epoch 144, batch    13] loss: 131.26904\n",
      "[epoch 144, batch    14] loss: 135.87582\n",
      "[epoch 144, batch    15] loss: 132.81952\n",
      "[epoch 144, batch    16] loss: 130.18980\n",
      "[epoch 144, batch    17] loss: 139.42154\n",
      "[epoch 144, batch    18] loss: 115.83983\n",
      "[epoch 144, batch    19] loss: 129.63976\n",
      "[epoch 144, batch    20] loss: 134.17509\n",
      "[epoch 144, batch    21] loss: 139.97157\n",
      "[epoch 144, batch    22] loss: 134.28472\n",
      "[epoch 144, batch    23] loss: 136.27422\n",
      "[epoch 144, batch    24] loss: 138.66374\n",
      "[epoch 144, batch    25] loss: 131.37847\n",
      "[epoch 144, batch    26] loss: 145.05992\n",
      "[epoch 144, batch    27] loss: 129.11454\n",
      "[epoch 144, batch    28] loss: 125.75177\n",
      "[epoch 144, batch    29] loss: 126.35109\n",
      "[epoch 144, batch    30] loss: 144.60417\n",
      "[epoch 144, batch    31] loss: 135.66843\n",
      "[epoch 144, batch    32] loss: 28.63129\n",
      "[epoch 145, batch     1] loss: 126.39644\n",
      "[epoch 145, batch     2] loss: 129.77045\n",
      "[epoch 145, batch     3] loss: 138.99569\n",
      "[epoch 145, batch     4] loss: 137.80817\n",
      "[epoch 145, batch     5] loss: 114.82461\n",
      "[epoch 145, batch     6] loss: 140.59216\n",
      "[epoch 145, batch     7] loss: 126.27517\n",
      "[epoch 145, batch     8] loss: 130.21789\n",
      "[epoch 145, batch     9] loss: 125.05414\n",
      "[epoch 145, batch    10] loss: 127.99710\n",
      "[epoch 145, batch    11] loss: 129.84971\n",
      "[epoch 145, batch    12] loss: 140.28937\n",
      "[epoch 145, batch    13] loss: 143.68898\n",
      "[epoch 145, batch    14] loss: 130.58848\n",
      "[epoch 145, batch    15] loss: 136.63327\n",
      "[epoch 145, batch    16] loss: 126.64350\n",
      "[epoch 145, batch    17] loss: 127.49364\n",
      "[epoch 145, batch    18] loss: 118.30245\n",
      "[epoch 145, batch    19] loss: 141.44030\n",
      "[epoch 145, batch    20] loss: 136.45713\n",
      "[epoch 145, batch    21] loss: 135.68501\n",
      "[epoch 145, batch    22] loss: 141.82773\n",
      "[epoch 145, batch    23] loss: 127.68638\n",
      "[epoch 145, batch    24] loss: 123.78248\n",
      "[epoch 145, batch    25] loss: 142.26352\n",
      "[epoch 145, batch    26] loss: 146.68806\n",
      "[epoch 145, batch    27] loss: 118.66077\n",
      "[epoch 145, batch    28] loss: 126.04031\n",
      "[epoch 145, batch    29] loss: 138.87989\n",
      "[epoch 145, batch    30] loss: 141.43294\n",
      "[epoch 145, batch    31] loss: 135.78985\n",
      "[epoch 145, batch    32] loss: 32.53773\n",
      "[epoch 146, batch     1] loss: 145.33011\n",
      "[epoch 146, batch     2] loss: 125.49701\n",
      "[epoch 146, batch     3] loss: 145.23773\n",
      "[epoch 146, batch     4] loss: 133.68446\n",
      "[epoch 146, batch     5] loss: 126.82351\n",
      "[epoch 146, batch     6] loss: 132.48131\n",
      "[epoch 146, batch     7] loss: 126.97184\n",
      "[epoch 146, batch     8] loss: 134.23164\n",
      "[epoch 146, batch     9] loss: 136.40302\n",
      "[epoch 146, batch    10] loss: 125.79303\n",
      "[epoch 146, batch    11] loss: 138.44409\n",
      "[epoch 146, batch    12] loss: 129.21583\n",
      "[epoch 146, batch    13] loss: 128.57967\n",
      "[epoch 146, batch    14] loss: 139.91657\n",
      "[epoch 146, batch    15] loss: 130.87517\n",
      "[epoch 146, batch    16] loss: 137.10029\n",
      "[epoch 146, batch    17] loss: 120.05749\n",
      "[epoch 146, batch    18] loss: 125.20942\n",
      "[epoch 146, batch    19] loss: 136.39651\n",
      "[epoch 146, batch    20] loss: 134.96191\n",
      "[epoch 146, batch    21] loss: 129.64181\n",
      "[epoch 146, batch    22] loss: 129.23558\n",
      "[epoch 146, batch    23] loss: 129.40791\n",
      "[epoch 146, batch    24] loss: 127.08116\n",
      "[epoch 146, batch    25] loss: 134.37706\n",
      "[epoch 146, batch    26] loss: 135.63128\n",
      "[epoch 146, batch    27] loss: 144.04083\n",
      "[epoch 146, batch    28] loss: 134.82830\n",
      "[epoch 146, batch    29] loss: 138.92712\n",
      "[epoch 146, batch    30] loss: 129.27802\n",
      "[epoch 146, batch    31] loss: 146.32233\n",
      "[epoch 146, batch    32] loss: 37.39283\n",
      "[epoch 147, batch     1] loss: 126.84815\n",
      "[epoch 147, batch     2] loss: 135.60712\n",
      "[epoch 147, batch     3] loss: 124.22882\n",
      "[epoch 147, batch     4] loss: 126.84209\n",
      "[epoch 147, batch     5] loss: 144.93284\n",
      "[epoch 147, batch     6] loss: 137.76921\n",
      "[epoch 147, batch     7] loss: 149.09611\n",
      "[epoch 147, batch     8] loss: 121.20325\n",
      "[epoch 147, batch     9] loss: 138.31708\n",
      "[epoch 147, batch    10] loss: 130.85079\n",
      "[epoch 147, batch    11] loss: 122.86469\n",
      "[epoch 147, batch    12] loss: 151.41376\n",
      "[epoch 147, batch    13] loss: 128.90295\n",
      "[epoch 147, batch    14] loss: 126.99661\n",
      "[epoch 147, batch    15] loss: 136.02588\n",
      "[epoch 147, batch    16] loss: 139.80406\n",
      "[epoch 147, batch    17] loss: 130.82965\n",
      "[epoch 147, batch    18] loss: 131.14380\n",
      "[epoch 147, batch    19] loss: 133.23533\n",
      "[epoch 147, batch    20] loss: 135.20517\n",
      "[epoch 147, batch    21] loss: 125.52643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 147, batch    22] loss: 138.74719\n",
      "[epoch 147, batch    23] loss: 130.76180\n",
      "[epoch 147, batch    24] loss: 135.62430\n",
      "[epoch 147, batch    25] loss: 123.14298\n",
      "[epoch 147, batch    26] loss: 147.46493\n",
      "[epoch 147, batch    27] loss: 136.11398\n",
      "[epoch 147, batch    28] loss: 138.44764\n",
      "[epoch 147, batch    29] loss: 142.59858\n",
      "[epoch 147, batch    30] loss: 134.23180\n",
      "[epoch 147, batch    31] loss: 123.02691\n",
      "[epoch 147, batch    32] loss: 32.23149\n",
      "[epoch 148, batch     1] loss: 112.95849\n",
      "[epoch 148, batch     2] loss: 140.38073\n",
      "[epoch 148, batch     3] loss: 137.03171\n",
      "[epoch 148, batch     4] loss: 125.41814\n",
      "[epoch 148, batch     5] loss: 140.40891\n",
      "[epoch 148, batch     6] loss: 116.51967\n",
      "[epoch 148, batch     7] loss: 134.16688\n",
      "[epoch 148, batch     8] loss: 138.86219\n",
      "[epoch 148, batch     9] loss: 135.83461\n",
      "[epoch 148, batch    10] loss: 133.79791\n",
      "[epoch 148, batch    11] loss: 122.75159\n",
      "[epoch 148, batch    12] loss: 131.48572\n",
      "[epoch 148, batch    13] loss: 133.82971\n",
      "[epoch 148, batch    14] loss: 140.22450\n",
      "[epoch 148, batch    15] loss: 137.87807\n",
      "[epoch 148, batch    16] loss: 137.34887\n",
      "[epoch 148, batch    17] loss: 133.44851\n",
      "[epoch 148, batch    18] loss: 131.06180\n",
      "[epoch 148, batch    19] loss: 139.39223\n",
      "[epoch 148, batch    20] loss: 130.42669\n",
      "[epoch 148, batch    21] loss: 141.33553\n",
      "[epoch 148, batch    22] loss: 146.93198\n",
      "[epoch 148, batch    23] loss: 147.31014\n",
      "[epoch 148, batch    24] loss: 129.40698\n",
      "[epoch 148, batch    25] loss: 135.34434\n",
      "[epoch 148, batch    26] loss: 126.98032\n",
      "[epoch 148, batch    27] loss: 142.83954\n",
      "[epoch 148, batch    28] loss: 134.28978\n",
      "[epoch 148, batch    29] loss: 127.59314\n",
      "[epoch 148, batch    30] loss: 144.75776\n",
      "[epoch 148, batch    31] loss: 132.82266\n",
      "[epoch 148, batch    32] loss: 33.25828\n",
      "[epoch 149, batch     1] loss: 134.74494\n",
      "[epoch 149, batch     2] loss: 139.16305\n",
      "[epoch 149, batch     3] loss: 137.86266\n",
      "[epoch 149, batch     4] loss: 138.70466\n",
      "[epoch 149, batch     5] loss: 129.62418\n",
      "[epoch 149, batch     6] loss: 120.07566\n",
      "[epoch 149, batch     7] loss: 122.19221\n",
      "[epoch 149, batch     8] loss: 147.03345\n",
      "[epoch 149, batch     9] loss: 137.04144\n",
      "[epoch 149, batch    10] loss: 138.27669\n",
      "[epoch 149, batch    11] loss: 128.10511\n",
      "[epoch 149, batch    12] loss: 145.88916\n",
      "[epoch 149, batch    13] loss: 144.37692\n",
      "[epoch 149, batch    14] loss: 136.79835\n",
      "[epoch 149, batch    15] loss: 130.11434\n",
      "[epoch 149, batch    16] loss: 136.59201\n",
      "[epoch 149, batch    17] loss: 130.33681\n",
      "[epoch 149, batch    18] loss: 128.44863\n",
      "[epoch 149, batch    19] loss: 134.80561\n",
      "[epoch 149, batch    20] loss: 125.46119\n",
      "[epoch 149, batch    21] loss: 124.99740\n",
      "[epoch 149, batch    22] loss: 142.81973\n",
      "[epoch 149, batch    23] loss: 123.67812\n",
      "[epoch 149, batch    24] loss: 135.75989\n",
      "[epoch 149, batch    25] loss: 132.72052\n",
      "[epoch 149, batch    26] loss: 135.49236\n",
      "[epoch 149, batch    27] loss: 129.81309\n",
      "[epoch 149, batch    28] loss: 128.39044\n",
      "[epoch 149, batch    29] loss: 116.93389\n",
      "[epoch 149, batch    30] loss: 128.93994\n",
      "[epoch 149, batch    31] loss: 134.73559\n",
      "[epoch 149, batch    32] loss: 37.61609\n",
      "[epoch 150, batch     1] loss: 130.53693\n",
      "[epoch 150, batch     2] loss: 132.36478\n",
      "[epoch 150, batch     3] loss: 133.21566\n",
      "[epoch 150, batch     4] loss: 135.78519\n",
      "[epoch 150, batch     5] loss: 123.62543\n",
      "[epoch 150, batch     6] loss: 134.39666\n",
      "[epoch 150, batch     7] loss: 128.36225\n",
      "[epoch 150, batch     8] loss: 141.84204\n",
      "[epoch 150, batch     9] loss: 130.29130\n",
      "[epoch 150, batch    10] loss: 144.96698\n",
      "[epoch 150, batch    11] loss: 122.24899\n",
      "[epoch 150, batch    12] loss: 121.49767\n",
      "[epoch 150, batch    13] loss: 136.97493\n",
      "[epoch 150, batch    14] loss: 137.42411\n",
      "[epoch 150, batch    15] loss: 126.09862\n",
      "[epoch 150, batch    16] loss: 150.30429\n",
      "[epoch 150, batch    17] loss: 142.39064\n",
      "[epoch 150, batch    18] loss: 140.66386\n",
      "[epoch 150, batch    19] loss: 130.81080\n",
      "[epoch 150, batch    20] loss: 135.89871\n",
      "[epoch 150, batch    21] loss: 135.14538\n",
      "[epoch 150, batch    22] loss: 130.03723\n",
      "[epoch 150, batch    23] loss: 125.81171\n",
      "[epoch 150, batch    24] loss: 130.17910\n",
      "[epoch 150, batch    25] loss: 145.01464\n",
      "[epoch 150, batch    26] loss: 136.63051\n",
      "[epoch 150, batch    27] loss: 129.80223\n",
      "[epoch 150, batch    28] loss: 140.16053\n",
      "[epoch 150, batch    29] loss: 132.79273\n",
      "[epoch 150, batch    30] loss: 126.16660\n",
      "[epoch 150, batch    31] loss: 132.82429\n",
      "[epoch 150, batch    32] loss: 30.68888\n",
      "[epoch 151, batch     1] loss: 116.72440\n",
      "[epoch 151, batch     2] loss: 127.87735\n",
      "[epoch 151, batch     3] loss: 136.36332\n",
      "[epoch 151, batch     4] loss: 132.48113\n",
      "[epoch 151, batch     5] loss: 141.08947\n",
      "[epoch 151, batch     6] loss: 121.19630\n",
      "[epoch 151, batch     7] loss: 127.42301\n",
      "[epoch 151, batch     8] loss: 150.13710\n",
      "[epoch 151, batch     9] loss: 146.38267\n",
      "[epoch 151, batch    10] loss: 127.99881\n",
      "[epoch 151, batch    11] loss: 130.49533\n",
      "[epoch 151, batch    12] loss: 129.18142\n",
      "[epoch 151, batch    13] loss: 131.85527\n",
      "[epoch 151, batch    14] loss: 138.12660\n",
      "[epoch 151, batch    15] loss: 134.55039\n",
      "[epoch 151, batch    16] loss: 128.99548\n",
      "[epoch 151, batch    17] loss: 135.67033\n",
      "[epoch 151, batch    18] loss: 132.01636\n",
      "[epoch 151, batch    19] loss: 130.31144\n",
      "[epoch 151, batch    20] loss: 134.05881\n",
      "[epoch 151, batch    21] loss: 139.30128\n",
      "[epoch 151, batch    22] loss: 127.17129\n",
      "[epoch 151, batch    23] loss: 124.37609\n",
      "[epoch 151, batch    24] loss: 134.04619\n",
      "[epoch 151, batch    25] loss: 127.94485\n",
      "[epoch 151, batch    26] loss: 137.00257\n",
      "[epoch 151, batch    27] loss: 136.73240\n",
      "[epoch 151, batch    28] loss: 129.32306\n",
      "[epoch 151, batch    29] loss: 129.91395\n",
      "[epoch 151, batch    30] loss: 121.97279\n",
      "[epoch 151, batch    31] loss: 126.13867\n",
      "[epoch 151, batch    32] loss: 30.99103\n",
      "[epoch 152, batch     1] loss: 131.41922\n",
      "[epoch 152, batch     2] loss: 117.46821\n",
      "[epoch 152, batch     3] loss: 133.61846\n",
      "[epoch 152, batch     4] loss: 140.43295\n",
      "[epoch 152, batch     5] loss: 134.93456\n",
      "[epoch 152, batch     6] loss: 144.83198\n",
      "[epoch 152, batch     7] loss: 131.15421\n",
      "[epoch 152, batch     8] loss: 139.04869\n",
      "[epoch 152, batch     9] loss: 133.88041\n",
      "[epoch 152, batch    10] loss: 126.45292\n",
      "[epoch 152, batch    11] loss: 130.40899\n",
      "[epoch 152, batch    12] loss: 136.67174\n",
      "[epoch 152, batch    13] loss: 130.45933\n",
      "[epoch 152, batch    14] loss: 118.82153\n",
      "[epoch 152, batch    15] loss: 134.26835\n",
      "[epoch 152, batch    16] loss: 124.87167\n",
      "[epoch 152, batch    17] loss: 123.10286\n",
      "[epoch 152, batch    18] loss: 125.62465\n",
      "[epoch 152, batch    19] loss: 126.41451\n",
      "[epoch 152, batch    20] loss: 122.81683\n",
      "[epoch 152, batch    21] loss: 141.26797\n",
      "[epoch 152, batch    22] loss: 126.00660\n",
      "[epoch 152, batch    23] loss: 148.39438\n",
      "[epoch 152, batch    24] loss: 132.33756\n",
      "[epoch 152, batch    25] loss: 138.13754\n",
      "[epoch 152, batch    26] loss: 139.40464\n",
      "[epoch 152, batch    27] loss: 126.73997\n",
      "[epoch 152, batch    28] loss: 145.07023\n",
      "[epoch 152, batch    29] loss: 136.72186\n",
      "[epoch 152, batch    30] loss: 129.72413\n",
      "[epoch 152, batch    31] loss: 139.73530\n",
      "[epoch 152, batch    32] loss: 34.90658\n",
      "[epoch 153, batch     1] loss: 139.31570\n",
      "[epoch 153, batch     2] loss: 140.46955\n",
      "[epoch 153, batch     3] loss: 125.10278\n",
      "[epoch 153, batch     4] loss: 141.91466\n",
      "[epoch 153, batch     5] loss: 139.57266\n",
      "[epoch 153, batch     6] loss: 133.31917\n",
      "[epoch 153, batch     7] loss: 124.15035\n",
      "[epoch 153, batch     8] loss: 128.17104\n",
      "[epoch 153, batch     9] loss: 128.75796\n",
      "[epoch 153, batch    10] loss: 118.76941\n",
      "[epoch 153, batch    11] loss: 125.09777\n",
      "[epoch 153, batch    12] loss: 134.32892\n",
      "[epoch 153, batch    13] loss: 122.90777\n",
      "[epoch 153, batch    14] loss: 130.10190\n",
      "[epoch 153, batch    15] loss: 127.55406\n",
      "[epoch 153, batch    16] loss: 135.27302\n",
      "[epoch 153, batch    17] loss: 129.30146\n",
      "[epoch 153, batch    18] loss: 123.42298\n",
      "[epoch 153, batch    19] loss: 131.62321\n",
      "[epoch 153, batch    20] loss: 127.33199\n",
      "[epoch 153, batch    21] loss: 125.95365\n",
      "[epoch 153, batch    22] loss: 124.06008\n",
      "[epoch 153, batch    23] loss: 137.63546\n",
      "[epoch 153, batch    24] loss: 135.72040\n",
      "[epoch 153, batch    25] loss: 129.99410\n",
      "[epoch 153, batch    26] loss: 117.49576\n",
      "[epoch 153, batch    27] loss: 136.90484\n",
      "[epoch 153, batch    28] loss: 141.26871\n",
      "[epoch 153, batch    29] loss: 133.63880\n",
      "[epoch 153, batch    30] loss: 145.69878\n",
      "[epoch 153, batch    31] loss: 137.36017\n",
      "[epoch 153, batch    32] loss: 26.38206\n",
      "[epoch 154, batch     1] loss: 136.92568\n",
      "[epoch 154, batch     2] loss: 139.64540\n",
      "[epoch 154, batch     3] loss: 131.99499\n",
      "[epoch 154, batch     4] loss: 128.72453\n",
      "[epoch 154, batch     5] loss: 122.08569\n",
      "[epoch 154, batch     6] loss: 121.39505\n",
      "[epoch 154, batch     7] loss: 136.84822\n",
      "[epoch 154, batch     8] loss: 127.23792\n",
      "[epoch 154, batch     9] loss: 143.57247\n",
      "[epoch 154, batch    10] loss: 137.66632\n",
      "[epoch 154, batch    11] loss: 139.23528\n",
      "[epoch 154, batch    12] loss: 132.27625\n",
      "[epoch 154, batch    13] loss: 121.82224\n",
      "[epoch 154, batch    14] loss: 129.17430\n",
      "[epoch 154, batch    15] loss: 134.15089\n",
      "[epoch 154, batch    16] loss: 142.23311\n",
      "[epoch 154, batch    17] loss: 145.28216\n",
      "[epoch 154, batch    18] loss: 139.69218\n",
      "[epoch 154, batch    19] loss: 134.49345\n",
      "[epoch 154, batch    20] loss: 135.41421\n",
      "[epoch 154, batch    21] loss: 130.38767\n",
      "[epoch 154, batch    22] loss: 125.56284\n",
      "[epoch 154, batch    23] loss: 137.02313\n",
      "[epoch 154, batch    24] loss: 123.45909\n",
      "[epoch 154, batch    25] loss: 139.95148\n",
      "[epoch 154, batch    26] loss: 144.84561\n",
      "[epoch 154, batch    27] loss: 135.38532\n",
      "[epoch 154, batch    28] loss: 144.03553\n",
      "[epoch 154, batch    29] loss: 126.75023\n",
      "[epoch 154, batch    30] loss: 132.51469\n",
      "[epoch 154, batch    31] loss: 133.91541\n",
      "[epoch 154, batch    32] loss: 35.76139\n",
      "[epoch 155, batch     1] loss: 136.02062\n",
      "[epoch 155, batch     2] loss: 142.24342\n",
      "[epoch 155, batch     3] loss: 134.14150\n",
      "[epoch 155, batch     4] loss: 126.44458\n",
      "[epoch 155, batch     5] loss: 132.97555\n",
      "[epoch 155, batch     6] loss: 138.12476\n",
      "[epoch 155, batch     7] loss: 131.26177\n",
      "[epoch 155, batch     8] loss: 147.20788\n",
      "[epoch 155, batch     9] loss: 138.22449\n",
      "[epoch 155, batch    10] loss: 143.27761\n",
      "[epoch 155, batch    11] loss: 129.72581\n",
      "[epoch 155, batch    12] loss: 130.55551\n",
      "[epoch 155, batch    13] loss: 135.00494\n",
      "[epoch 155, batch    14] loss: 122.41370\n",
      "[epoch 155, batch    15] loss: 133.18069\n",
      "[epoch 155, batch    16] loss: 129.82605\n",
      "[epoch 155, batch    17] loss: 137.46829\n",
      "[epoch 155, batch    18] loss: 135.33338\n",
      "[epoch 155, batch    19] loss: 138.76097\n",
      "[epoch 155, batch    20] loss: 132.14894\n",
      "[epoch 155, batch    21] loss: 126.63061\n",
      "[epoch 155, batch    22] loss: 135.31952\n",
      "[epoch 155, batch    23] loss: 141.26288\n",
      "[epoch 155, batch    24] loss: 130.56358\n",
      "[epoch 155, batch    25] loss: 138.52105\n",
      "[epoch 155, batch    26] loss: 129.84845\n",
      "[epoch 155, batch    27] loss: 123.90609\n",
      "[epoch 155, batch    28] loss: 138.51614\n",
      "[epoch 155, batch    29] loss: 139.80027\n",
      "[epoch 155, batch    30] loss: 139.21201\n",
      "[epoch 155, batch    31] loss: 132.35903\n",
      "[epoch 155, batch    32] loss: 36.05303\n",
      "[epoch 156, batch     1] loss: 125.08024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 156, batch     2] loss: 135.06847\n",
      "[epoch 156, batch     3] loss: 143.75793\n",
      "[epoch 156, batch     4] loss: 128.24493\n",
      "[epoch 156, batch     5] loss: 125.84457\n",
      "[epoch 156, batch     6] loss: 144.90572\n",
      "[epoch 156, batch     7] loss: 125.02261\n",
      "[epoch 156, batch     8] loss: 126.21971\n",
      "[epoch 156, batch     9] loss: 131.01896\n",
      "[epoch 156, batch    10] loss: 126.43182\n",
      "[epoch 156, batch    11] loss: 125.96910\n",
      "[epoch 156, batch    12] loss: 131.25092\n",
      "[epoch 156, batch    13] loss: 126.75410\n",
      "[epoch 156, batch    14] loss: 132.71297\n",
      "[epoch 156, batch    15] loss: 122.90041\n",
      "[epoch 156, batch    16] loss: 125.00589\n",
      "[epoch 156, batch    17] loss: 129.73363\n",
      "[epoch 156, batch    18] loss: 134.04204\n",
      "[epoch 156, batch    19] loss: 132.65295\n",
      "[epoch 156, batch    20] loss: 135.36325\n",
      "[epoch 156, batch    21] loss: 132.33684\n",
      "[epoch 156, batch    22] loss: 134.46122\n",
      "[epoch 156, batch    23] loss: 125.59199\n",
      "[epoch 156, batch    24] loss: 130.04027\n",
      "[epoch 156, batch    25] loss: 141.60501\n",
      "[epoch 156, batch    26] loss: 130.40891\n",
      "[epoch 156, batch    27] loss: 116.12614\n",
      "[epoch 156, batch    28] loss: 145.34426\n",
      "[epoch 156, batch    29] loss: 124.49817\n",
      "[epoch 156, batch    30] loss: 128.57291\n",
      "[epoch 156, batch    31] loss: 127.62641\n",
      "[epoch 156, batch    32] loss: 39.16515\n",
      "[epoch 157, batch     1] loss: 128.36827\n",
      "[epoch 157, batch     2] loss: 120.97465\n",
      "[epoch 157, batch     3] loss: 145.79173\n",
      "[epoch 157, batch     4] loss: 138.48063\n",
      "[epoch 157, batch     5] loss: 131.50490\n",
      "[epoch 157, batch     6] loss: 137.12149\n",
      "[epoch 157, batch     7] loss: 116.64212\n",
      "[epoch 157, batch     8] loss: 143.95437\n",
      "[epoch 157, batch     9] loss: 132.67011\n",
      "[epoch 157, batch    10] loss: 143.41695\n",
      "[epoch 157, batch    11] loss: 148.52084\n",
      "[epoch 157, batch    12] loss: 146.07285\n",
      "[epoch 157, batch    13] loss: 130.94467\n",
      "[epoch 157, batch    14] loss: 126.40770\n",
      "[epoch 157, batch    15] loss: 133.05843\n",
      "[epoch 157, batch    16] loss: 138.17539\n",
      "[epoch 157, batch    17] loss: 125.09779\n",
      "[epoch 157, batch    18] loss: 128.00251\n",
      "[epoch 157, batch    19] loss: 141.84780\n",
      "[epoch 157, batch    20] loss: 122.87141\n",
      "[epoch 157, batch    21] loss: 122.37936\n",
      "[epoch 157, batch    22] loss: 139.20385\n",
      "[epoch 157, batch    23] loss: 123.63723\n",
      "[epoch 157, batch    24] loss: 146.16164\n",
      "[epoch 157, batch    25] loss: 134.63989\n",
      "[epoch 157, batch    26] loss: 143.74287\n",
      "[epoch 157, batch    27] loss: 126.48139\n",
      "[epoch 157, batch    28] loss: 136.86100\n",
      "[epoch 157, batch    29] loss: 126.80141\n",
      "[epoch 157, batch    30] loss: 132.01467\n",
      "[epoch 157, batch    31] loss: 135.07400\n",
      "[epoch 157, batch    32] loss: 30.01245\n",
      "[epoch 158, batch     1] loss: 134.53630\n",
      "[epoch 158, batch     2] loss: 139.98431\n",
      "[epoch 158, batch     3] loss: 126.80175\n",
      "[epoch 158, batch     4] loss: 128.19590\n",
      "[epoch 158, batch     5] loss: 124.20297\n",
      "[epoch 158, batch     6] loss: 128.40807\n",
      "[epoch 158, batch     7] loss: 123.21841\n",
      "[epoch 158, batch     8] loss: 133.00635\n",
      "[epoch 158, batch     9] loss: 134.78356\n",
      "[epoch 158, batch    10] loss: 122.85877\n",
      "[epoch 158, batch    11] loss: 131.57569\n",
      "[epoch 158, batch    12] loss: 120.74492\n",
      "[epoch 158, batch    13] loss: 135.38741\n",
      "[epoch 158, batch    14] loss: 141.33437\n",
      "[epoch 158, batch    15] loss: 124.46721\n",
      "[epoch 158, batch    16] loss: 145.94272\n",
      "[epoch 158, batch    17] loss: 121.08261\n",
      "[epoch 158, batch    18] loss: 123.73081\n",
      "[epoch 158, batch    19] loss: 131.21087\n",
      "[epoch 158, batch    20] loss: 135.50719\n",
      "[epoch 158, batch    21] loss: 142.05275\n",
      "[epoch 158, batch    22] loss: 135.93684\n",
      "[epoch 158, batch    23] loss: 134.99994\n",
      "[epoch 158, batch    24] loss: 148.02812\n",
      "[epoch 158, batch    25] loss: 129.42665\n",
      "[epoch 158, batch    26] loss: 136.31895\n",
      "[epoch 158, batch    27] loss: 131.48915\n",
      "[epoch 158, batch    28] loss: 144.52574\n",
      "[epoch 158, batch    29] loss: 134.09023\n",
      "[epoch 158, batch    30] loss: 130.96125\n",
      "[epoch 158, batch    31] loss: 125.31284\n",
      "[epoch 158, batch    32] loss: 30.17916\n",
      "[epoch 159, batch     1] loss: 135.76740\n",
      "[epoch 159, batch     2] loss: 129.56103\n",
      "[epoch 159, batch     3] loss: 144.49852\n",
      "[epoch 159, batch     4] loss: 129.46127\n",
      "[epoch 159, batch     5] loss: 121.27205\n",
      "[epoch 159, batch     6] loss: 125.64772\n",
      "[epoch 159, batch     7] loss: 112.68391\n",
      "[epoch 159, batch     8] loss: 128.28013\n",
      "[epoch 159, batch     9] loss: 145.89403\n",
      "[epoch 159, batch    10] loss: 134.55374\n",
      "[epoch 159, batch    11] loss: 128.10020\n",
      "[epoch 159, batch    12] loss: 122.85028\n",
      "[epoch 159, batch    13] loss: 136.16786\n",
      "[epoch 159, batch    14] loss: 138.26487\n",
      "[epoch 159, batch    15] loss: 141.48646\n",
      "[epoch 159, batch    16] loss: 138.46769\n",
      "[epoch 159, batch    17] loss: 132.46818\n",
      "[epoch 159, batch    18] loss: 137.74741\n",
      "[epoch 159, batch    19] loss: 128.06343\n",
      "[epoch 159, batch    20] loss: 141.33057\n",
      "[epoch 159, batch    21] loss: 126.67375\n",
      "[epoch 159, batch    22] loss: 129.77465\n",
      "[epoch 159, batch    23] loss: 133.43221\n",
      "[epoch 159, batch    24] loss: 135.97134\n",
      "[epoch 159, batch    25] loss: 136.05085\n",
      "[epoch 159, batch    26] loss: 143.54561\n",
      "[epoch 159, batch    27] loss: 135.85222\n",
      "[epoch 159, batch    28] loss: 120.49586\n",
      "[epoch 159, batch    29] loss: 133.00328\n",
      "[epoch 159, batch    30] loss: 127.09711\n",
      "[epoch 159, batch    31] loss: 122.03871\n",
      "[epoch 159, batch    32] loss: 33.51883\n",
      "[epoch 160, batch     1] loss: 121.40046\n",
      "[epoch 160, batch     2] loss: 128.95454\n",
      "[epoch 160, batch     3] loss: 137.52218\n",
      "[epoch 160, batch     4] loss: 144.22143\n",
      "[epoch 160, batch     5] loss: 128.83428\n",
      "[epoch 160, batch     6] loss: 139.82731\n",
      "[epoch 160, batch     7] loss: 132.85922\n",
      "[epoch 160, batch     8] loss: 149.76420\n",
      "[epoch 160, batch     9] loss: 127.41297\n",
      "[epoch 160, batch    10] loss: 140.50101\n",
      "[epoch 160, batch    11] loss: 133.10433\n",
      "[epoch 160, batch    12] loss: 120.89598\n",
      "[epoch 160, batch    13] loss: 129.56499\n",
      "[epoch 160, batch    14] loss: 145.22254\n",
      "[epoch 160, batch    15] loss: 133.90310\n",
      "[epoch 160, batch    16] loss: 137.56343\n",
      "[epoch 160, batch    17] loss: 130.18843\n",
      "[epoch 160, batch    18] loss: 130.35139\n",
      "[epoch 160, batch    19] loss: 134.64570\n",
      "[epoch 160, batch    20] loss: 125.73588\n",
      "[epoch 160, batch    21] loss: 130.80314\n",
      "[epoch 160, batch    22] loss: 137.91792\n",
      "[epoch 160, batch    23] loss: 142.83838\n",
      "[epoch 160, batch    24] loss: 134.43594\n",
      "[epoch 160, batch    25] loss: 126.40381\n",
      "[epoch 160, batch    26] loss: 139.04742\n",
      "[epoch 160, batch    27] loss: 125.48378\n",
      "[epoch 160, batch    28] loss: 131.57910\n",
      "[epoch 160, batch    29] loss: 122.55716\n",
      "[epoch 160, batch    30] loss: 143.47376\n",
      "[epoch 160, batch    31] loss: 124.87671\n",
      "[epoch 160, batch    32] loss: 30.70990\n",
      "[epoch 161, batch     1] loss: 124.42905\n",
      "[epoch 161, batch     2] loss: 139.50890\n",
      "[epoch 161, batch     3] loss: 132.02498\n",
      "[epoch 161, batch     4] loss: 146.75326\n",
      "[epoch 161, batch     5] loss: 139.03675\n",
      "[epoch 161, batch     6] loss: 118.39717\n",
      "[epoch 161, batch     7] loss: 121.92063\n",
      "[epoch 161, batch     8] loss: 126.98069\n",
      "[epoch 161, batch     9] loss: 123.09755\n",
      "[epoch 161, batch    10] loss: 135.16146\n",
      "[epoch 161, batch    11] loss: 133.43841\n",
      "[epoch 161, batch    12] loss: 132.20049\n",
      "[epoch 161, batch    13] loss: 135.73363\n",
      "[epoch 161, batch    14] loss: 126.24531\n",
      "[epoch 161, batch    15] loss: 142.65552\n",
      "[epoch 161, batch    16] loss: 131.44721\n",
      "[epoch 161, batch    17] loss: 122.22337\n",
      "[epoch 161, batch    18] loss: 122.69990\n",
      "[epoch 161, batch    19] loss: 110.00312\n",
      "[epoch 161, batch    20] loss: 134.62563\n",
      "[epoch 161, batch    21] loss: 132.45067\n",
      "[epoch 161, batch    22] loss: 144.43232\n",
      "[epoch 161, batch    23] loss: 129.69058\n",
      "[epoch 161, batch    24] loss: 116.84123\n",
      "[epoch 161, batch    25] loss: 132.12929\n",
      "[epoch 161, batch    26] loss: 150.43050\n",
      "[epoch 161, batch    27] loss: 131.60765\n",
      "[epoch 161, batch    28] loss: 130.89498\n",
      "[epoch 161, batch    29] loss: 119.20552\n",
      "[epoch 161, batch    30] loss: 119.89142\n",
      "[epoch 161, batch    31] loss: 140.95329\n",
      "[epoch 161, batch    32] loss: 35.69543\n",
      "[epoch 162, batch     1] loss: 130.13066\n",
      "[epoch 162, batch     2] loss: 127.16480\n",
      "[epoch 162, batch     3] loss: 126.59891\n",
      "[epoch 162, batch     4] loss: 122.10168\n",
      "[epoch 162, batch     5] loss: 125.45713\n",
      "[epoch 162, batch     6] loss: 139.13806\n",
      "[epoch 162, batch     7] loss: 130.16093\n",
      "[epoch 162, batch     8] loss: 138.46863\n",
      "[epoch 162, batch     9] loss: 149.05204\n",
      "[epoch 162, batch    10] loss: 130.46530\n",
      "[epoch 162, batch    11] loss: 139.73336\n",
      "[epoch 162, batch    12] loss: 125.78567\n",
      "[epoch 162, batch    13] loss: 120.99514\n",
      "[epoch 162, batch    14] loss: 147.57660\n",
      "[epoch 162, batch    15] loss: 129.00577\n",
      "[epoch 162, batch    16] loss: 135.46911\n",
      "[epoch 162, batch    17] loss: 141.73209\n",
      "[epoch 162, batch    18] loss: 121.94534\n",
      "[epoch 162, batch    19] loss: 137.62603\n",
      "[epoch 162, batch    20] loss: 141.44978\n",
      "[epoch 162, batch    21] loss: 123.89756\n",
      "[epoch 162, batch    22] loss: 143.48062\n",
      "[epoch 162, batch    23] loss: 127.89223\n",
      "[epoch 162, batch    24] loss: 126.91338\n",
      "[epoch 162, batch    25] loss: 136.54771\n",
      "[epoch 162, batch    26] loss: 129.21509\n",
      "[epoch 162, batch    27] loss: 127.23893\n",
      "[epoch 162, batch    28] loss: 136.83979\n",
      "[epoch 162, batch    29] loss: 146.19584\n",
      "[epoch 162, batch    30] loss: 134.45496\n",
      "[epoch 162, batch    31] loss: 131.76986\n",
      "[epoch 162, batch    32] loss: 30.80902\n",
      "[epoch 163, batch     1] loss: 133.26163\n",
      "[epoch 163, batch     2] loss: 134.46022\n",
      "[epoch 163, batch     3] loss: 128.99875\n",
      "[epoch 163, batch     4] loss: 131.40293\n",
      "[epoch 163, batch     5] loss: 132.71167\n",
      "[epoch 163, batch     6] loss: 126.04491\n",
      "[epoch 163, batch     7] loss: 135.59454\n",
      "[epoch 163, batch     8] loss: 131.60235\n",
      "[epoch 163, batch     9] loss: 135.39051\n",
      "[epoch 163, batch    10] loss: 141.21606\n",
      "[epoch 163, batch    11] loss: 137.08710\n",
      "[epoch 163, batch    12] loss: 136.56847\n",
      "[epoch 163, batch    13] loss: 128.09195\n",
      "[epoch 163, batch    14] loss: 131.32638\n",
      "[epoch 163, batch    15] loss: 135.80175\n",
      "[epoch 163, batch    16] loss: 138.58552\n",
      "[epoch 163, batch    17] loss: 151.12459\n",
      "[epoch 163, batch    18] loss: 141.75469\n",
      "[epoch 163, batch    19] loss: 130.99602\n",
      "[epoch 163, batch    20] loss: 126.88673\n",
      "[epoch 163, batch    21] loss: 141.91984\n",
      "[epoch 163, batch    22] loss: 140.56393\n",
      "[epoch 163, batch    23] loss: 131.73907\n",
      "[epoch 163, batch    24] loss: 130.19348\n",
      "[epoch 163, batch    25] loss: 136.28047\n",
      "[epoch 163, batch    26] loss: 137.40687\n",
      "[epoch 163, batch    27] loss: 120.10031\n",
      "[epoch 163, batch    28] loss: 128.26636\n",
      "[epoch 163, batch    29] loss: 121.54841\n",
      "[epoch 163, batch    30] loss: 135.36609\n",
      "[epoch 163, batch    31] loss: 132.56801\n",
      "[epoch 163, batch    32] loss: 35.88443\n",
      "[epoch 164, batch     1] loss: 136.38848\n",
      "[epoch 164, batch     2] loss: 119.46992\n",
      "[epoch 164, batch     3] loss: 124.28842\n",
      "[epoch 164, batch     4] loss: 133.23704\n",
      "[epoch 164, batch     5] loss: 135.75905\n",
      "[epoch 164, batch     6] loss: 133.67243\n",
      "[epoch 164, batch     7] loss: 140.05566\n",
      "[epoch 164, batch     8] loss: 132.11859\n",
      "[epoch 164, batch     9] loss: 141.32971\n",
      "[epoch 164, batch    10] loss: 143.19443\n",
      "[epoch 164, batch    11] loss: 139.49948\n",
      "[epoch 164, batch    12] loss: 132.25158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 164, batch    13] loss: 124.36573\n",
      "[epoch 164, batch    14] loss: 136.87540\n",
      "[epoch 164, batch    15] loss: 124.36371\n",
      "[epoch 164, batch    16] loss: 143.20580\n",
      "[epoch 164, batch    17] loss: 128.81732\n",
      "[epoch 164, batch    18] loss: 145.47730\n",
      "[epoch 164, batch    19] loss: 149.08386\n",
      "[epoch 164, batch    20] loss: 128.33054\n",
      "[epoch 164, batch    21] loss: 123.41043\n",
      "[epoch 164, batch    22] loss: 134.26538\n",
      "[epoch 164, batch    23] loss: 124.88078\n",
      "[epoch 164, batch    24] loss: 130.94044\n",
      "[epoch 164, batch    25] loss: 132.22779\n",
      "[epoch 164, batch    26] loss: 141.68223\n",
      "[epoch 164, batch    27] loss: 141.15651\n",
      "[epoch 164, batch    28] loss: 142.00851\n",
      "[epoch 164, batch    29] loss: 137.35409\n",
      "[epoch 164, batch    30] loss: 125.81495\n",
      "[epoch 164, batch    31] loss: 132.65462\n",
      "[epoch 164, batch    32] loss: 33.30844\n",
      "[epoch 165, batch     1] loss: 120.85623\n",
      "[epoch 165, batch     2] loss: 131.06682\n",
      "[epoch 165, batch     3] loss: 134.60378\n",
      "[epoch 165, batch     4] loss: 137.84226\n",
      "[epoch 165, batch     5] loss: 137.51678\n",
      "[epoch 165, batch     6] loss: 124.48012\n",
      "[epoch 165, batch     7] loss: 136.25890\n",
      "[epoch 165, batch     8] loss: 134.23294\n",
      "[epoch 165, batch     9] loss: 134.11929\n",
      "[epoch 165, batch    10] loss: 125.68188\n",
      "[epoch 165, batch    11] loss: 131.56779\n",
      "[epoch 165, batch    12] loss: 130.43417\n",
      "[epoch 165, batch    13] loss: 128.10173\n",
      "[epoch 165, batch    14] loss: 128.90027\n",
      "[epoch 165, batch    15] loss: 125.71824\n",
      "[epoch 165, batch    16] loss: 142.82709\n",
      "[epoch 165, batch    17] loss: 134.35366\n",
      "[epoch 165, batch    18] loss: 134.89338\n",
      "[epoch 165, batch    19] loss: 122.66133\n",
      "[epoch 165, batch    20] loss: 145.34466\n",
      "[epoch 165, batch    21] loss: 130.50132\n",
      "[epoch 165, batch    22] loss: 137.92556\n",
      "[epoch 165, batch    23] loss: 119.34446\n",
      "[epoch 165, batch    24] loss: 141.91590\n",
      "[epoch 165, batch    25] loss: 142.88713\n",
      "[epoch 165, batch    26] loss: 142.78538\n",
      "[epoch 165, batch    27] loss: 152.23513\n",
      "[epoch 165, batch    28] loss: 140.00337\n",
      "[epoch 165, batch    29] loss: 134.92498\n",
      "[epoch 165, batch    30] loss: 120.44626\n",
      "[epoch 165, batch    31] loss: 136.61496\n",
      "[epoch 165, batch    32] loss: 35.99524\n",
      "[epoch 166, batch     1] loss: 134.16027\n",
      "[epoch 166, batch     2] loss: 138.01815\n",
      "[epoch 166, batch     3] loss: 129.27540\n",
      "[epoch 166, batch     4] loss: 129.20152\n",
      "[epoch 166, batch     5] loss: 136.53992\n",
      "[epoch 166, batch     6] loss: 141.84026\n",
      "[epoch 166, batch     7] loss: 128.94377\n",
      "[epoch 166, batch     8] loss: 130.24639\n",
      "[epoch 166, batch     9] loss: 135.09976\n",
      "[epoch 166, batch    10] loss: 133.38911\n",
      "[epoch 166, batch    11] loss: 126.36981\n",
      "[epoch 166, batch    12] loss: 147.78772\n",
      "[epoch 166, batch    13] loss: 140.39948\n",
      "[epoch 166, batch    14] loss: 119.62159\n",
      "[epoch 166, batch    15] loss: 128.95005\n",
      "[epoch 166, batch    16] loss: 137.28596\n",
      "[epoch 166, batch    17] loss: 126.04697\n",
      "[epoch 166, batch    18] loss: 136.75564\n",
      "[epoch 166, batch    19] loss: 131.50138\n",
      "[epoch 166, batch    20] loss: 136.59160\n",
      "[epoch 166, batch    21] loss: 144.55692\n",
      "[epoch 166, batch    22] loss: 126.65109\n",
      "[epoch 166, batch    23] loss: 126.85456\n",
      "[epoch 166, batch    24] loss: 124.14831\n",
      "[epoch 166, batch    25] loss: 118.95748\n",
      "[epoch 166, batch    26] loss: 133.27699\n",
      "[epoch 166, batch    27] loss: 132.20823\n",
      "[epoch 166, batch    28] loss: 124.10740\n",
      "[epoch 166, batch    29] loss: 120.88543\n",
      "[epoch 166, batch    30] loss: 142.84207\n",
      "[epoch 166, batch    31] loss: 141.44388\n",
      "[epoch 166, batch    32] loss: 33.39697\n",
      "[epoch 167, batch     1] loss: 135.91286\n",
      "[epoch 167, batch     2] loss: 129.15003\n",
      "[epoch 167, batch     3] loss: 131.97291\n",
      "[epoch 167, batch     4] loss: 128.08646\n",
      "[epoch 167, batch     5] loss: 136.52364\n",
      "[epoch 167, batch     6] loss: 125.11007\n",
      "[epoch 167, batch     7] loss: 138.10514\n",
      "[epoch 167, batch     8] loss: 133.61585\n",
      "[epoch 167, batch     9] loss: 135.11388\n",
      "[epoch 167, batch    10] loss: 127.74749\n",
      "[epoch 167, batch    11] loss: 129.80500\n",
      "[epoch 167, batch    12] loss: 143.06566\n",
      "[epoch 167, batch    13] loss: 123.24818\n",
      "[epoch 167, batch    14] loss: 129.85010\n",
      "[epoch 167, batch    15] loss: 127.26483\n",
      "[epoch 167, batch    16] loss: 137.71154\n",
      "[epoch 167, batch    17] loss: 146.83056\n",
      "[epoch 167, batch    18] loss: 142.46273\n",
      "[epoch 167, batch    19] loss: 130.27800\n",
      "[epoch 167, batch    20] loss: 127.78260\n",
      "[epoch 167, batch    21] loss: 133.31865\n",
      "[epoch 167, batch    22] loss: 131.10727\n",
      "[epoch 167, batch    23] loss: 136.76137\n",
      "[epoch 167, batch    24] loss: 131.44481\n",
      "[epoch 167, batch    25] loss: 134.00355\n",
      "[epoch 167, batch    26] loss: 137.06526\n",
      "[epoch 167, batch    27] loss: 131.79548\n",
      "[epoch 167, batch    28] loss: 124.71950\n",
      "[epoch 167, batch    29] loss: 131.75061\n",
      "[epoch 167, batch    30] loss: 134.60546\n",
      "[epoch 167, batch    31] loss: 135.41737\n",
      "[epoch 167, batch    32] loss: 31.58951\n",
      "[epoch 168, batch     1] loss: 145.08317\n",
      "[epoch 168, batch     2] loss: 133.26047\n",
      "[epoch 168, batch     3] loss: 132.63557\n",
      "[epoch 168, batch     4] loss: 133.07996\n",
      "[epoch 168, batch     5] loss: 128.54292\n",
      "[epoch 168, batch     6] loss: 135.59720\n",
      "[epoch 168, batch     7] loss: 124.38687\n",
      "[epoch 168, batch     8] loss: 134.21324\n",
      "[epoch 168, batch     9] loss: 130.06492\n",
      "[epoch 168, batch    10] loss: 123.78289\n",
      "[epoch 168, batch    11] loss: 124.29473\n",
      "[epoch 168, batch    12] loss: 144.27044\n",
      "[epoch 168, batch    13] loss: 130.99834\n",
      "[epoch 168, batch    14] loss: 132.24965\n",
      "[epoch 168, batch    15] loss: 134.98277\n",
      "[epoch 168, batch    16] loss: 130.49648\n",
      "[epoch 168, batch    17] loss: 151.18418\n",
      "[epoch 168, batch    18] loss: 138.37946\n",
      "[epoch 168, batch    19] loss: 139.81041\n",
      "[epoch 168, batch    20] loss: 117.57767\n",
      "[epoch 168, batch    21] loss: 126.09534\n",
      "[epoch 168, batch    22] loss: 136.71480\n",
      "[epoch 168, batch    23] loss: 131.76060\n",
      "[epoch 168, batch    24] loss: 139.24147\n",
      "[epoch 168, batch    25] loss: 127.72056\n",
      "[epoch 168, batch    26] loss: 137.38121\n",
      "[epoch 168, batch    27] loss: 133.95510\n",
      "[epoch 168, batch    28] loss: 132.59383\n",
      "[epoch 168, batch    29] loss: 141.78257\n",
      "[epoch 168, batch    30] loss: 131.43199\n",
      "[epoch 168, batch    31] loss: 127.44073\n",
      "[epoch 168, batch    32] loss: 36.72018\n",
      "[epoch 169, batch     1] loss: 134.05784\n",
      "[epoch 169, batch     2] loss: 122.33133\n",
      "[epoch 169, batch     3] loss: 136.41997\n",
      "[epoch 169, batch     4] loss: 122.71130\n",
      "[epoch 169, batch     5] loss: 126.56955\n",
      "[epoch 169, batch     6] loss: 142.25437\n",
      "[epoch 169, batch     7] loss: 137.45214\n",
      "[epoch 169, batch     8] loss: 133.65360\n",
      "[epoch 169, batch     9] loss: 142.01117\n",
      "[epoch 169, batch    10] loss: 130.24937\n",
      "[epoch 169, batch    11] loss: 134.16124\n",
      "[epoch 169, batch    12] loss: 125.52993\n",
      "[epoch 169, batch    13] loss: 125.48619\n",
      "[epoch 169, batch    14] loss: 125.07813\n",
      "[epoch 169, batch    15] loss: 129.05541\n",
      "[epoch 169, batch    16] loss: 127.65368\n",
      "[epoch 169, batch    17] loss: 131.87010\n",
      "[epoch 169, batch    18] loss: 119.43114\n",
      "[epoch 169, batch    19] loss: 141.77303\n",
      "[epoch 169, batch    20] loss: 139.72281\n",
      "[epoch 169, batch    21] loss: 124.99214\n",
      "[epoch 169, batch    22] loss: 127.51996\n",
      "[epoch 169, batch    23] loss: 134.00392\n",
      "[epoch 169, batch    24] loss: 124.30903\n",
      "[epoch 169, batch    25] loss: 131.51221\n",
      "[epoch 169, batch    26] loss: 125.79608\n",
      "[epoch 169, batch    27] loss: 137.55446\n",
      "[epoch 169, batch    28] loss: 122.99784\n",
      "[epoch 169, batch    29] loss: 136.41470\n",
      "[epoch 169, batch    30] loss: 130.35273\n",
      "[epoch 169, batch    31] loss: 124.97810\n",
      "[epoch 169, batch    32] loss: 34.19312\n",
      "[epoch 170, batch     1] loss: 131.02599\n",
      "[epoch 170, batch     2] loss: 132.52984\n",
      "[epoch 170, batch     3] loss: 125.58645\n",
      "[epoch 170, batch     4] loss: 124.36897\n",
      "[epoch 170, batch     5] loss: 154.33404\n",
      "[epoch 170, batch     6] loss: 129.48400\n",
      "[epoch 170, batch     7] loss: 128.63045\n",
      "[epoch 170, batch     8] loss: 127.85486\n",
      "[epoch 170, batch     9] loss: 139.25868\n",
      "[epoch 170, batch    10] loss: 140.95396\n",
      "[epoch 170, batch    11] loss: 138.76622\n",
      "[epoch 170, batch    12] loss: 156.74017\n",
      "[epoch 170, batch    13] loss: 134.27646\n",
      "[epoch 170, batch    14] loss: 132.29568\n",
      "[epoch 170, batch    15] loss: 133.07391\n",
      "[epoch 170, batch    16] loss: 137.52522\n",
      "[epoch 170, batch    17] loss: 129.74834\n",
      "[epoch 170, batch    18] loss: 132.18480\n",
      "[epoch 170, batch    19] loss: 137.76466\n",
      "[epoch 170, batch    20] loss: 139.26285\n",
      "[epoch 170, batch    21] loss: 136.51494\n",
      "[epoch 170, batch    22] loss: 124.64031\n",
      "[epoch 170, batch    23] loss: 128.82748\n",
      "[epoch 170, batch    24] loss: 130.35695\n",
      "[epoch 170, batch    25] loss: 136.97726\n",
      "[epoch 170, batch    26] loss: 125.53935\n",
      "[epoch 170, batch    27] loss: 120.34235\n",
      "[epoch 170, batch    28] loss: 140.38512\n",
      "[epoch 170, batch    29] loss: 131.28651\n",
      "[epoch 170, batch    30] loss: 125.86321\n",
      "[epoch 170, batch    31] loss: 137.46259\n",
      "[epoch 170, batch    32] loss: 28.78028\n",
      "[epoch 171, batch     1] loss: 141.16129\n",
      "[epoch 171, batch     2] loss: 138.22905\n",
      "[epoch 171, batch     3] loss: 130.36213\n",
      "[epoch 171, batch     4] loss: 148.06578\n",
      "[epoch 171, batch     5] loss: 133.11234\n",
      "[epoch 171, batch     6] loss: 132.46937\n",
      "[epoch 171, batch     7] loss: 128.60506\n",
      "[epoch 171, batch     8] loss: 130.75602\n",
      "[epoch 171, batch     9] loss: 127.69650\n",
      "[epoch 171, batch    10] loss: 139.75856\n",
      "[epoch 171, batch    11] loss: 127.05424\n",
      "[epoch 171, batch    12] loss: 122.89879\n",
      "[epoch 171, batch    13] loss: 143.06126\n",
      "[epoch 171, batch    14] loss: 133.49174\n",
      "[epoch 171, batch    15] loss: 139.71848\n",
      "[epoch 171, batch    16] loss: 134.66580\n",
      "[epoch 171, batch    17] loss: 144.38101\n",
      "[epoch 171, batch    18] loss: 128.51140\n",
      "[epoch 171, batch    19] loss: 117.55464\n",
      "[epoch 171, batch    20] loss: 139.82119\n",
      "[epoch 171, batch    21] loss: 132.83403\n",
      "[epoch 171, batch    22] loss: 131.29054\n",
      "[epoch 171, batch    23] loss: 145.05125\n",
      "[epoch 171, batch    24] loss: 128.57686\n",
      "[epoch 171, batch    25] loss: 135.95086\n",
      "[epoch 171, batch    26] loss: 128.88898\n",
      "[epoch 171, batch    27] loss: 139.61299\n",
      "[epoch 171, batch    28] loss: 125.97716\n",
      "[epoch 171, batch    29] loss: 133.40742\n",
      "[epoch 171, batch    30] loss: 118.77294\n",
      "[epoch 171, batch    31] loss: 136.09500\n",
      "[epoch 171, batch    32] loss: 34.78200\n",
      "[epoch 172, batch     1] loss: 129.38745\n",
      "[epoch 172, batch     2] loss: 128.61976\n",
      "[epoch 172, batch     3] loss: 135.20770\n",
      "[epoch 172, batch     4] loss: 140.45688\n",
      "[epoch 172, batch     5] loss: 130.63198\n",
      "[epoch 172, batch     6] loss: 137.05803\n",
      "[epoch 172, batch     7] loss: 119.03914\n",
      "[epoch 172, batch     8] loss: 136.18880\n",
      "[epoch 172, batch     9] loss: 126.33493\n",
      "[epoch 172, batch    10] loss: 146.18037\n",
      "[epoch 172, batch    11] loss: 146.97943\n",
      "[epoch 172, batch    12] loss: 135.17505\n",
      "[epoch 172, batch    13] loss: 123.91286\n",
      "[epoch 172, batch    14] loss: 135.67711\n",
      "[epoch 172, batch    15] loss: 121.26487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 172, batch    16] loss: 135.38967\n",
      "[epoch 172, batch    17] loss: 131.46029\n",
      "[epoch 172, batch    18] loss: 133.04186\n",
      "[epoch 172, batch    19] loss: 130.66064\n",
      "[epoch 172, batch    20] loss: 130.93740\n",
      "[epoch 172, batch    21] loss: 131.06756\n",
      "[epoch 172, batch    22] loss: 124.28936\n",
      "[epoch 172, batch    23] loss: 144.72320\n",
      "[epoch 172, batch    24] loss: 116.45564\n",
      "[epoch 172, batch    25] loss: 143.97344\n",
      "[epoch 172, batch    26] loss: 133.88943\n",
      "[epoch 172, batch    27] loss: 141.91580\n",
      "[epoch 172, batch    28] loss: 129.26333\n",
      "[epoch 172, batch    29] loss: 133.03144\n",
      "[epoch 172, batch    30] loss: 130.33505\n",
      "[epoch 172, batch    31] loss: 144.36095\n",
      "[epoch 172, batch    32] loss: 29.11180\n",
      "[epoch 173, batch     1] loss: 142.91121\n",
      "[epoch 173, batch     2] loss: 129.26302\n",
      "[epoch 173, batch     3] loss: 123.26762\n",
      "[epoch 173, batch     4] loss: 134.44194\n",
      "[epoch 173, batch     5] loss: 138.87537\n",
      "[epoch 173, batch     6] loss: 122.64922\n",
      "[epoch 173, batch     7] loss: 120.71939\n",
      "[epoch 173, batch     8] loss: 133.64184\n",
      "[epoch 173, batch     9] loss: 130.07553\n",
      "[epoch 173, batch    10] loss: 131.60765\n",
      "[epoch 173, batch    11] loss: 139.33161\n",
      "[epoch 173, batch    12] loss: 134.51108\n",
      "[epoch 173, batch    13] loss: 117.00957\n",
      "[epoch 173, batch    14] loss: 125.15629\n",
      "[epoch 173, batch    15] loss: 144.93504\n",
      "[epoch 173, batch    16] loss: 124.12418\n",
      "[epoch 173, batch    17] loss: 139.58538\n",
      "[epoch 173, batch    18] loss: 138.89052\n",
      "[epoch 173, batch    19] loss: 140.52731\n",
      "[epoch 173, batch    20] loss: 130.07267\n",
      "[epoch 173, batch    21] loss: 138.55698\n",
      "[epoch 173, batch    22] loss: 127.03489\n",
      "[epoch 173, batch    23] loss: 138.79437\n",
      "[epoch 173, batch    24] loss: 138.08175\n",
      "[epoch 173, batch    25] loss: 133.86028\n",
      "[epoch 173, batch    26] loss: 129.58923\n",
      "[epoch 173, batch    27] loss: 148.48783\n",
      "[epoch 173, batch    28] loss: 132.67552\n",
      "[epoch 173, batch    29] loss: 124.62303\n",
      "[epoch 173, batch    30] loss: 122.97581\n",
      "[epoch 173, batch    31] loss: 136.58470\n",
      "[epoch 173, batch    32] loss: 33.31354\n",
      "[epoch 174, batch     1] loss: 138.37035\n",
      "[epoch 174, batch     2] loss: 125.45084\n",
      "[epoch 174, batch     3] loss: 140.05902\n",
      "[epoch 174, batch     4] loss: 119.77604\n",
      "[epoch 174, batch     5] loss: 139.93332\n",
      "[epoch 174, batch     6] loss: 142.28369\n",
      "[epoch 174, batch     7] loss: 126.19102\n",
      "[epoch 174, batch     8] loss: 138.29165\n",
      "[epoch 174, batch     9] loss: 133.33164\n",
      "[epoch 174, batch    10] loss: 125.10247\n",
      "[epoch 174, batch    11] loss: 138.45303\n",
      "[epoch 174, batch    12] loss: 130.65584\n",
      "[epoch 174, batch    13] loss: 144.18205\n",
      "[epoch 174, batch    14] loss: 143.16039\n",
      "[epoch 174, batch    15] loss: 134.18184\n",
      "[epoch 174, batch    16] loss: 125.93786\n",
      "[epoch 174, batch    17] loss: 133.52995\n",
      "[epoch 174, batch    18] loss: 127.97637\n",
      "[epoch 174, batch    19] loss: 133.18486\n",
      "[epoch 174, batch    20] loss: 125.29595\n",
      "[epoch 174, batch    21] loss: 149.34648\n",
      "[epoch 174, batch    22] loss: 135.79808\n",
      "[epoch 174, batch    23] loss: 131.28543\n",
      "[epoch 174, batch    24] loss: 139.03423\n",
      "[epoch 174, batch    25] loss: 138.61274\n",
      "[epoch 174, batch    26] loss: 138.40020\n",
      "[epoch 174, batch    27] loss: 130.16183\n",
      "[epoch 174, batch    28] loss: 141.84172\n",
      "[epoch 174, batch    29] loss: 118.62342\n",
      "[epoch 174, batch    30] loss: 131.65852\n",
      "[epoch 174, batch    31] loss: 139.88063\n",
      "[epoch 174, batch    32] loss: 34.36069\n",
      "[epoch 175, batch     1] loss: 128.21030\n",
      "[epoch 175, batch     2] loss: 127.69445\n",
      "[epoch 175, batch     3] loss: 150.11617\n",
      "[epoch 175, batch     4] loss: 130.54184\n",
      "[epoch 175, batch     5] loss: 137.43856\n",
      "[epoch 175, batch     6] loss: 132.46487\n",
      "[epoch 175, batch     7] loss: 123.37322\n",
      "[epoch 175, batch     8] loss: 127.76269\n",
      "[epoch 175, batch     9] loss: 145.03464\n",
      "[epoch 175, batch    10] loss: 130.79889\n",
      "[epoch 175, batch    11] loss: 127.31775\n",
      "[epoch 175, batch    12] loss: 148.59948\n",
      "[epoch 175, batch    13] loss: 131.30884\n",
      "[epoch 175, batch    14] loss: 116.94911\n",
      "[epoch 175, batch    15] loss: 132.22576\n",
      "[epoch 175, batch    16] loss: 131.84043\n",
      "[epoch 175, batch    17] loss: 128.46814\n",
      "[epoch 175, batch    18] loss: 142.19733\n",
      "[epoch 175, batch    19] loss: 142.66003\n",
      "[epoch 175, batch    20] loss: 137.64965\n",
      "[epoch 175, batch    21] loss: 134.00323\n",
      "[epoch 175, batch    22] loss: 136.41937\n",
      "[epoch 175, batch    23] loss: 138.31341\n",
      "[epoch 175, batch    24] loss: 143.56022\n",
      "[epoch 175, batch    25] loss: 131.80166\n",
      "[epoch 175, batch    26] loss: 130.90954\n",
      "[epoch 175, batch    27] loss: 127.34170\n",
      "[epoch 175, batch    28] loss: 127.97703\n",
      "[epoch 175, batch    29] loss: 140.45046\n",
      "[epoch 175, batch    30] loss: 141.66609\n",
      "[epoch 175, batch    31] loss: 135.23639\n",
      "[epoch 175, batch    32] loss: 33.22355\n",
      "[epoch 176, batch     1] loss: 128.79923\n",
      "[epoch 176, batch     2] loss: 129.39125\n",
      "[epoch 176, batch     3] loss: 123.29967\n",
      "[epoch 176, batch     4] loss: 126.20318\n",
      "[epoch 176, batch     5] loss: 135.71357\n",
      "[epoch 176, batch     6] loss: 132.41746\n",
      "[epoch 176, batch     7] loss: 128.65636\n",
      "[epoch 176, batch     8] loss: 125.38201\n",
      "[epoch 176, batch     9] loss: 121.07589\n",
      "[epoch 176, batch    10] loss: 147.49996\n",
      "[epoch 176, batch    11] loss: 120.83793\n",
      "[epoch 176, batch    12] loss: 143.37606\n",
      "[epoch 176, batch    13] loss: 149.13054\n",
      "[epoch 176, batch    14] loss: 132.76351\n",
      "[epoch 176, batch    15] loss: 132.43317\n",
      "[epoch 176, batch    16] loss: 125.98414\n",
      "[epoch 176, batch    17] loss: 129.78260\n",
      "[epoch 176, batch    18] loss: 137.30336\n",
      "[epoch 176, batch    19] loss: 134.21885\n",
      "[epoch 176, batch    20] loss: 143.33101\n",
      "[epoch 176, batch    21] loss: 132.29039\n",
      "[epoch 176, batch    22] loss: 126.85011\n",
      "[epoch 176, batch    23] loss: 126.57085\n",
      "[epoch 176, batch    24] loss: 128.36639\n",
      "[epoch 176, batch    25] loss: 130.75839\n",
      "[epoch 176, batch    26] loss: 134.58384\n",
      "[epoch 176, batch    27] loss: 134.61805\n",
      "[epoch 176, batch    28] loss: 144.19696\n",
      "[epoch 176, batch    29] loss: 138.85429\n",
      "[epoch 176, batch    30] loss: 134.44690\n",
      "[epoch 176, batch    31] loss: 128.81101\n",
      "[epoch 176, batch    32] loss: 28.50757\n",
      "[epoch 177, batch     1] loss: 139.87861\n",
      "[epoch 177, batch     2] loss: 129.35281\n",
      "[epoch 177, batch     3] loss: 131.46373\n",
      "[epoch 177, batch     4] loss: 143.85464\n",
      "[epoch 177, batch     5] loss: 122.25019\n",
      "[epoch 177, batch     6] loss: 127.05062\n",
      "[epoch 177, batch     7] loss: 123.61892\n",
      "[epoch 177, batch     8] loss: 140.31640\n",
      "[epoch 177, batch     9] loss: 128.57228\n",
      "[epoch 177, batch    10] loss: 132.95662\n",
      "[epoch 177, batch    11] loss: 130.72255\n",
      "[epoch 177, batch    12] loss: 137.64908\n",
      "[epoch 177, batch    13] loss: 134.11553\n",
      "[epoch 177, batch    14] loss: 129.24976\n",
      "[epoch 177, batch    15] loss: 132.27403\n",
      "[epoch 177, batch    16] loss: 121.58098\n",
      "[epoch 177, batch    17] loss: 141.39882\n",
      "[epoch 177, batch    18] loss: 134.17060\n",
      "[epoch 177, batch    19] loss: 117.48517\n",
      "[epoch 177, batch    20] loss: 139.82438\n",
      "[epoch 177, batch    21] loss: 122.91308\n",
      "[epoch 177, batch    22] loss: 131.86188\n",
      "[epoch 177, batch    23] loss: 136.59793\n",
      "[epoch 177, batch    24] loss: 135.75369\n",
      "[epoch 177, batch    25] loss: 134.35283\n",
      "[epoch 177, batch    26] loss: 120.37143\n",
      "[epoch 177, batch    27] loss: 119.50557\n",
      "[epoch 177, batch    28] loss: 132.22825\n",
      "[epoch 177, batch    29] loss: 131.29864\n",
      "[epoch 177, batch    30] loss: 148.63127\n",
      "[epoch 177, batch    31] loss: 125.69633\n",
      "[epoch 177, batch    32] loss: 30.37230\n",
      "[epoch 178, batch     1] loss: 130.80169\n",
      "[epoch 178, batch     2] loss: 137.90382\n",
      "[epoch 178, batch     3] loss: 127.52416\n",
      "[epoch 178, batch     4] loss: 129.93749\n",
      "[epoch 178, batch     5] loss: 131.75884\n",
      "[epoch 178, batch     6] loss: 133.96618\n",
      "[epoch 178, batch     7] loss: 124.10461\n",
      "[epoch 178, batch     8] loss: 127.81385\n",
      "[epoch 178, batch     9] loss: 131.96905\n",
      "[epoch 178, batch    10] loss: 143.60735\n",
      "[epoch 178, batch    11] loss: 134.71890\n",
      "[epoch 178, batch    12] loss: 130.73912\n",
      "[epoch 178, batch    13] loss: 122.28158\n",
      "[epoch 178, batch    14] loss: 137.99478\n",
      "[epoch 178, batch    15] loss: 132.56607\n",
      "[epoch 178, batch    16] loss: 147.09434\n",
      "[epoch 178, batch    17] loss: 126.06331\n",
      "[epoch 178, batch    18] loss: 134.83588\n",
      "[epoch 178, batch    19] loss: 143.12111\n",
      "[epoch 178, batch    20] loss: 141.50489\n",
      "[epoch 178, batch    21] loss: 134.91868\n",
      "[epoch 178, batch    22] loss: 132.40309\n",
      "[epoch 178, batch    23] loss: 129.80779\n",
      "[epoch 178, batch    24] loss: 134.50645\n",
      "[epoch 178, batch    25] loss: 124.39497\n",
      "[epoch 178, batch    26] loss: 116.66584\n",
      "[epoch 178, batch    27] loss: 133.31101\n",
      "[epoch 178, batch    28] loss: 134.73656\n",
      "[epoch 178, batch    29] loss: 126.26596\n",
      "[epoch 178, batch    30] loss: 139.90103\n",
      "[epoch 178, batch    31] loss: 119.59906\n",
      "[epoch 178, batch    32] loss: 34.18474\n",
      "[epoch 179, batch     1] loss: 134.85777\n",
      "[epoch 179, batch     2] loss: 148.19124\n",
      "[epoch 179, batch     3] loss: 122.87418\n",
      "[epoch 179, batch     4] loss: 140.43200\n",
      "[epoch 179, batch     5] loss: 128.38932\n",
      "[epoch 179, batch     6] loss: 139.35255\n",
      "[epoch 179, batch     7] loss: 135.72225\n",
      "[epoch 179, batch     8] loss: 145.14358\n",
      "[epoch 179, batch     9] loss: 141.19711\n",
      "[epoch 179, batch    10] loss: 131.42239\n",
      "[epoch 179, batch    11] loss: 126.46757\n",
      "[epoch 179, batch    12] loss: 137.83449\n",
      "[epoch 179, batch    13] loss: 134.98899\n",
      "[epoch 179, batch    14] loss: 153.12043\n",
      "[epoch 179, batch    15] loss: 119.55334\n",
      "[epoch 179, batch    16] loss: 139.91360\n",
      "[epoch 179, batch    17] loss: 129.52669\n",
      "[epoch 179, batch    18] loss: 127.32678\n",
      "[epoch 179, batch    19] loss: 126.08214\n",
      "[epoch 179, batch    20] loss: 127.85662\n",
      "[epoch 179, batch    21] loss: 138.19915\n",
      "[epoch 179, batch    22] loss: 134.24615\n",
      "[epoch 179, batch    23] loss: 137.92420\n",
      "[epoch 179, batch    24] loss: 135.02853\n",
      "[epoch 179, batch    25] loss: 133.64672\n",
      "[epoch 179, batch    26] loss: 131.21021\n",
      "[epoch 179, batch    27] loss: 129.51012\n",
      "[epoch 179, batch    28] loss: 123.90432\n",
      "[epoch 179, batch    29] loss: 133.30997\n",
      "[epoch 179, batch    30] loss: 136.48965\n",
      "[epoch 179, batch    31] loss: 120.33489\n",
      "[epoch 179, batch    32] loss: 34.22360\n",
      "[epoch 180, batch     1] loss: 134.67463\n",
      "[epoch 180, batch     2] loss: 131.33077\n",
      "[epoch 180, batch     3] loss: 138.58581\n",
      "[epoch 180, batch     4] loss: 132.02671\n",
      "[epoch 180, batch     5] loss: 134.01920\n",
      "[epoch 180, batch     6] loss: 129.98340\n",
      "[epoch 180, batch     7] loss: 126.30960\n",
      "[epoch 180, batch     8] loss: 120.13405\n",
      "[epoch 180, batch     9] loss: 130.61028\n",
      "[epoch 180, batch    10] loss: 124.84357\n",
      "[epoch 180, batch    11] loss: 144.91795\n",
      "[epoch 180, batch    12] loss: 144.81384\n",
      "[epoch 180, batch    13] loss: 128.02050\n",
      "[epoch 180, batch    14] loss: 140.90971\n",
      "[epoch 180, batch    15] loss: 133.45145\n",
      "[epoch 180, batch    16] loss: 130.38812\n",
      "[epoch 180, batch    17] loss: 140.16877\n",
      "[epoch 180, batch    18] loss: 128.87295\n",
      "[epoch 180, batch    19] loss: 128.59470\n",
      "[epoch 180, batch    20] loss: 126.59790\n",
      "[epoch 180, batch    21] loss: 130.81189\n",
      "[epoch 180, batch    22] loss: 139.74900\n",
      "[epoch 180, batch    23] loss: 127.34713\n",
      "[epoch 180, batch    24] loss: 133.36748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 180, batch    25] loss: 128.49401\n",
      "[epoch 180, batch    26] loss: 123.69639\n",
      "[epoch 180, batch    27] loss: 122.46511\n",
      "[epoch 180, batch    28] loss: 134.64420\n",
      "[epoch 180, batch    29] loss: 138.15264\n",
      "[epoch 180, batch    30] loss: 133.83889\n",
      "[epoch 180, batch    31] loss: 130.77125\n",
      "[epoch 180, batch    32] loss: 30.35644\n",
      "[epoch 181, batch     1] loss: 135.19648\n",
      "[epoch 181, batch     2] loss: 125.70391\n",
      "[epoch 181, batch     3] loss: 133.85159\n",
      "[epoch 181, batch     4] loss: 128.65303\n",
      "[epoch 181, batch     5] loss: 144.23288\n",
      "[epoch 181, batch     6] loss: 129.55351\n",
      "[epoch 181, batch     7] loss: 136.59823\n",
      "[epoch 181, batch     8] loss: 131.92213\n",
      "[epoch 181, batch     9] loss: 136.94313\n",
      "[epoch 181, batch    10] loss: 134.36816\n",
      "[epoch 181, batch    11] loss: 133.01752\n",
      "[epoch 181, batch    12] loss: 119.20183\n",
      "[epoch 181, batch    13] loss: 121.22060\n",
      "[epoch 181, batch    14] loss: 136.26520\n",
      "[epoch 181, batch    15] loss: 136.81629\n",
      "[epoch 181, batch    16] loss: 147.32887\n",
      "[epoch 181, batch    17] loss: 131.90721\n",
      "[epoch 181, batch    18] loss: 122.28388\n",
      "[epoch 181, batch    19] loss: 133.59175\n",
      "[epoch 181, batch    20] loss: 127.04406\n",
      "[epoch 181, batch    21] loss: 150.56356\n",
      "[epoch 181, batch    22] loss: 150.86716\n",
      "[epoch 181, batch    23] loss: 137.89413\n",
      "[epoch 181, batch    24] loss: 125.66211\n",
      "[epoch 181, batch    25] loss: 118.06543\n",
      "[epoch 181, batch    26] loss: 131.11835\n",
      "[epoch 181, batch    27] loss: 130.76438\n",
      "[epoch 181, batch    28] loss: 129.64526\n",
      "[epoch 181, batch    29] loss: 130.63003\n",
      "[epoch 181, batch    30] loss: 141.04264\n",
      "[epoch 181, batch    31] loss: 131.46756\n",
      "[epoch 181, batch    32] loss: 34.93708\n",
      "[epoch 182, batch     1] loss: 143.20300\n",
      "[epoch 182, batch     2] loss: 134.71864\n",
      "[epoch 182, batch     3] loss: 131.54271\n",
      "[epoch 182, batch     4] loss: 137.57747\n",
      "[epoch 182, batch     5] loss: 118.72156\n",
      "[epoch 182, batch     6] loss: 127.04143\n",
      "[epoch 182, batch     7] loss: 123.06619\n",
      "[epoch 182, batch     8] loss: 121.14366\n",
      "[epoch 182, batch     9] loss: 133.05744\n",
      "[epoch 182, batch    10] loss: 146.14307\n",
      "[epoch 182, batch    11] loss: 138.59041\n",
      "[epoch 182, batch    12] loss: 136.16581\n",
      "[epoch 182, batch    13] loss: 131.62008\n",
      "[epoch 182, batch    14] loss: 123.38438\n",
      "[epoch 182, batch    15] loss: 152.81228\n",
      "[epoch 182, batch    16] loss: 124.73008\n",
      "[epoch 182, batch    17] loss: 143.71025\n",
      "[epoch 182, batch    18] loss: 132.28348\n",
      "[epoch 182, batch    19] loss: 129.33721\n",
      "[epoch 182, batch    20] loss: 132.62583\n",
      "[epoch 182, batch    21] loss: 133.40666\n",
      "[epoch 182, batch    22] loss: 126.52089\n",
      "[epoch 182, batch    23] loss: 123.52366\n",
      "[epoch 182, batch    24] loss: 130.85322\n",
      "[epoch 182, batch    25] loss: 132.25100\n",
      "[epoch 182, batch    26] loss: 127.06643\n",
      "[epoch 182, batch    27] loss: 137.30243\n",
      "[epoch 182, batch    28] loss: 130.96257\n",
      "[epoch 182, batch    29] loss: 126.39024\n",
      "[epoch 182, batch    30] loss: 131.05350\n",
      "[epoch 182, batch    31] loss: 123.71128\n",
      "[epoch 182, batch    32] loss: 35.75173\n",
      "[epoch 183, batch     1] loss: 130.47143\n",
      "[epoch 183, batch     2] loss: 132.52417\n",
      "[epoch 183, batch     3] loss: 132.72905\n",
      "[epoch 183, batch     4] loss: 131.59955\n",
      "[epoch 183, batch     5] loss: 123.80660\n",
      "[epoch 183, batch     6] loss: 132.98742\n",
      "[epoch 183, batch     7] loss: 138.47942\n",
      "[epoch 183, batch     8] loss: 127.63759\n",
      "[epoch 183, batch     9] loss: 125.25417\n",
      "[epoch 183, batch    10] loss: 134.29002\n",
      "[epoch 183, batch    11] loss: 134.66422\n",
      "[epoch 183, batch    12] loss: 134.39909\n",
      "[epoch 183, batch    13] loss: 126.68694\n",
      "[epoch 183, batch    14] loss: 134.49738\n",
      "[epoch 183, batch    15] loss: 139.22159\n",
      "[epoch 183, batch    16] loss: 128.98174\n",
      "[epoch 183, batch    17] loss: 134.53700\n",
      "[epoch 183, batch    18] loss: 135.59842\n",
      "[epoch 183, batch    19] loss: 145.89716\n",
      "[epoch 183, batch    20] loss: 138.73800\n",
      "[epoch 183, batch    21] loss: 120.96268\n",
      "[epoch 183, batch    22] loss: 124.42146\n",
      "[epoch 183, batch    23] loss: 132.27935\n",
      "[epoch 183, batch    24] loss: 131.57639\n",
      "[epoch 183, batch    25] loss: 128.80609\n",
      "[epoch 183, batch    26] loss: 125.46735\n",
      "[epoch 183, batch    27] loss: 129.77646\n",
      "[epoch 183, batch    28] loss: 133.55619\n",
      "[epoch 183, batch    29] loss: 127.14793\n",
      "[epoch 183, batch    30] loss: 128.98117\n",
      "[epoch 183, batch    31] loss: 132.48165\n",
      "[epoch 183, batch    32] loss: 35.21219\n",
      "[epoch 184, batch     1] loss: 128.15615\n",
      "[epoch 184, batch     2] loss: 135.27024\n",
      "[epoch 184, batch     3] loss: 128.38964\n",
      "[epoch 184, batch     4] loss: 144.36978\n",
      "[epoch 184, batch     5] loss: 132.25434\n",
      "[epoch 184, batch     6] loss: 129.54455\n",
      "[epoch 184, batch     7] loss: 122.41606\n",
      "[epoch 184, batch     8] loss: 120.42205\n",
      "[epoch 184, batch     9] loss: 136.18552\n",
      "[epoch 184, batch    10] loss: 127.93735\n",
      "[epoch 184, batch    11] loss: 127.83676\n",
      "[epoch 184, batch    12] loss: 139.40649\n",
      "[epoch 184, batch    13] loss: 138.00651\n",
      "[epoch 184, batch    14] loss: 124.76108\n",
      "[epoch 184, batch    15] loss: 150.97501\n",
      "[epoch 184, batch    16] loss: 137.91131\n",
      "[epoch 184, batch    17] loss: 134.99978\n",
      "[epoch 184, batch    18] loss: 132.79329\n",
      "[epoch 184, batch    19] loss: 144.02889\n",
      "[epoch 184, batch    20] loss: 136.12656\n",
      "[epoch 184, batch    21] loss: 132.00699\n",
      "[epoch 184, batch    22] loss: 131.34998\n",
      "[epoch 184, batch    23] loss: 135.70862\n",
      "[epoch 184, batch    24] loss: 133.49368\n",
      "[epoch 184, batch    25] loss: 145.06961\n",
      "[epoch 184, batch    26] loss: 136.21385\n",
      "[epoch 184, batch    27] loss: 125.00933\n",
      "[epoch 184, batch    28] loss: 132.72524\n",
      "[epoch 184, batch    29] loss: 135.51455\n",
      "[epoch 184, batch    30] loss: 143.42543\n",
      "[epoch 184, batch    31] loss: 122.57162\n",
      "[epoch 184, batch    32] loss: 31.72509\n",
      "[epoch 185, batch     1] loss: 132.15921\n",
      "[epoch 185, batch     2] loss: 127.54259\n",
      "[epoch 185, batch     3] loss: 115.02429\n",
      "[epoch 185, batch     4] loss: 126.69820\n",
      "[epoch 185, batch     5] loss: 134.67299\n",
      "[epoch 185, batch     6] loss: 129.31041\n",
      "[epoch 185, batch     7] loss: 135.15506\n",
      "[epoch 185, batch     8] loss: 131.97109\n",
      "[epoch 185, batch     9] loss: 127.27905\n",
      "[epoch 185, batch    10] loss: 127.96601\n",
      "[epoch 185, batch    11] loss: 146.00031\n",
      "[epoch 185, batch    12] loss: 134.64702\n",
      "[epoch 185, batch    13] loss: 143.73625\n",
      "[epoch 185, batch    14] loss: 133.94599\n",
      "[epoch 185, batch    15] loss: 133.35844\n",
      "[epoch 185, batch    16] loss: 145.65334\n",
      "[epoch 185, batch    17] loss: 122.91119\n",
      "[epoch 185, batch    18] loss: 128.69261\n",
      "[epoch 185, batch    19] loss: 132.92930\n",
      "[epoch 185, batch    20] loss: 140.40548\n",
      "[epoch 185, batch    21] loss: 128.00343\n",
      "[epoch 185, batch    22] loss: 137.99818\n",
      "[epoch 185, batch    23] loss: 131.36870\n",
      "[epoch 185, batch    24] loss: 141.11566\n",
      "[epoch 185, batch    25] loss: 134.36425\n",
      "[epoch 185, batch    26] loss: 128.37562\n",
      "[epoch 185, batch    27] loss: 135.93847\n",
      "[epoch 185, batch    28] loss: 146.62082\n",
      "[epoch 185, batch    29] loss: 142.13431\n",
      "[epoch 185, batch    30] loss: 130.54403\n",
      "[epoch 185, batch    31] loss: 137.07172\n",
      "[epoch 185, batch    32] loss: 29.60052\n",
      "[epoch 186, batch     1] loss: 131.79838\n",
      "[epoch 186, batch     2] loss: 139.92379\n",
      "[epoch 186, batch     3] loss: 130.30293\n",
      "[epoch 186, batch     4] loss: 133.12824\n",
      "[epoch 186, batch     5] loss: 134.37015\n",
      "[epoch 186, batch     6] loss: 122.16061\n",
      "[epoch 186, batch     7] loss: 143.56226\n",
      "[epoch 186, batch     8] loss: 133.96898\n",
      "[epoch 186, batch     9] loss: 128.84164\n",
      "[epoch 186, batch    10] loss: 135.34781\n",
      "[epoch 186, batch    11] loss: 145.46243\n",
      "[epoch 186, batch    12] loss: 139.43646\n",
      "[epoch 186, batch    13] loss: 139.12434\n",
      "[epoch 186, batch    14] loss: 127.91706\n",
      "[epoch 186, batch    15] loss: 141.24406\n",
      "[epoch 186, batch    16] loss: 139.16289\n",
      "[epoch 186, batch    17] loss: 125.68842\n",
      "[epoch 186, batch    18] loss: 141.00638\n",
      "[epoch 186, batch    19] loss: 115.35855\n",
      "[epoch 186, batch    20] loss: 129.70610\n",
      "[epoch 186, batch    21] loss: 126.35113\n",
      "[epoch 186, batch    22] loss: 128.44301\n",
      "[epoch 186, batch    23] loss: 141.91052\n",
      "[epoch 186, batch    24] loss: 123.79339\n",
      "[epoch 186, batch    25] loss: 143.49835\n",
      "[epoch 186, batch    26] loss: 138.49226\n",
      "[epoch 186, batch    27] loss: 131.17275\n",
      "[epoch 186, batch    28] loss: 134.09698\n",
      "[epoch 186, batch    29] loss: 126.94293\n",
      "[epoch 186, batch    30] loss: 138.61681\n",
      "[epoch 186, batch    31] loss: 129.78869\n",
      "[epoch 186, batch    32] loss: 37.48380\n",
      "[epoch 187, batch     1] loss: 121.99330\n",
      "[epoch 187, batch     2] loss: 133.43482\n",
      "[epoch 187, batch     3] loss: 131.39459\n",
      "[epoch 187, batch     4] loss: 137.31281\n",
      "[epoch 187, batch     5] loss: 134.97309\n",
      "[epoch 187, batch     6] loss: 137.68591\n",
      "[epoch 187, batch     7] loss: 125.93059\n",
      "[epoch 187, batch     8] loss: 145.09638\n",
      "[epoch 187, batch     9] loss: 137.59163\n",
      "[epoch 187, batch    10] loss: 122.25314\n",
      "[epoch 187, batch    11] loss: 122.74188\n",
      "[epoch 187, batch    12] loss: 123.91681\n",
      "[epoch 187, batch    13] loss: 134.23688\n",
      "[epoch 187, batch    14] loss: 134.50397\n",
      "[epoch 187, batch    15] loss: 140.65614\n",
      "[epoch 187, batch    16] loss: 125.55003\n",
      "[epoch 187, batch    17] loss: 132.40809\n",
      "[epoch 187, batch    18] loss: 127.05996\n",
      "[epoch 187, batch    19] loss: 124.15197\n",
      "[epoch 187, batch    20] loss: 138.58000\n",
      "[epoch 187, batch    21] loss: 151.90474\n",
      "[epoch 187, batch    22] loss: 145.21641\n",
      "[epoch 187, batch    23] loss: 128.12861\n",
      "[epoch 187, batch    24] loss: 136.74538\n",
      "[epoch 187, batch    25] loss: 134.19234\n",
      "[epoch 187, batch    26] loss: 142.33555\n",
      "[epoch 187, batch    27] loss: 129.20520\n",
      "[epoch 187, batch    28] loss: 142.94485\n",
      "[epoch 187, batch    29] loss: 119.35114\n",
      "[epoch 187, batch    30] loss: 144.16470\n",
      "[epoch 187, batch    31] loss: 133.16107\n",
      "[epoch 187, batch    32] loss: 35.02273\n",
      "[epoch 188, batch     1] loss: 113.28925\n",
      "[epoch 188, batch     2] loss: 124.87210\n",
      "[epoch 188, batch     3] loss: 144.12242\n",
      "[epoch 188, batch     4] loss: 130.42710\n",
      "[epoch 188, batch     5] loss: 132.91821\n",
      "[epoch 188, batch     6] loss: 122.92176\n",
      "[epoch 188, batch     7] loss: 138.30583\n",
      "[epoch 188, batch     8] loss: 143.89734\n",
      "[epoch 188, batch     9] loss: 134.17682\n",
      "[epoch 188, batch    10] loss: 127.31360\n",
      "[epoch 188, batch    11] loss: 134.53490\n",
      "[epoch 188, batch    12] loss: 145.92995\n",
      "[epoch 188, batch    13] loss: 123.55250\n",
      "[epoch 188, batch    14] loss: 138.54739\n",
      "[epoch 188, batch    15] loss: 136.44067\n",
      "[epoch 188, batch    16] loss: 124.12837\n",
      "[epoch 188, batch    17] loss: 132.97456\n",
      "[epoch 188, batch    18] loss: 138.89105\n",
      "[epoch 188, batch    19] loss: 125.68398\n",
      "[epoch 188, batch    20] loss: 130.91762\n",
      "[epoch 188, batch    21] loss: 135.23234\n",
      "[epoch 188, batch    22] loss: 130.17726\n",
      "[epoch 188, batch    23] loss: 139.28731\n",
      "[epoch 188, batch    24] loss: 126.21686\n",
      "[epoch 188, batch    25] loss: 137.72073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 188, batch    26] loss: 125.69730\n",
      "[epoch 188, batch    27] loss: 125.03004\n",
      "[epoch 188, batch    28] loss: 127.95236\n",
      "[epoch 188, batch    29] loss: 137.47303\n",
      "[epoch 188, batch    30] loss: 147.15505\n",
      "[epoch 188, batch    31] loss: 128.12960\n",
      "[epoch 188, batch    32] loss: 31.14398\n",
      "[epoch 189, batch     1] loss: 126.26258\n",
      "[epoch 189, batch     2] loss: 137.38331\n",
      "[epoch 189, batch     3] loss: 134.22369\n",
      "[epoch 189, batch     4] loss: 128.65954\n",
      "[epoch 189, batch     5] loss: 129.32495\n",
      "[epoch 189, batch     6] loss: 130.18916\n",
      "[epoch 189, batch     7] loss: 127.47183\n",
      "[epoch 189, batch     8] loss: 132.12274\n",
      "[epoch 189, batch     9] loss: 120.64283\n",
      "[epoch 189, batch    10] loss: 137.31580\n",
      "[epoch 189, batch    11] loss: 120.46949\n",
      "[epoch 189, batch    12] loss: 134.36800\n",
      "[epoch 189, batch    13] loss: 136.08201\n",
      "[epoch 189, batch    14] loss: 137.33216\n",
      "[epoch 189, batch    15] loss: 139.67616\n",
      "[epoch 189, batch    16] loss: 139.97766\n",
      "[epoch 189, batch    17] loss: 131.17949\n",
      "[epoch 189, batch    18] loss: 118.87841\n",
      "[epoch 189, batch    19] loss: 131.03865\n",
      "[epoch 189, batch    20] loss: 118.91955\n",
      "[epoch 189, batch    21] loss: 125.95658\n",
      "[epoch 189, batch    22] loss: 133.18809\n",
      "[epoch 189, batch    23] loss: 139.25181\n",
      "[epoch 189, batch    24] loss: 131.06248\n",
      "[epoch 189, batch    25] loss: 134.03502\n",
      "[epoch 189, batch    26] loss: 131.15729\n",
      "[epoch 189, batch    27] loss: 121.87280\n",
      "[epoch 189, batch    28] loss: 125.93814\n",
      "[epoch 189, batch    29] loss: 138.45734\n",
      "[epoch 189, batch    30] loss: 140.11126\n",
      "[epoch 189, batch    31] loss: 121.63086\n",
      "[epoch 189, batch    32] loss: 32.91022\n",
      "[epoch 190, batch     1] loss: 138.43986\n",
      "[epoch 190, batch     2] loss: 155.04713\n",
      "[epoch 190, batch     3] loss: 135.33155\n",
      "[epoch 190, batch     4] loss: 119.87685\n",
      "[epoch 190, batch     5] loss: 124.38462\n",
      "[epoch 190, batch     6] loss: 122.90871\n",
      "[epoch 190, batch     7] loss: 131.60013\n",
      "[epoch 190, batch     8] loss: 137.12392\n",
      "[epoch 190, batch     9] loss: 126.83243\n",
      "[epoch 190, batch    10] loss: 136.05396\n",
      "[epoch 190, batch    11] loss: 138.21083\n",
      "[epoch 190, batch    12] loss: 133.24088\n",
      "[epoch 190, batch    13] loss: 142.12863\n",
      "[epoch 190, batch    14] loss: 132.29504\n",
      "[epoch 190, batch    15] loss: 129.53057\n",
      "[epoch 190, batch    16] loss: 132.52702\n",
      "[epoch 190, batch    17] loss: 125.42094\n",
      "[epoch 190, batch    18] loss: 132.80083\n",
      "[epoch 190, batch    19] loss: 145.11266\n",
      "[epoch 190, batch    20] loss: 122.51481\n",
      "[epoch 190, batch    21] loss: 139.30554\n",
      "[epoch 190, batch    22] loss: 121.37122\n",
      "[epoch 190, batch    23] loss: 140.21309\n",
      "[epoch 190, batch    24] loss: 136.15075\n",
      "[epoch 190, batch    25] loss: 125.59715\n",
      "[epoch 190, batch    26] loss: 143.85927\n",
      "[epoch 190, batch    27] loss: 143.39909\n",
      "[epoch 190, batch    28] loss: 112.91900\n",
      "[epoch 190, batch    29] loss: 130.63149\n",
      "[epoch 190, batch    30] loss: 123.11281\n",
      "[epoch 190, batch    31] loss: 156.05108\n",
      "[epoch 190, batch    32] loss: 30.87726\n",
      "[epoch 191, batch     1] loss: 122.74795\n",
      "[epoch 191, batch     2] loss: 129.06336\n",
      "[epoch 191, batch     3] loss: 129.31874\n",
      "[epoch 191, batch     4] loss: 149.32607\n",
      "[epoch 191, batch     5] loss: 137.15039\n",
      "[epoch 191, batch     6] loss: 119.08417\n",
      "[epoch 191, batch     7] loss: 127.16637\n",
      "[epoch 191, batch     8] loss: 138.81528\n",
      "[epoch 191, batch     9] loss: 129.28076\n",
      "[epoch 191, batch    10] loss: 143.19507\n",
      "[epoch 191, batch    11] loss: 149.54045\n",
      "[epoch 191, batch    12] loss: 131.39680\n",
      "[epoch 191, batch    13] loss: 152.00383\n",
      "[epoch 191, batch    14] loss: 126.55510\n",
      "[epoch 191, batch    15] loss: 127.34955\n",
      "[epoch 191, batch    16] loss: 136.76527\n",
      "[epoch 191, batch    17] loss: 142.00829\n",
      "[epoch 191, batch    18] loss: 135.42506\n",
      "[epoch 191, batch    19] loss: 145.19900\n",
      "[epoch 191, batch    20] loss: 138.70357\n",
      "[epoch 191, batch    21] loss: 123.98286\n",
      "[epoch 191, batch    22] loss: 124.09408\n",
      "[epoch 191, batch    23] loss: 123.13082\n",
      "[epoch 191, batch    24] loss: 137.42537\n",
      "[epoch 191, batch    25] loss: 120.40777\n",
      "[epoch 191, batch    26] loss: 146.49388\n",
      "[epoch 191, batch    27] loss: 135.76305\n",
      "[epoch 191, batch    28] loss: 131.54959\n",
      "[epoch 191, batch    29] loss: 139.78812\n",
      "[epoch 191, batch    30] loss: 136.08955\n",
      "[epoch 191, batch    31] loss: 131.13641\n",
      "[epoch 191, batch    32] loss: 32.81288\n",
      "[epoch 192, batch     1] loss: 122.27409\n",
      "[epoch 192, batch     2] loss: 132.72841\n",
      "[epoch 192, batch     3] loss: 128.07547\n",
      "[epoch 192, batch     4] loss: 141.10292\n",
      "[epoch 192, batch     5] loss: 133.93678\n",
      "[epoch 192, batch     6] loss: 125.32579\n",
      "[epoch 192, batch     7] loss: 117.33168\n",
      "[epoch 192, batch     8] loss: 142.36386\n",
      "[epoch 192, batch     9] loss: 137.71911\n",
      "[epoch 192, batch    10] loss: 136.88547\n",
      "[epoch 192, batch    11] loss: 130.27036\n",
      "[epoch 192, batch    12] loss: 129.65094\n",
      "[epoch 192, batch    13] loss: 120.23158\n",
      "[epoch 192, batch    14] loss: 121.05351\n",
      "[epoch 192, batch    15] loss: 146.03977\n",
      "[epoch 192, batch    16] loss: 132.03005\n",
      "[epoch 192, batch    17] loss: 145.82716\n",
      "[epoch 192, batch    18] loss: 136.33902\n",
      "[epoch 192, batch    19] loss: 134.68813\n",
      "[epoch 192, batch    20] loss: 128.65355\n",
      "[epoch 192, batch    21] loss: 129.99443\n",
      "[epoch 192, batch    22] loss: 121.66859\n",
      "[epoch 192, batch    23] loss: 133.77757\n",
      "[epoch 192, batch    24] loss: 127.17134\n",
      "[epoch 192, batch    25] loss: 127.01305\n",
      "[epoch 192, batch    26] loss: 133.39722\n",
      "[epoch 192, batch    27] loss: 130.12598\n",
      "[epoch 192, batch    28] loss: 137.90287\n",
      "[epoch 192, batch    29] loss: 147.41597\n",
      "[epoch 192, batch    30] loss: 130.09328\n",
      "[epoch 192, batch    31] loss: 123.91879\n",
      "[epoch 192, batch    32] loss: 31.53950\n",
      "[epoch 193, batch     1] loss: 133.16623\n",
      "[epoch 193, batch     2] loss: 139.10454\n",
      "[epoch 193, batch     3] loss: 141.57006\n",
      "[epoch 193, batch     4] loss: 137.65231\n",
      "[epoch 193, batch     5] loss: 133.39995\n",
      "[epoch 193, batch     6] loss: 134.55845\n",
      "[epoch 193, batch     7] loss: 136.79009\n",
      "[epoch 193, batch     8] loss: 133.93543\n",
      "[epoch 193, batch     9] loss: 140.40071\n",
      "[epoch 193, batch    10] loss: 143.01192\n",
      "[epoch 193, batch    11] loss: 138.41138\n",
      "[epoch 193, batch    12] loss: 131.48632\n",
      "[epoch 193, batch    13] loss: 129.02851\n",
      "[epoch 193, batch    14] loss: 123.83798\n",
      "[epoch 193, batch    15] loss: 135.64068\n",
      "[epoch 193, batch    16] loss: 136.21616\n",
      "[epoch 193, batch    17] loss: 122.70858\n",
      "[epoch 193, batch    18] loss: 145.61021\n",
      "[epoch 193, batch    19] loss: 128.92692\n",
      "[epoch 193, batch    20] loss: 126.61526\n",
      "[epoch 193, batch    21] loss: 139.63403\n",
      "[epoch 193, batch    22] loss: 122.80042\n",
      "[epoch 193, batch    23] loss: 116.10672\n",
      "[epoch 193, batch    24] loss: 131.52371\n",
      "[epoch 193, batch    25] loss: 140.28071\n",
      "[epoch 193, batch    26] loss: 125.42246\n",
      "[epoch 193, batch    27] loss: 127.07202\n",
      "[epoch 193, batch    28] loss: 149.57384\n",
      "[epoch 193, batch    29] loss: 136.12403\n",
      "[epoch 193, batch    30] loss: 138.86128\n",
      "[epoch 193, batch    31] loss: 135.87201\n",
      "[epoch 193, batch    32] loss: 30.07912\n",
      "[epoch 194, batch     1] loss: 133.87253\n",
      "[epoch 194, batch     2] loss: 149.80492\n",
      "[epoch 194, batch     3] loss: 122.97668\n",
      "[epoch 194, batch     4] loss: 128.86795\n",
      "[epoch 194, batch     5] loss: 124.35552\n",
      "[epoch 194, batch     6] loss: 127.92225\n",
      "[epoch 194, batch     7] loss: 132.75285\n",
      "[epoch 194, batch     8] loss: 128.24628\n",
      "[epoch 194, batch     9] loss: 138.38130\n",
      "[epoch 194, batch    10] loss: 132.96413\n",
      "[epoch 194, batch    11] loss: 156.60646\n",
      "[epoch 194, batch    12] loss: 126.89163\n",
      "[epoch 194, batch    13] loss: 131.44513\n",
      "[epoch 194, batch    14] loss: 119.99882\n",
      "[epoch 194, batch    15] loss: 136.25703\n",
      "[epoch 194, batch    16] loss: 131.09207\n",
      "[epoch 194, batch    17] loss: 138.52253\n",
      "[epoch 194, batch    18] loss: 129.90265\n",
      "[epoch 194, batch    19] loss: 139.29363\n",
      "[epoch 194, batch    20] loss: 133.70914\n",
      "[epoch 194, batch    21] loss: 147.27093\n",
      "[epoch 194, batch    22] loss: 128.21195\n",
      "[epoch 194, batch    23] loss: 139.89954\n",
      "[epoch 194, batch    24] loss: 118.07455\n",
      "[epoch 194, batch    25] loss: 141.59523\n",
      "[epoch 194, batch    26] loss: 126.44209\n",
      "[epoch 194, batch    27] loss: 117.88988\n",
      "[epoch 194, batch    28] loss: 122.66772\n",
      "[epoch 194, batch    29] loss: 132.29655\n",
      "[epoch 194, batch    30] loss: 122.81616\n",
      "[epoch 194, batch    31] loss: 114.04338\n",
      "[epoch 194, batch    32] loss: 40.37442\n",
      "[epoch 195, batch     1] loss: 122.22306\n",
      "[epoch 195, batch     2] loss: 137.77049\n",
      "[epoch 195, batch     3] loss: 121.11201\n",
      "[epoch 195, batch     4] loss: 128.77982\n",
      "[epoch 195, batch     5] loss: 133.84036\n",
      "[epoch 195, batch     6] loss: 136.52393\n",
      "[epoch 195, batch     7] loss: 132.07157\n",
      "[epoch 195, batch     8] loss: 131.15846\n",
      "[epoch 195, batch     9] loss: 153.27362\n",
      "[epoch 195, batch    10] loss: 122.16500\n",
      "[epoch 195, batch    11] loss: 129.98920\n",
      "[epoch 195, batch    12] loss: 121.04823\n",
      "[epoch 195, batch    13] loss: 148.27209\n",
      "[epoch 195, batch    14] loss: 117.25166\n",
      "[epoch 195, batch    15] loss: 138.39240\n",
      "[epoch 195, batch    16] loss: 126.24772\n",
      "[epoch 195, batch    17] loss: 138.88705\n",
      "[epoch 195, batch    18] loss: 132.07335\n",
      "[epoch 195, batch    19] loss: 117.40450\n",
      "[epoch 195, batch    20] loss: 129.36212\n",
      "[epoch 195, batch    21] loss: 132.21871\n",
      "[epoch 195, batch    22] loss: 129.74524\n",
      "[epoch 195, batch    23] loss: 121.23219\n",
      "[epoch 195, batch    24] loss: 131.89948\n",
      "[epoch 195, batch    25] loss: 137.95055\n",
      "[epoch 195, batch    26] loss: 145.05376\n",
      "[epoch 195, batch    27] loss: 136.93221\n",
      "[epoch 195, batch    28] loss: 133.70010\n",
      "[epoch 195, batch    29] loss: 127.17192\n",
      "[epoch 195, batch    30] loss: 132.24958\n",
      "[epoch 195, batch    31] loss: 136.51178\n",
      "[epoch 195, batch    32] loss: 35.05149\n",
      "[epoch 196, batch     1] loss: 122.57435\n",
      "[epoch 196, batch     2] loss: 141.25030\n",
      "[epoch 196, batch     3] loss: 144.09891\n",
      "[epoch 196, batch     4] loss: 132.72591\n",
      "[epoch 196, batch     5] loss: 112.74568\n",
      "[epoch 196, batch     6] loss: 137.65421\n",
      "[epoch 196, batch     7] loss: 118.55722\n",
      "[epoch 196, batch     8] loss: 136.34776\n",
      "[epoch 196, batch     9] loss: 137.22156\n",
      "[epoch 196, batch    10] loss: 138.26758\n",
      "[epoch 196, batch    11] loss: 137.97645\n",
      "[epoch 196, batch    12] loss: 133.78343\n",
      "[epoch 196, batch    13] loss: 139.59063\n",
      "[epoch 196, batch    14] loss: 129.38876\n",
      "[epoch 196, batch    15] loss: 128.66782\n",
      "[epoch 196, batch    16] loss: 126.71656\n",
      "[epoch 196, batch    17] loss: 148.98422\n",
      "[epoch 196, batch    18] loss: 139.87203\n",
      "[epoch 196, batch    19] loss: 134.17407\n",
      "[epoch 196, batch    20] loss: 140.90788\n",
      "[epoch 196, batch    21] loss: 131.50978\n",
      "[epoch 196, batch    22] loss: 131.74410\n",
      "[epoch 196, batch    23] loss: 125.91631\n",
      "[epoch 196, batch    24] loss: 136.06743\n",
      "[epoch 196, batch    25] loss: 131.77546\n",
      "[epoch 196, batch    26] loss: 121.86397\n",
      "[epoch 196, batch    27] loss: 123.91725\n",
      "[epoch 196, batch    28] loss: 136.84045\n",
      "[epoch 196, batch    29] loss: 134.69892\n",
      "[epoch 196, batch    30] loss: 131.92138\n",
      "[epoch 196, batch    31] loss: 129.27909\n",
      "[epoch 196, batch    32] loss: 44.30913\n",
      "[epoch 197, batch     1] loss: 123.71403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 197, batch     2] loss: 138.34514\n",
      "[epoch 197, batch     3] loss: 135.81582\n",
      "[epoch 197, batch     4] loss: 132.48626\n",
      "[epoch 197, batch     5] loss: 144.61645\n",
      "[epoch 197, batch     6] loss: 128.41163\n",
      "[epoch 197, batch     7] loss: 135.01231\n",
      "[epoch 197, batch     8] loss: 136.19355\n",
      "[epoch 197, batch     9] loss: 134.62909\n",
      "[epoch 197, batch    10] loss: 138.83020\n",
      "[epoch 197, batch    11] loss: 135.10290\n",
      "[epoch 197, batch    12] loss: 131.53045\n",
      "[epoch 197, batch    13] loss: 131.01586\n",
      "[epoch 197, batch    14] loss: 123.93751\n",
      "[epoch 197, batch    15] loss: 127.59974\n",
      "[epoch 197, batch    16] loss: 144.56737\n",
      "[epoch 197, batch    17] loss: 126.08487\n",
      "[epoch 197, batch    18] loss: 127.51753\n",
      "[epoch 197, batch    19] loss: 128.22798\n",
      "[epoch 197, batch    20] loss: 127.24195\n",
      "[epoch 197, batch    21] loss: 124.24927\n",
      "[epoch 197, batch    22] loss: 129.13037\n",
      "[epoch 197, batch    23] loss: 126.96212\n",
      "[epoch 197, batch    24] loss: 155.55239\n",
      "[epoch 197, batch    25] loss: 124.46741\n",
      "[epoch 197, batch    26] loss: 139.30852\n",
      "[epoch 197, batch    27] loss: 128.99591\n",
      "[epoch 197, batch    28] loss: 123.16360\n",
      "[epoch 197, batch    29] loss: 135.08307\n",
      "[epoch 197, batch    30] loss: 127.52542\n",
      "[epoch 197, batch    31] loss: 126.98793\n",
      "[epoch 197, batch    32] loss: 31.77398\n",
      "[epoch 198, batch     1] loss: 121.06789\n",
      "[epoch 198, batch     2] loss: 137.77310\n",
      "[epoch 198, batch     3] loss: 123.43701\n",
      "[epoch 198, batch     4] loss: 118.61811\n",
      "[epoch 198, batch     5] loss: 117.08665\n",
      "[epoch 198, batch     6] loss: 113.89807\n",
      "[epoch 198, batch     7] loss: 131.12011\n",
      "[epoch 198, batch     8] loss: 130.71369\n",
      "[epoch 198, batch     9] loss: 142.68506\n",
      "[epoch 198, batch    10] loss: 137.04484\n",
      "[epoch 198, batch    11] loss: 137.04269\n",
      "[epoch 198, batch    12] loss: 145.68257\n",
      "[epoch 198, batch    13] loss: 118.88475\n",
      "[epoch 198, batch    14] loss: 130.86202\n",
      "[epoch 198, batch    15] loss: 130.44362\n",
      "[epoch 198, batch    16] loss: 138.85833\n",
      "[epoch 198, batch    17] loss: 144.08557\n",
      "[epoch 198, batch    18] loss: 150.25467\n",
      "[epoch 198, batch    19] loss: 116.76885\n",
      "[epoch 198, batch    20] loss: 145.15448\n",
      "[epoch 198, batch    21] loss: 133.02645\n",
      "[epoch 198, batch    22] loss: 133.57603\n",
      "[epoch 198, batch    23] loss: 136.52274\n",
      "[epoch 198, batch    24] loss: 135.06745\n",
      "[epoch 198, batch    25] loss: 138.56374\n",
      "[epoch 198, batch    26] loss: 138.00570\n",
      "[epoch 198, batch    27] loss: 130.26169\n",
      "[epoch 198, batch    28] loss: 131.23698\n",
      "[epoch 198, batch    29] loss: 130.36614\n",
      "[epoch 198, batch    30] loss: 131.81569\n",
      "[epoch 198, batch    31] loss: 143.31549\n",
      "[epoch 198, batch    32] loss: 31.08102\n",
      "[epoch 199, batch     1] loss: 120.94062\n",
      "[epoch 199, batch     2] loss: 134.85984\n",
      "[epoch 199, batch     3] loss: 133.25801\n",
      "[epoch 199, batch     4] loss: 119.75557\n",
      "[epoch 199, batch     5] loss: 131.41786\n",
      "[epoch 199, batch     6] loss: 137.32455\n",
      "[epoch 199, batch     7] loss: 129.47604\n",
      "[epoch 199, batch     8] loss: 140.63586\n",
      "[epoch 199, batch     9] loss: 130.68473\n",
      "[epoch 199, batch    10] loss: 138.92335\n",
      "[epoch 199, batch    11] loss: 133.54409\n",
      "[epoch 199, batch    12] loss: 145.10279\n",
      "[epoch 199, batch    13] loss: 118.07086\n",
      "[epoch 199, batch    14] loss: 134.76156\n",
      "[epoch 199, batch    15] loss: 127.21602\n",
      "[epoch 199, batch    16] loss: 130.98837\n",
      "[epoch 199, batch    17] loss: 127.02105\n",
      "[epoch 199, batch    18] loss: 131.94147\n",
      "[epoch 199, batch    19] loss: 132.42453\n",
      "[epoch 199, batch    20] loss: 136.71821\n",
      "[epoch 199, batch    21] loss: 140.86754\n",
      "[epoch 199, batch    22] loss: 141.74912\n",
      "[epoch 199, batch    23] loss: 132.93439\n",
      "[epoch 199, batch    24] loss: 131.35904\n",
      "[epoch 199, batch    25] loss: 125.74799\n",
      "[epoch 199, batch    26] loss: 133.24255\n",
      "[epoch 199, batch    27] loss: 147.12133\n",
      "[epoch 199, batch    28] loss: 133.64558\n",
      "[epoch 199, batch    29] loss: 135.32409\n",
      "[epoch 199, batch    30] loss: 138.84708\n",
      "[epoch 199, batch    31] loss: 145.65167\n",
      "[epoch 199, batch    32] loss: 29.55754\n",
      "[epoch 200, batch     1] loss: 130.71099\n",
      "[epoch 200, batch     2] loss: 122.50807\n",
      "[epoch 200, batch     3] loss: 138.71538\n",
      "[epoch 200, batch     4] loss: 121.73775\n",
      "[epoch 200, batch     5] loss: 126.89947\n",
      "[epoch 200, batch     6] loss: 136.05681\n",
      "[epoch 200, batch     7] loss: 130.94007\n",
      "[epoch 200, batch     8] loss: 140.53654\n",
      "[epoch 200, batch     9] loss: 140.70615\n",
      "[epoch 200, batch    10] loss: 128.31139\n",
      "[epoch 200, batch    11] loss: 142.43787\n",
      "[epoch 200, batch    12] loss: 134.72615\n",
      "[epoch 200, batch    13] loss: 138.86885\n",
      "[epoch 200, batch    14] loss: 118.17940\n",
      "[epoch 200, batch    15] loss: 145.31215\n",
      "[epoch 200, batch    16] loss: 142.17125\n",
      "[epoch 200, batch    17] loss: 125.93941\n",
      "[epoch 200, batch    18] loss: 138.61675\n",
      "[epoch 200, batch    19] loss: 130.20806\n",
      "[epoch 200, batch    20] loss: 121.10487\n",
      "[epoch 200, batch    21] loss: 111.10237\n",
      "[epoch 200, batch    22] loss: 137.07985\n",
      "[epoch 200, batch    23] loss: 126.04288\n",
      "[epoch 200, batch    24] loss: 137.28479\n",
      "[epoch 200, batch    25] loss: 136.84393\n",
      "[epoch 200, batch    26] loss: 127.38672\n",
      "[epoch 200, batch    27] loss: 126.68143\n",
      "[epoch 200, batch    28] loss: 138.78929\n",
      "[epoch 200, batch    29] loss: 135.57207\n",
      "[epoch 200, batch    30] loss: 141.62398\n",
      "[epoch 200, batch    31] loss: 125.53255\n",
      "[epoch 200, batch    32] loss: 29.26356\n",
      "[epoch 201, batch     1] loss: 121.63356\n",
      "[epoch 201, batch     2] loss: 128.15588\n",
      "[epoch 201, batch     3] loss: 130.57837\n",
      "[epoch 201, batch     4] loss: 133.18446\n",
      "[epoch 201, batch     5] loss: 134.86542\n",
      "[epoch 201, batch     6] loss: 132.98245\n",
      "[epoch 201, batch     7] loss: 129.33005\n",
      "[epoch 201, batch     8] loss: 129.97032\n",
      "[epoch 201, batch     9] loss: 141.63651\n",
      "[epoch 201, batch    10] loss: 130.25825\n",
      "[epoch 201, batch    11] loss: 129.42729\n",
      "[epoch 201, batch    12] loss: 126.02684\n",
      "[epoch 201, batch    13] loss: 134.66369\n",
      "[epoch 201, batch    14] loss: 134.71875\n",
      "[epoch 201, batch    15] loss: 127.46507\n",
      "[epoch 201, batch    16] loss: 124.65108\n",
      "[epoch 201, batch    17] loss: 135.87541\n",
      "[epoch 201, batch    18] loss: 129.81246\n",
      "[epoch 201, batch    19] loss: 136.11323\n",
      "[epoch 201, batch    20] loss: 142.95377\n",
      "[epoch 201, batch    21] loss: 131.98005\n",
      "[epoch 201, batch    22] loss: 134.84734\n",
      "[epoch 201, batch    23] loss: 139.95627\n",
      "[epoch 201, batch    24] loss: 129.71570\n",
      "[epoch 201, batch    25] loss: 149.08250\n",
      "[epoch 201, batch    26] loss: 147.27078\n",
      "[epoch 201, batch    27] loss: 143.82574\n",
      "[epoch 201, batch    28] loss: 138.20457\n",
      "[epoch 201, batch    29] loss: 129.51525\n",
      "[epoch 201, batch    30] loss: 139.19108\n",
      "[epoch 201, batch    31] loss: 136.31116\n",
      "[epoch 201, batch    32] loss: 34.43327\n",
      "[epoch 202, batch     1] loss: 130.15960\n",
      "[epoch 202, batch     2] loss: 129.79380\n",
      "[epoch 202, batch     3] loss: 136.36628\n",
      "[epoch 202, batch     4] loss: 134.60474\n",
      "[epoch 202, batch     5] loss: 136.23616\n",
      "[epoch 202, batch     6] loss: 123.92646\n",
      "[epoch 202, batch     7] loss: 131.93192\n",
      "[epoch 202, batch     8] loss: 138.24376\n",
      "[epoch 202, batch     9] loss: 126.91206\n",
      "[epoch 202, batch    10] loss: 128.69199\n",
      "[epoch 202, batch    11] loss: 138.20009\n",
      "[epoch 202, batch    12] loss: 131.98325\n",
      "[epoch 202, batch    13] loss: 123.27614\n",
      "[epoch 202, batch    14] loss: 126.94288\n",
      "[epoch 202, batch    15] loss: 131.64327\n",
      "[epoch 202, batch    16] loss: 137.22470\n",
      "[epoch 202, batch    17] loss: 135.75996\n",
      "[epoch 202, batch    18] loss: 131.68896\n",
      "[epoch 202, batch    19] loss: 146.58069\n",
      "[epoch 202, batch    20] loss: 130.82365\n",
      "[epoch 202, batch    21] loss: 129.34187\n",
      "[epoch 202, batch    22] loss: 134.05044\n",
      "[epoch 202, batch    23] loss: 127.97472\n",
      "[epoch 202, batch    24] loss: 129.77845\n",
      "[epoch 202, batch    25] loss: 146.39613\n",
      "[epoch 202, batch    26] loss: 139.93299\n",
      "[epoch 202, batch    27] loss: 133.44291\n",
      "[epoch 202, batch    28] loss: 134.45305\n",
      "[epoch 202, batch    29] loss: 136.35846\n",
      "[epoch 202, batch    30] loss: 138.53230\n",
      "[epoch 202, batch    31] loss: 137.75880\n",
      "[epoch 202, batch    32] loss: 31.80163\n",
      "[epoch 203, batch     1] loss: 138.29624\n",
      "[epoch 203, batch     2] loss: 126.59244\n",
      "[epoch 203, batch     3] loss: 132.52835\n",
      "[epoch 203, batch     4] loss: 152.85115\n",
      "[epoch 203, batch     5] loss: 130.47938\n",
      "[epoch 203, batch     6] loss: 130.97397\n",
      "[epoch 203, batch     7] loss: 129.53137\n",
      "[epoch 203, batch     8] loss: 130.54479\n",
      "[epoch 203, batch     9] loss: 133.27832\n",
      "[epoch 203, batch    10] loss: 140.49314\n",
      "[epoch 203, batch    11] loss: 137.54514\n",
      "[epoch 203, batch    12] loss: 127.64798\n",
      "[epoch 203, batch    13] loss: 141.70698\n",
      "[epoch 203, batch    14] loss: 130.69288\n",
      "[epoch 203, batch    15] loss: 143.88278\n",
      "[epoch 203, batch    16] loss: 136.36004\n",
      "[epoch 203, batch    17] loss: 137.43178\n",
      "[epoch 203, batch    18] loss: 129.93961\n",
      "[epoch 203, batch    19] loss: 133.86021\n",
      "[epoch 203, batch    20] loss: 139.20447\n",
      "[epoch 203, batch    21] loss: 131.16277\n",
      "[epoch 203, batch    22] loss: 142.08014\n",
      "[epoch 203, batch    23] loss: 136.52977\n",
      "[epoch 203, batch    24] loss: 128.23931\n",
      "[epoch 203, batch    25] loss: 136.38136\n",
      "[epoch 203, batch    26] loss: 140.34659\n",
      "[epoch 203, batch    27] loss: 130.59996\n",
      "[epoch 203, batch    28] loss: 128.14156\n",
      "[epoch 203, batch    29] loss: 131.17403\n",
      "[epoch 203, batch    30] loss: 121.96563\n",
      "[epoch 203, batch    31] loss: 130.09337\n",
      "[epoch 203, batch    32] loss: 35.29972\n",
      "[epoch 204, batch     1] loss: 126.51489\n",
      "[epoch 204, batch     2] loss: 124.82608\n",
      "[epoch 204, batch     3] loss: 140.36084\n",
      "[epoch 204, batch     4] loss: 133.48358\n",
      "[epoch 204, batch     5] loss: 132.35976\n",
      "[epoch 204, batch     6] loss: 124.86466\n",
      "[epoch 204, batch     7] loss: 125.79474\n",
      "[epoch 204, batch     8] loss: 132.21091\n",
      "[epoch 204, batch     9] loss: 129.00855\n",
      "[epoch 204, batch    10] loss: 121.45184\n",
      "[epoch 204, batch    11] loss: 135.33979\n",
      "[epoch 204, batch    12] loss: 148.59257\n",
      "[epoch 204, batch    13] loss: 122.68422\n",
      "[epoch 204, batch    14] loss: 139.76322\n",
      "[epoch 204, batch    15] loss: 128.31552\n",
      "[epoch 204, batch    16] loss: 144.03346\n",
      "[epoch 204, batch    17] loss: 144.38635\n",
      "[epoch 204, batch    18] loss: 113.23725\n",
      "[epoch 204, batch    19] loss: 125.12555\n",
      "[epoch 204, batch    20] loss: 144.77857\n",
      "[epoch 204, batch    21] loss: 137.31097\n",
      "[epoch 204, batch    22] loss: 129.83056\n",
      "[epoch 204, batch    23] loss: 131.69432\n",
      "[epoch 204, batch    24] loss: 138.13970\n",
      "[epoch 204, batch    25] loss: 138.99552\n",
      "[epoch 204, batch    26] loss: 146.34793\n",
      "[epoch 204, batch    27] loss: 120.61838\n",
      "[epoch 204, batch    28] loss: 144.17316\n",
      "[epoch 204, batch    29] loss: 126.29870\n",
      "[epoch 204, batch    30] loss: 138.52678\n",
      "[epoch 204, batch    31] loss: 134.70359\n",
      "[epoch 204, batch    32] loss: 30.15847\n",
      "[epoch 205, batch     1] loss: 129.27515\n",
      "[epoch 205, batch     2] loss: 131.01705\n",
      "[epoch 205, batch     3] loss: 128.98314\n",
      "[epoch 205, batch     4] loss: 137.98141\n",
      "[epoch 205, batch     5] loss: 143.77043\n",
      "[epoch 205, batch     6] loss: 115.25891\n",
      "[epoch 205, batch     7] loss: 135.79084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 205, batch     8] loss: 130.05117\n",
      "[epoch 205, batch     9] loss: 122.60516\n",
      "[epoch 205, batch    10] loss: 131.02379\n",
      "[epoch 205, batch    11] loss: 128.42151\n",
      "[epoch 205, batch    12] loss: 135.16759\n",
      "[epoch 205, batch    13] loss: 139.76861\n",
      "[epoch 205, batch    14] loss: 141.74591\n",
      "[epoch 205, batch    15] loss: 137.07313\n",
      "[epoch 205, batch    16] loss: 130.68813\n",
      "[epoch 205, batch    17] loss: 129.95839\n",
      "[epoch 205, batch    18] loss: 129.74042\n",
      "[epoch 205, batch    19] loss: 136.99843\n",
      "[epoch 205, batch    20] loss: 127.93209\n",
      "[epoch 205, batch    21] loss: 150.35497\n",
      "[epoch 205, batch    22] loss: 145.14295\n",
      "[epoch 205, batch    23] loss: 126.86724\n",
      "[epoch 205, batch    24] loss: 128.85299\n",
      "[epoch 205, batch    25] loss: 131.77635\n",
      "[epoch 205, batch    26] loss: 127.18598\n",
      "[epoch 205, batch    27] loss: 128.43343\n",
      "[epoch 205, batch    28] loss: 135.04575\n",
      "[epoch 205, batch    29] loss: 133.57269\n",
      "[epoch 205, batch    30] loss: 144.05326\n",
      "[epoch 205, batch    31] loss: 138.12049\n",
      "[epoch 205, batch    32] loss: 35.75952\n",
      "[epoch 206, batch     1] loss: 127.67862\n",
      "[epoch 206, batch     2] loss: 130.48342\n",
      "[epoch 206, batch     3] loss: 140.98340\n",
      "[epoch 206, batch     4] loss: 148.60164\n",
      "[epoch 206, batch     5] loss: 132.28762\n",
      "[epoch 206, batch     6] loss: 129.10895\n",
      "[epoch 206, batch     7] loss: 140.06825\n",
      "[epoch 206, batch     8] loss: 123.38236\n",
      "[epoch 206, batch     9] loss: 126.43497\n",
      "[epoch 206, batch    10] loss: 131.35828\n",
      "[epoch 206, batch    11] loss: 131.95299\n",
      "[epoch 206, batch    12] loss: 114.70868\n",
      "[epoch 206, batch    13] loss: 130.77588\n",
      "[epoch 206, batch    14] loss: 147.51858\n",
      "[epoch 206, batch    15] loss: 143.05476\n",
      "[epoch 206, batch    16] loss: 142.78111\n",
      "[epoch 206, batch    17] loss: 136.05324\n",
      "[epoch 206, batch    18] loss: 139.14124\n",
      "[epoch 206, batch    19] loss: 120.07452\n",
      "[epoch 206, batch    20] loss: 127.38200\n",
      "[epoch 206, batch    21] loss: 135.00321\n",
      "[epoch 206, batch    22] loss: 124.08105\n",
      "[epoch 206, batch    23] loss: 145.99559\n",
      "[epoch 206, batch    24] loss: 132.99922\n",
      "[epoch 206, batch    25] loss: 133.08694\n",
      "[epoch 206, batch    26] loss: 135.53022\n",
      "[epoch 206, batch    27] loss: 121.05548\n",
      "[epoch 206, batch    28] loss: 144.55907\n",
      "[epoch 206, batch    29] loss: 136.94396\n",
      "[epoch 206, batch    30] loss: 126.37819\n",
      "[epoch 206, batch    31] loss: 142.16082\n",
      "[epoch 206, batch    32] loss: 30.77698\n",
      "[epoch 207, batch     1] loss: 123.49542\n",
      "[epoch 207, batch     2] loss: 139.19956\n",
      "[epoch 207, batch     3] loss: 125.24116\n",
      "[epoch 207, batch     4] loss: 132.87817\n",
      "[epoch 207, batch     5] loss: 132.75017\n",
      "[epoch 207, batch     6] loss: 133.91825\n",
      "[epoch 207, batch     7] loss: 136.51295\n",
      "[epoch 207, batch     8] loss: 149.73843\n",
      "[epoch 207, batch     9] loss: 131.33932\n",
      "[epoch 207, batch    10] loss: 128.82164\n",
      "[epoch 207, batch    11] loss: 130.98736\n",
      "[epoch 207, batch    12] loss: 125.62624\n",
      "[epoch 207, batch    13] loss: 148.06703\n",
      "[epoch 207, batch    14] loss: 136.73830\n",
      "[epoch 207, batch    15] loss: 126.95620\n",
      "[epoch 207, batch    16] loss: 130.06781\n",
      "[epoch 207, batch    17] loss: 146.71601\n",
      "[epoch 207, batch    18] loss: 136.48005\n",
      "[epoch 207, batch    19] loss: 133.66932\n",
      "[epoch 207, batch    20] loss: 129.60670\n",
      "[epoch 207, batch    21] loss: 128.25444\n",
      "[epoch 207, batch    22] loss: 122.32784\n",
      "[epoch 207, batch    23] loss: 128.04419\n",
      "[epoch 207, batch    24] loss: 126.35734\n",
      "[epoch 207, batch    25] loss: 130.43709\n",
      "[epoch 207, batch    26] loss: 140.19805\n",
      "[epoch 207, batch    27] loss: 142.61179\n",
      "[epoch 207, batch    28] loss: 131.45726\n",
      "[epoch 207, batch    29] loss: 135.99587\n",
      "[epoch 207, batch    30] loss: 126.96999\n",
      "[epoch 207, batch    31] loss: 128.94649\n",
      "[epoch 207, batch    32] loss: 33.75699\n",
      "[epoch 208, batch     1] loss: 128.26471\n",
      "[epoch 208, batch     2] loss: 129.95763\n",
      "[epoch 208, batch     3] loss: 129.56655\n",
      "[epoch 208, batch     4] loss: 133.09537\n",
      "[epoch 208, batch     5] loss: 147.26009\n",
      "[epoch 208, batch     6] loss: 158.60017\n",
      "[epoch 208, batch     7] loss: 122.52326\n",
      "[epoch 208, batch     8] loss: 133.41802\n",
      "[epoch 208, batch     9] loss: 126.76751\n",
      "[epoch 208, batch    10] loss: 130.76703\n",
      "[epoch 208, batch    11] loss: 144.27592\n",
      "[epoch 208, batch    12] loss: 138.67043\n",
      "[epoch 208, batch    13] loss: 152.05423\n",
      "[epoch 208, batch    14] loss: 140.59985\n",
      "[epoch 208, batch    15] loss: 149.80346\n",
      "[epoch 208, batch    16] loss: 131.15758\n",
      "[epoch 208, batch    17] loss: 128.06805\n",
      "[epoch 208, batch    18] loss: 141.52039\n",
      "[epoch 208, batch    19] loss: 132.94504\n",
      "[epoch 208, batch    20] loss: 128.05206\n",
      "[epoch 208, batch    21] loss: 134.78644\n",
      "[epoch 208, batch    22] loss: 127.81872\n",
      "[epoch 208, batch    23] loss: 123.08730\n",
      "[epoch 208, batch    24] loss: 126.97218\n",
      "[epoch 208, batch    25] loss: 147.37045\n",
      "[epoch 208, batch    26] loss: 136.17702\n",
      "[epoch 208, batch    27] loss: 128.87498\n",
      "[epoch 208, batch    28] loss: 130.40842\n",
      "[epoch 208, batch    29] loss: 120.07796\n",
      "[epoch 208, batch    30] loss: 140.14332\n",
      "[epoch 208, batch    31] loss: 136.74714\n",
      "[epoch 208, batch    32] loss: 32.09308\n",
      "[epoch 209, batch     1] loss: 141.39049\n",
      "[epoch 209, batch     2] loss: 139.76125\n",
      "[epoch 209, batch     3] loss: 121.24615\n",
      "[epoch 209, batch     4] loss: 125.23325\n",
      "[epoch 209, batch     5] loss: 140.90304\n",
      "[epoch 209, batch     6] loss: 136.63579\n",
      "[epoch 209, batch     7] loss: 145.08754\n",
      "[epoch 209, batch     8] loss: 135.86011\n",
      "[epoch 209, batch     9] loss: 134.81154\n",
      "[epoch 209, batch    10] loss: 142.29143\n",
      "[epoch 209, batch    11] loss: 134.58995\n",
      "[epoch 209, batch    12] loss: 130.92252\n",
      "[epoch 209, batch    13] loss: 125.44135\n",
      "[epoch 209, batch    14] loss: 147.74487\n",
      "[epoch 209, batch    15] loss: 137.22312\n",
      "[epoch 209, batch    16] loss: 133.23246\n",
      "[epoch 209, batch    17] loss: 136.65041\n",
      "[epoch 209, batch    18] loss: 121.28153\n",
      "[epoch 209, batch    19] loss: 138.12849\n",
      "[epoch 209, batch    20] loss: 126.21384\n",
      "[epoch 209, batch    21] loss: 144.68020\n",
      "[epoch 209, batch    22] loss: 130.76441\n",
      "[epoch 209, batch    23] loss: 158.04396\n",
      "[epoch 209, batch    24] loss: 146.50379\n",
      "[epoch 209, batch    25] loss: 121.51957\n",
      "[epoch 209, batch    26] loss: 131.60087\n",
      "[epoch 209, batch    27] loss: 127.67385\n",
      "[epoch 209, batch    28] loss: 124.12091\n",
      "[epoch 209, batch    29] loss: 129.44239\n",
      "[epoch 209, batch    30] loss: 118.90735\n",
      "[epoch 209, batch    31] loss: 140.99483\n",
      "[epoch 209, batch    32] loss: 32.69421\n",
      "[epoch 210, batch     1] loss: 136.39152\n",
      "[epoch 210, batch     2] loss: 134.00959\n",
      "[epoch 210, batch     3] loss: 130.76305\n",
      "[epoch 210, batch     4] loss: 130.30702\n",
      "[epoch 210, batch     5] loss: 143.14686\n",
      "[epoch 210, batch     6] loss: 133.81231\n",
      "[epoch 210, batch     7] loss: 147.22783\n",
      "[epoch 210, batch     8] loss: 141.51089\n",
      "[epoch 210, batch     9] loss: 137.62275\n",
      "[epoch 210, batch    10] loss: 147.23005\n",
      "[epoch 210, batch    11] loss: 130.58993\n",
      "[epoch 210, batch    12] loss: 132.63688\n",
      "[epoch 210, batch    13] loss: 150.94444\n",
      "[epoch 210, batch    14] loss: 138.77679\n",
      "[epoch 210, batch    15] loss: 134.37967\n",
      "[epoch 210, batch    16] loss: 128.52167\n",
      "[epoch 210, batch    17] loss: 108.26333\n",
      "[epoch 210, batch    18] loss: 137.14730\n",
      "[epoch 210, batch    19] loss: 123.68614\n",
      "[epoch 210, batch    20] loss: 131.32578\n",
      "[epoch 210, batch    21] loss: 124.89374\n",
      "[epoch 210, batch    22] loss: 145.28807\n",
      "[epoch 210, batch    23] loss: 138.39069\n",
      "[epoch 210, batch    24] loss: 137.88033\n",
      "[epoch 210, batch    25] loss: 134.99362\n",
      "[epoch 210, batch    26] loss: 147.89402\n",
      "[epoch 210, batch    27] loss: 121.50986\n",
      "[epoch 210, batch    28] loss: 134.24313\n",
      "[epoch 210, batch    29] loss: 148.84350\n",
      "[epoch 210, batch    30] loss: 120.73585\n",
      "[epoch 210, batch    31] loss: 135.22702\n",
      "[epoch 210, batch    32] loss: 30.17146\n",
      "[epoch 211, batch     1] loss: 136.78747\n",
      "[epoch 211, batch     2] loss: 137.02497\n",
      "[epoch 211, batch     3] loss: 143.82776\n",
      "[epoch 211, batch     4] loss: 135.83631\n",
      "[epoch 211, batch     5] loss: 124.40733\n",
      "[epoch 211, batch     6] loss: 125.94740\n",
      "[epoch 211, batch     7] loss: 139.30387\n",
      "[epoch 211, batch     8] loss: 129.13519\n",
      "[epoch 211, batch     9] loss: 133.58296\n",
      "[epoch 211, batch    10] loss: 122.70552\n",
      "[epoch 211, batch    11] loss: 124.82032\n",
      "[epoch 211, batch    12] loss: 129.05658\n",
      "[epoch 211, batch    13] loss: 127.78136\n",
      "[epoch 211, batch    14] loss: 140.41580\n",
      "[epoch 211, batch    15] loss: 126.23619\n",
      "[epoch 211, batch    16] loss: 127.42476\n",
      "[epoch 211, batch    17] loss: 136.20594\n",
      "[epoch 211, batch    18] loss: 137.34110\n",
      "[epoch 211, batch    19] loss: 128.89745\n",
      "[epoch 211, batch    20] loss: 139.90990\n",
      "[epoch 211, batch    21] loss: 138.40065\n",
      "[epoch 211, batch    22] loss: 153.34399\n",
      "[epoch 211, batch    23] loss: 140.77855\n",
      "[epoch 211, batch    24] loss: 121.55663\n",
      "[epoch 211, batch    25] loss: 137.14624\n",
      "[epoch 211, batch    26] loss: 121.59978\n",
      "[epoch 211, batch    27] loss: 124.68926\n",
      "[epoch 211, batch    28] loss: 126.22823\n",
      "[epoch 211, batch    29] loss: 123.73843\n",
      "[epoch 211, batch    30] loss: 148.74706\n",
      "[epoch 211, batch    31] loss: 123.32989\n",
      "[epoch 211, batch    32] loss: 37.73773\n",
      "[epoch 212, batch     1] loss: 122.81661\n",
      "[epoch 212, batch     2] loss: 127.81532\n",
      "[epoch 212, batch     3] loss: 136.14799\n",
      "[epoch 212, batch     4] loss: 130.88175\n",
      "[epoch 212, batch     5] loss: 119.53315\n",
      "[epoch 212, batch     6] loss: 126.13305\n",
      "[epoch 212, batch     7] loss: 138.39485\n",
      "[epoch 212, batch     8] loss: 121.95780\n",
      "[epoch 212, batch     9] loss: 143.80537\n",
      "[epoch 212, batch    10] loss: 138.80522\n",
      "[epoch 212, batch    11] loss: 135.97863\n",
      "[epoch 212, batch    12] loss: 139.22649\n",
      "[epoch 212, batch    13] loss: 139.42832\n",
      "[epoch 212, batch    14] loss: 127.77382\n",
      "[epoch 212, batch    15] loss: 143.16915\n",
      "[epoch 212, batch    16] loss: 133.29088\n",
      "[epoch 212, batch    17] loss: 143.99387\n",
      "[epoch 212, batch    18] loss: 119.08146\n",
      "[epoch 212, batch    19] loss: 134.90238\n",
      "[epoch 212, batch    20] loss: 131.65221\n",
      "[epoch 212, batch    21] loss: 131.75721\n",
      "[epoch 212, batch    22] loss: 130.99369\n",
      "[epoch 212, batch    23] loss: 127.01020\n",
      "[epoch 212, batch    24] loss: 151.45328\n",
      "[epoch 212, batch    25] loss: 141.74097\n",
      "[epoch 212, batch    26] loss: 125.48498\n",
      "[epoch 212, batch    27] loss: 127.62389\n",
      "[epoch 212, batch    28] loss: 142.33151\n",
      "[epoch 212, batch    29] loss: 143.04210\n",
      "[epoch 212, batch    30] loss: 127.36356\n",
      "[epoch 212, batch    31] loss: 135.25038\n",
      "[epoch 212, batch    32] loss: 26.43785\n",
      "[epoch 213, batch     1] loss: 131.35005\n",
      "[epoch 213, batch     2] loss: 124.92185\n",
      "[epoch 213, batch     3] loss: 146.90554\n",
      "[epoch 213, batch     4] loss: 124.77020\n",
      "[epoch 213, batch     5] loss: 136.38694\n",
      "[epoch 213, batch     6] loss: 134.47998\n",
      "[epoch 213, batch     7] loss: 122.37530\n",
      "[epoch 213, batch     8] loss: 127.23438\n",
      "[epoch 213, batch     9] loss: 132.93299\n",
      "[epoch 213, batch    10] loss: 137.38881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 213, batch    11] loss: 129.95991\n",
      "[epoch 213, batch    12] loss: 135.66223\n",
      "[epoch 213, batch    13] loss: 127.06547\n",
      "[epoch 213, batch    14] loss: 133.30563\n",
      "[epoch 213, batch    15] loss: 131.43452\n",
      "[epoch 213, batch    16] loss: 139.97463\n",
      "[epoch 213, batch    17] loss: 126.48365\n",
      "[epoch 213, batch    18] loss: 132.38340\n",
      "[epoch 213, batch    19] loss: 138.78943\n",
      "[epoch 213, batch    20] loss: 118.34429\n",
      "[epoch 213, batch    21] loss: 142.07231\n",
      "[epoch 213, batch    22] loss: 142.28228\n",
      "[epoch 213, batch    23] loss: 132.31815\n",
      "[epoch 213, batch    24] loss: 122.13698\n",
      "[epoch 213, batch    25] loss: 128.77191\n",
      "[epoch 213, batch    26] loss: 136.96116\n",
      "[epoch 213, batch    27] loss: 133.34584\n",
      "[epoch 213, batch    28] loss: 132.02752\n",
      "[epoch 213, batch    29] loss: 133.22947\n",
      "[epoch 213, batch    30] loss: 129.01560\n",
      "[epoch 213, batch    31] loss: 125.18186\n",
      "[epoch 213, batch    32] loss: 33.63633\n",
      "[epoch 214, batch     1] loss: 127.91557\n",
      "[epoch 214, batch     2] loss: 133.27433\n",
      "[epoch 214, batch     3] loss: 151.76068\n",
      "[epoch 214, batch     4] loss: 128.46971\n",
      "[epoch 214, batch     5] loss: 140.17109\n",
      "[epoch 214, batch     6] loss: 136.35976\n",
      "[epoch 214, batch     7] loss: 120.98987\n",
      "[epoch 214, batch     8] loss: 137.23510\n",
      "[epoch 214, batch     9] loss: 128.07803\n",
      "[epoch 214, batch    10] loss: 123.57337\n",
      "[epoch 214, batch    11] loss: 136.91136\n",
      "[epoch 214, batch    12] loss: 129.45387\n",
      "[epoch 214, batch    13] loss: 140.09064\n",
      "[epoch 214, batch    14] loss: 120.71025\n",
      "[epoch 214, batch    15] loss: 144.58254\n",
      "[epoch 214, batch    16] loss: 121.77002\n",
      "[epoch 214, batch    17] loss: 145.86942\n",
      "[epoch 214, batch    18] loss: 125.73409\n",
      "[epoch 214, batch    19] loss: 131.13107\n",
      "[epoch 214, batch    20] loss: 128.33779\n",
      "[epoch 214, batch    21] loss: 138.00153\n",
      "[epoch 214, batch    22] loss: 132.38943\n",
      "[epoch 214, batch    23] loss: 125.56498\n",
      "[epoch 214, batch    24] loss: 121.19967\n",
      "[epoch 214, batch    25] loss: 121.27674\n",
      "[epoch 214, batch    26] loss: 140.44868\n",
      "[epoch 214, batch    27] loss: 137.45025\n",
      "[epoch 214, batch    28] loss: 134.04707\n",
      "[epoch 214, batch    29] loss: 127.79843\n",
      "[epoch 214, batch    30] loss: 132.49647\n",
      "[epoch 214, batch    31] loss: 127.35039\n",
      "[epoch 214, batch    32] loss: 30.74119\n",
      "[epoch 215, batch     1] loss: 132.40598\n",
      "[epoch 215, batch     2] loss: 126.46454\n",
      "[epoch 215, batch     3] loss: 127.23366\n",
      "[epoch 215, batch     4] loss: 113.60736\n",
      "[epoch 215, batch     5] loss: 129.68927\n",
      "[epoch 215, batch     6] loss: 138.11082\n",
      "[epoch 215, batch     7] loss: 135.05011\n",
      "[epoch 215, batch     8] loss: 137.38871\n",
      "[epoch 215, batch     9] loss: 135.34247\n",
      "[epoch 215, batch    10] loss: 125.76412\n",
      "[epoch 215, batch    11] loss: 132.11302\n",
      "[epoch 215, batch    12] loss: 119.22775\n",
      "[epoch 215, batch    13] loss: 132.18320\n",
      "[epoch 215, batch    14] loss: 133.94934\n",
      "[epoch 215, batch    15] loss: 130.77169\n",
      "[epoch 215, batch    16] loss: 139.10643\n",
      "[epoch 215, batch    17] loss: 132.49459\n",
      "[epoch 215, batch    18] loss: 137.33302\n",
      "[epoch 215, batch    19] loss: 122.06078\n",
      "[epoch 215, batch    20] loss: 133.42062\n",
      "[epoch 215, batch    21] loss: 148.42806\n",
      "[epoch 215, batch    22] loss: 134.73398\n",
      "[epoch 215, batch    23] loss: 136.43915\n",
      "[epoch 215, batch    24] loss: 126.23605\n",
      "[epoch 215, batch    25] loss: 139.94585\n",
      "[epoch 215, batch    26] loss: 132.03336\n",
      "[epoch 215, batch    27] loss: 143.62750\n",
      "[epoch 215, batch    28] loss: 137.14979\n",
      "[epoch 215, batch    29] loss: 133.79599\n",
      "[epoch 215, batch    30] loss: 138.89060\n",
      "[epoch 215, batch    31] loss: 131.08657\n",
      "[epoch 215, batch    32] loss: 34.55019\n",
      "[epoch 216, batch     1] loss: 136.36533\n",
      "[epoch 216, batch     2] loss: 147.27321\n",
      "[epoch 216, batch     3] loss: 145.44117\n",
      "[epoch 216, batch     4] loss: 132.36558\n",
      "[epoch 216, batch     5] loss: 130.59033\n",
      "[epoch 216, batch     6] loss: 143.31563\n",
      "[epoch 216, batch     7] loss: 126.73336\n",
      "[epoch 216, batch     8] loss: 139.17908\n",
      "[epoch 216, batch     9] loss: 134.52093\n",
      "[epoch 216, batch    10] loss: 129.83816\n",
      "[epoch 216, batch    11] loss: 128.03473\n",
      "[epoch 216, batch    12] loss: 129.35597\n",
      "[epoch 216, batch    13] loss: 130.94115\n",
      "[epoch 216, batch    14] loss: 121.05866\n",
      "[epoch 216, batch    15] loss: 129.54636\n",
      "[epoch 216, batch    16] loss: 136.14727\n",
      "[epoch 216, batch    17] loss: 124.82149\n",
      "[epoch 216, batch    18] loss: 137.57116\n",
      "[epoch 216, batch    19] loss: 119.63030\n",
      "[epoch 216, batch    20] loss: 133.68219\n",
      "[epoch 216, batch    21] loss: 142.37356\n",
      "[epoch 216, batch    22] loss: 141.99683\n",
      "[epoch 216, batch    23] loss: 124.63022\n",
      "[epoch 216, batch    24] loss: 143.18905\n",
      "[epoch 216, batch    25] loss: 130.70101\n",
      "[epoch 216, batch    26] loss: 133.69910\n",
      "[epoch 216, batch    27] loss: 136.99242\n",
      "[epoch 216, batch    28] loss: 144.23739\n",
      "[epoch 216, batch    29] loss: 128.48553\n",
      "[epoch 216, batch    30] loss: 137.07289\n",
      "[epoch 216, batch    31] loss: 136.05272\n",
      "[epoch 216, batch    32] loss: 24.68459\n",
      "[epoch 217, batch     1] loss: 127.79544\n",
      "[epoch 217, batch     2] loss: 138.57045\n",
      "[epoch 217, batch     3] loss: 135.23941\n",
      "[epoch 217, batch     4] loss: 145.04222\n",
      "[epoch 217, batch     5] loss: 124.08184\n",
      "[epoch 217, batch     6] loss: 128.07864\n",
      "[epoch 217, batch     7] loss: 127.77490\n",
      "[epoch 217, batch     8] loss: 130.04266\n",
      "[epoch 217, batch     9] loss: 129.94372\n",
      "[epoch 217, batch    10] loss: 137.85281\n",
      "[epoch 217, batch    11] loss: 128.03413\n",
      "[epoch 217, batch    12] loss: 144.40770\n",
      "[epoch 217, batch    13] loss: 135.19892\n",
      "[epoch 217, batch    14] loss: 138.71141\n",
      "[epoch 217, batch    15] loss: 131.81278\n",
      "[epoch 217, batch    16] loss: 127.76704\n",
      "[epoch 217, batch    17] loss: 134.81017\n",
      "[epoch 217, batch    18] loss: 127.39416\n",
      "[epoch 217, batch    19] loss: 122.47794\n",
      "[epoch 217, batch    20] loss: 139.08137\n",
      "[epoch 217, batch    21] loss: 143.02734\n",
      "[epoch 217, batch    22] loss: 144.54864\n",
      "[epoch 217, batch    23] loss: 129.50779\n",
      "[epoch 217, batch    24] loss: 129.72129\n",
      "[epoch 217, batch    25] loss: 124.69026\n",
      "[epoch 217, batch    26] loss: 127.25982\n",
      "[epoch 217, batch    27] loss: 138.16354\n",
      "[epoch 217, batch    28] loss: 135.29096\n",
      "[epoch 217, batch    29] loss: 129.27729\n",
      "[epoch 217, batch    30] loss: 131.93777\n",
      "[epoch 217, batch    31] loss: 130.83329\n",
      "[epoch 217, batch    32] loss: 35.37413\n",
      "[epoch 218, batch     1] loss: 119.78832\n",
      "[epoch 218, batch     2] loss: 135.59201\n",
      "[epoch 218, batch     3] loss: 133.41896\n",
      "[epoch 218, batch     4] loss: 132.02841\n",
      "[epoch 218, batch     5] loss: 132.53694\n",
      "[epoch 218, batch     6] loss: 137.38968\n",
      "[epoch 218, batch     7] loss: 133.59869\n",
      "[epoch 218, batch     8] loss: 150.22627\n",
      "[epoch 218, batch     9] loss: 127.28460\n",
      "[epoch 218, batch    10] loss: 132.98758\n",
      "[epoch 218, batch    11] loss: 132.12035\n",
      "[epoch 218, batch    12] loss: 141.09100\n",
      "[epoch 218, batch    13] loss: 134.54108\n",
      "[epoch 218, batch    14] loss: 128.10613\n",
      "[epoch 218, batch    15] loss: 133.99901\n",
      "[epoch 218, batch    16] loss: 143.78965\n",
      "[epoch 218, batch    17] loss: 139.15927\n",
      "[epoch 218, batch    18] loss: 132.83263\n",
      "[epoch 218, batch    19] loss: 128.89875\n",
      "[epoch 218, batch    20] loss: 124.03642\n",
      "[epoch 218, batch    21] loss: 123.53698\n",
      "[epoch 218, batch    22] loss: 125.56207\n",
      "[epoch 218, batch    23] loss: 126.90304\n",
      "[epoch 218, batch    24] loss: 128.89172\n",
      "[epoch 218, batch    25] loss: 121.21107\n",
      "[epoch 218, batch    26] loss: 128.14087\n",
      "[epoch 218, batch    27] loss: 135.16937\n",
      "[epoch 218, batch    28] loss: 143.90904\n",
      "[epoch 218, batch    29] loss: 137.22761\n",
      "[epoch 218, batch    30] loss: 129.85229\n",
      "[epoch 218, batch    31] loss: 140.64707\n",
      "[epoch 218, batch    32] loss: 32.55634\n",
      "[epoch 219, batch     1] loss: 118.69589\n",
      "[epoch 219, batch     2] loss: 128.87450\n",
      "[epoch 219, batch     3] loss: 135.73826\n",
      "[epoch 219, batch     4] loss: 139.24662\n",
      "[epoch 219, batch     5] loss: 128.43614\n",
      "[epoch 219, batch     6] loss: 140.80721\n",
      "[epoch 219, batch     7] loss: 124.65960\n",
      "[epoch 219, batch     8] loss: 131.52008\n",
      "[epoch 219, batch     9] loss: 139.89226\n",
      "[epoch 219, batch    10] loss: 131.74216\n",
      "[epoch 219, batch    11] loss: 130.05206\n",
      "[epoch 219, batch    12] loss: 133.87897\n",
      "[epoch 219, batch    13] loss: 126.37419\n",
      "[epoch 219, batch    14] loss: 125.79082\n",
      "[epoch 219, batch    15] loss: 150.18047\n",
      "[epoch 219, batch    16] loss: 129.61638\n",
      "[epoch 219, batch    17] loss: 137.04889\n",
      "[epoch 219, batch    18] loss: 135.35309\n",
      "[epoch 219, batch    19] loss: 133.63161\n",
      "[epoch 219, batch    20] loss: 125.03217\n",
      "[epoch 219, batch    21] loss: 129.58475\n",
      "[epoch 219, batch    22] loss: 136.83413\n",
      "[epoch 219, batch    23] loss: 140.96838\n",
      "[epoch 219, batch    24] loss: 125.74800\n",
      "[epoch 219, batch    25] loss: 135.32522\n",
      "[epoch 219, batch    26] loss: 124.37001\n",
      "[epoch 219, batch    27] loss: 120.85042\n",
      "[epoch 219, batch    28] loss: 137.86650\n",
      "[epoch 219, batch    29] loss: 128.44204\n",
      "[epoch 219, batch    30] loss: 123.51914\n",
      "[epoch 219, batch    31] loss: 142.75724\n",
      "[epoch 219, batch    32] loss: 34.22374\n",
      "[epoch 220, batch     1] loss: 133.37514\n",
      "[epoch 220, batch     2] loss: 143.55984\n",
      "[epoch 220, batch     3] loss: 135.14076\n",
      "[epoch 220, batch     4] loss: 134.65253\n",
      "[epoch 220, batch     5] loss: 147.18095\n",
      "[epoch 220, batch     6] loss: 149.57745\n",
      "[epoch 220, batch     7] loss: 117.75199\n",
      "[epoch 220, batch     8] loss: 132.50152\n",
      "[epoch 220, batch     9] loss: 131.20072\n",
      "[epoch 220, batch    10] loss: 122.94643\n",
      "[epoch 220, batch    11] loss: 139.30680\n",
      "[epoch 220, batch    12] loss: 128.23577\n",
      "[epoch 220, batch    13] loss: 138.61319\n",
      "[epoch 220, batch    14] loss: 130.57158\n",
      "[epoch 220, batch    15] loss: 126.86750\n",
      "[epoch 220, batch    16] loss: 138.85391\n",
      "[epoch 220, batch    17] loss: 134.05544\n",
      "[epoch 220, batch    18] loss: 127.63867\n",
      "[epoch 220, batch    19] loss: 141.26758\n",
      "[epoch 220, batch    20] loss: 133.99216\n",
      "[epoch 220, batch    21] loss: 133.77754\n",
      "[epoch 220, batch    22] loss: 134.95544\n",
      "[epoch 220, batch    23] loss: 131.46447\n",
      "[epoch 220, batch    24] loss: 128.50554\n",
      "[epoch 220, batch    25] loss: 150.36459\n",
      "[epoch 220, batch    26] loss: 134.53345\n",
      "[epoch 220, batch    27] loss: 136.50204\n",
      "[epoch 220, batch    28] loss: 122.09416\n",
      "[epoch 220, batch    29] loss: 137.07951\n",
      "[epoch 220, batch    30] loss: 132.17541\n",
      "[epoch 220, batch    31] loss: 129.55865\n",
      "[epoch 220, batch    32] loss: 32.19670\n",
      "[epoch 221, batch     1] loss: 119.34947\n",
      "[epoch 221, batch     2] loss: 130.61577\n",
      "[epoch 221, batch     3] loss: 130.53621\n",
      "[epoch 221, batch     4] loss: 132.67145\n",
      "[epoch 221, batch     5] loss: 135.70814\n",
      "[epoch 221, batch     6] loss: 144.19056\n",
      "[epoch 221, batch     7] loss: 120.94194\n",
      "[epoch 221, batch     8] loss: 138.52707\n",
      "[epoch 221, batch     9] loss: 133.76388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 221, batch    10] loss: 142.91772\n",
      "[epoch 221, batch    11] loss: 130.66457\n",
      "[epoch 221, batch    12] loss: 135.22996\n",
      "[epoch 221, batch    13] loss: 140.84775\n",
      "[epoch 221, batch    14] loss: 131.96672\n",
      "[epoch 221, batch    15] loss: 130.88498\n",
      "[epoch 221, batch    16] loss: 131.22703\n",
      "[epoch 221, batch    17] loss: 136.49035\n",
      "[epoch 221, batch    18] loss: 138.58208\n",
      "[epoch 221, batch    19] loss: 145.72187\n",
      "[epoch 221, batch    20] loss: 136.90072\n",
      "[epoch 221, batch    21] loss: 127.21316\n",
      "[epoch 221, batch    22] loss: 142.02912\n",
      "[epoch 221, batch    23] loss: 134.89377\n",
      "[epoch 221, batch    24] loss: 125.13258\n",
      "[epoch 221, batch    25] loss: 123.57047\n",
      "[epoch 221, batch    26] loss: 121.12506\n",
      "[epoch 221, batch    27] loss: 131.29093\n",
      "[epoch 221, batch    28] loss: 136.80372\n",
      "[epoch 221, batch    29] loss: 126.71848\n",
      "[epoch 221, batch    30] loss: 123.28746\n",
      "[epoch 221, batch    31] loss: 140.68516\n",
      "[epoch 221, batch    32] loss: 39.08288\n",
      "[epoch 222, batch     1] loss: 118.70187\n",
      "[epoch 222, batch     2] loss: 135.17604\n",
      "[epoch 222, batch     3] loss: 128.64043\n",
      "[epoch 222, batch     4] loss: 127.14667\n",
      "[epoch 222, batch     5] loss: 137.58564\n",
      "[epoch 222, batch     6] loss: 125.78608\n",
      "[epoch 222, batch     7] loss: 140.94111\n",
      "[epoch 222, batch     8] loss: 129.63846\n",
      "[epoch 222, batch     9] loss: 127.91084\n",
      "[epoch 222, batch    10] loss: 128.41148\n",
      "[epoch 222, batch    11] loss: 124.87317\n",
      "[epoch 222, batch    12] loss: 127.73872\n",
      "[epoch 222, batch    13] loss: 147.32740\n",
      "[epoch 222, batch    14] loss: 131.41725\n",
      "[epoch 222, batch    15] loss: 130.39466\n",
      "[epoch 222, batch    16] loss: 134.51939\n",
      "[epoch 222, batch    17] loss: 134.37856\n",
      "[epoch 222, batch    18] loss: 146.56186\n",
      "[epoch 222, batch    19] loss: 133.93259\n",
      "[epoch 222, batch    20] loss: 126.57611\n",
      "[epoch 222, batch    21] loss: 134.73362\n",
      "[epoch 222, batch    22] loss: 137.94839\n",
      "[epoch 222, batch    23] loss: 130.92553\n",
      "[epoch 222, batch    24] loss: 143.53679\n",
      "[epoch 222, batch    25] loss: 134.65533\n",
      "[epoch 222, batch    26] loss: 114.52683\n",
      "[epoch 222, batch    27] loss: 133.05203\n",
      "[epoch 222, batch    28] loss: 121.63628\n",
      "[epoch 222, batch    29] loss: 129.09642\n",
      "[epoch 222, batch    30] loss: 130.85419\n",
      "[epoch 222, batch    31] loss: 125.90596\n",
      "[epoch 222, batch    32] loss: 32.71584\n",
      "[epoch 223, batch     1] loss: 131.57135\n",
      "[epoch 223, batch     2] loss: 128.55460\n",
      "[epoch 223, batch     3] loss: 133.67107\n",
      "[epoch 223, batch     4] loss: 137.19651\n",
      "[epoch 223, batch     5] loss: 134.82575\n",
      "[epoch 223, batch     6] loss: 129.00152\n",
      "[epoch 223, batch     7] loss: 134.28251\n",
      "[epoch 223, batch     8] loss: 154.99892\n",
      "[epoch 223, batch     9] loss: 133.48697\n",
      "[epoch 223, batch    10] loss: 135.62797\n",
      "[epoch 223, batch    11] loss: 126.86409\n",
      "[epoch 223, batch    12] loss: 132.01378\n",
      "[epoch 223, batch    13] loss: 139.98093\n",
      "[epoch 223, batch    14] loss: 126.70106\n",
      "[epoch 223, batch    15] loss: 136.74629\n",
      "[epoch 223, batch    16] loss: 129.62508\n",
      "[epoch 223, batch    17] loss: 133.68631\n",
      "[epoch 223, batch    18] loss: 137.94616\n",
      "[epoch 223, batch    19] loss: 133.24506\n",
      "[epoch 223, batch    20] loss: 133.71040\n",
      "[epoch 223, batch    21] loss: 131.49688\n",
      "[epoch 223, batch    22] loss: 132.01634\n",
      "[epoch 223, batch    23] loss: 132.95666\n",
      "[epoch 223, batch    24] loss: 124.31857\n",
      "[epoch 223, batch    25] loss: 144.93391\n",
      "[epoch 223, batch    26] loss: 146.13601\n",
      "[epoch 223, batch    27] loss: 133.76693\n",
      "[epoch 223, batch    28] loss: 130.33427\n",
      "[epoch 223, batch    29] loss: 127.54263\n",
      "[epoch 223, batch    30] loss: 131.11312\n",
      "[epoch 223, batch    31] loss: 135.95921\n",
      "[epoch 223, batch    32] loss: 27.53355\n",
      "[epoch 224, batch     1] loss: 138.31977\n",
      "[epoch 224, batch     2] loss: 119.92437\n",
      "[epoch 224, batch     3] loss: 134.10606\n",
      "[epoch 224, batch     4] loss: 137.50275\n",
      "[epoch 224, batch     5] loss: 132.75958\n",
      "[epoch 224, batch     6] loss: 135.11288\n",
      "[epoch 224, batch     7] loss: 133.39135\n",
      "[epoch 224, batch     8] loss: 132.99568\n",
      "[epoch 224, batch     9] loss: 134.42096\n",
      "[epoch 224, batch    10] loss: 137.43116\n",
      "[epoch 224, batch    11] loss: 136.13817\n",
      "[epoch 224, batch    12] loss: 133.24555\n",
      "[epoch 224, batch    13] loss: 131.07487\n",
      "[epoch 224, batch    14] loss: 127.90068\n",
      "[epoch 224, batch    15] loss: 133.55818\n",
      "[epoch 224, batch    16] loss: 123.76218\n",
      "[epoch 224, batch    17] loss: 127.85216\n",
      "[epoch 224, batch    18] loss: 129.21003\n",
      "[epoch 224, batch    19] loss: 143.92733\n",
      "[epoch 224, batch    20] loss: 133.12173\n",
      "[epoch 224, batch    21] loss: 129.23740\n",
      "[epoch 224, batch    22] loss: 133.25413\n",
      "[epoch 224, batch    23] loss: 127.10176\n",
      "[epoch 224, batch    24] loss: 132.51504\n",
      "[epoch 224, batch    25] loss: 132.25110\n",
      "[epoch 224, batch    26] loss: 139.52354\n",
      "[epoch 224, batch    27] loss: 130.71307\n",
      "[epoch 224, batch    28] loss: 124.65261\n",
      "[epoch 224, batch    29] loss: 134.26099\n",
      "[epoch 224, batch    30] loss: 129.11407\n",
      "[epoch 224, batch    31] loss: 122.95576\n",
      "[epoch 224, batch    32] loss: 31.48727\n",
      "[epoch 225, batch     1] loss: 131.77195\n",
      "[epoch 225, batch     2] loss: 142.83003\n",
      "[epoch 225, batch     3] loss: 134.08058\n",
      "[epoch 225, batch     4] loss: 123.16122\n",
      "[epoch 225, batch     5] loss: 133.60530\n",
      "[epoch 225, batch     6] loss: 135.33983\n",
      "[epoch 225, batch     7] loss: 130.29726\n",
      "[epoch 225, batch     8] loss: 133.58424\n",
      "[epoch 225, batch     9] loss: 140.98912\n",
      "[epoch 225, batch    10] loss: 139.73577\n",
      "[epoch 225, batch    11] loss: 138.20265\n",
      "[epoch 225, batch    12] loss: 130.51130\n",
      "[epoch 225, batch    13] loss: 124.28447\n",
      "[epoch 225, batch    14] loss: 131.11200\n",
      "[epoch 225, batch    15] loss: 128.01690\n",
      "[epoch 225, batch    16] loss: 135.06129\n",
      "[epoch 225, batch    17] loss: 120.63410\n",
      "[epoch 225, batch    18] loss: 127.24230\n",
      "[epoch 225, batch    19] loss: 132.66711\n",
      "[epoch 225, batch    20] loss: 137.18011\n",
      "[epoch 225, batch    21] loss: 149.80286\n",
      "[epoch 225, batch    22] loss: 138.13878\n",
      "[epoch 225, batch    23] loss: 118.79527\n",
      "[epoch 225, batch    24] loss: 140.55138\n",
      "[epoch 225, batch    25] loss: 131.64209\n",
      "[epoch 225, batch    26] loss: 133.99595\n",
      "[epoch 225, batch    27] loss: 121.85676\n",
      "[epoch 225, batch    28] loss: 128.34136\n",
      "[epoch 225, batch    29] loss: 123.49635\n",
      "[epoch 225, batch    30] loss: 147.24596\n",
      "[epoch 225, batch    31] loss: 137.88498\n",
      "[epoch 225, batch    32] loss: 30.62827\n",
      "[epoch 226, batch     1] loss: 135.70021\n",
      "[epoch 226, batch     2] loss: 125.82045\n",
      "[epoch 226, batch     3] loss: 130.54362\n",
      "[epoch 226, batch     4] loss: 132.51779\n",
      "[epoch 226, batch     5] loss: 133.85292\n",
      "[epoch 226, batch     6] loss: 121.86222\n",
      "[epoch 226, batch     7] loss: 131.25812\n",
      "[epoch 226, batch     8] loss: 131.74853\n",
      "[epoch 226, batch     9] loss: 132.70835\n",
      "[epoch 226, batch    10] loss: 126.42339\n",
      "[epoch 226, batch    11] loss: 129.55446\n",
      "[epoch 226, batch    12] loss: 138.80273\n",
      "[epoch 226, batch    13] loss: 137.34968\n",
      "[epoch 226, batch    14] loss: 135.29089\n",
      "[epoch 226, batch    15] loss: 138.63535\n",
      "[epoch 226, batch    16] loss: 140.66786\n",
      "[epoch 226, batch    17] loss: 123.07616\n",
      "[epoch 226, batch    18] loss: 126.72928\n",
      "[epoch 226, batch    19] loss: 137.82518\n",
      "[epoch 226, batch    20] loss: 137.33612\n",
      "[epoch 226, batch    21] loss: 136.05194\n",
      "[epoch 226, batch    22] loss: 130.08471\n",
      "[epoch 226, batch    23] loss: 133.22753\n",
      "[epoch 226, batch    24] loss: 137.09602\n",
      "[epoch 226, batch    25] loss: 131.13577\n",
      "[epoch 226, batch    26] loss: 134.08215\n",
      "[epoch 226, batch    27] loss: 132.83665\n",
      "[epoch 226, batch    28] loss: 126.44809\n",
      "[epoch 226, batch    29] loss: 136.22656\n",
      "[epoch 226, batch    30] loss: 141.94462\n",
      "[epoch 226, batch    31] loss: 125.62845\n",
      "[epoch 226, batch    32] loss: 35.80991\n",
      "[epoch 227, batch     1] loss: 127.70768\n",
      "[epoch 227, batch     2] loss: 138.25981\n",
      "[epoch 227, batch     3] loss: 133.55339\n",
      "[epoch 227, batch     4] loss: 135.16221\n",
      "[epoch 227, batch     5] loss: 137.02441\n",
      "[epoch 227, batch     6] loss: 139.32580\n",
      "[epoch 227, batch     7] loss: 132.71004\n",
      "[epoch 227, batch     8] loss: 125.12233\n",
      "[epoch 227, batch     9] loss: 134.95537\n",
      "[epoch 227, batch    10] loss: 130.49633\n",
      "[epoch 227, batch    11] loss: 131.20543\n",
      "[epoch 227, batch    12] loss: 128.50435\n",
      "[epoch 227, batch    13] loss: 128.97129\n",
      "[epoch 227, batch    14] loss: 124.97186\n",
      "[epoch 227, batch    15] loss: 133.23833\n",
      "[epoch 227, batch    16] loss: 125.22450\n",
      "[epoch 227, batch    17] loss: 132.41016\n",
      "[epoch 227, batch    18] loss: 132.70532\n",
      "[epoch 227, batch    19] loss: 140.45557\n",
      "[epoch 227, batch    20] loss: 129.25391\n",
      "[epoch 227, batch    21] loss: 143.64987\n",
      "[epoch 227, batch    22] loss: 138.65672\n",
      "[epoch 227, batch    23] loss: 123.77549\n",
      "[epoch 227, batch    24] loss: 127.34042\n",
      "[epoch 227, batch    25] loss: 138.39963\n",
      "[epoch 227, batch    26] loss: 140.85169\n",
      "[epoch 227, batch    27] loss: 151.96267\n",
      "[epoch 227, batch    28] loss: 124.34018\n",
      "[epoch 227, batch    29] loss: 134.20980\n",
      "[epoch 227, batch    30] loss: 128.60379\n",
      "[epoch 227, batch    31] loss: 137.10455\n",
      "[epoch 227, batch    32] loss: 31.47764\n",
      "[epoch 228, batch     1] loss: 132.96447\n",
      "[epoch 228, batch     2] loss: 131.19459\n",
      "[epoch 228, batch     3] loss: 128.38409\n",
      "[epoch 228, batch     4] loss: 134.84689\n",
      "[epoch 228, batch     5] loss: 132.98586\n",
      "[epoch 228, batch     6] loss: 135.73439\n",
      "[epoch 228, batch     7] loss: 124.71609\n",
      "[epoch 228, batch     8] loss: 138.66800\n",
      "[epoch 228, batch     9] loss: 127.23297\n",
      "[epoch 228, batch    10] loss: 131.82004\n",
      "[epoch 228, batch    11] loss: 126.90205\n",
      "[epoch 228, batch    12] loss: 114.87036\n",
      "[epoch 228, batch    13] loss: 123.79111\n",
      "[epoch 228, batch    14] loss: 132.15770\n",
      "[epoch 228, batch    15] loss: 132.22235\n",
      "[epoch 228, batch    16] loss: 128.85323\n",
      "[epoch 228, batch    17] loss: 143.52391\n",
      "[epoch 228, batch    18] loss: 139.31468\n",
      "[epoch 228, batch    19] loss: 142.15004\n",
      "[epoch 228, batch    20] loss: 115.37041\n",
      "[epoch 228, batch    21] loss: 145.41144\n",
      "[epoch 228, batch    22] loss: 141.55891\n",
      "[epoch 228, batch    23] loss: 137.88076\n",
      "[epoch 228, batch    24] loss: 147.90814\n",
      "[epoch 228, batch    25] loss: 131.26466\n",
      "[epoch 228, batch    26] loss: 128.06648\n",
      "[epoch 228, batch    27] loss: 116.35869\n",
      "[epoch 228, batch    28] loss: 135.03298\n",
      "[epoch 228, batch    29] loss: 131.43814\n",
      "[epoch 228, batch    30] loss: 133.01774\n",
      "[epoch 228, batch    31] loss: 130.61022\n",
      "[epoch 228, batch    32] loss: 33.33419\n",
      "[epoch 229, batch     1] loss: 134.32793\n",
      "[epoch 229, batch     2] loss: 127.49998\n",
      "[epoch 229, batch     3] loss: 125.00293\n",
      "[epoch 229, batch     4] loss: 125.18988\n",
      "[epoch 229, batch     5] loss: 140.62367\n",
      "[epoch 229, batch     6] loss: 133.27517\n",
      "[epoch 229, batch     7] loss: 131.86572\n",
      "[epoch 229, batch     8] loss: 131.41014\n",
      "[epoch 229, batch     9] loss: 131.40314\n",
      "[epoch 229, batch    10] loss: 126.07268\n",
      "[epoch 229, batch    11] loss: 136.48853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 229, batch    12] loss: 125.34029\n",
      "[epoch 229, batch    13] loss: 126.51896\n",
      "[epoch 229, batch    14] loss: 135.03842\n",
      "[epoch 229, batch    15] loss: 124.66215\n",
      "[epoch 229, batch    16] loss: 129.60767\n",
      "[epoch 229, batch    17] loss: 140.12546\n",
      "[epoch 229, batch    18] loss: 136.91946\n",
      "[epoch 229, batch    19] loss: 132.06541\n",
      "[epoch 229, batch    20] loss: 145.94215\n",
      "[epoch 229, batch    21] loss: 122.89095\n",
      "[epoch 229, batch    22] loss: 137.18626\n",
      "[epoch 229, batch    23] loss: 129.47746\n",
      "[epoch 229, batch    24] loss: 139.25873\n",
      "[epoch 229, batch    25] loss: 142.23564\n",
      "[epoch 229, batch    26] loss: 136.19400\n",
      "[epoch 229, batch    27] loss: 122.85945\n",
      "[epoch 229, batch    28] loss: 121.57665\n",
      "[epoch 229, batch    29] loss: 132.19469\n",
      "[epoch 229, batch    30] loss: 127.64780\n",
      "[epoch 229, batch    31] loss: 134.94879\n",
      "[epoch 229, batch    32] loss: 36.07342\n",
      "[epoch 230, batch     1] loss: 131.12386\n",
      "[epoch 230, batch     2] loss: 128.76417\n",
      "[epoch 230, batch     3] loss: 129.56239\n",
      "[epoch 230, batch     4] loss: 133.48264\n",
      "[epoch 230, batch     5] loss: 125.15441\n",
      "[epoch 230, batch     6] loss: 133.04947\n",
      "[epoch 230, batch     7] loss: 127.50209\n",
      "[epoch 230, batch     8] loss: 128.25335\n",
      "[epoch 230, batch     9] loss: 146.62275\n",
      "[epoch 230, batch    10] loss: 142.66115\n",
      "[epoch 230, batch    11] loss: 123.24639\n",
      "[epoch 230, batch    12] loss: 128.40174\n",
      "[epoch 230, batch    13] loss: 138.71423\n",
      "[epoch 230, batch    14] loss: 132.86029\n",
      "[epoch 230, batch    15] loss: 130.47941\n",
      "[epoch 230, batch    16] loss: 137.33166\n",
      "[epoch 230, batch    17] loss: 144.01426\n",
      "[epoch 230, batch    18] loss: 141.30814\n",
      "[epoch 230, batch    19] loss: 126.88403\n",
      "[epoch 230, batch    20] loss: 144.20299\n",
      "[epoch 230, batch    21] loss: 126.06552\n",
      "[epoch 230, batch    22] loss: 130.42863\n",
      "[epoch 230, batch    23] loss: 123.16943\n",
      "[epoch 230, batch    24] loss: 141.00469\n",
      "[epoch 230, batch    25] loss: 134.36986\n",
      "[epoch 230, batch    26] loss: 139.53517\n",
      "[epoch 230, batch    27] loss: 123.52292\n",
      "[epoch 230, batch    28] loss: 128.43663\n",
      "[epoch 230, batch    29] loss: 136.25099\n",
      "[epoch 230, batch    30] loss: 135.23147\n",
      "[epoch 230, batch    31] loss: 134.32792\n",
      "[epoch 230, batch    32] loss: 31.09445\n",
      "[epoch 231, batch     1] loss: 141.06998\n",
      "[epoch 231, batch     2] loss: 130.10459\n",
      "[epoch 231, batch     3] loss: 143.56368\n",
      "[epoch 231, batch     4] loss: 134.60941\n",
      "[epoch 231, batch     5] loss: 134.02006\n",
      "[epoch 231, batch     6] loss: 133.54672\n",
      "[epoch 231, batch     7] loss: 125.31615\n",
      "[epoch 231, batch     8] loss: 136.48533\n",
      "[epoch 231, batch     9] loss: 138.46615\n",
      "[epoch 231, batch    10] loss: 136.15631\n",
      "[epoch 231, batch    11] loss: 129.75652\n",
      "[epoch 231, batch    12] loss: 129.44243\n",
      "[epoch 231, batch    13] loss: 136.61351\n",
      "[epoch 231, batch    14] loss: 127.62486\n",
      "[epoch 231, batch    15] loss: 134.60532\n",
      "[epoch 231, batch    16] loss: 124.09058\n",
      "[epoch 231, batch    17] loss: 126.56630\n",
      "[epoch 231, batch    18] loss: 120.62256\n",
      "[epoch 231, batch    19] loss: 133.78708\n",
      "[epoch 231, batch    20] loss: 113.22549\n",
      "[epoch 231, batch    21] loss: 139.67908\n",
      "[epoch 231, batch    22] loss: 128.82161\n",
      "[epoch 231, batch    23] loss: 130.26762\n",
      "[epoch 231, batch    24] loss: 133.92090\n",
      "[epoch 231, batch    25] loss: 136.33843\n",
      "[epoch 231, batch    26] loss: 130.38924\n",
      "[epoch 231, batch    27] loss: 125.08311\n",
      "[epoch 231, batch    28] loss: 137.59423\n",
      "[epoch 231, batch    29] loss: 132.11035\n",
      "[epoch 231, batch    30] loss: 129.98515\n",
      "[epoch 231, batch    31] loss: 139.05416\n",
      "[epoch 231, batch    32] loss: 29.34795\n",
      "[epoch 232, batch     1] loss: 124.48932\n",
      "[epoch 232, batch     2] loss: 124.69843\n",
      "[epoch 232, batch     3] loss: 135.82255\n",
      "[epoch 232, batch     4] loss: 129.75389\n",
      "[epoch 232, batch     5] loss: 131.78594\n",
      "[epoch 232, batch     6] loss: 136.41625\n",
      "[epoch 232, batch     7] loss: 131.15749\n",
      "[epoch 232, batch     8] loss: 124.65238\n",
      "[epoch 232, batch     9] loss: 127.99626\n",
      "[epoch 232, batch    10] loss: 138.01643\n",
      "[epoch 232, batch    11] loss: 137.29849\n",
      "[epoch 232, batch    12] loss: 132.42898\n",
      "[epoch 232, batch    13] loss: 129.00859\n",
      "[epoch 232, batch    14] loss: 125.13599\n",
      "[epoch 232, batch    15] loss: 143.53625\n",
      "[epoch 232, batch    16] loss: 134.57812\n",
      "[epoch 232, batch    17] loss: 134.72260\n",
      "[epoch 232, batch    18] loss: 123.95386\n",
      "[epoch 232, batch    19] loss: 125.34232\n",
      "[epoch 232, batch    20] loss: 130.44062\n",
      "[epoch 232, batch    21] loss: 133.01658\n",
      "[epoch 232, batch    22] loss: 132.82840\n",
      "[epoch 232, batch    23] loss: 155.53049\n",
      "[epoch 232, batch    24] loss: 132.60527\n",
      "[epoch 232, batch    25] loss: 135.02737\n",
      "[epoch 232, batch    26] loss: 129.21954\n",
      "[epoch 232, batch    27] loss: 132.47789\n",
      "[epoch 232, batch    28] loss: 134.36997\n",
      "[epoch 232, batch    29] loss: 148.93563\n",
      "[epoch 232, batch    30] loss: 139.49366\n",
      "[epoch 232, batch    31] loss: 129.43411\n",
      "[epoch 232, batch    32] loss: 30.14078\n",
      "[epoch 233, batch     1] loss: 135.74006\n",
      "[epoch 233, batch     2] loss: 132.27010\n",
      "[epoch 233, batch     3] loss: 136.02649\n",
      "[epoch 233, batch     4] loss: 133.86373\n",
      "[epoch 233, batch     5] loss: 135.71173\n",
      "[epoch 233, batch     6] loss: 122.19312\n",
      "[epoch 233, batch     7] loss: 141.14483\n",
      "[epoch 233, batch     8] loss: 124.27001\n",
      "[epoch 233, batch     9] loss: 124.07617\n",
      "[epoch 233, batch    10] loss: 132.41482\n",
      "[epoch 233, batch    11] loss: 133.58829\n",
      "[epoch 233, batch    12] loss: 126.89682\n",
      "[epoch 233, batch    13] loss: 129.06799\n",
      "[epoch 233, batch    14] loss: 121.11715\n",
      "[epoch 233, batch    15] loss: 136.87778\n",
      "[epoch 233, batch    16] loss: 129.58278\n",
      "[epoch 233, batch    17] loss: 130.54456\n",
      "[epoch 233, batch    18] loss: 135.57661\n",
      "[epoch 233, batch    19] loss: 148.43195\n",
      "[epoch 233, batch    20] loss: 136.62385\n",
      "[epoch 233, batch    21] loss: 124.60397\n",
      "[epoch 233, batch    22] loss: 119.23911\n",
      "[epoch 233, batch    23] loss: 141.12811\n",
      "[epoch 233, batch    24] loss: 141.47792\n",
      "[epoch 233, batch    25] loss: 127.86859\n",
      "[epoch 233, batch    26] loss: 133.69267\n",
      "[epoch 233, batch    27] loss: 134.03773\n",
      "[epoch 233, batch    28] loss: 140.38218\n",
      "[epoch 233, batch    29] loss: 144.82345\n",
      "[epoch 233, batch    30] loss: 126.75987\n",
      "[epoch 233, batch    31] loss: 142.17597\n",
      "[epoch 233, batch    32] loss: 33.23314\n",
      "[epoch 234, batch     1] loss: 130.68402\n",
      "[epoch 234, batch     2] loss: 121.09537\n",
      "[epoch 234, batch     3] loss: 133.65810\n",
      "[epoch 234, batch     4] loss: 132.99904\n",
      "[epoch 234, batch     5] loss: 138.99258\n",
      "[epoch 234, batch     6] loss: 134.76923\n",
      "[epoch 234, batch     7] loss: 118.43132\n",
      "[epoch 234, batch     8] loss: 137.07975\n",
      "[epoch 234, batch     9] loss: 124.17303\n",
      "[epoch 234, batch    10] loss: 127.31330\n",
      "[epoch 234, batch    11] loss: 128.66152\n",
      "[epoch 234, batch    12] loss: 131.34289\n",
      "[epoch 234, batch    13] loss: 124.97907\n",
      "[epoch 234, batch    14] loss: 120.60793\n",
      "[epoch 234, batch    15] loss: 126.86475\n",
      "[epoch 234, batch    16] loss: 123.07464\n",
      "[epoch 234, batch    17] loss: 132.21287\n",
      "[epoch 234, batch    18] loss: 138.70055\n",
      "[epoch 234, batch    19] loss: 124.70410\n",
      "[epoch 234, batch    20] loss: 127.30164\n",
      "[epoch 234, batch    21] loss: 148.26457\n",
      "[epoch 234, batch    22] loss: 121.46333\n",
      "[epoch 234, batch    23] loss: 128.04210\n",
      "[epoch 234, batch    24] loss: 123.11088\n",
      "[epoch 234, batch    25] loss: 121.12556\n",
      "[epoch 234, batch    26] loss: 125.58578\n",
      "[epoch 234, batch    27] loss: 135.05599\n",
      "[epoch 234, batch    28] loss: 139.38612\n",
      "[epoch 234, batch    29] loss: 126.46221\n",
      "[epoch 234, batch    30] loss: 150.35200\n",
      "[epoch 234, batch    31] loss: 128.11707\n",
      "[epoch 234, batch    32] loss: 32.60764\n",
      "[epoch 235, batch     1] loss: 146.05891\n",
      "[epoch 235, batch     2] loss: 140.51788\n",
      "[epoch 235, batch     3] loss: 119.51481\n",
      "[epoch 235, batch     4] loss: 137.83207\n",
      "[epoch 235, batch     5] loss: 126.35793\n",
      "[epoch 235, batch     6] loss: 127.42343\n",
      "[epoch 235, batch     7] loss: 134.15202\n",
      "[epoch 235, batch     8] loss: 130.67819\n",
      "[epoch 235, batch     9] loss: 142.29999\n",
      "[epoch 235, batch    10] loss: 142.57184\n",
      "[epoch 235, batch    11] loss: 128.45221\n",
      "[epoch 235, batch    12] loss: 133.66196\n",
      "[epoch 235, batch    13] loss: 127.94408\n",
      "[epoch 235, batch    14] loss: 123.39215\n",
      "[epoch 235, batch    15] loss: 138.01811\n",
      "[epoch 235, batch    16] loss: 121.45214\n",
      "[epoch 235, batch    17] loss: 132.49786\n",
      "[epoch 235, batch    18] loss: 127.58440\n",
      "[epoch 235, batch    19] loss: 137.70686\n",
      "[epoch 235, batch    20] loss: 135.05431\n",
      "[epoch 235, batch    21] loss: 124.92938\n",
      "[epoch 235, batch    22] loss: 129.63292\n",
      "[epoch 235, batch    23] loss: 130.01476\n",
      "[epoch 235, batch    24] loss: 132.27181\n",
      "[epoch 235, batch    25] loss: 129.36331\n",
      "[epoch 235, batch    26] loss: 139.37373\n",
      "[epoch 235, batch    27] loss: 117.55966\n",
      "[epoch 235, batch    28] loss: 136.09948\n",
      "[epoch 235, batch    29] loss: 151.30316\n",
      "[epoch 235, batch    30] loss: 129.65644\n",
      "[epoch 235, batch    31] loss: 139.42023\n",
      "[epoch 235, batch    32] loss: 37.03275\n",
      "[epoch 236, batch     1] loss: 132.65066\n",
      "[epoch 236, batch     2] loss: 109.06876\n",
      "[epoch 236, batch     3] loss: 121.87717\n",
      "[epoch 236, batch     4] loss: 123.58466\n",
      "[epoch 236, batch     5] loss: 129.08536\n",
      "[epoch 236, batch     6] loss: 121.13182\n",
      "[epoch 236, batch     7] loss: 137.86788\n",
      "[epoch 236, batch     8] loss: 141.49159\n",
      "[epoch 236, batch     9] loss: 125.99098\n",
      "[epoch 236, batch    10] loss: 144.73312\n",
      "[epoch 236, batch    11] loss: 151.33163\n",
      "[epoch 236, batch    12] loss: 136.70775\n",
      "[epoch 236, batch    13] loss: 131.45655\n",
      "[epoch 236, batch    14] loss: 132.82826\n",
      "[epoch 236, batch    15] loss: 141.02919\n",
      "[epoch 236, batch    16] loss: 126.14146\n",
      "[epoch 236, batch    17] loss: 138.06123\n",
      "[epoch 236, batch    18] loss: 127.89162\n",
      "[epoch 236, batch    19] loss: 128.61033\n",
      "[epoch 236, batch    20] loss: 131.30204\n",
      "[epoch 236, batch    21] loss: 139.29715\n",
      "[epoch 236, batch    22] loss: 125.06532\n",
      "[epoch 236, batch    23] loss: 127.64307\n",
      "[epoch 236, batch    24] loss: 143.07293\n",
      "[epoch 236, batch    25] loss: 121.41606\n",
      "[epoch 236, batch    26] loss: 138.86833\n",
      "[epoch 236, batch    27] loss: 137.73607\n",
      "[epoch 236, batch    28] loss: 152.97252\n",
      "[epoch 236, batch    29] loss: 131.62133\n",
      "[epoch 236, batch    30] loss: 124.75587\n",
      "[epoch 236, batch    31] loss: 128.06575\n",
      "[epoch 236, batch    32] loss: 34.16305\n",
      "[epoch 237, batch     1] loss: 135.21792\n",
      "[epoch 237, batch     2] loss: 133.73196\n",
      "[epoch 237, batch     3] loss: 126.60230\n",
      "[epoch 237, batch     4] loss: 128.01166\n",
      "[epoch 237, batch     5] loss: 139.62946\n",
      "[epoch 237, batch     6] loss: 141.55138\n",
      "[epoch 237, batch     7] loss: 140.15692\n",
      "[epoch 237, batch     8] loss: 138.53754\n",
      "[epoch 237, batch     9] loss: 134.16279\n",
      "[epoch 237, batch    10] loss: 128.58960\n",
      "[epoch 237, batch    11] loss: 124.49636\n",
      "[epoch 237, batch    12] loss: 139.52394\n",
      "[epoch 237, batch    13] loss: 144.13123\n",
      "[epoch 237, batch    14] loss: 142.28905\n",
      "[epoch 237, batch    15] loss: 129.03028\n",
      "[epoch 237, batch    16] loss: 148.04109\n",
      "[epoch 237, batch    17] loss: 138.88674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 237, batch    18] loss: 137.54727\n",
      "[epoch 237, batch    19] loss: 137.76086\n",
      "[epoch 237, batch    20] loss: 129.46535\n",
      "[epoch 237, batch    21] loss: 128.46216\n",
      "[epoch 237, batch    22] loss: 131.43264\n",
      "[epoch 237, batch    23] loss: 129.95686\n",
      "[epoch 237, batch    24] loss: 127.37875\n",
      "[epoch 237, batch    25] loss: 135.44769\n",
      "[epoch 237, batch    26] loss: 126.14435\n",
      "[epoch 237, batch    27] loss: 142.08124\n",
      "[epoch 237, batch    28] loss: 138.77961\n",
      "[epoch 237, batch    29] loss: 127.90254\n",
      "[epoch 237, batch    30] loss: 125.05292\n",
      "[epoch 237, batch    31] loss: 131.47353\n",
      "[epoch 237, batch    32] loss: 38.50392\n",
      "[epoch 238, batch     1] loss: 131.76995\n",
      "[epoch 238, batch     2] loss: 136.26861\n",
      "[epoch 238, batch     3] loss: 132.19954\n",
      "[epoch 238, batch     4] loss: 137.69883\n",
      "[epoch 238, batch     5] loss: 137.23147\n",
      "[epoch 238, batch     6] loss: 124.00230\n",
      "[epoch 238, batch     7] loss: 129.01424\n",
      "[epoch 238, batch     8] loss: 140.42183\n",
      "[epoch 238, batch     9] loss: 133.90676\n",
      "[epoch 238, batch    10] loss: 135.24669\n",
      "[epoch 238, batch    11] loss: 127.33791\n",
      "[epoch 238, batch    12] loss: 143.03709\n",
      "[epoch 238, batch    13] loss: 142.17354\n",
      "[epoch 238, batch    14] loss: 130.54934\n",
      "[epoch 238, batch    15] loss: 140.59975\n",
      "[epoch 238, batch    16] loss: 131.77848\n",
      "[epoch 238, batch    17] loss: 128.07703\n",
      "[epoch 238, batch    18] loss: 141.29303\n",
      "[epoch 238, batch    19] loss: 121.45411\n",
      "[epoch 238, batch    20] loss: 131.15858\n",
      "[epoch 238, batch    21] loss: 135.48827\n",
      "[epoch 238, batch    22] loss: 132.96880\n",
      "[epoch 238, batch    23] loss: 133.57009\n",
      "[epoch 238, batch    24] loss: 126.58007\n",
      "[epoch 238, batch    25] loss: 129.24319\n",
      "[epoch 238, batch    26] loss: 121.49833\n",
      "[epoch 238, batch    27] loss: 127.54282\n",
      "[epoch 238, batch    28] loss: 135.94689\n",
      "[epoch 238, batch    29] loss: 132.60602\n",
      "[epoch 238, batch    30] loss: 127.04566\n",
      "[epoch 238, batch    31] loss: 123.10096\n",
      "[epoch 238, batch    32] loss: 32.59182\n",
      "[epoch 239, batch     1] loss: 120.00998\n",
      "[epoch 239, batch     2] loss: 127.06365\n",
      "[epoch 239, batch     3] loss: 139.09445\n",
      "[epoch 239, batch     4] loss: 114.31396\n",
      "[epoch 239, batch     5] loss: 132.85855\n",
      "[epoch 239, batch     6] loss: 130.84082\n",
      "[epoch 239, batch     7] loss: 139.22714\n",
      "[epoch 239, batch     8] loss: 118.83552\n",
      "[epoch 239, batch     9] loss: 130.68978\n",
      "[epoch 239, batch    10] loss: 139.27407\n",
      "[epoch 239, batch    11] loss: 130.98083\n",
      "[epoch 239, batch    12] loss: 126.01217\n",
      "[epoch 239, batch    13] loss: 122.97118\n",
      "[epoch 239, batch    14] loss: 137.69190\n",
      "[epoch 239, batch    15] loss: 133.98019\n",
      "[epoch 239, batch    16] loss: 136.52544\n",
      "[epoch 239, batch    17] loss: 124.09008\n",
      "[epoch 239, batch    18] loss: 119.20025\n",
      "[epoch 239, batch    19] loss: 128.25419\n",
      "[epoch 239, batch    20] loss: 133.63218\n",
      "[epoch 239, batch    21] loss: 139.74092\n",
      "[epoch 239, batch    22] loss: 130.01816\n",
      "[epoch 239, batch    23] loss: 140.13899\n",
      "[epoch 239, batch    24] loss: 132.19574\n",
      "[epoch 239, batch    25] loss: 134.37014\n",
      "[epoch 239, batch    26] loss: 130.72323\n",
      "[epoch 239, batch    27] loss: 128.58174\n",
      "[epoch 239, batch    28] loss: 137.43379\n",
      "[epoch 239, batch    29] loss: 135.22440\n",
      "[epoch 239, batch    30] loss: 135.16634\n",
      "[epoch 239, batch    31] loss: 130.56543\n",
      "[epoch 239, batch    32] loss: 29.90317\n",
      "[epoch 240, batch     1] loss: 124.37532\n",
      "[epoch 240, batch     2] loss: 147.93435\n",
      "[epoch 240, batch     3] loss: 120.86568\n",
      "[epoch 240, batch     4] loss: 123.32212\n",
      "[epoch 240, batch     5] loss: 124.05062\n",
      "[epoch 240, batch     6] loss: 123.32307\n",
      "[epoch 240, batch     7] loss: 136.13207\n",
      "[epoch 240, batch     8] loss: 142.54324\n",
      "[epoch 240, batch     9] loss: 130.12364\n",
      "[epoch 240, batch    10] loss: 133.32841\n",
      "[epoch 240, batch    11] loss: 130.04934\n",
      "[epoch 240, batch    12] loss: 136.02809\n",
      "[epoch 240, batch    13] loss: 117.67880\n",
      "[epoch 240, batch    14] loss: 123.55212\n",
      "[epoch 240, batch    15] loss: 111.84009\n",
      "[epoch 240, batch    16] loss: 127.76225\n",
      "[epoch 240, batch    17] loss: 145.76060\n",
      "[epoch 240, batch    18] loss: 124.48676\n",
      "[epoch 240, batch    19] loss: 133.16405\n",
      "[epoch 240, batch    20] loss: 136.60375\n",
      "[epoch 240, batch    21] loss: 129.43669\n",
      "[epoch 240, batch    22] loss: 128.23520\n",
      "[epoch 240, batch    23] loss: 127.87146\n",
      "[epoch 240, batch    24] loss: 148.12186\n",
      "[epoch 240, batch    25] loss: 129.96468\n",
      "[epoch 240, batch    26] loss: 137.01711\n",
      "[epoch 240, batch    27] loss: 129.44113\n",
      "[epoch 240, batch    28] loss: 123.65233\n",
      "[epoch 240, batch    29] loss: 144.43568\n",
      "[epoch 240, batch    30] loss: 124.80295\n",
      "[epoch 240, batch    31] loss: 136.62970\n",
      "[epoch 240, batch    32] loss: 30.74129\n",
      "[epoch 241, batch     1] loss: 113.74035\n",
      "[epoch 241, batch     2] loss: 135.26876\n",
      "[epoch 241, batch     3] loss: 139.74144\n",
      "[epoch 241, batch     4] loss: 135.85497\n",
      "[epoch 241, batch     5] loss: 144.25029\n",
      "[epoch 241, batch     6] loss: 131.70740\n",
      "[epoch 241, batch     7] loss: 127.38027\n",
      "[epoch 241, batch     8] loss: 121.26600\n",
      "[epoch 241, batch     9] loss: 125.20650\n",
      "[epoch 241, batch    10] loss: 123.19119\n",
      "[epoch 241, batch    11] loss: 137.37913\n",
      "[epoch 241, batch    12] loss: 129.56252\n",
      "[epoch 241, batch    13] loss: 133.70412\n",
      "[epoch 241, batch    14] loss: 144.25524\n",
      "[epoch 241, batch    15] loss: 126.36716\n",
      "[epoch 241, batch    16] loss: 122.43113\n",
      "[epoch 241, batch    17] loss: 136.06556\n",
      "[epoch 241, batch    18] loss: 138.93301\n",
      "[epoch 241, batch    19] loss: 116.75184\n",
      "[epoch 241, batch    20] loss: 129.12979\n",
      "[epoch 241, batch    21] loss: 146.30395\n",
      "[epoch 241, batch    22] loss: 145.38033\n",
      "[epoch 241, batch    23] loss: 130.42027\n",
      "[epoch 241, batch    24] loss: 118.54141\n",
      "[epoch 241, batch    25] loss: 138.68245\n",
      "[epoch 241, batch    26] loss: 120.15563\n",
      "[epoch 241, batch    27] loss: 148.95810\n",
      "[epoch 241, batch    28] loss: 120.62233\n",
      "[epoch 241, batch    29] loss: 134.42527\n",
      "[epoch 241, batch    30] loss: 134.31097\n",
      "[epoch 241, batch    31] loss: 139.11341\n",
      "[epoch 241, batch    32] loss: 30.69920\n",
      "[epoch 242, batch     1] loss: 127.16402\n",
      "[epoch 242, batch     2] loss: 128.31041\n",
      "[epoch 242, batch     3] loss: 127.37554\n",
      "[epoch 242, batch     4] loss: 133.88194\n",
      "[epoch 242, batch     5] loss: 126.86401\n",
      "[epoch 242, batch     6] loss: 123.67808\n",
      "[epoch 242, batch     7] loss: 117.65408\n",
      "[epoch 242, batch     8] loss: 119.49522\n",
      "[epoch 242, batch     9] loss: 137.50510\n",
      "[epoch 242, batch    10] loss: 120.81572\n",
      "[epoch 242, batch    11] loss: 134.26364\n",
      "[epoch 242, batch    12] loss: 124.62595\n",
      "[epoch 242, batch    13] loss: 132.00117\n",
      "[epoch 242, batch    14] loss: 131.37862\n",
      "[epoch 242, batch    15] loss: 141.29344\n",
      "[epoch 242, batch    16] loss: 121.81008\n",
      "[epoch 242, batch    17] loss: 138.56933\n",
      "[epoch 242, batch    18] loss: 124.57493\n",
      "[epoch 242, batch    19] loss: 136.52421\n",
      "[epoch 242, batch    20] loss: 138.41223\n",
      "[epoch 242, batch    21] loss: 124.69346\n",
      "[epoch 242, batch    22] loss: 139.66239\n",
      "[epoch 242, batch    23] loss: 133.07021\n",
      "[epoch 242, batch    24] loss: 131.82545\n",
      "[epoch 242, batch    25] loss: 134.30392\n",
      "[epoch 242, batch    26] loss: 142.38747\n",
      "[epoch 242, batch    27] loss: 132.65639\n",
      "[epoch 242, batch    28] loss: 132.86522\n",
      "[epoch 242, batch    29] loss: 134.40288\n",
      "[epoch 242, batch    30] loss: 129.16025\n",
      "[epoch 242, batch    31] loss: 131.99415\n",
      "[epoch 242, batch    32] loss: 34.52633\n",
      "[epoch 243, batch     1] loss: 128.81938\n",
      "[epoch 243, batch     2] loss: 126.34582\n",
      "[epoch 243, batch     3] loss: 131.26947\n",
      "[epoch 243, batch     4] loss: 143.65091\n",
      "[epoch 243, batch     5] loss: 139.04382\n",
      "[epoch 243, batch     6] loss: 133.82453\n",
      "[epoch 243, batch     7] loss: 126.62019\n",
      "[epoch 243, batch     8] loss: 133.11865\n",
      "[epoch 243, batch     9] loss: 139.43851\n",
      "[epoch 243, batch    10] loss: 134.84955\n",
      "[epoch 243, batch    11] loss: 128.92747\n",
      "[epoch 243, batch    12] loss: 138.01515\n",
      "[epoch 243, batch    13] loss: 136.63294\n",
      "[epoch 243, batch    14] loss: 126.08935\n",
      "[epoch 243, batch    15] loss: 126.46078\n",
      "[epoch 243, batch    16] loss: 127.89721\n",
      "[epoch 243, batch    17] loss: 130.75003\n",
      "[epoch 243, batch    18] loss: 123.32856\n",
      "[epoch 243, batch    19] loss: 136.73082\n",
      "[epoch 243, batch    20] loss: 137.12388\n",
      "[epoch 243, batch    21] loss: 130.64020\n",
      "[epoch 243, batch    22] loss: 131.46916\n",
      "[epoch 243, batch    23] loss: 130.08644\n",
      "[epoch 243, batch    24] loss: 134.71374\n",
      "[epoch 243, batch    25] loss: 129.74834\n",
      "[epoch 243, batch    26] loss: 123.36101\n",
      "[epoch 243, batch    27] loss: 150.08832\n",
      "[epoch 243, batch    28] loss: 129.34664\n",
      "[epoch 243, batch    29] loss: 122.03453\n",
      "[epoch 243, batch    30] loss: 149.68390\n",
      "[epoch 243, batch    31] loss: 126.38753\n",
      "[epoch 243, batch    32] loss: 34.46548\n",
      "[epoch 244, batch     1] loss: 131.34854\n",
      "[epoch 244, batch     2] loss: 128.89462\n",
      "[epoch 244, batch     3] loss: 131.60577\n",
      "[epoch 244, batch     4] loss: 139.47075\n",
      "[epoch 244, batch     5] loss: 123.63044\n",
      "[epoch 244, batch     6] loss: 133.34384\n",
      "[epoch 244, batch     7] loss: 141.87457\n",
      "[epoch 244, batch     8] loss: 139.02078\n",
      "[epoch 244, batch     9] loss: 113.62845\n",
      "[epoch 244, batch    10] loss: 128.63451\n",
      "[epoch 244, batch    11] loss: 138.74684\n",
      "[epoch 244, batch    12] loss: 138.99167\n",
      "[epoch 244, batch    13] loss: 129.82491\n",
      "[epoch 244, batch    14] loss: 145.82592\n",
      "[epoch 244, batch    15] loss: 123.12259\n",
      "[epoch 244, batch    16] loss: 121.69111\n",
      "[epoch 244, batch    17] loss: 131.21095\n",
      "[epoch 244, batch    18] loss: 133.20386\n",
      "[epoch 244, batch    19] loss: 124.79178\n",
      "[epoch 244, batch    20] loss: 120.54433\n",
      "[epoch 244, batch    21] loss: 137.26914\n",
      "[epoch 244, batch    22] loss: 127.05004\n",
      "[epoch 244, batch    23] loss: 144.64717\n",
      "[epoch 244, batch    24] loss: 141.04633\n",
      "[epoch 244, batch    25] loss: 128.36042\n",
      "[epoch 244, batch    26] loss: 147.00239\n",
      "[epoch 244, batch    27] loss: 132.03834\n",
      "[epoch 244, batch    28] loss: 126.50157\n",
      "[epoch 244, batch    29] loss: 134.83276\n",
      "[epoch 244, batch    30] loss: 139.58471\n",
      "[epoch 244, batch    31] loss: 120.28746\n",
      "[epoch 244, batch    32] loss: 28.26227\n",
      "[epoch 245, batch     1] loss: 128.01797\n",
      "[epoch 245, batch     2] loss: 127.97008\n",
      "[epoch 245, batch     3] loss: 144.31471\n",
      "[epoch 245, batch     4] loss: 143.63429\n",
      "[epoch 245, batch     5] loss: 132.00296\n",
      "[epoch 245, batch     6] loss: 124.15815\n",
      "[epoch 245, batch     7] loss: 137.22119\n",
      "[epoch 245, batch     8] loss: 134.48996\n",
      "[epoch 245, batch     9] loss: 124.52835\n",
      "[epoch 245, batch    10] loss: 122.99835\n",
      "[epoch 245, batch    11] loss: 145.01707\n",
      "[epoch 245, batch    12] loss: 131.80439\n",
      "[epoch 245, batch    13] loss: 135.29958\n",
      "[epoch 245, batch    14] loss: 139.37411\n",
      "[epoch 245, batch    15] loss: 138.74258\n",
      "[epoch 245, batch    16] loss: 131.73020\n",
      "[epoch 245, batch    17] loss: 128.65639\n",
      "[epoch 245, batch    18] loss: 126.40097\n",
      "[epoch 245, batch    19] loss: 129.53621\n",
      "[epoch 245, batch    20] loss: 148.49405\n",
      "[epoch 245, batch    21] loss: 125.04689\n",
      "[epoch 245, batch    22] loss: 142.60154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 245, batch    23] loss: 125.34483\n",
      "[epoch 245, batch    24] loss: 119.42701\n",
      "[epoch 245, batch    25] loss: 143.19748\n",
      "[epoch 245, batch    26] loss: 126.52380\n",
      "[epoch 245, batch    27] loss: 131.10193\n",
      "[epoch 245, batch    28] loss: 125.96492\n",
      "[epoch 245, batch    29] loss: 129.03563\n",
      "[epoch 245, batch    30] loss: 126.17514\n",
      "[epoch 245, batch    31] loss: 112.80561\n",
      "[epoch 245, batch    32] loss: 30.10705\n",
      "[epoch 246, batch     1] loss: 119.14793\n",
      "[epoch 246, batch     2] loss: 125.43498\n",
      "[epoch 246, batch     3] loss: 128.60261\n",
      "[epoch 246, batch     4] loss: 130.84013\n",
      "[epoch 246, batch     5] loss: 135.21583\n",
      "[epoch 246, batch     6] loss: 126.33765\n",
      "[epoch 246, batch     7] loss: 134.45024\n",
      "[epoch 246, batch     8] loss: 121.72352\n",
      "[epoch 246, batch     9] loss: 140.74645\n",
      "[epoch 246, batch    10] loss: 130.53625\n",
      "[epoch 246, batch    11] loss: 135.97047\n",
      "[epoch 246, batch    12] loss: 137.67962\n",
      "[epoch 246, batch    13] loss: 136.22563\n",
      "[epoch 246, batch    14] loss: 134.57096\n",
      "[epoch 246, batch    15] loss: 146.01781\n",
      "[epoch 246, batch    16] loss: 146.78430\n",
      "[epoch 246, batch    17] loss: 130.07743\n",
      "[epoch 246, batch    18] loss: 118.55642\n",
      "[epoch 246, batch    19] loss: 137.24103\n",
      "[epoch 246, batch    20] loss: 139.09595\n",
      "[epoch 246, batch    21] loss: 136.60741\n",
      "[epoch 246, batch    22] loss: 132.54605\n",
      "[epoch 246, batch    23] loss: 126.15740\n",
      "[epoch 246, batch    24] loss: 133.66896\n",
      "[epoch 246, batch    25] loss: 123.05017\n",
      "[epoch 246, batch    26] loss: 133.48487\n",
      "[epoch 246, batch    27] loss: 131.52566\n",
      "[epoch 246, batch    28] loss: 136.39503\n",
      "[epoch 246, batch    29] loss: 126.87524\n",
      "[epoch 246, batch    30] loss: 141.01059\n",
      "[epoch 246, batch    31] loss: 132.47137\n",
      "[epoch 246, batch    32] loss: 37.53833\n",
      "[epoch 247, batch     1] loss: 127.21780\n",
      "[epoch 247, batch     2] loss: 142.26548\n",
      "[epoch 247, batch     3] loss: 128.67243\n",
      "[epoch 247, batch     4] loss: 149.80113\n",
      "[epoch 247, batch     5] loss: 141.61965\n",
      "[epoch 247, batch     6] loss: 119.66801\n",
      "[epoch 247, batch     7] loss: 131.36075\n",
      "[epoch 247, batch     8] loss: 135.36268\n",
      "[epoch 247, batch     9] loss: 124.58716\n",
      "[epoch 247, batch    10] loss: 136.43068\n",
      "[epoch 247, batch    11] loss: 124.48446\n",
      "[epoch 247, batch    12] loss: 144.80581\n",
      "[epoch 247, batch    13] loss: 131.34103\n",
      "[epoch 247, batch    14] loss: 124.06551\n",
      "[epoch 247, batch    15] loss: 133.99465\n",
      "[epoch 247, batch    16] loss: 125.75524\n",
      "[epoch 247, batch    17] loss: 136.18740\n",
      "[epoch 247, batch    18] loss: 136.95840\n",
      "[epoch 247, batch    19] loss: 136.03934\n",
      "[epoch 247, batch    20] loss: 121.90539\n",
      "[epoch 247, batch    21] loss: 137.49828\n",
      "[epoch 247, batch    22] loss: 153.80927\n",
      "[epoch 247, batch    23] loss: 132.04122\n",
      "[epoch 247, batch    24] loss: 143.37620\n",
      "[epoch 247, batch    25] loss: 124.48292\n",
      "[epoch 247, batch    26] loss: 130.90850\n",
      "[epoch 247, batch    27] loss: 116.66375\n",
      "[epoch 247, batch    28] loss: 126.92499\n",
      "[epoch 247, batch    29] loss: 136.04078\n",
      "[epoch 247, batch    30] loss: 126.31838\n",
      "[epoch 247, batch    31] loss: 130.64841\n",
      "[epoch 247, batch    32] loss: 36.38664\n",
      "[epoch 248, batch     1] loss: 127.37971\n",
      "[epoch 248, batch     2] loss: 139.20173\n",
      "[epoch 248, batch     3] loss: 136.84605\n",
      "[epoch 248, batch     4] loss: 124.57713\n",
      "[epoch 248, batch     5] loss: 141.55365\n",
      "[epoch 248, batch     6] loss: 139.84844\n",
      "[epoch 248, batch     7] loss: 142.58224\n",
      "[epoch 248, batch     8] loss: 139.42656\n",
      "[epoch 248, batch     9] loss: 128.41478\n",
      "[epoch 248, batch    10] loss: 130.24064\n",
      "[epoch 248, batch    11] loss: 125.15391\n",
      "[epoch 248, batch    12] loss: 117.16096\n",
      "[epoch 248, batch    13] loss: 120.75883\n",
      "[epoch 248, batch    14] loss: 128.87847\n",
      "[epoch 248, batch    15] loss: 136.25622\n",
      "[epoch 248, batch    16] loss: 127.64324\n",
      "[epoch 248, batch    17] loss: 130.68462\n",
      "[epoch 248, batch    18] loss: 131.83890\n",
      "[epoch 248, batch    19] loss: 120.00546\n",
      "[epoch 248, batch    20] loss: 140.56401\n",
      "[epoch 248, batch    21] loss: 140.23828\n",
      "[epoch 248, batch    22] loss: 137.91371\n",
      "[epoch 248, batch    23] loss: 142.91269\n",
      "[epoch 248, batch    24] loss: 137.03682\n",
      "[epoch 248, batch    25] loss: 126.51115\n",
      "[epoch 248, batch    26] loss: 147.87119\n",
      "[epoch 248, batch    27] loss: 133.02282\n",
      "[epoch 248, batch    28] loss: 131.44367\n",
      "[epoch 248, batch    29] loss: 133.54794\n",
      "[epoch 248, batch    30] loss: 120.40406\n",
      "[epoch 248, batch    31] loss: 141.05256\n",
      "[epoch 248, batch    32] loss: 38.97515\n",
      "[epoch 249, batch     1] loss: 132.90331\n",
      "[epoch 249, batch     2] loss: 130.05255\n",
      "[epoch 249, batch     3] loss: 136.51539\n",
      "[epoch 249, batch     4] loss: 130.24307\n",
      "[epoch 249, batch     5] loss: 136.37531\n",
      "[epoch 249, batch     6] loss: 128.38441\n",
      "[epoch 249, batch     7] loss: 123.79564\n",
      "[epoch 249, batch     8] loss: 139.85129\n",
      "[epoch 249, batch     9] loss: 131.66162\n",
      "[epoch 249, batch    10] loss: 137.10543\n",
      "[epoch 249, batch    11] loss: 140.30839\n",
      "[epoch 249, batch    12] loss: 144.01380\n",
      "[epoch 249, batch    13] loss: 141.28372\n",
      "[epoch 249, batch    14] loss: 133.82939\n",
      "[epoch 249, batch    15] loss: 142.18586\n",
      "[epoch 249, batch    16] loss: 133.08473\n",
      "[epoch 249, batch    17] loss: 128.87652\n",
      "[epoch 249, batch    18] loss: 132.73599\n",
      "[epoch 249, batch    19] loss: 131.41775\n",
      "[epoch 249, batch    20] loss: 136.64410\n",
      "[epoch 249, batch    21] loss: 135.65937\n",
      "[epoch 249, batch    22] loss: 140.28337\n",
      "[epoch 249, batch    23] loss: 126.46590\n",
      "[epoch 249, batch    24] loss: 135.70232\n",
      "[epoch 249, batch    25] loss: 132.62882\n",
      "[epoch 249, batch    26] loss: 137.33868\n",
      "[epoch 249, batch    27] loss: 138.09873\n",
      "[epoch 249, batch    28] loss: 122.21600\n",
      "[epoch 249, batch    29] loss: 136.18517\n",
      "[epoch 249, batch    30] loss: 125.34629\n",
      "[epoch 249, batch    31] loss: 119.26392\n",
      "[epoch 249, batch    32] loss: 36.16046\n",
      "[epoch 250, batch     1] loss: 128.24680\n",
      "[epoch 250, batch     2] loss: 135.91328\n",
      "[epoch 250, batch     3] loss: 133.00431\n",
      "[epoch 250, batch     4] loss: 133.92559\n",
      "[epoch 250, batch     5] loss: 131.41357\n",
      "[epoch 250, batch     6] loss: 132.45489\n",
      "[epoch 250, batch     7] loss: 139.18620\n",
      "[epoch 250, batch     8] loss: 128.93328\n",
      "[epoch 250, batch     9] loss: 130.11493\n",
      "[epoch 250, batch    10] loss: 141.87034\n",
      "[epoch 250, batch    11] loss: 132.18235\n",
      "[epoch 250, batch    12] loss: 134.72994\n",
      "[epoch 250, batch    13] loss: 132.84317\n",
      "[epoch 250, batch    14] loss: 136.42461\n",
      "[epoch 250, batch    15] loss: 119.52826\n",
      "[epoch 250, batch    16] loss: 132.43540\n",
      "[epoch 250, batch    17] loss: 133.95699\n",
      "[epoch 250, batch    18] loss: 133.65131\n",
      "[epoch 250, batch    19] loss: 139.11780\n",
      "[epoch 250, batch    20] loss: 129.08538\n",
      "[epoch 250, batch    21] loss: 126.33093\n",
      "[epoch 250, batch    22] loss: 123.82095\n",
      "[epoch 250, batch    23] loss: 129.07393\n",
      "[epoch 250, batch    24] loss: 126.12326\n",
      "[epoch 250, batch    25] loss: 137.06158\n",
      "[epoch 250, batch    26] loss: 137.21335\n",
      "[epoch 250, batch    27] loss: 127.68205\n",
      "[epoch 250, batch    28] loss: 135.93362\n",
      "[epoch 250, batch    29] loss: 139.48536\n",
      "[epoch 250, batch    30] loss: 124.75808\n",
      "[epoch 250, batch    31] loss: 124.36451\n",
      "[epoch 250, batch    32] loss: 30.12047\n",
      "[epoch 251, batch     1] loss: 143.27604\n",
      "[epoch 251, batch     2] loss: 128.85093\n",
      "[epoch 251, batch     3] loss: 121.15510\n",
      "[epoch 251, batch     4] loss: 127.92527\n",
      "[epoch 251, batch     5] loss: 140.89742\n",
      "[epoch 251, batch     6] loss: 132.21841\n",
      "[epoch 251, batch     7] loss: 145.45161\n",
      "[epoch 251, batch     8] loss: 140.74895\n",
      "[epoch 251, batch     9] loss: 127.71816\n",
      "[epoch 251, batch    10] loss: 133.47042\n",
      "[epoch 251, batch    11] loss: 141.75605\n",
      "[epoch 251, batch    12] loss: 133.37694\n",
      "[epoch 251, batch    13] loss: 129.65534\n",
      "[epoch 251, batch    14] loss: 132.59257\n",
      "[epoch 251, batch    15] loss: 137.21832\n",
      "[epoch 251, batch    16] loss: 138.38231\n",
      "[epoch 251, batch    17] loss: 123.55009\n",
      "[epoch 251, batch    18] loss: 127.77890\n",
      "[epoch 251, batch    19] loss: 121.85428\n",
      "[epoch 251, batch    20] loss: 124.53125\n",
      "[epoch 251, batch    21] loss: 127.15755\n",
      "[epoch 251, batch    22] loss: 121.14213\n",
      "[epoch 251, batch    23] loss: 143.63040\n",
      "[epoch 251, batch    24] loss: 140.77469\n",
      "[epoch 251, batch    25] loss: 138.11976\n",
      "[epoch 251, batch    26] loss: 136.00304\n",
      "[epoch 251, batch    27] loss: 135.76188\n",
      "[epoch 251, batch    28] loss: 120.77249\n",
      "[epoch 251, batch    29] loss: 126.63817\n",
      "[epoch 251, batch    30] loss: 121.62812\n",
      "[epoch 251, batch    31] loss: 131.24228\n",
      "[epoch 251, batch    32] loss: 34.66772\n",
      "[epoch 252, batch     1] loss: 132.66453\n",
      "[epoch 252, batch     2] loss: 138.75002\n",
      "[epoch 252, batch     3] loss: 129.02235\n",
      "[epoch 252, batch     4] loss: 123.91168\n",
      "[epoch 252, batch     5] loss: 149.33134\n",
      "[epoch 252, batch     6] loss: 126.31659\n",
      "[epoch 252, batch     7] loss: 143.40796\n",
      "[epoch 252, batch     8] loss: 118.57378\n",
      "[epoch 252, batch     9] loss: 131.53265\n",
      "[epoch 252, batch    10] loss: 138.14293\n",
      "[epoch 252, batch    11] loss: 131.73245\n",
      "[epoch 252, batch    12] loss: 141.23178\n",
      "[epoch 252, batch    13] loss: 140.82017\n",
      "[epoch 252, batch    14] loss: 129.63565\n",
      "[epoch 252, batch    15] loss: 140.64421\n",
      "[epoch 252, batch    16] loss: 129.04864\n",
      "[epoch 252, batch    17] loss: 123.31917\n",
      "[epoch 252, batch    18] loss: 122.03052\n",
      "[epoch 252, batch    19] loss: 132.62362\n",
      "[epoch 252, batch    20] loss: 139.33249\n",
      "[epoch 252, batch    21] loss: 123.11266\n",
      "[epoch 252, batch    22] loss: 131.61064\n",
      "[epoch 252, batch    23] loss: 123.37072\n",
      "[epoch 252, batch    24] loss: 136.77521\n",
      "[epoch 252, batch    25] loss: 133.09973\n",
      "[epoch 252, batch    26] loss: 123.77461\n",
      "[epoch 252, batch    27] loss: 132.73075\n",
      "[epoch 252, batch    28] loss: 120.15943\n",
      "[epoch 252, batch    29] loss: 134.53355\n",
      "[epoch 252, batch    30] loss: 140.81002\n",
      "[epoch 252, batch    31] loss: 136.16635\n",
      "[epoch 252, batch    32] loss: 34.31885\n",
      "[epoch 253, batch     1] loss: 134.99714\n",
      "[epoch 253, batch     2] loss: 132.49957\n",
      "[epoch 253, batch     3] loss: 134.74347\n",
      "[epoch 253, batch     4] loss: 123.24568\n",
      "[epoch 253, batch     5] loss: 136.39223\n",
      "[epoch 253, batch     6] loss: 141.71991\n",
      "[epoch 253, batch     7] loss: 141.60184\n",
      "[epoch 253, batch     8] loss: 126.54183\n",
      "[epoch 253, batch     9] loss: 150.88747\n",
      "[epoch 253, batch    10] loss: 130.22223\n",
      "[epoch 253, batch    11] loss: 137.07085\n",
      "[epoch 253, batch    12] loss: 125.99131\n",
      "[epoch 253, batch    13] loss: 135.60440\n",
      "[epoch 253, batch    14] loss: 137.61790\n",
      "[epoch 253, batch    15] loss: 134.40077\n",
      "[epoch 253, batch    16] loss: 129.79205\n",
      "[epoch 253, batch    17] loss: 125.21855\n",
      "[epoch 253, batch    18] loss: 120.25293\n",
      "[epoch 253, batch    19] loss: 132.37686\n",
      "[epoch 253, batch    20] loss: 120.30858\n",
      "[epoch 253, batch    21] loss: 116.92309\n",
      "[epoch 253, batch    22] loss: 132.20618\n",
      "[epoch 253, batch    23] loss: 139.58789\n",
      "[epoch 253, batch    24] loss: 125.00298\n",
      "[epoch 253, batch    25] loss: 128.22085\n",
      "[epoch 253, batch    26] loss: 126.84769\n",
      "[epoch 253, batch    27] loss: 125.13144\n",
      "[epoch 253, batch    28] loss: 133.97221\n",
      "[epoch 253, batch    29] loss: 136.91653\n",
      "[epoch 253, batch    30] loss: 125.31332\n",
      "[epoch 253, batch    31] loss: 141.41962\n",
      "[epoch 253, batch    32] loss: 39.66005\n",
      "[epoch 254, batch     1] loss: 132.16592\n",
      "[epoch 254, batch     2] loss: 135.43481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 254, batch     3] loss: 134.18896\n",
      "[epoch 254, batch     4] loss: 143.15512\n",
      "[epoch 254, batch     5] loss: 136.80415\n",
      "[epoch 254, batch     6] loss: 131.25754\n",
      "[epoch 254, batch     7] loss: 135.48407\n",
      "[epoch 254, batch     8] loss: 129.00272\n",
      "[epoch 254, batch     9] loss: 132.97893\n",
      "[epoch 254, batch    10] loss: 128.32674\n",
      "[epoch 254, batch    11] loss: 124.61680\n",
      "[epoch 254, batch    12] loss: 137.24614\n",
      "[epoch 254, batch    13] loss: 119.01931\n",
      "[epoch 254, batch    14] loss: 129.25937\n",
      "[epoch 254, batch    15] loss: 129.71250\n",
      "[epoch 254, batch    16] loss: 131.35564\n",
      "[epoch 254, batch    17] loss: 133.82370\n",
      "[epoch 254, batch    18] loss: 129.57300\n",
      "[epoch 254, batch    19] loss: 124.74347\n",
      "[epoch 254, batch    20] loss: 138.00487\n",
      "[epoch 254, batch    21] loss: 142.65486\n",
      "[epoch 254, batch    22] loss: 130.60799\n",
      "[epoch 254, batch    23] loss: 147.07829\n",
      "[epoch 254, batch    24] loss: 140.30275\n",
      "[epoch 254, batch    25] loss: 141.05275\n",
      "[epoch 254, batch    26] loss: 119.75312\n",
      "[epoch 254, batch    27] loss: 138.86136\n",
      "[epoch 254, batch    28] loss: 127.96437\n",
      "[epoch 254, batch    29] loss: 131.93255\n",
      "[epoch 254, batch    30] loss: 126.13209\n",
      "[epoch 254, batch    31] loss: 130.19478\n",
      "[epoch 254, batch    32] loss: 36.30318\n",
      "[epoch 255, batch     1] loss: 125.16912\n",
      "[epoch 255, batch     2] loss: 127.63473\n",
      "[epoch 255, batch     3] loss: 143.14823\n",
      "[epoch 255, batch     4] loss: 141.89389\n",
      "[epoch 255, batch     5] loss: 123.18248\n",
      "[epoch 255, batch     6] loss: 131.40825\n",
      "[epoch 255, batch     7] loss: 136.55514\n",
      "[epoch 255, batch     8] loss: 126.17728\n",
      "[epoch 255, batch     9] loss: 137.00308\n",
      "[epoch 255, batch    10] loss: 127.48170\n",
      "[epoch 255, batch    11] loss: 131.98218\n",
      "[epoch 255, batch    12] loss: 128.26041\n",
      "[epoch 255, batch    13] loss: 125.95585\n",
      "[epoch 255, batch    14] loss: 132.59393\n",
      "[epoch 255, batch    15] loss: 135.80926\n",
      "[epoch 255, batch    16] loss: 132.89245\n",
      "[epoch 255, batch    17] loss: 138.22150\n",
      "[epoch 255, batch    18] loss: 142.61909\n",
      "[epoch 255, batch    19] loss: 140.71949\n",
      "[epoch 255, batch    20] loss: 128.48997\n",
      "[epoch 255, batch    21] loss: 140.18115\n",
      "[epoch 255, batch    22] loss: 119.54055\n",
      "[epoch 255, batch    23] loss: 126.37836\n",
      "[epoch 255, batch    24] loss: 130.30430\n",
      "[epoch 255, batch    25] loss: 134.68078\n",
      "[epoch 255, batch    26] loss: 145.67263\n",
      "[epoch 255, batch    27] loss: 128.84875\n",
      "[epoch 255, batch    28] loss: 137.01588\n",
      "[epoch 255, batch    29] loss: 129.96714\n",
      "[epoch 255, batch    30] loss: 138.17672\n",
      "[epoch 255, batch    31] loss: 123.98036\n",
      "[epoch 255, batch    32] loss: 33.71137\n",
      "[epoch 256, batch     1] loss: 138.84565\n",
      "[epoch 256, batch     2] loss: 120.23678\n",
      "[epoch 256, batch     3] loss: 139.50787\n",
      "[epoch 256, batch     4] loss: 138.04202\n",
      "[epoch 256, batch     5] loss: 131.52161\n",
      "[epoch 256, batch     6] loss: 133.39752\n",
      "[epoch 256, batch     7] loss: 132.08370\n",
      "[epoch 256, batch     8] loss: 130.31254\n",
      "[epoch 256, batch     9] loss: 135.69537\n",
      "[epoch 256, batch    10] loss: 129.20462\n",
      "[epoch 256, batch    11] loss: 140.60060\n",
      "[epoch 256, batch    12] loss: 137.30833\n",
      "[epoch 256, batch    13] loss: 138.06887\n",
      "[epoch 256, batch    14] loss: 142.22827\n",
      "[epoch 256, batch    15] loss: 120.76587\n",
      "[epoch 256, batch    16] loss: 139.06324\n",
      "[epoch 256, batch    17] loss: 123.12121\n",
      "[epoch 256, batch    18] loss: 130.07763\n",
      "[epoch 256, batch    19] loss: 134.26394\n",
      "[epoch 256, batch    20] loss: 123.83125\n",
      "[epoch 256, batch    21] loss: 137.88506\n",
      "[epoch 256, batch    22] loss: 135.08987\n",
      "[epoch 256, batch    23] loss: 124.56576\n",
      "[epoch 256, batch    24] loss: 130.91883\n",
      "[epoch 256, batch    25] loss: 111.52451\n",
      "[epoch 256, batch    26] loss: 134.60832\n",
      "[epoch 256, batch    27] loss: 128.09877\n",
      "[epoch 256, batch    28] loss: 126.17094\n",
      "[epoch 256, batch    29] loss: 138.49059\n",
      "[epoch 256, batch    30] loss: 127.82500\n",
      "[epoch 256, batch    31] loss: 125.57228\n",
      "[epoch 256, batch    32] loss: 28.87826\n",
      "[epoch 257, batch     1] loss: 123.42770\n",
      "[epoch 257, batch     2] loss: 127.57147\n",
      "[epoch 257, batch     3] loss: 137.13655\n",
      "[epoch 257, batch     4] loss: 126.50172\n",
      "[epoch 257, batch     5] loss: 128.25149\n",
      "[epoch 257, batch     6] loss: 134.58191\n",
      "[epoch 257, batch     7] loss: 134.94428\n",
      "[epoch 257, batch     8] loss: 145.92472\n",
      "[epoch 257, batch     9] loss: 133.99930\n",
      "[epoch 257, batch    10] loss: 136.11955\n",
      "[epoch 257, batch    11] loss: 135.05716\n",
      "[epoch 257, batch    12] loss: 142.13379\n",
      "[epoch 257, batch    13] loss: 130.09821\n",
      "[epoch 257, batch    14] loss: 133.85929\n",
      "[epoch 257, batch    15] loss: 129.21555\n",
      "[epoch 257, batch    16] loss: 144.87702\n",
      "[epoch 257, batch    17] loss: 137.00594\n",
      "[epoch 257, batch    18] loss: 133.37931\n",
      "[epoch 257, batch    19] loss: 125.54306\n",
      "[epoch 257, batch    20] loss: 130.24394\n",
      "[epoch 257, batch    21] loss: 121.71980\n",
      "[epoch 257, batch    22] loss: 132.94523\n",
      "[epoch 257, batch    23] loss: 126.06057\n",
      "[epoch 257, batch    24] loss: 130.42468\n",
      "[epoch 257, batch    25] loss: 136.43009\n",
      "[epoch 257, batch    26] loss: 134.37533\n",
      "[epoch 257, batch    27] loss: 125.41595\n",
      "[epoch 257, batch    28] loss: 138.32012\n",
      "[epoch 257, batch    29] loss: 138.56123\n",
      "[epoch 257, batch    30] loss: 149.19220\n",
      "[epoch 257, batch    31] loss: 132.69866\n",
      "[epoch 257, batch    32] loss: 39.64480\n",
      "[epoch 258, batch     1] loss: 134.54093\n",
      "[epoch 258, batch     2] loss: 126.76329\n",
      "[epoch 258, batch     3] loss: 141.96702\n",
      "[epoch 258, batch     4] loss: 133.88099\n",
      "[epoch 258, batch     5] loss: 126.78627\n",
      "[epoch 258, batch     6] loss: 144.31724\n",
      "[epoch 258, batch     7] loss: 135.04473\n",
      "[epoch 258, batch     8] loss: 134.17516\n",
      "[epoch 258, batch     9] loss: 128.73283\n",
      "[epoch 258, batch    10] loss: 136.89408\n",
      "[epoch 258, batch    11] loss: 137.57520\n",
      "[epoch 258, batch    12] loss: 128.44727\n",
      "[epoch 258, batch    13] loss: 126.34451\n",
      "[epoch 258, batch    14] loss: 121.48075\n",
      "[epoch 258, batch    15] loss: 127.84960\n",
      "[epoch 258, batch    16] loss: 132.99881\n",
      "[epoch 258, batch    17] loss: 124.50685\n",
      "[epoch 258, batch    18] loss: 129.46229\n",
      "[epoch 258, batch    19] loss: 132.60908\n",
      "[epoch 258, batch    20] loss: 143.26516\n",
      "[epoch 258, batch    21] loss: 129.11736\n",
      "[epoch 258, batch    22] loss: 134.12620\n",
      "[epoch 258, batch    23] loss: 126.40324\n",
      "[epoch 258, batch    24] loss: 140.46748\n",
      "[epoch 258, batch    25] loss: 131.98424\n",
      "[epoch 258, batch    26] loss: 134.27020\n",
      "[epoch 258, batch    27] loss: 128.08669\n",
      "[epoch 258, batch    28] loss: 123.04214\n",
      "[epoch 258, batch    29] loss: 134.30707\n",
      "[epoch 258, batch    30] loss: 135.45615\n",
      "[epoch 258, batch    31] loss: 122.56003\n",
      "[epoch 258, batch    32] loss: 36.46109\n",
      "[epoch 259, batch     1] loss: 138.74950\n",
      "[epoch 259, batch     2] loss: 121.77245\n",
      "[epoch 259, batch     3] loss: 133.98101\n",
      "[epoch 259, batch     4] loss: 126.03351\n",
      "[epoch 259, batch     5] loss: 126.71966\n",
      "[epoch 259, batch     6] loss: 136.97202\n",
      "[epoch 259, batch     7] loss: 125.15566\n",
      "[epoch 259, batch     8] loss: 145.72220\n",
      "[epoch 259, batch     9] loss: 135.13046\n",
      "[epoch 259, batch    10] loss: 132.94353\n",
      "[epoch 259, batch    11] loss: 126.30858\n",
      "[epoch 259, batch    12] loss: 128.27543\n",
      "[epoch 259, batch    13] loss: 134.67484\n",
      "[epoch 259, batch    14] loss: 141.59591\n",
      "[epoch 259, batch    15] loss: 138.43338\n",
      "[epoch 259, batch    16] loss: 125.62277\n",
      "[epoch 259, batch    17] loss: 135.29298\n",
      "[epoch 259, batch    18] loss: 149.31730\n",
      "[epoch 259, batch    19] loss: 132.00314\n",
      "[epoch 259, batch    20] loss: 119.59316\n",
      "[epoch 259, batch    21] loss: 126.27082\n",
      "[epoch 259, batch    22] loss: 132.98811\n",
      "[epoch 259, batch    23] loss: 132.88523\n",
      "[epoch 259, batch    24] loss: 135.53944\n",
      "[epoch 259, batch    25] loss: 140.68878\n",
      "[epoch 259, batch    26] loss: 154.73130\n",
      "[epoch 259, batch    27] loss: 144.00382\n",
      "[epoch 259, batch    28] loss: 130.79191\n",
      "[epoch 259, batch    29] loss: 132.67598\n",
      "[epoch 259, batch    30] loss: 139.04195\n",
      "[epoch 259, batch    31] loss: 132.72373\n",
      "[epoch 259, batch    32] loss: 26.75901\n",
      "[epoch 260, batch     1] loss: 136.58357\n",
      "[epoch 260, batch     2] loss: 123.42142\n",
      "[epoch 260, batch     3] loss: 133.00951\n",
      "[epoch 260, batch     4] loss: 134.83947\n",
      "[epoch 260, batch     5] loss: 145.95730\n",
      "[epoch 260, batch     6] loss: 122.62997\n",
      "[epoch 260, batch     7] loss: 123.21031\n",
      "[epoch 260, batch     8] loss: 133.12044\n",
      "[epoch 260, batch     9] loss: 122.13231\n",
      "[epoch 260, batch    10] loss: 128.76636\n",
      "[epoch 260, batch    11] loss: 132.32521\n",
      "[epoch 260, batch    12] loss: 134.15078\n",
      "[epoch 260, batch    13] loss: 129.16669\n",
      "[epoch 260, batch    14] loss: 143.57528\n",
      "[epoch 260, batch    15] loss: 131.39218\n",
      "[epoch 260, batch    16] loss: 142.46837\n",
      "[epoch 260, batch    17] loss: 126.96084\n",
      "[epoch 260, batch    18] loss: 120.09566\n",
      "[epoch 260, batch    19] loss: 131.62478\n",
      "[epoch 260, batch    20] loss: 124.30073\n",
      "[epoch 260, batch    21] loss: 135.66449\n",
      "[epoch 260, batch    22] loss: 138.32017\n",
      "[epoch 260, batch    23] loss: 130.69870\n",
      "[epoch 260, batch    24] loss: 128.28919\n",
      "[epoch 260, batch    25] loss: 131.96201\n",
      "[epoch 260, batch    26] loss: 122.53091\n",
      "[epoch 260, batch    27] loss: 113.53715\n",
      "[epoch 260, batch    28] loss: 117.53740\n",
      "[epoch 260, batch    29] loss: 135.15168\n",
      "[epoch 260, batch    30] loss: 136.09474\n",
      "[epoch 260, batch    31] loss: 123.23481\n",
      "[epoch 260, batch    32] loss: 32.11113\n",
      "[epoch 261, batch     1] loss: 152.03701\n",
      "[epoch 261, batch     2] loss: 125.97572\n",
      "[epoch 261, batch     3] loss: 145.34562\n",
      "[epoch 261, batch     4] loss: 137.20041\n",
      "[epoch 261, batch     5] loss: 147.75285\n",
      "[epoch 261, batch     6] loss: 135.69260\n",
      "[epoch 261, batch     7] loss: 137.18750\n",
      "[epoch 261, batch     8] loss: 135.89918\n",
      "[epoch 261, batch     9] loss: 133.83509\n",
      "[epoch 261, batch    10] loss: 137.05215\n",
      "[epoch 261, batch    11] loss: 131.49218\n",
      "[epoch 261, batch    12] loss: 135.51204\n",
      "[epoch 261, batch    13] loss: 134.79798\n",
      "[epoch 261, batch    14] loss: 134.13290\n",
      "[epoch 261, batch    15] loss: 133.90231\n",
      "[epoch 261, batch    16] loss: 123.96024\n",
      "[epoch 261, batch    17] loss: 137.23026\n",
      "[epoch 261, batch    18] loss: 126.24008\n",
      "[epoch 261, batch    19] loss: 146.15933\n",
      "[epoch 261, batch    20] loss: 130.09025\n",
      "[epoch 261, batch    21] loss: 130.49236\n",
      "[epoch 261, batch    22] loss: 137.93669\n",
      "[epoch 261, batch    23] loss: 128.67369\n",
      "[epoch 261, batch    24] loss: 135.19582\n",
      "[epoch 261, batch    25] loss: 128.49956\n",
      "[epoch 261, batch    26] loss: 116.94042\n",
      "[epoch 261, batch    27] loss: 126.22601\n",
      "[epoch 261, batch    28] loss: 126.88702\n",
      "[epoch 261, batch    29] loss: 133.84327\n",
      "[epoch 261, batch    30] loss: 131.46308\n",
      "[epoch 261, batch    31] loss: 124.53529\n",
      "[epoch 261, batch    32] loss: 30.22647\n",
      "[epoch 262, batch     1] loss: 143.49593\n",
      "[epoch 262, batch     2] loss: 133.29914\n",
      "[epoch 262, batch     3] loss: 142.56098\n",
      "[epoch 262, batch     4] loss: 132.66297\n",
      "[epoch 262, batch     5] loss: 129.94184\n",
      "[epoch 262, batch     6] loss: 123.17221\n",
      "[epoch 262, batch     7] loss: 126.72940\n",
      "[epoch 262, batch     8] loss: 129.64868\n",
      "[epoch 262, batch     9] loss: 132.19101\n",
      "[epoch 262, batch    10] loss: 132.91459\n",
      "[epoch 262, batch    11] loss: 136.21867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 262, batch    12] loss: 121.10134\n",
      "[epoch 262, batch    13] loss: 133.35354\n",
      "[epoch 262, batch    14] loss: 132.21052\n",
      "[epoch 262, batch    15] loss: 128.24093\n",
      "[epoch 262, batch    16] loss: 130.89532\n",
      "[epoch 262, batch    17] loss: 126.83705\n",
      "[epoch 262, batch    18] loss: 123.19619\n",
      "[epoch 262, batch    19] loss: 124.68143\n",
      "[epoch 262, batch    20] loss: 141.99459\n",
      "[epoch 262, batch    21] loss: 134.02702\n",
      "[epoch 262, batch    22] loss: 137.39517\n",
      "[epoch 262, batch    23] loss: 129.02473\n",
      "[epoch 262, batch    24] loss: 123.70990\n",
      "[epoch 262, batch    25] loss: 130.17032\n",
      "[epoch 262, batch    26] loss: 157.53657\n",
      "[epoch 262, batch    27] loss: 135.02151\n",
      "[epoch 262, batch    28] loss: 129.56416\n",
      "[epoch 262, batch    29] loss: 125.95939\n",
      "[epoch 262, batch    30] loss: 140.67412\n",
      "[epoch 262, batch    31] loss: 131.89693\n",
      "[epoch 262, batch    32] loss: 25.11197\n",
      "[epoch 263, batch     1] loss: 138.22881\n",
      "[epoch 263, batch     2] loss: 130.60406\n",
      "[epoch 263, batch     3] loss: 128.84009\n",
      "[epoch 263, batch     4] loss: 139.96212\n",
      "[epoch 263, batch     5] loss: 131.75454\n",
      "[epoch 263, batch     6] loss: 128.77343\n",
      "[epoch 263, batch     7] loss: 145.89149\n",
      "[epoch 263, batch     8] loss: 130.11506\n",
      "[epoch 263, batch     9] loss: 139.61335\n",
      "[epoch 263, batch    10] loss: 134.94542\n",
      "[epoch 263, batch    11] loss: 141.75958\n",
      "[epoch 263, batch    12] loss: 124.73377\n",
      "[epoch 263, batch    13] loss: 125.45989\n",
      "[epoch 263, batch    14] loss: 127.57733\n",
      "[epoch 263, batch    15] loss: 126.22439\n",
      "[epoch 263, batch    16] loss: 127.11271\n",
      "[epoch 263, batch    17] loss: 128.47692\n",
      "[epoch 263, batch    18] loss: 132.17770\n",
      "[epoch 263, batch    19] loss: 133.86045\n",
      "[epoch 263, batch    20] loss: 142.60298\n",
      "[epoch 263, batch    21] loss: 139.15302\n",
      "[epoch 263, batch    22] loss: 139.90995\n",
      "[epoch 263, batch    23] loss: 125.23340\n",
      "[epoch 263, batch    24] loss: 119.47268\n",
      "[epoch 263, batch    25] loss: 121.50855\n",
      "[epoch 263, batch    26] loss: 128.57492\n",
      "[epoch 263, batch    27] loss: 140.87428\n",
      "[epoch 263, batch    28] loss: 118.38663\n",
      "[epoch 263, batch    29] loss: 118.11650\n",
      "[epoch 263, batch    30] loss: 130.41452\n",
      "[epoch 263, batch    31] loss: 139.61872\n",
      "[epoch 263, batch    32] loss: 31.64614\n",
      "[epoch 264, batch     1] loss: 126.42176\n",
      "[epoch 264, batch     2] loss: 124.12141\n",
      "[epoch 264, batch     3] loss: 150.13749\n",
      "[epoch 264, batch     4] loss: 131.70118\n",
      "[epoch 264, batch     5] loss: 133.95092\n",
      "[epoch 264, batch     6] loss: 126.85076\n",
      "[epoch 264, batch     7] loss: 126.33619\n",
      "[epoch 264, batch     8] loss: 133.89014\n",
      "[epoch 264, batch     9] loss: 142.47966\n",
      "[epoch 264, batch    10] loss: 121.63315\n",
      "[epoch 264, batch    11] loss: 141.19172\n",
      "[epoch 264, batch    12] loss: 128.67541\n",
      "[epoch 264, batch    13] loss: 145.53050\n",
      "[epoch 264, batch    14] loss: 138.45701\n",
      "[epoch 264, batch    15] loss: 141.62377\n",
      "[epoch 264, batch    16] loss: 131.09662\n",
      "[epoch 264, batch    17] loss: 129.27373\n",
      "[epoch 264, batch    18] loss: 131.15520\n",
      "[epoch 264, batch    19] loss: 137.03394\n",
      "[epoch 264, batch    20] loss: 134.09761\n",
      "[epoch 264, batch    21] loss: 120.22726\n",
      "[epoch 264, batch    22] loss: 122.25067\n",
      "[epoch 264, batch    23] loss: 133.29295\n",
      "[epoch 264, batch    24] loss: 133.07812\n",
      "[epoch 264, batch    25] loss: 126.20362\n",
      "[epoch 264, batch    26] loss: 142.10965\n",
      "[epoch 264, batch    27] loss: 128.64834\n",
      "[epoch 264, batch    28] loss: 118.54099\n",
      "[epoch 264, batch    29] loss: 132.78232\n",
      "[epoch 264, batch    30] loss: 147.78516\n",
      "[epoch 264, batch    31] loss: 122.06800\n",
      "[epoch 264, batch    32] loss: 31.34410\n",
      "[epoch 265, batch     1] loss: 130.13005\n",
      "[epoch 265, batch     2] loss: 129.85885\n",
      "[epoch 265, batch     3] loss: 131.40766\n",
      "[epoch 265, batch     4] loss: 139.65527\n",
      "[epoch 265, batch     5] loss: 120.42186\n",
      "[epoch 265, batch     6] loss: 135.70344\n",
      "[epoch 265, batch     7] loss: 143.33245\n",
      "[epoch 265, batch     8] loss: 137.81966\n",
      "[epoch 265, batch     9] loss: 142.05623\n",
      "[epoch 265, batch    10] loss: 132.16124\n",
      "[epoch 265, batch    11] loss: 123.65055\n",
      "[epoch 265, batch    12] loss: 142.91232\n",
      "[epoch 265, batch    13] loss: 132.93509\n",
      "[epoch 265, batch    14] loss: 140.25897\n",
      "[epoch 265, batch    15] loss: 121.84524\n",
      "[epoch 265, batch    16] loss: 137.28247\n",
      "[epoch 265, batch    17] loss: 135.80888\n",
      "[epoch 265, batch    18] loss: 134.79019\n",
      "[epoch 265, batch    19] loss: 132.78414\n",
      "[epoch 265, batch    20] loss: 121.55759\n",
      "[epoch 265, batch    21] loss: 129.34700\n",
      "[epoch 265, batch    22] loss: 123.17492\n",
      "[epoch 265, batch    23] loss: 125.89094\n",
      "[epoch 265, batch    24] loss: 136.04785\n",
      "[epoch 265, batch    25] loss: 129.21729\n",
      "[epoch 265, batch    26] loss: 154.71976\n",
      "[epoch 265, batch    27] loss: 129.86670\n",
      "[epoch 265, batch    28] loss: 134.43304\n",
      "[epoch 265, batch    29] loss: 139.72927\n",
      "[epoch 265, batch    30] loss: 141.22358\n",
      "[epoch 265, batch    31] loss: 126.11284\n",
      "[epoch 265, batch    32] loss: 31.49620\n",
      "[epoch 266, batch     1] loss: 146.01329\n",
      "[epoch 266, batch     2] loss: 140.74516\n",
      "[epoch 266, batch     3] loss: 132.86507\n",
      "[epoch 266, batch     4] loss: 140.77689\n",
      "[epoch 266, batch     5] loss: 134.36323\n",
      "[epoch 266, batch     6] loss: 135.77367\n",
      "[epoch 266, batch     7] loss: 123.04766\n",
      "[epoch 266, batch     8] loss: 124.88258\n",
      "[epoch 266, batch     9] loss: 125.05011\n",
      "[epoch 266, batch    10] loss: 134.17623\n",
      "[epoch 266, batch    11] loss: 121.06946\n",
      "[epoch 266, batch    12] loss: 124.22184\n",
      "[epoch 266, batch    13] loss: 127.51729\n",
      "[epoch 266, batch    14] loss: 145.52976\n",
      "[epoch 266, batch    15] loss: 124.36049\n",
      "[epoch 266, batch    16] loss: 116.14668\n",
      "[epoch 266, batch    17] loss: 145.72674\n",
      "[epoch 266, batch    18] loss: 116.35214\n",
      "[epoch 266, batch    19] loss: 127.35136\n",
      "[epoch 266, batch    20] loss: 134.61057\n",
      "[epoch 266, batch    21] loss: 142.34013\n",
      "[epoch 266, batch    22] loss: 127.01752\n",
      "[epoch 266, batch    23] loss: 125.27460\n",
      "[epoch 266, batch    24] loss: 141.24336\n",
      "[epoch 266, batch    25] loss: 124.71910\n",
      "[epoch 266, batch    26] loss: 120.62487\n",
      "[epoch 266, batch    27] loss: 120.67961\n",
      "[epoch 266, batch    28] loss: 121.98837\n",
      "[epoch 266, batch    29] loss: 136.23154\n",
      "[epoch 266, batch    30] loss: 130.89008\n",
      "[epoch 266, batch    31] loss: 134.60269\n",
      "[epoch 266, batch    32] loss: 29.15647\n",
      "[epoch 267, batch     1] loss: 150.58217\n",
      "[epoch 267, batch     2] loss: 138.04491\n",
      "[epoch 267, batch     3] loss: 128.87900\n",
      "[epoch 267, batch     4] loss: 133.20655\n",
      "[epoch 267, batch     5] loss: 132.20032\n",
      "[epoch 267, batch     6] loss: 135.15143\n",
      "[epoch 267, batch     7] loss: 132.53464\n",
      "[epoch 267, batch     8] loss: 120.29085\n",
      "[epoch 267, batch     9] loss: 127.46150\n",
      "[epoch 267, batch    10] loss: 141.12670\n",
      "[epoch 267, batch    11] loss: 125.03676\n",
      "[epoch 267, batch    12] loss: 126.10670\n",
      "[epoch 267, batch    13] loss: 135.81037\n",
      "[epoch 267, batch    14] loss: 129.82833\n",
      "[epoch 267, batch    15] loss: 131.67193\n",
      "[epoch 267, batch    16] loss: 134.16711\n",
      "[epoch 267, batch    17] loss: 133.19340\n",
      "[epoch 267, batch    18] loss: 135.00348\n",
      "[epoch 267, batch    19] loss: 146.04242\n",
      "[epoch 267, batch    20] loss: 117.42330\n",
      "[epoch 267, batch    21] loss: 129.10238\n",
      "[epoch 267, batch    22] loss: 134.75164\n",
      "[epoch 267, batch    23] loss: 123.15891\n",
      "[epoch 267, batch    24] loss: 148.24762\n",
      "[epoch 267, batch    25] loss: 129.58728\n",
      "[epoch 267, batch    26] loss: 141.04362\n",
      "[epoch 267, batch    27] loss: 123.13337\n",
      "[epoch 267, batch    28] loss: 128.78249\n",
      "[epoch 267, batch    29] loss: 116.10216\n",
      "[epoch 267, batch    30] loss: 123.86985\n",
      "[epoch 267, batch    31] loss: 137.10422\n",
      "[epoch 267, batch    32] loss: 35.99446\n",
      "[epoch 268, batch     1] loss: 146.12353\n",
      "[epoch 268, batch     2] loss: 136.96921\n",
      "[epoch 268, batch     3] loss: 137.02113\n",
      "[epoch 268, batch     4] loss: 133.25470\n",
      "[epoch 268, batch     5] loss: 130.63542\n",
      "[epoch 268, batch     6] loss: 124.41294\n",
      "[epoch 268, batch     7] loss: 120.48877\n",
      "[epoch 268, batch     8] loss: 134.15078\n",
      "[epoch 268, batch     9] loss: 143.84604\n",
      "[epoch 268, batch    10] loss: 131.88377\n",
      "[epoch 268, batch    11] loss: 132.82855\n",
      "[epoch 268, batch    12] loss: 129.21035\n",
      "[epoch 268, batch    13] loss: 130.27396\n",
      "[epoch 268, batch    14] loss: 139.73108\n",
      "[epoch 268, batch    15] loss: 123.47773\n",
      "[epoch 268, batch    16] loss: 116.40820\n",
      "[epoch 268, batch    17] loss: 139.06967\n",
      "[epoch 268, batch    18] loss: 142.10600\n",
      "[epoch 268, batch    19] loss: 132.14298\n",
      "[epoch 268, batch    20] loss: 154.48560\n",
      "[epoch 268, batch    21] loss: 133.07291\n",
      "[epoch 268, batch    22] loss: 134.27123\n",
      "[epoch 268, batch    23] loss: 127.91193\n",
      "[epoch 268, batch    24] loss: 136.27798\n",
      "[epoch 268, batch    25] loss: 123.44257\n",
      "[epoch 268, batch    26] loss: 130.58993\n",
      "[epoch 268, batch    27] loss: 130.75982\n",
      "[epoch 268, batch    28] loss: 132.26557\n",
      "[epoch 268, batch    29] loss: 146.67046\n",
      "[epoch 268, batch    30] loss: 142.47837\n",
      "[epoch 268, batch    31] loss: 128.96347\n",
      "[epoch 268, batch    32] loss: 31.25158\n",
      "[epoch 269, batch     1] loss: 145.29779\n",
      "[epoch 269, batch     2] loss: 137.91381\n",
      "[epoch 269, batch     3] loss: 137.44521\n",
      "[epoch 269, batch     4] loss: 140.32253\n",
      "[epoch 269, batch     5] loss: 129.53910\n",
      "[epoch 269, batch     6] loss: 121.99723\n",
      "[epoch 269, batch     7] loss: 119.70575\n",
      "[epoch 269, batch     8] loss: 124.03465\n",
      "[epoch 269, batch     9] loss: 143.23161\n",
      "[epoch 269, batch    10] loss: 140.27500\n",
      "[epoch 269, batch    11] loss: 126.26208\n",
      "[epoch 269, batch    12] loss: 130.09444\n",
      "[epoch 269, batch    13] loss: 132.63672\n",
      "[epoch 269, batch    14] loss: 135.77510\n",
      "[epoch 269, batch    15] loss: 122.16583\n",
      "[epoch 269, batch    16] loss: 138.03662\n",
      "[epoch 269, batch    17] loss: 139.72468\n",
      "[epoch 269, batch    18] loss: 127.23318\n",
      "[epoch 269, batch    19] loss: 131.03149\n",
      "[epoch 269, batch    20] loss: 127.71071\n",
      "[epoch 269, batch    21] loss: 132.16330\n",
      "[epoch 269, batch    22] loss: 128.47619\n",
      "[epoch 269, batch    23] loss: 139.78541\n",
      "[epoch 269, batch    24] loss: 138.40838\n",
      "[epoch 269, batch    25] loss: 128.71606\n",
      "[epoch 269, batch    26] loss: 137.70340\n",
      "[epoch 269, batch    27] loss: 141.73659\n",
      "[epoch 269, batch    28] loss: 123.15865\n",
      "[epoch 269, batch    29] loss: 146.13045\n",
      "[epoch 269, batch    30] loss: 137.59624\n",
      "[epoch 269, batch    31] loss: 142.80224\n",
      "[epoch 269, batch    32] loss: 32.84703\n",
      "[epoch 270, batch     1] loss: 117.96529\n",
      "[epoch 270, batch     2] loss: 141.24255\n",
      "[epoch 270, batch     3] loss: 127.77410\n",
      "[epoch 270, batch     4] loss: 132.43061\n",
      "[epoch 270, batch     5] loss: 130.48842\n",
      "[epoch 270, batch     6] loss: 140.66186\n",
      "[epoch 270, batch     7] loss: 129.40847\n",
      "[epoch 270, batch     8] loss: 132.75142\n",
      "[epoch 270, batch     9] loss: 128.48576\n",
      "[epoch 270, batch    10] loss: 119.63141\n",
      "[epoch 270, batch    11] loss: 130.12241\n",
      "[epoch 270, batch    12] loss: 139.83539\n",
      "[epoch 270, batch    13] loss: 128.60259\n",
      "[epoch 270, batch    14] loss: 136.41109\n",
      "[epoch 270, batch    15] loss: 134.06334\n",
      "[epoch 270, batch    16] loss: 137.50781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 270, batch    17] loss: 126.86482\n",
      "[epoch 270, batch    18] loss: 125.12836\n",
      "[epoch 270, batch    19] loss: 140.28542\n",
      "[epoch 270, batch    20] loss: 136.00590\n",
      "[epoch 270, batch    21] loss: 140.06690\n",
      "[epoch 270, batch    22] loss: 145.12137\n",
      "[epoch 270, batch    23] loss: 130.89245\n",
      "[epoch 270, batch    24] loss: 134.04816\n",
      "[epoch 270, batch    25] loss: 124.68809\n",
      "[epoch 270, batch    26] loss: 136.86136\n",
      "[epoch 270, batch    27] loss: 128.66136\n",
      "[epoch 270, batch    28] loss: 128.63646\n",
      "[epoch 270, batch    29] loss: 131.58683\n",
      "[epoch 270, batch    30] loss: 128.05847\n",
      "[epoch 270, batch    31] loss: 121.22332\n",
      "[epoch 270, batch    32] loss: 35.58762\n",
      "[epoch 271, batch     1] loss: 141.92783\n",
      "[epoch 271, batch     2] loss: 127.69745\n",
      "[epoch 271, batch     3] loss: 123.53024\n",
      "[epoch 271, batch     4] loss: 131.84206\n",
      "[epoch 271, batch     5] loss: 141.91997\n",
      "[epoch 271, batch     6] loss: 135.43892\n",
      "[epoch 271, batch     7] loss: 132.59463\n",
      "[epoch 271, batch     8] loss: 124.84014\n",
      "[epoch 271, batch     9] loss: 133.43619\n",
      "[epoch 271, batch    10] loss: 126.05006\n",
      "[epoch 271, batch    11] loss: 121.15599\n",
      "[epoch 271, batch    12] loss: 129.32416\n",
      "[epoch 271, batch    13] loss: 124.59425\n",
      "[epoch 271, batch    14] loss: 142.28898\n",
      "[epoch 271, batch    15] loss: 133.35136\n",
      "[epoch 271, batch    16] loss: 129.17843\n",
      "[epoch 271, batch    17] loss: 130.04852\n",
      "[epoch 271, batch    18] loss: 127.64517\n",
      "[epoch 271, batch    19] loss: 124.43069\n",
      "[epoch 271, batch    20] loss: 135.70509\n",
      "[epoch 271, batch    21] loss: 122.03505\n",
      "[epoch 271, batch    22] loss: 130.70850\n",
      "[epoch 271, batch    23] loss: 138.09875\n",
      "[epoch 271, batch    24] loss: 129.50267\n",
      "[epoch 271, batch    25] loss: 123.83776\n",
      "[epoch 271, batch    26] loss: 125.72402\n",
      "[epoch 271, batch    27] loss: 119.91091\n",
      "[epoch 271, batch    28] loss: 136.19385\n",
      "[epoch 271, batch    29] loss: 118.58613\n",
      "[epoch 271, batch    30] loss: 140.73607\n",
      "[epoch 271, batch    31] loss: 135.89293\n",
      "[epoch 271, batch    32] loss: 35.07989\n",
      "[epoch 272, batch     1] loss: 126.41504\n",
      "[epoch 272, batch     2] loss: 131.42327\n",
      "[epoch 272, batch     3] loss: 121.19401\n",
      "[epoch 272, batch     4] loss: 122.40340\n",
      "[epoch 272, batch     5] loss: 145.95174\n",
      "[epoch 272, batch     6] loss: 128.71065\n",
      "[epoch 272, batch     7] loss: 132.28799\n",
      "[epoch 272, batch     8] loss: 125.88955\n",
      "[epoch 272, batch     9] loss: 135.65683\n",
      "[epoch 272, batch    10] loss: 130.85777\n",
      "[epoch 272, batch    11] loss: 133.00460\n",
      "[epoch 272, batch    12] loss: 138.52515\n",
      "[epoch 272, batch    13] loss: 141.34397\n",
      "[epoch 272, batch    14] loss: 138.00292\n",
      "[epoch 272, batch    15] loss: 126.71710\n",
      "[epoch 272, batch    16] loss: 131.10486\n",
      "[epoch 272, batch    17] loss: 128.63827\n",
      "[epoch 272, batch    18] loss: 133.44854\n",
      "[epoch 272, batch    19] loss: 128.82410\n",
      "[epoch 272, batch    20] loss: 119.18966\n",
      "[epoch 272, batch    21] loss: 135.31721\n",
      "[epoch 272, batch    22] loss: 134.10823\n",
      "[epoch 272, batch    23] loss: 133.76714\n",
      "[epoch 272, batch    24] loss: 135.14404\n",
      "[epoch 272, batch    25] loss: 134.69268\n",
      "[epoch 272, batch    26] loss: 134.81565\n",
      "[epoch 272, batch    27] loss: 126.78807\n",
      "[epoch 272, batch    28] loss: 132.36555\n",
      "[epoch 272, batch    29] loss: 127.14668\n",
      "[epoch 272, batch    30] loss: 140.70559\n",
      "[epoch 272, batch    31] loss: 136.96254\n",
      "[epoch 272, batch    32] loss: 37.60607\n",
      "[epoch 273, batch     1] loss: 138.06335\n",
      "[epoch 273, batch     2] loss: 144.21884\n",
      "[epoch 273, batch     3] loss: 127.60659\n",
      "[epoch 273, batch     4] loss: 131.43460\n",
      "[epoch 273, batch     5] loss: 138.38842\n",
      "[epoch 273, batch     6] loss: 125.95926\n",
      "[epoch 273, batch     7] loss: 144.81010\n",
      "[epoch 273, batch     8] loss: 134.99225\n",
      "[epoch 273, batch     9] loss: 130.99311\n",
      "[epoch 273, batch    10] loss: 122.40201\n",
      "[epoch 273, batch    11] loss: 127.17581\n",
      "[epoch 273, batch    12] loss: 123.68930\n",
      "[epoch 273, batch    13] loss: 128.11249\n",
      "[epoch 273, batch    14] loss: 136.38995\n",
      "[epoch 273, batch    15] loss: 128.41315\n",
      "[epoch 273, batch    16] loss: 142.20490\n",
      "[epoch 273, batch    17] loss: 135.05661\n",
      "[epoch 273, batch    18] loss: 127.17663\n",
      "[epoch 273, batch    19] loss: 141.21976\n",
      "[epoch 273, batch    20] loss: 128.14169\n",
      "[epoch 273, batch    21] loss: 141.19912\n",
      "[epoch 273, batch    22] loss: 129.30071\n",
      "[epoch 273, batch    23] loss: 136.53275\n",
      "[epoch 273, batch    24] loss: 124.39103\n",
      "[epoch 273, batch    25] loss: 140.18046\n",
      "[epoch 273, batch    26] loss: 130.00864\n",
      "[epoch 273, batch    27] loss: 133.60533\n",
      "[epoch 273, batch    28] loss: 142.77324\n",
      "[epoch 273, batch    29] loss: 132.33984\n",
      "[epoch 273, batch    30] loss: 128.53826\n",
      "[epoch 273, batch    31] loss: 143.71204\n",
      "[epoch 273, batch    32] loss: 32.11816\n",
      "[epoch 274, batch     1] loss: 153.79861\n",
      "[epoch 274, batch     2] loss: 129.74441\n",
      "[epoch 274, batch     3] loss: 134.94763\n",
      "[epoch 274, batch     4] loss: 137.27189\n",
      "[epoch 274, batch     5] loss: 130.12992\n",
      "[epoch 274, batch     6] loss: 118.86647\n",
      "[epoch 274, batch     7] loss: 134.11017\n",
      "[epoch 274, batch     8] loss: 137.44303\n",
      "[epoch 274, batch     9] loss: 142.59652\n",
      "[epoch 274, batch    10] loss: 129.33746\n",
      "[epoch 274, batch    11] loss: 121.93604\n",
      "[epoch 274, batch    12] loss: 146.50494\n",
      "[epoch 274, batch    13] loss: 135.16417\n",
      "[epoch 274, batch    14] loss: 128.65998\n",
      "[epoch 274, batch    15] loss: 139.25693\n",
      "[epoch 274, batch    16] loss: 130.94411\n",
      "[epoch 274, batch    17] loss: 133.01243\n",
      "[epoch 274, batch    18] loss: 137.24019\n",
      "[epoch 274, batch    19] loss: 154.18222\n",
      "[epoch 274, batch    20] loss: 126.61771\n",
      "[epoch 274, batch    21] loss: 128.54611\n",
      "[epoch 274, batch    22] loss: 133.48670\n",
      "[epoch 274, batch    23] loss: 135.90301\n",
      "[epoch 274, batch    24] loss: 125.95547\n",
      "[epoch 274, batch    25] loss: 126.90533\n",
      "[epoch 274, batch    26] loss: 123.35021\n",
      "[epoch 274, batch    27] loss: 128.10894\n",
      "[epoch 274, batch    28] loss: 137.42450\n",
      "[epoch 274, batch    29] loss: 118.27985\n",
      "[epoch 274, batch    30] loss: 125.08807\n",
      "[epoch 274, batch    31] loss: 127.31739\n",
      "[epoch 274, batch    32] loss: 33.06187\n",
      "[epoch 275, batch     1] loss: 135.15229\n",
      "[epoch 275, batch     2] loss: 125.87585\n",
      "[epoch 275, batch     3] loss: 140.31545\n",
      "[epoch 275, batch     4] loss: 133.93253\n",
      "[epoch 275, batch     5] loss: 133.98474\n",
      "[epoch 275, batch     6] loss: 131.72360\n",
      "[epoch 275, batch     7] loss: 128.13286\n",
      "[epoch 275, batch     8] loss: 124.76970\n",
      "[epoch 275, batch     9] loss: 128.06279\n",
      "[epoch 275, batch    10] loss: 138.30017\n",
      "[epoch 275, batch    11] loss: 121.17954\n",
      "[epoch 275, batch    12] loss: 133.47600\n",
      "[epoch 275, batch    13] loss: 138.04520\n",
      "[epoch 275, batch    14] loss: 127.41707\n",
      "[epoch 275, batch    15] loss: 128.46855\n",
      "[epoch 275, batch    16] loss: 130.32349\n",
      "[epoch 275, batch    17] loss: 127.47583\n",
      "[epoch 275, batch    18] loss: 151.57911\n",
      "[epoch 275, batch    19] loss: 134.30401\n",
      "[epoch 275, batch    20] loss: 139.18875\n",
      "[epoch 275, batch    21] loss: 144.47997\n",
      "[epoch 275, batch    22] loss: 127.08107\n",
      "[epoch 275, batch    23] loss: 133.13341\n",
      "[epoch 275, batch    24] loss: 128.27781\n",
      "[epoch 275, batch    25] loss: 120.01835\n",
      "[epoch 275, batch    26] loss: 123.86442\n",
      "[epoch 275, batch    27] loss: 127.22221\n",
      "[epoch 275, batch    28] loss: 129.65699\n",
      "[epoch 275, batch    29] loss: 136.14866\n",
      "[epoch 275, batch    30] loss: 139.63140\n",
      "[epoch 275, batch    31] loss: 145.49084\n",
      "[epoch 275, batch    32] loss: 29.05546\n",
      "[epoch 276, batch     1] loss: 136.16836\n",
      "[epoch 276, batch     2] loss: 129.51185\n",
      "[epoch 276, batch     3] loss: 128.82424\n",
      "[epoch 276, batch     4] loss: 129.89804\n",
      "[epoch 276, batch     5] loss: 123.45859\n",
      "[epoch 276, batch     6] loss: 143.07815\n",
      "[epoch 276, batch     7] loss: 138.72198\n",
      "[epoch 276, batch     8] loss: 127.38706\n",
      "[epoch 276, batch     9] loss: 128.19341\n",
      "[epoch 276, batch    10] loss: 135.88119\n",
      "[epoch 276, batch    11] loss: 125.96567\n",
      "[epoch 276, batch    12] loss: 128.94858\n",
      "[epoch 276, batch    13] loss: 124.21196\n",
      "[epoch 276, batch    14] loss: 133.98879\n",
      "[epoch 276, batch    15] loss: 126.52519\n",
      "[epoch 276, batch    16] loss: 127.11269\n",
      "[epoch 276, batch    17] loss: 141.33839\n",
      "[epoch 276, batch    18] loss: 121.85172\n",
      "[epoch 276, batch    19] loss: 130.20291\n",
      "[epoch 276, batch    20] loss: 128.40445\n",
      "[epoch 276, batch    21] loss: 123.76328\n",
      "[epoch 276, batch    22] loss: 141.32332\n",
      "[epoch 276, batch    23] loss: 129.37405\n",
      "[epoch 276, batch    24] loss: 129.59719\n",
      "[epoch 276, batch    25] loss: 140.90745\n",
      "[epoch 276, batch    26] loss: 138.75877\n",
      "[epoch 276, batch    27] loss: 129.94344\n",
      "[epoch 276, batch    28] loss: 132.21800\n",
      "[epoch 276, batch    29] loss: 123.06804\n",
      "[epoch 276, batch    30] loss: 132.61776\n",
      "[epoch 276, batch    31] loss: 127.15725\n",
      "[epoch 276, batch    32] loss: 33.73051\n",
      "[epoch 277, batch     1] loss: 138.29179\n",
      "[epoch 277, batch     2] loss: 132.02752\n",
      "[epoch 277, batch     3] loss: 130.06171\n",
      "[epoch 277, batch     4] loss: 133.05862\n",
      "[epoch 277, batch     5] loss: 135.18899\n",
      "[epoch 277, batch     6] loss: 124.35025\n",
      "[epoch 277, batch     7] loss: 139.72039\n",
      "[epoch 277, batch     8] loss: 133.75712\n",
      "[epoch 277, batch     9] loss: 118.42943\n",
      "[epoch 277, batch    10] loss: 128.92746\n",
      "[epoch 277, batch    11] loss: 120.84140\n",
      "[epoch 277, batch    12] loss: 131.26218\n",
      "[epoch 277, batch    13] loss: 131.63691\n",
      "[epoch 277, batch    14] loss: 142.61567\n",
      "[epoch 277, batch    15] loss: 144.08079\n",
      "[epoch 277, batch    16] loss: 130.52061\n",
      "[epoch 277, batch    17] loss: 127.55690\n",
      "[epoch 277, batch    18] loss: 137.77051\n",
      "[epoch 277, batch    19] loss: 135.79473\n",
      "[epoch 277, batch    20] loss: 126.60340\n",
      "[epoch 277, batch    21] loss: 144.00670\n",
      "[epoch 277, batch    22] loss: 127.68474\n",
      "[epoch 277, batch    23] loss: 144.36117\n",
      "[epoch 277, batch    24] loss: 134.28044\n",
      "[epoch 277, batch    25] loss: 140.23618\n",
      "[epoch 277, batch    26] loss: 124.47928\n",
      "[epoch 277, batch    27] loss: 125.01873\n",
      "[epoch 277, batch    28] loss: 130.50847\n",
      "[epoch 277, batch    29] loss: 144.28748\n",
      "[epoch 277, batch    30] loss: 128.43776\n",
      "[epoch 277, batch    31] loss: 121.06670\n",
      "[epoch 277, batch    32] loss: 33.11910\n",
      "[epoch 278, batch     1] loss: 122.71872\n",
      "[epoch 278, batch     2] loss: 132.39535\n",
      "[epoch 278, batch     3] loss: 122.72660\n",
      "[epoch 278, batch     4] loss: 130.31591\n",
      "[epoch 278, batch     5] loss: 135.07469\n",
      "[epoch 278, batch     6] loss: 121.39375\n",
      "[epoch 278, batch     7] loss: 122.68110\n",
      "[epoch 278, batch     8] loss: 122.72579\n",
      "[epoch 278, batch     9] loss: 129.86319\n",
      "[epoch 278, batch    10] loss: 119.36996\n",
      "[epoch 278, batch    11] loss: 131.30349\n",
      "[epoch 278, batch    12] loss: 128.36981\n",
      "[epoch 278, batch    13] loss: 125.26528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 278, batch    14] loss: 132.62577\n",
      "[epoch 278, batch    15] loss: 122.83579\n",
      "[epoch 278, batch    16] loss: 132.05916\n",
      "[epoch 278, batch    17] loss: 138.72318\n",
      "[epoch 278, batch    18] loss: 128.62333\n",
      "[epoch 278, batch    19] loss: 127.77594\n",
      "[epoch 278, batch    20] loss: 119.18580\n",
      "[epoch 278, batch    21] loss: 131.52802\n",
      "[epoch 278, batch    22] loss: 143.21362\n",
      "[epoch 278, batch    23] loss: 154.12969\n",
      "[epoch 278, batch    24] loss: 136.34763\n",
      "[epoch 278, batch    25] loss: 125.85068\n",
      "[epoch 278, batch    26] loss: 131.22760\n",
      "[epoch 278, batch    27] loss: 122.28060\n",
      "[epoch 278, batch    28] loss: 123.78853\n",
      "[epoch 278, batch    29] loss: 135.85714\n",
      "[epoch 278, batch    30] loss: 138.56997\n",
      "[epoch 278, batch    31] loss: 145.21256\n",
      "[epoch 278, batch    32] loss: 37.78850\n",
      "[epoch 279, batch     1] loss: 131.32412\n",
      "[epoch 279, batch     2] loss: 130.90937\n",
      "[epoch 279, batch     3] loss: 145.06131\n",
      "[epoch 279, batch     4] loss: 121.47036\n",
      "[epoch 279, batch     5] loss: 129.71167\n",
      "[epoch 279, batch     6] loss: 126.41320\n",
      "[epoch 279, batch     7] loss: 129.05484\n",
      "[epoch 279, batch     8] loss: 141.99112\n",
      "[epoch 279, batch     9] loss: 137.23769\n",
      "[epoch 279, batch    10] loss: 127.40166\n",
      "[epoch 279, batch    11] loss: 126.42057\n",
      "[epoch 279, batch    12] loss: 126.15325\n",
      "[epoch 279, batch    13] loss: 119.28934\n",
      "[epoch 279, batch    14] loss: 129.05172\n",
      "[epoch 279, batch    15] loss: 131.57708\n",
      "[epoch 279, batch    16] loss: 125.18751\n",
      "[epoch 279, batch    17] loss: 152.78155\n",
      "[epoch 279, batch    18] loss: 131.93538\n",
      "[epoch 279, batch    19] loss: 133.23668\n",
      "[epoch 279, batch    20] loss: 120.79332\n",
      "[epoch 279, batch    21] loss: 135.00994\n",
      "[epoch 279, batch    22] loss: 128.58704\n",
      "[epoch 279, batch    23] loss: 130.31256\n",
      "[epoch 279, batch    24] loss: 123.21366\n",
      "[epoch 279, batch    25] loss: 129.57290\n",
      "[epoch 279, batch    26] loss: 136.86499\n",
      "[epoch 279, batch    27] loss: 123.96473\n",
      "[epoch 279, batch    28] loss: 128.09469\n",
      "[epoch 279, batch    29] loss: 132.81237\n",
      "[epoch 279, batch    30] loss: 129.08603\n",
      "[epoch 279, batch    31] loss: 136.18898\n",
      "[epoch 279, batch    32] loss: 28.35022\n",
      "[epoch 280, batch     1] loss: 142.21878\n",
      "[epoch 280, batch     2] loss: 119.86134\n",
      "[epoch 280, batch     3] loss: 133.14724\n",
      "[epoch 280, batch     4] loss: 146.80980\n",
      "[epoch 280, batch     5] loss: 144.76729\n",
      "[epoch 280, batch     6] loss: 123.17899\n",
      "[epoch 280, batch     7] loss: 138.23542\n",
      "[epoch 280, batch     8] loss: 118.97487\n",
      "[epoch 280, batch     9] loss: 134.92191\n",
      "[epoch 280, batch    10] loss: 133.40492\n",
      "[epoch 280, batch    11] loss: 131.12148\n",
      "[epoch 280, batch    12] loss: 135.39228\n",
      "[epoch 280, batch    13] loss: 133.20829\n",
      "[epoch 280, batch    14] loss: 141.87167\n",
      "[epoch 280, batch    15] loss: 126.27137\n",
      "[epoch 280, batch    16] loss: 128.87055\n",
      "[epoch 280, batch    17] loss: 136.93393\n",
      "[epoch 280, batch    18] loss: 130.48968\n",
      "[epoch 280, batch    19] loss: 142.59167\n",
      "[epoch 280, batch    20] loss: 138.03727\n",
      "[epoch 280, batch    21] loss: 130.21536\n",
      "[epoch 280, batch    22] loss: 128.78472\n",
      "[epoch 280, batch    23] loss: 125.31679\n",
      "[epoch 280, batch    24] loss: 124.09813\n",
      "[epoch 280, batch    25] loss: 143.90821\n",
      "[epoch 280, batch    26] loss: 139.91056\n",
      "[epoch 280, batch    27] loss: 123.26125\n",
      "[epoch 280, batch    28] loss: 123.35107\n",
      "[epoch 280, batch    29] loss: 130.67638\n",
      "[epoch 280, batch    30] loss: 120.99752\n",
      "[epoch 280, batch    31] loss: 114.01300\n",
      "[epoch 280, batch    32] loss: 34.21696\n",
      "[epoch 281, batch     1] loss: 134.24275\n",
      "[epoch 281, batch     2] loss: 130.91274\n",
      "[epoch 281, batch     3] loss: 131.39065\n",
      "[epoch 281, batch     4] loss: 125.96372\n",
      "[epoch 281, batch     5] loss: 121.68528\n",
      "[epoch 281, batch     6] loss: 149.42785\n",
      "[epoch 281, batch     7] loss: 130.90509\n",
      "[epoch 281, batch     8] loss: 145.87931\n",
      "[epoch 281, batch     9] loss: 146.80220\n",
      "[epoch 281, batch    10] loss: 126.30722\n",
      "[epoch 281, batch    11] loss: 142.90365\n",
      "[epoch 281, batch    12] loss: 132.70175\n",
      "[epoch 281, batch    13] loss: 126.62465\n",
      "[epoch 281, batch    14] loss: 142.80838\n",
      "[epoch 281, batch    15] loss: 130.11051\n",
      "[epoch 281, batch    16] loss: 125.25615\n",
      "[epoch 281, batch    17] loss: 132.97086\n",
      "[epoch 281, batch    18] loss: 126.99516\n",
      "[epoch 281, batch    19] loss: 134.28356\n",
      "[epoch 281, batch    20] loss: 123.99420\n",
      "[epoch 281, batch    21] loss: 124.72087\n",
      "[epoch 281, batch    22] loss: 138.02371\n",
      "[epoch 281, batch    23] loss: 127.75966\n",
      "[epoch 281, batch    24] loss: 124.09166\n",
      "[epoch 281, batch    25] loss: 127.45930\n",
      "[epoch 281, batch    26] loss: 139.54441\n",
      "[epoch 281, batch    27] loss: 142.94777\n",
      "[epoch 281, batch    28] loss: 132.48773\n",
      "[epoch 281, batch    29] loss: 129.95218\n",
      "[epoch 281, batch    30] loss: 132.18872\n",
      "[epoch 281, batch    31] loss: 127.48843\n",
      "[epoch 281, batch    32] loss: 25.89822\n",
      "[epoch 282, batch     1] loss: 137.70645\n",
      "[epoch 282, batch     2] loss: 136.93042\n",
      "[epoch 282, batch     3] loss: 145.48157\n",
      "[epoch 282, batch     4] loss: 143.45978\n",
      "[epoch 282, batch     5] loss: 130.24606\n",
      "[epoch 282, batch     6] loss: 116.72767\n",
      "[epoch 282, batch     7] loss: 124.51919\n",
      "[epoch 282, batch     8] loss: 128.16793\n",
      "[epoch 282, batch     9] loss: 136.30742\n",
      "[epoch 282, batch    10] loss: 136.66699\n",
      "[epoch 282, batch    11] loss: 130.25761\n",
      "[epoch 282, batch    12] loss: 122.85859\n",
      "[epoch 282, batch    13] loss: 129.90487\n",
      "[epoch 282, batch    14] loss: 126.61791\n",
      "[epoch 282, batch    15] loss: 145.11962\n",
      "[epoch 282, batch    16] loss: 137.15969\n",
      "[epoch 282, batch    17] loss: 126.78396\n",
      "[epoch 282, batch    18] loss: 122.97443\n",
      "[epoch 282, batch    19] loss: 133.90943\n",
      "[epoch 282, batch    20] loss: 131.85364\n",
      "[epoch 282, batch    21] loss: 134.64978\n",
      "[epoch 282, batch    22] loss: 125.18095\n",
      "[epoch 282, batch    23] loss: 126.63141\n",
      "[epoch 282, batch    24] loss: 126.46533\n",
      "[epoch 282, batch    25] loss: 127.39703\n",
      "[epoch 282, batch    26] loss: 131.26740\n",
      "[epoch 282, batch    27] loss: 131.15928\n",
      "[epoch 282, batch    28] loss: 132.26148\n",
      "[epoch 282, batch    29] loss: 127.83372\n",
      "[epoch 282, batch    30] loss: 129.92989\n",
      "[epoch 282, batch    31] loss: 136.41338\n",
      "[epoch 282, batch    32] loss: 33.85891\n",
      "[epoch 283, batch     1] loss: 147.44499\n",
      "[epoch 283, batch     2] loss: 123.62809\n",
      "[epoch 283, batch     3] loss: 138.32251\n",
      "[epoch 283, batch     4] loss: 135.94420\n",
      "[epoch 283, batch     5] loss: 124.21710\n",
      "[epoch 283, batch     6] loss: 130.33369\n",
      "[epoch 283, batch     7] loss: 127.89761\n",
      "[epoch 283, batch     8] loss: 138.01632\n",
      "[epoch 283, batch     9] loss: 139.97660\n",
      "[epoch 283, batch    10] loss: 128.85566\n",
      "[epoch 283, batch    11] loss: 141.46660\n",
      "[epoch 283, batch    12] loss: 142.63774\n",
      "[epoch 283, batch    13] loss: 135.10413\n",
      "[epoch 283, batch    14] loss: 139.41035\n",
      "[epoch 283, batch    15] loss: 115.32919\n",
      "[epoch 283, batch    16] loss: 125.41689\n",
      "[epoch 283, batch    17] loss: 126.80737\n",
      "[epoch 283, batch    18] loss: 127.09760\n",
      "[epoch 283, batch    19] loss: 135.43871\n",
      "[epoch 283, batch    20] loss: 133.66510\n",
      "[epoch 283, batch    21] loss: 130.34894\n",
      "[epoch 283, batch    22] loss: 142.71896\n",
      "[epoch 283, batch    23] loss: 130.69168\n",
      "[epoch 283, batch    24] loss: 137.05283\n",
      "[epoch 283, batch    25] loss: 127.44111\n",
      "[epoch 283, batch    26] loss: 134.13490\n",
      "[epoch 283, batch    27] loss: 138.93079\n",
      "[epoch 283, batch    28] loss: 111.83903\n",
      "[epoch 283, batch    29] loss: 120.05745\n",
      "[epoch 283, batch    30] loss: 137.70604\n",
      "[epoch 283, batch    31] loss: 133.33851\n",
      "[epoch 283, batch    32] loss: 33.50899\n",
      "[epoch 284, batch     1] loss: 119.13330\n",
      "[epoch 284, batch     2] loss: 135.65213\n",
      "[epoch 284, batch     3] loss: 127.12162\n",
      "[epoch 284, batch     4] loss: 138.38315\n",
      "[epoch 284, batch     5] loss: 130.78592\n",
      "[epoch 284, batch     6] loss: 145.52714\n",
      "[epoch 284, batch     7] loss: 136.70238\n",
      "[epoch 284, batch     8] loss: 127.66993\n",
      "[epoch 284, batch     9] loss: 139.61328\n",
      "[epoch 284, batch    10] loss: 133.01219\n",
      "[epoch 284, batch    11] loss: 132.04629\n",
      "[epoch 284, batch    12] loss: 124.89871\n",
      "[epoch 284, batch    13] loss: 135.61693\n",
      "[epoch 284, batch    14] loss: 147.20635\n",
      "[epoch 284, batch    15] loss: 129.95906\n",
      "[epoch 284, batch    16] loss: 123.82622\n",
      "[epoch 284, batch    17] loss: 138.65680\n",
      "[epoch 284, batch    18] loss: 137.31897\n",
      "[epoch 284, batch    19] loss: 142.50994\n",
      "[epoch 284, batch    20] loss: 130.07763\n",
      "[epoch 284, batch    21] loss: 115.95511\n",
      "[epoch 284, batch    22] loss: 125.35228\n",
      "[epoch 284, batch    23] loss: 127.67260\n",
      "[epoch 284, batch    24] loss: 126.71435\n",
      "[epoch 284, batch    25] loss: 139.84944\n",
      "[epoch 284, batch    26] loss: 124.84651\n",
      "[epoch 284, batch    27] loss: 133.68162\n",
      "[epoch 284, batch    28] loss: 121.14090\n",
      "[epoch 284, batch    29] loss: 128.21789\n",
      "[epoch 284, batch    30] loss: 135.57274\n",
      "[epoch 284, batch    31] loss: 131.97935\n",
      "[epoch 284, batch    32] loss: 36.29421\n",
      "[epoch 285, batch     1] loss: 121.09385\n",
      "[epoch 285, batch     2] loss: 132.12929\n",
      "[epoch 285, batch     3] loss: 128.06401\n",
      "[epoch 285, batch     4] loss: 135.99302\n",
      "[epoch 285, batch     5] loss: 139.51489\n",
      "[epoch 285, batch     6] loss: 130.02985\n",
      "[epoch 285, batch     7] loss: 123.81648\n",
      "[epoch 285, batch     8] loss: 140.99692\n",
      "[epoch 285, batch     9] loss: 132.22933\n",
      "[epoch 285, batch    10] loss: 130.22878\n",
      "[epoch 285, batch    11] loss: 144.83096\n",
      "[epoch 285, batch    12] loss: 139.25672\n",
      "[epoch 285, batch    13] loss: 126.37878\n",
      "[epoch 285, batch    14] loss: 124.18213\n",
      "[epoch 285, batch    15] loss: 134.82146\n",
      "[epoch 285, batch    16] loss: 123.97191\n",
      "[epoch 285, batch    17] loss: 122.02831\n",
      "[epoch 285, batch    18] loss: 136.33773\n",
      "[epoch 285, batch    19] loss: 136.73793\n",
      "[epoch 285, batch    20] loss: 137.17685\n",
      "[epoch 285, batch    21] loss: 114.11476\n",
      "[epoch 285, batch    22] loss: 123.31009\n",
      "[epoch 285, batch    23] loss: 126.46598\n",
      "[epoch 285, batch    24] loss: 128.34863\n",
      "[epoch 285, batch    25] loss: 132.52342\n",
      "[epoch 285, batch    26] loss: 139.63693\n",
      "[epoch 285, batch    27] loss: 140.06623\n",
      "[epoch 285, batch    28] loss: 136.95065\n",
      "[epoch 285, batch    29] loss: 133.20665\n",
      "[epoch 285, batch    30] loss: 145.11942\n",
      "[epoch 285, batch    31] loss: 122.52732\n",
      "[epoch 285, batch    32] loss: 31.99774\n",
      "[epoch 286, batch     1] loss: 121.29520\n",
      "[epoch 286, batch     2] loss: 121.69761\n",
      "[epoch 286, batch     3] loss: 129.51793\n",
      "[epoch 286, batch     4] loss: 129.94353\n",
      "[epoch 286, batch     5] loss: 136.41871\n",
      "[epoch 286, batch     6] loss: 126.02735\n",
      "[epoch 286, batch     7] loss: 124.11172\n",
      "[epoch 286, batch     8] loss: 136.13204\n",
      "[epoch 286, batch     9] loss: 123.85873\n",
      "[epoch 286, batch    10] loss: 131.38930\n",
      "[epoch 286, batch    11] loss: 132.56889\n",
      "[epoch 286, batch    12] loss: 146.51140\n",
      "[epoch 286, batch    13] loss: 134.22411\n",
      "[epoch 286, batch    14] loss: 125.71663\n",
      "[epoch 286, batch    15] loss: 138.15095\n",
      "[epoch 286, batch    16] loss: 134.31721\n",
      "[epoch 286, batch    17] loss: 135.80418\n",
      "[epoch 286, batch    18] loss: 137.39749\n",
      "[epoch 286, batch    19] loss: 131.13877\n",
      "[epoch 286, batch    20] loss: 129.62287\n",
      "[epoch 286, batch    21] loss: 119.99824\n",
      "[epoch 286, batch    22] loss: 138.87674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 286, batch    23] loss: 131.64744\n",
      "[epoch 286, batch    24] loss: 138.55438\n",
      "[epoch 286, batch    25] loss: 134.43369\n",
      "[epoch 286, batch    26] loss: 139.67870\n",
      "[epoch 286, batch    27] loss: 144.53467\n",
      "[epoch 286, batch    28] loss: 137.39493\n",
      "[epoch 286, batch    29] loss: 126.20313\n",
      "[epoch 286, batch    30] loss: 128.94869\n",
      "[epoch 286, batch    31] loss: 124.26622\n",
      "[epoch 286, batch    32] loss: 33.15869\n",
      "[epoch 287, batch     1] loss: 129.64244\n",
      "[epoch 287, batch     2] loss: 132.49521\n",
      "[epoch 287, batch     3] loss: 121.25534\n",
      "[epoch 287, batch     4] loss: 145.15374\n",
      "[epoch 287, batch     5] loss: 140.38487\n",
      "[epoch 287, batch     6] loss: 132.74010\n",
      "[epoch 287, batch     7] loss: 145.70338\n",
      "[epoch 287, batch     8] loss: 137.09218\n",
      "[epoch 287, batch     9] loss: 123.35688\n",
      "[epoch 287, batch    10] loss: 133.27913\n",
      "[epoch 287, batch    11] loss: 130.86792\n",
      "[epoch 287, batch    12] loss: 123.71167\n",
      "[epoch 287, batch    13] loss: 132.09045\n",
      "[epoch 287, batch    14] loss: 134.57332\n",
      "[epoch 287, batch    15] loss: 130.00423\n",
      "[epoch 287, batch    16] loss: 134.22413\n",
      "[epoch 287, batch    17] loss: 132.98315\n",
      "[epoch 287, batch    18] loss: 134.26914\n",
      "[epoch 287, batch    19] loss: 135.17574\n",
      "[epoch 287, batch    20] loss: 133.63306\n",
      "[epoch 287, batch    21] loss: 129.52103\n",
      "[epoch 287, batch    22] loss: 135.35155\n",
      "[epoch 287, batch    23] loss: 119.56263\n",
      "[epoch 287, batch    24] loss: 131.05195\n",
      "[epoch 287, batch    25] loss: 120.56296\n",
      "[epoch 287, batch    26] loss: 132.16568\n",
      "[epoch 287, batch    27] loss: 133.11237\n",
      "[epoch 287, batch    28] loss: 133.32670\n",
      "[epoch 287, batch    29] loss: 126.73948\n",
      "[epoch 287, batch    30] loss: 133.94763\n",
      "[epoch 287, batch    31] loss: 127.20049\n",
      "[epoch 287, batch    32] loss: 38.00479\n",
      "[epoch 288, batch     1] loss: 139.27779\n",
      "[epoch 288, batch     2] loss: 133.02106\n",
      "[epoch 288, batch     3] loss: 139.82393\n",
      "[epoch 288, batch     4] loss: 129.16178\n",
      "[epoch 288, batch     5] loss: 128.62934\n",
      "[epoch 288, batch     6] loss: 127.02841\n",
      "[epoch 288, batch     7] loss: 139.58870\n",
      "[epoch 288, batch     8] loss: 126.19826\n",
      "[epoch 288, batch     9] loss: 133.75196\n",
      "[epoch 288, batch    10] loss: 136.36765\n",
      "[epoch 288, batch    11] loss: 132.44861\n",
      "[epoch 288, batch    12] loss: 114.77158\n",
      "[epoch 288, batch    13] loss: 141.55195\n",
      "[epoch 288, batch    14] loss: 137.51556\n",
      "[epoch 288, batch    15] loss: 133.27458\n",
      "[epoch 288, batch    16] loss: 117.43752\n",
      "[epoch 288, batch    17] loss: 140.94938\n",
      "[epoch 288, batch    18] loss: 126.58115\n",
      "[epoch 288, batch    19] loss: 137.79220\n",
      "[epoch 288, batch    20] loss: 128.49880\n",
      "[epoch 288, batch    21] loss: 133.43266\n",
      "[epoch 288, batch    22] loss: 128.53885\n",
      "[epoch 288, batch    23] loss: 125.60134\n",
      "[epoch 288, batch    24] loss: 124.41523\n",
      "[epoch 288, batch    25] loss: 129.49728\n",
      "[epoch 288, batch    26] loss: 153.78198\n",
      "[epoch 288, batch    27] loss: 125.86402\n",
      "[epoch 288, batch    28] loss: 123.91269\n",
      "[epoch 288, batch    29] loss: 131.34577\n",
      "[epoch 288, batch    30] loss: 128.32934\n",
      "[epoch 288, batch    31] loss: 127.48210\n",
      "[epoch 288, batch    32] loss: 40.82144\n",
      "[epoch 289, batch     1] loss: 124.53942\n",
      "[epoch 289, batch     2] loss: 139.46741\n",
      "[epoch 289, batch     3] loss: 126.77034\n",
      "[epoch 289, batch     4] loss: 136.85912\n",
      "[epoch 289, batch     5] loss: 131.69001\n",
      "[epoch 289, batch     6] loss: 123.91661\n",
      "[epoch 289, batch     7] loss: 144.18777\n",
      "[epoch 289, batch     8] loss: 133.21228\n",
      "[epoch 289, batch     9] loss: 125.32303\n",
      "[epoch 289, batch    10] loss: 128.08724\n",
      "[epoch 289, batch    11] loss: 129.88969\n",
      "[epoch 289, batch    12] loss: 136.88845\n",
      "[epoch 289, batch    13] loss: 130.24300\n",
      "[epoch 289, batch    14] loss: 132.85136\n",
      "[epoch 289, batch    15] loss: 126.10554\n",
      "[epoch 289, batch    16] loss: 142.56985\n",
      "[epoch 289, batch    17] loss: 133.38396\n",
      "[epoch 289, batch    18] loss: 133.68329\n",
      "[epoch 289, batch    19] loss: 135.17632\n",
      "[epoch 289, batch    20] loss: 144.57414\n",
      "[epoch 289, batch    21] loss: 125.69964\n",
      "[epoch 289, batch    22] loss: 126.97885\n",
      "[epoch 289, batch    23] loss: 116.85087\n",
      "[epoch 289, batch    24] loss: 128.63917\n",
      "[epoch 289, batch    25] loss: 141.26798\n",
      "[epoch 289, batch    26] loss: 123.14643\n",
      "[epoch 289, batch    27] loss: 134.60447\n",
      "[epoch 289, batch    28] loss: 130.70160\n",
      "[epoch 289, batch    29] loss: 130.39285\n",
      "[epoch 289, batch    30] loss: 132.17588\n",
      "[epoch 289, batch    31] loss: 140.86796\n",
      "[epoch 289, batch    32] loss: 32.42858\n",
      "[epoch 290, batch     1] loss: 126.46513\n",
      "[epoch 290, batch     2] loss: 131.66652\n",
      "[epoch 290, batch     3] loss: 134.56621\n",
      "[epoch 290, batch     4] loss: 122.24896\n",
      "[epoch 290, batch     5] loss: 133.76259\n",
      "[epoch 290, batch     6] loss: 134.84367\n",
      "[epoch 290, batch     7] loss: 132.91900\n",
      "[epoch 290, batch     8] loss: 129.74862\n",
      "[epoch 290, batch     9] loss: 120.17100\n",
      "[epoch 290, batch    10] loss: 128.47463\n",
      "[epoch 290, batch    11] loss: 122.00406\n",
      "[epoch 290, batch    12] loss: 137.43903\n",
      "[epoch 290, batch    13] loss: 134.89855\n",
      "[epoch 290, batch    14] loss: 128.57145\n",
      "[epoch 290, batch    15] loss: 128.10061\n",
      "[epoch 290, batch    16] loss: 127.53629\n",
      "[epoch 290, batch    17] loss: 122.70468\n",
      "[epoch 290, batch    18] loss: 123.86447\n",
      "[epoch 290, batch    19] loss: 135.09198\n",
      "[epoch 290, batch    20] loss: 134.54799\n",
      "[epoch 290, batch    21] loss: 142.45985\n",
      "[epoch 290, batch    22] loss: 130.59246\n",
      "[epoch 290, batch    23] loss: 146.16371\n",
      "[epoch 290, batch    24] loss: 126.91689\n",
      "[epoch 290, batch    25] loss: 125.04152\n",
      "[epoch 290, batch    26] loss: 134.18192\n",
      "[epoch 290, batch    27] loss: 131.71836\n",
      "[epoch 290, batch    28] loss: 135.99376\n",
      "[epoch 290, batch    29] loss: 121.93104\n",
      "[epoch 290, batch    30] loss: 132.48691\n",
      "[epoch 290, batch    31] loss: 128.25668\n",
      "[epoch 290, batch    32] loss: 34.59325\n",
      "[epoch 291, batch     1] loss: 125.86980\n",
      "[epoch 291, batch     2] loss: 127.79672\n",
      "[epoch 291, batch     3] loss: 124.19329\n",
      "[epoch 291, batch     4] loss: 123.73297\n",
      "[epoch 291, batch     5] loss: 127.31638\n",
      "[epoch 291, batch     6] loss: 129.04115\n",
      "[epoch 291, batch     7] loss: 145.90091\n",
      "[epoch 291, batch     8] loss: 129.41874\n",
      "[epoch 291, batch     9] loss: 135.84700\n",
      "[epoch 291, batch    10] loss: 129.83009\n",
      "[epoch 291, batch    11] loss: 139.97671\n",
      "[epoch 291, batch    12] loss: 124.65520\n",
      "[epoch 291, batch    13] loss: 122.98550\n",
      "[epoch 291, batch    14] loss: 136.20057\n",
      "[epoch 291, batch    15] loss: 133.88247\n",
      "[epoch 291, batch    16] loss: 131.73015\n",
      "[epoch 291, batch    17] loss: 126.96352\n",
      "[epoch 291, batch    18] loss: 123.61876\n",
      "[epoch 291, batch    19] loss: 139.56043\n",
      "[epoch 291, batch    20] loss: 138.80146\n",
      "[epoch 291, batch    21] loss: 133.02933\n",
      "[epoch 291, batch    22] loss: 133.64851\n",
      "[epoch 291, batch    23] loss: 125.13388\n",
      "[epoch 291, batch    24] loss: 140.51583\n",
      "[epoch 291, batch    25] loss: 150.97046\n",
      "[epoch 291, batch    26] loss: 136.49579\n",
      "[epoch 291, batch    27] loss: 133.47857\n",
      "[epoch 291, batch    28] loss: 138.53942\n",
      "[epoch 291, batch    29] loss: 124.59746\n",
      "[epoch 291, batch    30] loss: 128.52659\n",
      "[epoch 291, batch    31] loss: 130.58354\n",
      "[epoch 291, batch    32] loss: 30.87206\n",
      "[epoch 292, batch     1] loss: 123.71328\n",
      "[epoch 292, batch     2] loss: 125.98730\n",
      "[epoch 292, batch     3] loss: 127.92946\n",
      "[epoch 292, batch     4] loss: 129.10184\n",
      "[epoch 292, batch     5] loss: 132.27466\n",
      "[epoch 292, batch     6] loss: 132.36438\n",
      "[epoch 292, batch     7] loss: 139.14155\n",
      "[epoch 292, batch     8] loss: 132.97620\n",
      "[epoch 292, batch     9] loss: 142.60398\n",
      "[epoch 292, batch    10] loss: 127.30413\n",
      "[epoch 292, batch    11] loss: 131.51979\n",
      "[epoch 292, batch    12] loss: 141.99377\n",
      "[epoch 292, batch    13] loss: 131.70615\n",
      "[epoch 292, batch    14] loss: 136.37178\n",
      "[epoch 292, batch    15] loss: 122.77128\n",
      "[epoch 292, batch    16] loss: 123.68035\n",
      "[epoch 292, batch    17] loss: 133.86373\n",
      "[epoch 292, batch    18] loss: 135.75844\n",
      "[epoch 292, batch    19] loss: 117.99494\n",
      "[epoch 292, batch    20] loss: 137.17390\n",
      "[epoch 292, batch    21] loss: 127.26713\n",
      "[epoch 292, batch    22] loss: 141.24018\n",
      "[epoch 292, batch    23] loss: 141.08869\n",
      "[epoch 292, batch    24] loss: 159.27564\n",
      "[epoch 292, batch    25] loss: 139.50427\n",
      "[epoch 292, batch    26] loss: 123.32504\n",
      "[epoch 292, batch    27] loss: 126.72890\n",
      "[epoch 292, batch    28] loss: 145.66409\n",
      "[epoch 292, batch    29] loss: 128.75602\n",
      "[epoch 292, batch    30] loss: 123.87658\n",
      "[epoch 292, batch    31] loss: 139.16159\n",
      "[epoch 292, batch    32] loss: 33.88588\n",
      "[epoch 293, batch     1] loss: 130.26873\n",
      "[epoch 293, batch     2] loss: 117.04404\n",
      "[epoch 293, batch     3] loss: 133.52591\n",
      "[epoch 293, batch     4] loss: 135.22776\n",
      "[epoch 293, batch     5] loss: 130.69983\n",
      "[epoch 293, batch     6] loss: 127.60876\n",
      "[epoch 293, batch     7] loss: 135.99594\n",
      "[epoch 293, batch     8] loss: 142.37518\n",
      "[epoch 293, batch     9] loss: 130.97061\n",
      "[epoch 293, batch    10] loss: 130.72480\n",
      "[epoch 293, batch    11] loss: 139.75255\n",
      "[epoch 293, batch    12] loss: 123.10064\n",
      "[epoch 293, batch    13] loss: 130.32131\n",
      "[epoch 293, batch    14] loss: 128.02554\n",
      "[epoch 293, batch    15] loss: 129.92206\n",
      "[epoch 293, batch    16] loss: 138.26264\n",
      "[epoch 293, batch    17] loss: 114.73158\n",
      "[epoch 293, batch    18] loss: 120.89093\n",
      "[epoch 293, batch    19] loss: 139.72413\n",
      "[epoch 293, batch    20] loss: 134.30880\n",
      "[epoch 293, batch    21] loss: 132.86777\n",
      "[epoch 293, batch    22] loss: 127.43321\n",
      "[epoch 293, batch    23] loss: 137.97479\n",
      "[epoch 293, batch    24] loss: 125.99330\n",
      "[epoch 293, batch    25] loss: 129.43807\n",
      "[epoch 293, batch    26] loss: 126.41381\n",
      "[epoch 293, batch    27] loss: 128.12448\n",
      "[epoch 293, batch    28] loss: 128.49759\n",
      "[epoch 293, batch    29] loss: 129.97403\n",
      "[epoch 293, batch    30] loss: 132.36451\n",
      "[epoch 293, batch    31] loss: 131.09246\n",
      "[epoch 293, batch    32] loss: 36.20385\n",
      "[epoch 294, batch     1] loss: 138.41288\n",
      "[epoch 294, batch     2] loss: 131.48267\n",
      "[epoch 294, batch     3] loss: 150.64303\n",
      "[epoch 294, batch     4] loss: 138.21106\n",
      "[epoch 294, batch     5] loss: 134.81448\n",
      "[epoch 294, batch     6] loss: 127.98824\n",
      "[epoch 294, batch     7] loss: 126.15833\n",
      "[epoch 294, batch     8] loss: 134.17627\n",
      "[epoch 294, batch     9] loss: 125.73152\n",
      "[epoch 294, batch    10] loss: 127.01606\n",
      "[epoch 294, batch    11] loss: 130.70353\n",
      "[epoch 294, batch    12] loss: 139.95766\n",
      "[epoch 294, batch    13] loss: 141.94991\n",
      "[epoch 294, batch    14] loss: 144.53670\n",
      "[epoch 294, batch    15] loss: 136.80074\n",
      "[epoch 294, batch    16] loss: 135.99109\n",
      "[epoch 294, batch    17] loss: 131.12283\n",
      "[epoch 294, batch    18] loss: 135.97294\n",
      "[epoch 294, batch    19] loss: 124.96475\n",
      "[epoch 294, batch    20] loss: 127.11058\n",
      "[epoch 294, batch    21] loss: 133.16280\n",
      "[epoch 294, batch    22] loss: 128.52179\n",
      "[epoch 294, batch    23] loss: 122.63639\n",
      "[epoch 294, batch    24] loss: 130.85854\n",
      "[epoch 294, batch    25] loss: 142.28900\n",
      "[epoch 294, batch    26] loss: 137.61529\n",
      "[epoch 294, batch    27] loss: 130.50864\n",
      "[epoch 294, batch    28] loss: 131.71560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 294, batch    29] loss: 135.34976\n",
      "[epoch 294, batch    30] loss: 131.30569\n",
      "[epoch 294, batch    31] loss: 133.72290\n",
      "[epoch 294, batch    32] loss: 31.48660\n",
      "[epoch 295, batch     1] loss: 131.80137\n",
      "[epoch 295, batch     2] loss: 136.23872\n",
      "[epoch 295, batch     3] loss: 128.60804\n",
      "[epoch 295, batch     4] loss: 142.35429\n",
      "[epoch 295, batch     5] loss: 137.10525\n",
      "[epoch 295, batch     6] loss: 139.84817\n",
      "[epoch 295, batch     7] loss: 127.64029\n",
      "[epoch 295, batch     8] loss: 129.09925\n",
      "[epoch 295, batch     9] loss: 133.15767\n",
      "[epoch 295, batch    10] loss: 131.61602\n",
      "[epoch 295, batch    11] loss: 132.01681\n",
      "[epoch 295, batch    12] loss: 153.12363\n",
      "[epoch 295, batch    13] loss: 140.53056\n",
      "[epoch 295, batch    14] loss: 136.10675\n",
      "[epoch 295, batch    15] loss: 128.67036\n",
      "[epoch 295, batch    16] loss: 131.04111\n",
      "[epoch 295, batch    17] loss: 130.10783\n",
      "[epoch 295, batch    18] loss: 136.50245\n",
      "[epoch 295, batch    19] loss: 128.76181\n",
      "[epoch 295, batch    20] loss: 127.73081\n",
      "[epoch 295, batch    21] loss: 126.75956\n",
      "[epoch 295, batch    22] loss: 122.60647\n",
      "[epoch 295, batch    23] loss: 126.98179\n",
      "[epoch 295, batch    24] loss: 135.68923\n",
      "[epoch 295, batch    25] loss: 124.94984\n",
      "[epoch 295, batch    26] loss: 125.86592\n",
      "[epoch 295, batch    27] loss: 134.33725\n",
      "[epoch 295, batch    28] loss: 136.65705\n",
      "[epoch 295, batch    29] loss: 123.15609\n",
      "[epoch 295, batch    30] loss: 127.45594\n",
      "[epoch 295, batch    31] loss: 121.78625\n",
      "[epoch 295, batch    32] loss: 30.50967\n",
      "[epoch 296, batch     1] loss: 124.11734\n",
      "[epoch 296, batch     2] loss: 122.35256\n",
      "[epoch 296, batch     3] loss: 122.30096\n",
      "[epoch 296, batch     4] loss: 139.45071\n",
      "[epoch 296, batch     5] loss: 125.51900\n",
      "[epoch 296, batch     6] loss: 125.58820\n",
      "[epoch 296, batch     7] loss: 130.52321\n",
      "[epoch 296, batch     8] loss: 129.50324\n",
      "[epoch 296, batch     9] loss: 125.25158\n",
      "[epoch 296, batch    10] loss: 129.79732\n",
      "[epoch 296, batch    11] loss: 125.66819\n",
      "[epoch 296, batch    12] loss: 141.19408\n",
      "[epoch 296, batch    13] loss: 132.56704\n",
      "[epoch 296, batch    14] loss: 136.55338\n",
      "[epoch 296, batch    15] loss: 134.18663\n",
      "[epoch 296, batch    16] loss: 136.19392\n",
      "[epoch 296, batch    17] loss: 120.89255\n",
      "[epoch 296, batch    18] loss: 127.19333\n",
      "[epoch 296, batch    19] loss: 127.12352\n",
      "[epoch 296, batch    20] loss: 121.03232\n",
      "[epoch 296, batch    21] loss: 138.45755\n",
      "[epoch 296, batch    22] loss: 136.08010\n",
      "[epoch 296, batch    23] loss: 134.01644\n",
      "[epoch 296, batch    24] loss: 133.65725\n",
      "[epoch 296, batch    25] loss: 131.31897\n",
      "[epoch 296, batch    26] loss: 121.49777\n",
      "[epoch 296, batch    27] loss: 128.76482\n",
      "[epoch 296, batch    28] loss: 127.61666\n",
      "[epoch 296, batch    29] loss: 114.75791\n",
      "[epoch 296, batch    30] loss: 132.65327\n",
      "[epoch 296, batch    31] loss: 125.65537\n",
      "[epoch 296, batch    32] loss: 35.26989\n",
      "[epoch 297, batch     1] loss: 119.24007\n",
      "[epoch 297, batch     2] loss: 152.03631\n",
      "[epoch 297, batch     3] loss: 122.46746\n",
      "[epoch 297, batch     4] loss: 124.89525\n",
      "[epoch 297, batch     5] loss: 128.21538\n",
      "[epoch 297, batch     6] loss: 141.03004\n",
      "[epoch 297, batch     7] loss: 129.33220\n",
      "[epoch 297, batch     8] loss: 137.54491\n",
      "[epoch 297, batch     9] loss: 122.59850\n",
      "[epoch 297, batch    10] loss: 149.23200\n",
      "[epoch 297, batch    11] loss: 138.16100\n",
      "[epoch 297, batch    12] loss: 132.56189\n",
      "[epoch 297, batch    13] loss: 152.24256\n",
      "[epoch 297, batch    14] loss: 125.71242\n",
      "[epoch 297, batch    15] loss: 130.95576\n",
      "[epoch 297, batch    16] loss: 139.58751\n",
      "[epoch 297, batch    17] loss: 129.50024\n",
      "[epoch 297, batch    18] loss: 124.60351\n",
      "[epoch 297, batch    19] loss: 116.66525\n",
      "[epoch 297, batch    20] loss: 139.18130\n",
      "[epoch 297, batch    21] loss: 117.74532\n",
      "[epoch 297, batch    22] loss: 121.88266\n",
      "[epoch 297, batch    23] loss: 145.69348\n",
      "[epoch 297, batch    24] loss: 129.59299\n",
      "[epoch 297, batch    25] loss: 133.46877\n",
      "[epoch 297, batch    26] loss: 138.04217\n",
      "[epoch 297, batch    27] loss: 135.57597\n",
      "[epoch 297, batch    28] loss: 135.78852\n",
      "[epoch 297, batch    29] loss: 134.67156\n",
      "[epoch 297, batch    30] loss: 137.53689\n",
      "[epoch 297, batch    31] loss: 137.70686\n",
      "[epoch 297, batch    32] loss: 28.96874\n",
      "[epoch 298, batch     1] loss: 137.05503\n",
      "[epoch 298, batch     2] loss: 125.94781\n",
      "[epoch 298, batch     3] loss: 121.50899\n",
      "[epoch 298, batch     4] loss: 129.15496\n",
      "[epoch 298, batch     5] loss: 130.72213\n",
      "[epoch 298, batch     6] loss: 136.73339\n",
      "[epoch 298, batch     7] loss: 142.96966\n",
      "[epoch 298, batch     8] loss: 124.53658\n",
      "[epoch 298, batch     9] loss: 127.80040\n",
      "[epoch 298, batch    10] loss: 134.09300\n",
      "[epoch 298, batch    11] loss: 132.07266\n",
      "[epoch 298, batch    12] loss: 141.63176\n",
      "[epoch 298, batch    13] loss: 133.15976\n",
      "[epoch 298, batch    14] loss: 129.51975\n",
      "[epoch 298, batch    15] loss: 126.22604\n",
      "[epoch 298, batch    16] loss: 139.11082\n",
      "[epoch 298, batch    17] loss: 127.89924\n",
      "[epoch 298, batch    18] loss: 117.89874\n",
      "[epoch 298, batch    19] loss: 140.54843\n",
      "[epoch 298, batch    20] loss: 142.74556\n",
      "[epoch 298, batch    21] loss: 136.26250\n",
      "[epoch 298, batch    22] loss: 134.58433\n",
      "[epoch 298, batch    23] loss: 137.28998\n",
      "[epoch 298, batch    24] loss: 118.34819\n",
      "[epoch 298, batch    25] loss: 136.29741\n",
      "[epoch 298, batch    26] loss: 123.22452\n",
      "[epoch 298, batch    27] loss: 122.90687\n",
      "[epoch 298, batch    28] loss: 133.20296\n",
      "[epoch 298, batch    29] loss: 127.07942\n",
      "[epoch 298, batch    30] loss: 134.06124\n",
      "[epoch 298, batch    31] loss: 147.24777\n",
      "[epoch 298, batch    32] loss: 27.12158\n",
      "[epoch 299, batch     1] loss: 134.62376\n",
      "[epoch 299, batch     2] loss: 121.25116\n",
      "[epoch 299, batch     3] loss: 132.72714\n",
      "[epoch 299, batch     4] loss: 140.86776\n",
      "[epoch 299, batch     5] loss: 133.17337\n",
      "[epoch 299, batch     6] loss: 124.66739\n",
      "[epoch 299, batch     7] loss: 118.40414\n",
      "[epoch 299, batch     8] loss: 131.22205\n",
      "[epoch 299, batch     9] loss: 131.86178\n",
      "[epoch 299, batch    10] loss: 136.17888\n",
      "[epoch 299, batch    11] loss: 133.45664\n",
      "[epoch 299, batch    12] loss: 141.40872\n",
      "[epoch 299, batch    13] loss: 138.82774\n",
      "[epoch 299, batch    14] loss: 139.93523\n",
      "[epoch 299, batch    15] loss: 124.66337\n",
      "[epoch 299, batch    16] loss: 128.00152\n",
      "[epoch 299, batch    17] loss: 116.29426\n",
      "[epoch 299, batch    18] loss: 127.76615\n",
      "[epoch 299, batch    19] loss: 139.60794\n",
      "[epoch 299, batch    20] loss: 136.09133\n",
      "[epoch 299, batch    21] loss: 133.54486\n",
      "[epoch 299, batch    22] loss: 136.65986\n",
      "[epoch 299, batch    23] loss: 135.51785\n",
      "[epoch 299, batch    24] loss: 130.54975\n",
      "[epoch 299, batch    25] loss: 133.93273\n",
      "[epoch 299, batch    26] loss: 130.54100\n",
      "[epoch 299, batch    27] loss: 135.32186\n",
      "[epoch 299, batch    28] loss: 126.05861\n",
      "[epoch 299, batch    29] loss: 145.49009\n",
      "[epoch 299, batch    30] loss: 121.21121\n",
      "[epoch 299, batch    31] loss: 123.74014\n",
      "[epoch 299, batch    32] loss: 34.04255\n",
      "[epoch 300, batch     1] loss: 138.93431\n",
      "[epoch 300, batch     2] loss: 142.65162\n",
      "[epoch 300, batch     3] loss: 127.85682\n",
      "[epoch 300, batch     4] loss: 128.98892\n",
      "[epoch 300, batch     5] loss: 129.57014\n",
      "[epoch 300, batch     6] loss: 131.65512\n",
      "[epoch 300, batch     7] loss: 133.05074\n",
      "[epoch 300, batch     8] loss: 135.33422\n",
      "[epoch 300, batch     9] loss: 132.97703\n",
      "[epoch 300, batch    10] loss: 123.59099\n",
      "[epoch 300, batch    11] loss: 126.33944\n",
      "[epoch 300, batch    12] loss: 121.68272\n",
      "[epoch 300, batch    13] loss: 128.31386\n",
      "[epoch 300, batch    14] loss: 130.16753\n",
      "[epoch 300, batch    15] loss: 148.77840\n",
      "[epoch 300, batch    16] loss: 137.41675\n",
      "[epoch 300, batch    17] loss: 143.47435\n",
      "[epoch 300, batch    18] loss: 134.34110\n",
      "[epoch 300, batch    19] loss: 138.73160\n",
      "[epoch 300, batch    20] loss: 132.57220\n",
      "[epoch 300, batch    21] loss: 131.77088\n",
      "[epoch 300, batch    22] loss: 142.24464\n",
      "[epoch 300, batch    23] loss: 132.03388\n",
      "[epoch 300, batch    24] loss: 124.46354\n",
      "[epoch 300, batch    25] loss: 124.75572\n",
      "[epoch 300, batch    26] loss: 138.70786\n",
      "[epoch 300, batch    27] loss: 126.82599\n",
      "[epoch 300, batch    28] loss: 144.93892\n",
      "[epoch 300, batch    29] loss: 121.15033\n",
      "[epoch 300, batch    30] loss: 157.62364\n",
      "[epoch 300, batch    31] loss: 129.42324\n",
      "[epoch 300, batch    32] loss: 34.25236\n",
      "[epoch 301, batch     1] loss: 128.62325\n",
      "[epoch 301, batch     2] loss: 132.82796\n",
      "[epoch 301, batch     3] loss: 121.25792\n",
      "[epoch 301, batch     4] loss: 135.79337\n",
      "[epoch 301, batch     5] loss: 148.05368\n",
      "[epoch 301, batch     6] loss: 139.37893\n",
      "[epoch 301, batch     7] loss: 133.07691\n",
      "[epoch 301, batch     8] loss: 143.90655\n",
      "[epoch 301, batch     9] loss: 122.37445\n",
      "[epoch 301, batch    10] loss: 143.33369\n",
      "[epoch 301, batch    11] loss: 136.32031\n",
      "[epoch 301, batch    12] loss: 131.87449\n",
      "[epoch 301, batch    13] loss: 120.83403\n",
      "[epoch 301, batch    14] loss: 142.34208\n",
      "[epoch 301, batch    15] loss: 119.92230\n",
      "[epoch 301, batch    16] loss: 138.05722\n",
      "[epoch 301, batch    17] loss: 124.79908\n",
      "[epoch 301, batch    18] loss: 136.86001\n",
      "[epoch 301, batch    19] loss: 128.93523\n",
      "[epoch 301, batch    20] loss: 133.53559\n",
      "[epoch 301, batch    21] loss: 131.26535\n",
      "[epoch 301, batch    22] loss: 133.40390\n",
      "[epoch 301, batch    23] loss: 126.47223\n",
      "[epoch 301, batch    24] loss: 127.49199\n",
      "[epoch 301, batch    25] loss: 135.59122\n",
      "[epoch 301, batch    26] loss: 116.33408\n",
      "[epoch 301, batch    27] loss: 126.67746\n",
      "[epoch 301, batch    28] loss: 124.50963\n",
      "[epoch 301, batch    29] loss: 125.51143\n",
      "[epoch 301, batch    30] loss: 127.22384\n",
      "[epoch 301, batch    31] loss: 145.17103\n",
      "[epoch 301, batch    32] loss: 33.11173\n",
      "[epoch 302, batch     1] loss: 123.40838\n",
      "[epoch 302, batch     2] loss: 125.02026\n",
      "[epoch 302, batch     3] loss: 132.64101\n",
      "[epoch 302, batch     4] loss: 141.61586\n",
      "[epoch 302, batch     5] loss: 146.07130\n",
      "[epoch 302, batch     6] loss: 136.92139\n",
      "[epoch 302, batch     7] loss: 127.94821\n",
      "[epoch 302, batch     8] loss: 136.35676\n",
      "[epoch 302, batch     9] loss: 127.44772\n",
      "[epoch 302, batch    10] loss: 141.72859\n",
      "[epoch 302, batch    11] loss: 127.73982\n",
      "[epoch 302, batch    12] loss: 129.13949\n",
      "[epoch 302, batch    13] loss: 125.77139\n",
      "[epoch 302, batch    14] loss: 125.97374\n",
      "[epoch 302, batch    15] loss: 127.02382\n",
      "[epoch 302, batch    16] loss: 127.86554\n",
      "[epoch 302, batch    17] loss: 133.96079\n",
      "[epoch 302, batch    18] loss: 130.67605\n",
      "[epoch 302, batch    19] loss: 137.50213\n",
      "[epoch 302, batch    20] loss: 132.72884\n",
      "[epoch 302, batch    21] loss: 135.64438\n",
      "[epoch 302, batch    22] loss: 135.98927\n",
      "[epoch 302, batch    23] loss: 131.44367\n",
      "[epoch 302, batch    24] loss: 156.32270\n",
      "[epoch 302, batch    25] loss: 128.89646\n",
      "[epoch 302, batch    26] loss: 122.40068\n",
      "[epoch 302, batch    27] loss: 132.38321\n",
      "[epoch 302, batch    28] loss: 132.21511\n",
      "[epoch 302, batch    29] loss: 141.97176\n",
      "[epoch 302, batch    30] loss: 139.96967\n",
      "[epoch 302, batch    31] loss: 122.82878\n",
      "[epoch 302, batch    32] loss: 37.07268\n",
      "[epoch 303, batch     1] loss: 131.84840\n",
      "[epoch 303, batch     2] loss: 140.63761\n",
      "[epoch 303, batch     3] loss: 137.35312\n",
      "[epoch 303, batch     4] loss: 136.74580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 303, batch     5] loss: 124.64282\n",
      "[epoch 303, batch     6] loss: 138.59266\n",
      "[epoch 303, batch     7] loss: 146.94790\n",
      "[epoch 303, batch     8] loss: 135.11240\n",
      "[epoch 303, batch     9] loss: 142.33895\n",
      "[epoch 303, batch    10] loss: 134.22372\n",
      "[epoch 303, batch    11] loss: 131.93388\n",
      "[epoch 303, batch    12] loss: 137.11253\n",
      "[epoch 303, batch    13] loss: 132.76013\n",
      "[epoch 303, batch    14] loss: 127.45196\n",
      "[epoch 303, batch    15] loss: 133.17325\n",
      "[epoch 303, batch    16] loss: 130.18063\n",
      "[epoch 303, batch    17] loss: 120.52049\n",
      "[epoch 303, batch    18] loss: 121.85954\n",
      "[epoch 303, batch    19] loss: 130.90992\n",
      "[epoch 303, batch    20] loss: 116.73407\n",
      "[epoch 303, batch    21] loss: 130.70588\n",
      "[epoch 303, batch    22] loss: 127.66478\n",
      "[epoch 303, batch    23] loss: 141.92591\n",
      "[epoch 303, batch    24] loss: 138.05700\n",
      "[epoch 303, batch    25] loss: 133.90013\n",
      "[epoch 303, batch    26] loss: 144.87225\n",
      "[epoch 303, batch    27] loss: 142.15393\n",
      "[epoch 303, batch    28] loss: 123.89377\n",
      "[epoch 303, batch    29] loss: 119.40096\n",
      "[epoch 303, batch    30] loss: 139.91601\n",
      "[epoch 303, batch    31] loss: 144.32025\n",
      "[epoch 303, batch    32] loss: 28.76870\n",
      "[epoch 304, batch     1] loss: 130.85109\n",
      "[epoch 304, batch     2] loss: 143.11706\n",
      "[epoch 304, batch     3] loss: 121.77080\n",
      "[epoch 304, batch     4] loss: 130.56577\n",
      "[epoch 304, batch     5] loss: 132.92737\n",
      "[epoch 304, batch     6] loss: 138.42978\n",
      "[epoch 304, batch     7] loss: 118.93321\n",
      "[epoch 304, batch     8] loss: 135.61432\n",
      "[epoch 304, batch     9] loss: 140.93377\n",
      "[epoch 304, batch    10] loss: 130.00187\n",
      "[epoch 304, batch    11] loss: 120.04499\n",
      "[epoch 304, batch    12] loss: 138.85888\n",
      "[epoch 304, batch    13] loss: 119.03407\n",
      "[epoch 304, batch    14] loss: 133.91261\n",
      "[epoch 304, batch    15] loss: 131.22911\n",
      "[epoch 304, batch    16] loss: 132.01812\n",
      "[epoch 304, batch    17] loss: 133.58346\n",
      "[epoch 304, batch    18] loss: 119.55640\n",
      "[epoch 304, batch    19] loss: 121.38169\n",
      "[epoch 304, batch    20] loss: 133.59072\n",
      "[epoch 304, batch    21] loss: 131.73497\n",
      "[epoch 304, batch    22] loss: 127.09737\n",
      "[epoch 304, batch    23] loss: 120.56985\n",
      "[epoch 304, batch    24] loss: 139.81328\n",
      "[epoch 304, batch    25] loss: 141.01841\n",
      "[epoch 304, batch    26] loss: 122.57774\n",
      "[epoch 304, batch    27] loss: 116.11345\n",
      "[epoch 304, batch    28] loss: 136.25839\n",
      "[epoch 304, batch    29] loss: 122.07185\n",
      "[epoch 304, batch    30] loss: 124.46751\n",
      "[epoch 304, batch    31] loss: 138.58976\n",
      "[epoch 304, batch    32] loss: 31.10244\n",
      "[epoch 305, batch     1] loss: 130.91574\n",
      "[epoch 305, batch     2] loss: 135.78462\n",
      "[epoch 305, batch     3] loss: 143.72242\n",
      "[epoch 305, batch     4] loss: 122.37790\n",
      "[epoch 305, batch     5] loss: 138.40205\n",
      "[epoch 305, batch     6] loss: 136.90507\n",
      "[epoch 305, batch     7] loss: 136.55330\n",
      "[epoch 305, batch     8] loss: 135.62335\n",
      "[epoch 305, batch     9] loss: 141.52846\n",
      "[epoch 305, batch    10] loss: 132.60170\n",
      "[epoch 305, batch    11] loss: 136.65137\n",
      "[epoch 305, batch    12] loss: 125.05174\n",
      "[epoch 305, batch    13] loss: 136.98781\n",
      "[epoch 305, batch    14] loss: 136.47485\n",
      "[epoch 305, batch    15] loss: 136.51970\n",
      "[epoch 305, batch    16] loss: 140.55620\n",
      "[epoch 305, batch    17] loss: 140.88462\n",
      "[epoch 305, batch    18] loss: 123.13171\n",
      "[epoch 305, batch    19] loss: 118.00059\n",
      "[epoch 305, batch    20] loss: 125.14949\n",
      "[epoch 305, batch    21] loss: 127.06355\n",
      "[epoch 305, batch    22] loss: 127.10821\n",
      "[epoch 305, batch    23] loss: 114.39449\n",
      "[epoch 305, batch    24] loss: 136.48590\n",
      "[epoch 305, batch    25] loss: 137.52473\n",
      "[epoch 305, batch    26] loss: 127.28917\n",
      "[epoch 305, batch    27] loss: 141.18791\n",
      "[epoch 305, batch    28] loss: 128.72599\n",
      "[epoch 305, batch    29] loss: 125.69897\n",
      "[epoch 305, batch    30] loss: 137.15185\n",
      "[epoch 305, batch    31] loss: 122.98353\n",
      "[epoch 305, batch    32] loss: 27.19245\n",
      "[epoch 306, batch     1] loss: 126.86817\n",
      "[epoch 306, batch     2] loss: 129.18662\n",
      "[epoch 306, batch     3] loss: 135.05554\n",
      "[epoch 306, batch     4] loss: 140.82081\n",
      "[epoch 306, batch     5] loss: 129.54419\n",
      "[epoch 306, batch     6] loss: 125.31742\n",
      "[epoch 306, batch     7] loss: 126.27024\n",
      "[epoch 306, batch     8] loss: 129.84038\n",
      "[epoch 306, batch     9] loss: 125.78802\n",
      "[epoch 306, batch    10] loss: 130.52844\n",
      "[epoch 306, batch    11] loss: 139.98026\n",
      "[epoch 306, batch    12] loss: 127.88387\n",
      "[epoch 306, batch    13] loss: 126.59749\n",
      "[epoch 306, batch    14] loss: 134.93695\n",
      "[epoch 306, batch    15] loss: 129.25626\n",
      "[epoch 306, batch    16] loss: 127.06698\n",
      "[epoch 306, batch    17] loss: 135.12400\n",
      "[epoch 306, batch    18] loss: 127.46519\n",
      "[epoch 306, batch    19] loss: 147.40596\n",
      "[epoch 306, batch    20] loss: 126.04922\n",
      "[epoch 306, batch    21] loss: 115.49561\n",
      "[epoch 306, batch    22] loss: 140.13870\n",
      "[epoch 306, batch    23] loss: 127.29337\n",
      "[epoch 306, batch    24] loss: 133.74199\n",
      "[epoch 306, batch    25] loss: 131.30893\n",
      "[epoch 306, batch    26] loss: 132.92440\n",
      "[epoch 306, batch    27] loss: 126.55823\n",
      "[epoch 306, batch    28] loss: 128.96307\n",
      "[epoch 306, batch    29] loss: 135.72917\n",
      "[epoch 306, batch    30] loss: 128.92236\n",
      "[epoch 306, batch    31] loss: 136.51884\n",
      "[epoch 306, batch    32] loss: 30.33255\n",
      "[epoch 307, batch     1] loss: 133.67400\n",
      "[epoch 307, batch     2] loss: 118.09259\n",
      "[epoch 307, batch     3] loss: 128.41508\n",
      "[epoch 307, batch     4] loss: 124.31970\n",
      "[epoch 307, batch     5] loss: 137.76091\n",
      "[epoch 307, batch     6] loss: 138.61527\n",
      "[epoch 307, batch     7] loss: 121.38869\n",
      "[epoch 307, batch     8] loss: 126.03735\n",
      "[epoch 307, batch     9] loss: 133.06672\n",
      "[epoch 307, batch    10] loss: 124.32139\n",
      "[epoch 307, batch    11] loss: 128.64334\n",
      "[epoch 307, batch    12] loss: 124.03992\n",
      "[epoch 307, batch    13] loss: 132.54383\n",
      "[epoch 307, batch    14] loss: 137.36606\n",
      "[epoch 307, batch    15] loss: 132.97874\n",
      "[epoch 307, batch    16] loss: 133.67592\n",
      "[epoch 307, batch    17] loss: 140.39156\n",
      "[epoch 307, batch    18] loss: 141.51082\n",
      "[epoch 307, batch    19] loss: 127.08962\n",
      "[epoch 307, batch    20] loss: 130.02607\n",
      "[epoch 307, batch    21] loss: 144.94586\n",
      "[epoch 307, batch    22] loss: 128.34534\n",
      "[epoch 307, batch    23] loss: 127.71198\n",
      "[epoch 307, batch    24] loss: 135.13827\n",
      "[epoch 307, batch    25] loss: 134.56553\n",
      "[epoch 307, batch    26] loss: 131.74376\n",
      "[epoch 307, batch    27] loss: 123.56663\n",
      "[epoch 307, batch    28] loss: 137.46624\n",
      "[epoch 307, batch    29] loss: 137.64433\n",
      "[epoch 307, batch    30] loss: 139.27170\n",
      "[epoch 307, batch    31] loss: 121.21767\n",
      "[epoch 307, batch    32] loss: 30.73867\n",
      "[epoch 308, batch     1] loss: 143.22317\n",
      "[epoch 308, batch     2] loss: 128.26528\n",
      "[epoch 308, batch     3] loss: 135.54707\n",
      "[epoch 308, batch     4] loss: 133.05585\n",
      "[epoch 308, batch     5] loss: 128.79621\n",
      "[epoch 308, batch     6] loss: 134.16100\n",
      "[epoch 308, batch     7] loss: 124.84038\n",
      "[epoch 308, batch     8] loss: 129.92891\n",
      "[epoch 308, batch     9] loss: 117.80125\n",
      "[epoch 308, batch    10] loss: 129.98198\n",
      "[epoch 308, batch    11] loss: 118.67759\n",
      "[epoch 308, batch    12] loss: 135.51202\n",
      "[epoch 308, batch    13] loss: 135.68191\n",
      "[epoch 308, batch    14] loss: 137.65934\n",
      "[epoch 308, batch    15] loss: 135.49490\n",
      "[epoch 308, batch    16] loss: 130.52595\n",
      "[epoch 308, batch    17] loss: 129.97834\n",
      "[epoch 308, batch    18] loss: 115.79790\n",
      "[epoch 308, batch    19] loss: 143.75933\n",
      "[epoch 308, batch    20] loss: 129.55304\n",
      "[epoch 308, batch    21] loss: 138.79617\n",
      "[epoch 308, batch    22] loss: 134.77981\n",
      "[epoch 308, batch    23] loss: 145.54087\n",
      "[epoch 308, batch    24] loss: 125.72905\n",
      "[epoch 308, batch    25] loss: 137.79389\n",
      "[epoch 308, batch    26] loss: 134.38652\n",
      "[epoch 308, batch    27] loss: 128.14895\n",
      "[epoch 308, batch    28] loss: 129.60339\n",
      "[epoch 308, batch    29] loss: 120.97397\n",
      "[epoch 308, batch    30] loss: 111.84385\n",
      "[epoch 308, batch    31] loss: 129.27531\n",
      "[epoch 308, batch    32] loss: 30.94326\n",
      "[epoch 309, batch     1] loss: 130.43856\n",
      "[epoch 309, batch     2] loss: 143.51223\n",
      "[epoch 309, batch     3] loss: 122.81130\n",
      "[epoch 309, batch     4] loss: 136.69551\n",
      "[epoch 309, batch     5] loss: 122.80219\n",
      "[epoch 309, batch     6] loss: 119.41382\n",
      "[epoch 309, batch     7] loss: 131.20220\n",
      "[epoch 309, batch     8] loss: 123.07517\n",
      "[epoch 309, batch     9] loss: 141.02814\n",
      "[epoch 309, batch    10] loss: 130.74030\n",
      "[epoch 309, batch    11] loss: 141.16111\n",
      "[epoch 309, batch    12] loss: 137.65888\n",
      "[epoch 309, batch    13] loss: 149.58615\n",
      "[epoch 309, batch    14] loss: 135.71841\n",
      "[epoch 309, batch    15] loss: 139.38007\n",
      "[epoch 309, batch    16] loss: 127.10026\n",
      "[epoch 309, batch    17] loss: 133.71861\n",
      "[epoch 309, batch    18] loss: 137.90612\n",
      "[epoch 309, batch    19] loss: 116.23326\n",
      "[epoch 309, batch    20] loss: 131.99665\n",
      "[epoch 309, batch    21] loss: 113.78151\n",
      "[epoch 309, batch    22] loss: 129.88582\n",
      "[epoch 309, batch    23] loss: 142.83478\n",
      "[epoch 309, batch    24] loss: 136.84723\n",
      "[epoch 309, batch    25] loss: 126.62221\n",
      "[epoch 309, batch    26] loss: 133.95961\n",
      "[epoch 309, batch    27] loss: 126.52465\n",
      "[epoch 309, batch    28] loss: 124.87310\n",
      "[epoch 309, batch    29] loss: 142.40157\n",
      "[epoch 309, batch    30] loss: 127.96195\n",
      "[epoch 309, batch    31] loss: 123.32426\n",
      "[epoch 309, batch    32] loss: 30.27061\n",
      "[epoch 310, batch     1] loss: 127.50463\n",
      "[epoch 310, batch     2] loss: 152.15549\n",
      "[epoch 310, batch     3] loss: 132.75469\n",
      "[epoch 310, batch     4] loss: 123.43805\n",
      "[epoch 310, batch     5] loss: 129.63948\n",
      "[epoch 310, batch     6] loss: 136.83824\n",
      "[epoch 310, batch     7] loss: 131.06245\n",
      "[epoch 310, batch     8] loss: 123.03054\n",
      "[epoch 310, batch     9] loss: 119.93585\n",
      "[epoch 310, batch    10] loss: 132.70160\n",
      "[epoch 310, batch    11] loss: 126.85447\n",
      "[epoch 310, batch    12] loss: 136.18127\n",
      "[epoch 310, batch    13] loss: 124.58559\n",
      "[epoch 310, batch    14] loss: 121.44942\n",
      "[epoch 310, batch    15] loss: 138.15948\n",
      "[epoch 310, batch    16] loss: 121.23493\n",
      "[epoch 310, batch    17] loss: 135.10026\n",
      "[epoch 310, batch    18] loss: 123.37471\n",
      "[epoch 310, batch    19] loss: 139.89674\n",
      "[epoch 310, batch    20] loss: 148.19488\n",
      "[epoch 310, batch    21] loss: 121.27916\n",
      "[epoch 310, batch    22] loss: 124.61240\n",
      "[epoch 310, batch    23] loss: 133.25061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 310, batch    24] loss: 131.79958\n",
      "[epoch 310, batch    25] loss: 131.81581\n",
      "[epoch 310, batch    26] loss: 140.03508\n",
      "[epoch 310, batch    27] loss: 142.58035\n",
      "[epoch 310, batch    28] loss: 135.98209\n",
      "[epoch 310, batch    29] loss: 126.23910\n",
      "[epoch 310, batch    30] loss: 124.21544\n",
      "[epoch 310, batch    31] loss: 121.04549\n",
      "[epoch 310, batch    32] loss: 29.84664\n",
      "[epoch 311, batch     1] loss: 133.96418\n",
      "[epoch 311, batch     2] loss: 135.27493\n",
      "[epoch 311, batch     3] loss: 130.63713\n",
      "[epoch 311, batch     4] loss: 132.43168\n",
      "[epoch 311, batch     5] loss: 134.46759\n",
      "[epoch 311, batch     6] loss: 114.93206\n",
      "[epoch 311, batch     7] loss: 142.02883\n",
      "[epoch 311, batch     8] loss: 133.16043\n",
      "[epoch 311, batch     9] loss: 125.32816\n",
      "[epoch 311, batch    10] loss: 142.08536\n",
      "[epoch 311, batch    11] loss: 123.36456\n",
      "[epoch 311, batch    12] loss: 137.99077\n",
      "[epoch 311, batch    13] loss: 125.96005\n",
      "[epoch 311, batch    14] loss: 127.14118\n",
      "[epoch 311, batch    15] loss: 149.13155\n",
      "[epoch 311, batch    16] loss: 129.80316\n",
      "[epoch 311, batch    17] loss: 128.68873\n",
      "[epoch 311, batch    18] loss: 138.23819\n",
      "[epoch 311, batch    19] loss: 135.33891\n",
      "[epoch 311, batch    20] loss: 129.15164\n",
      "[epoch 311, batch    21] loss: 141.91568\n",
      "[epoch 311, batch    22] loss: 126.93709\n",
      "[epoch 311, batch    23] loss: 129.86140\n",
      "[epoch 311, batch    24] loss: 137.55571\n",
      "[epoch 311, batch    25] loss: 132.75915\n",
      "[epoch 311, batch    26] loss: 131.83513\n",
      "[epoch 311, batch    27] loss: 131.89044\n",
      "[epoch 311, batch    28] loss: 133.01964\n",
      "[epoch 311, batch    29] loss: 121.67071\n",
      "[epoch 311, batch    30] loss: 124.00533\n",
      "[epoch 311, batch    31] loss: 132.18261\n",
      "[epoch 311, batch    32] loss: 32.77765\n",
      "[epoch 312, batch     1] loss: 122.55979\n",
      "[epoch 312, batch     2] loss: 131.26494\n",
      "[epoch 312, batch     3] loss: 136.95472\n",
      "[epoch 312, batch     4] loss: 149.55930\n",
      "[epoch 312, batch     5] loss: 145.69035\n",
      "[epoch 312, batch     6] loss: 123.06119\n",
      "[epoch 312, batch     7] loss: 124.03577\n",
      "[epoch 312, batch     8] loss: 125.96974\n",
      "[epoch 312, batch     9] loss: 133.15663\n",
      "[epoch 312, batch    10] loss: 129.93292\n",
      "[epoch 312, batch    11] loss: 151.65093\n",
      "[epoch 312, batch    12] loss: 136.97044\n",
      "[epoch 312, batch    13] loss: 130.98306\n",
      "[epoch 312, batch    14] loss: 131.10290\n",
      "[epoch 312, batch    15] loss: 124.78248\n",
      "[epoch 312, batch    16] loss: 132.18749\n",
      "[epoch 312, batch    17] loss: 138.17762\n",
      "[epoch 312, batch    18] loss: 139.81632\n",
      "[epoch 312, batch    19] loss: 135.54088\n",
      "[epoch 312, batch    20] loss: 131.84592\n",
      "[epoch 312, batch    21] loss: 116.83750\n",
      "[epoch 312, batch    22] loss: 125.07474\n",
      "[epoch 312, batch    23] loss: 121.47098\n",
      "[epoch 312, batch    24] loss: 122.10034\n",
      "[epoch 312, batch    25] loss: 121.30375\n",
      "[epoch 312, batch    26] loss: 131.10875\n",
      "[epoch 312, batch    27] loss: 129.70402\n",
      "[epoch 312, batch    28] loss: 117.60625\n",
      "[epoch 312, batch    29] loss: 143.94128\n",
      "[epoch 312, batch    30] loss: 132.06760\n",
      "[epoch 312, batch    31] loss: 124.23958\n",
      "[epoch 312, batch    32] loss: 34.91598\n",
      "[epoch 313, batch     1] loss: 124.93358\n",
      "[epoch 313, batch     2] loss: 136.08348\n",
      "[epoch 313, batch     3] loss: 137.90413\n",
      "[epoch 313, batch     4] loss: 138.05665\n",
      "[epoch 313, batch     5] loss: 122.69805\n",
      "[epoch 313, batch     6] loss: 137.20153\n",
      "[epoch 313, batch     7] loss: 129.54964\n",
      "[epoch 313, batch     8] loss: 141.81904\n",
      "[epoch 313, batch     9] loss: 125.60714\n",
      "[epoch 313, batch    10] loss: 145.32882\n",
      "[epoch 313, batch    11] loss: 133.65354\n",
      "[epoch 313, batch    12] loss: 119.76587\n",
      "[epoch 313, batch    13] loss: 121.34324\n",
      "[epoch 313, batch    14] loss: 128.54005\n",
      "[epoch 313, batch    15] loss: 131.55873\n",
      "[epoch 313, batch    16] loss: 135.77737\n",
      "[epoch 313, batch    17] loss: 130.49199\n",
      "[epoch 313, batch    18] loss: 125.15090\n",
      "[epoch 313, batch    19] loss: 130.23125\n",
      "[epoch 313, batch    20] loss: 130.81429\n",
      "[epoch 313, batch    21] loss: 136.48040\n",
      "[epoch 313, batch    22] loss: 138.40617\n",
      "[epoch 313, batch    23] loss: 126.40894\n",
      "[epoch 313, batch    24] loss: 122.60270\n",
      "[epoch 313, batch    25] loss: 139.68776\n",
      "[epoch 313, batch    26] loss: 150.20986\n",
      "[epoch 313, batch    27] loss: 139.30208\n",
      "[epoch 313, batch    28] loss: 131.91081\n",
      "[epoch 313, batch    29] loss: 136.47890\n",
      "[epoch 313, batch    30] loss: 128.28912\n",
      "[epoch 313, batch    31] loss: 136.28878\n",
      "[epoch 313, batch    32] loss: 32.09689\n",
      "[epoch 314, batch     1] loss: 125.06229\n",
      "[epoch 314, batch     2] loss: 138.58639\n",
      "[epoch 314, batch     3] loss: 139.48311\n",
      "[epoch 314, batch     4] loss: 135.70659\n",
      "[epoch 314, batch     5] loss: 140.31024\n",
      "[epoch 314, batch     6] loss: 130.42297\n",
      "[epoch 314, batch     7] loss: 131.32488\n",
      "[epoch 314, batch     8] loss: 128.56598\n",
      "[epoch 314, batch     9] loss: 129.89264\n",
      "[epoch 314, batch    10] loss: 137.60361\n",
      "[epoch 314, batch    11] loss: 125.89602\n",
      "[epoch 314, batch    12] loss: 130.68406\n",
      "[epoch 314, batch    13] loss: 133.99897\n",
      "[epoch 314, batch    14] loss: 147.39063\n",
      "[epoch 314, batch    15] loss: 124.78256\n",
      "[epoch 314, batch    16] loss: 147.21912\n",
      "[epoch 314, batch    17] loss: 134.31254\n",
      "[epoch 314, batch    18] loss: 142.42502\n",
      "[epoch 314, batch    19] loss: 129.69673\n",
      "[epoch 314, batch    20] loss: 142.25699\n",
      "[epoch 314, batch    21] loss: 125.86556\n",
      "[epoch 314, batch    22] loss: 138.82403\n",
      "[epoch 314, batch    23] loss: 127.35730\n",
      "[epoch 314, batch    24] loss: 129.91826\n",
      "[epoch 314, batch    25] loss: 138.13443\n",
      "[epoch 314, batch    26] loss: 121.22750\n",
      "[epoch 314, batch    27] loss: 121.99655\n",
      "[epoch 314, batch    28] loss: 137.66259\n",
      "[epoch 314, batch    29] loss: 129.25328\n",
      "[epoch 314, batch    30] loss: 134.37670\n",
      "[epoch 314, batch    31] loss: 120.30976\n",
      "[epoch 314, batch    32] loss: 34.46795\n",
      "[epoch 315, batch     1] loss: 143.70125\n",
      "[epoch 315, batch     2] loss: 119.63735\n",
      "[epoch 315, batch     3] loss: 126.14200\n",
      "[epoch 315, batch     4] loss: 136.96715\n",
      "[epoch 315, batch     5] loss: 126.70627\n",
      "[epoch 315, batch     6] loss: 127.73037\n",
      "[epoch 315, batch     7] loss: 131.84497\n",
      "[epoch 315, batch     8] loss: 134.06387\n",
      "[epoch 315, batch     9] loss: 133.06345\n",
      "[epoch 315, batch    10] loss: 133.80672\n",
      "[epoch 315, batch    11] loss: 126.67928\n",
      "[epoch 315, batch    12] loss: 126.27940\n",
      "[epoch 315, batch    13] loss: 119.64480\n",
      "[epoch 315, batch    14] loss: 137.94683\n",
      "[epoch 315, batch    15] loss: 130.34374\n",
      "[epoch 315, batch    16] loss: 130.41516\n",
      "[epoch 315, batch    17] loss: 132.91215\n",
      "[epoch 315, batch    18] loss: 131.05904\n",
      "[epoch 315, batch    19] loss: 146.02184\n",
      "[epoch 315, batch    20] loss: 141.64877\n",
      "[epoch 315, batch    21] loss: 131.34130\n",
      "[epoch 315, batch    22] loss: 122.79527\n",
      "[epoch 315, batch    23] loss: 121.06579\n",
      "[epoch 315, batch    24] loss: 135.30588\n",
      "[epoch 315, batch    25] loss: 138.76799\n",
      "[epoch 315, batch    26] loss: 132.58999\n",
      "[epoch 315, batch    27] loss: 139.61179\n",
      "[epoch 315, batch    28] loss: 129.58245\n",
      "[epoch 315, batch    29] loss: 135.06685\n",
      "[epoch 315, batch    30] loss: 143.87781\n",
      "[epoch 315, batch    31] loss: 131.45981\n",
      "[epoch 315, batch    32] loss: 32.82591\n",
      "[epoch 316, batch     1] loss: 136.26863\n",
      "[epoch 316, batch     2] loss: 138.61990\n",
      "[epoch 316, batch     3] loss: 134.98633\n",
      "[epoch 316, batch     4] loss: 140.45412\n",
      "[epoch 316, batch     5] loss: 124.33559\n",
      "[epoch 316, batch     6] loss: 136.80890\n",
      "[epoch 316, batch     7] loss: 134.86115\n",
      "[epoch 316, batch     8] loss: 119.93250\n",
      "[epoch 316, batch     9] loss: 144.86050\n",
      "[epoch 316, batch    10] loss: 136.40148\n",
      "[epoch 316, batch    11] loss: 134.35852\n",
      "[epoch 316, batch    12] loss: 127.13554\n",
      "[epoch 316, batch    13] loss: 140.40847\n",
      "[epoch 316, batch    14] loss: 116.99512\n",
      "[epoch 316, batch    15] loss: 120.03102\n",
      "[epoch 316, batch    16] loss: 117.30397\n",
      "[epoch 316, batch    17] loss: 127.19700\n",
      "[epoch 316, batch    18] loss: 126.75381\n",
      "[epoch 316, batch    19] loss: 130.00155\n",
      "[epoch 316, batch    20] loss: 134.45522\n",
      "[epoch 316, batch    21] loss: 128.04332\n",
      "[epoch 316, batch    22] loss: 140.25909\n",
      "[epoch 316, batch    23] loss: 143.61097\n",
      "[epoch 316, batch    24] loss: 128.59603\n",
      "[epoch 316, batch    25] loss: 127.85901\n",
      "[epoch 316, batch    26] loss: 135.91499\n",
      "[epoch 316, batch    27] loss: 129.29396\n",
      "[epoch 316, batch    28] loss: 129.17446\n",
      "[epoch 316, batch    29] loss: 141.10630\n",
      "[epoch 316, batch    30] loss: 134.60378\n",
      "[epoch 316, batch    31] loss: 131.76959\n",
      "[epoch 316, batch    32] loss: 31.03374\n",
      "[epoch 317, batch     1] loss: 135.33802\n",
      "[epoch 317, batch     2] loss: 128.69971\n",
      "[epoch 317, batch     3] loss: 124.54646\n",
      "[epoch 317, batch     4] loss: 133.43931\n",
      "[epoch 317, batch     5] loss: 130.01864\n",
      "[epoch 317, batch     6] loss: 108.58512\n",
      "[epoch 317, batch     7] loss: 120.67346\n",
      "[epoch 317, batch     8] loss: 132.45217\n",
      "[epoch 317, batch     9] loss: 114.30496\n",
      "[epoch 317, batch    10] loss: 139.91161\n",
      "[epoch 317, batch    11] loss: 125.15123\n",
      "[epoch 317, batch    12] loss: 138.80353\n",
      "[epoch 317, batch    13] loss: 127.60454\n",
      "[epoch 317, batch    14] loss: 136.40581\n",
      "[epoch 317, batch    15] loss: 133.61073\n",
      "[epoch 317, batch    16] loss: 138.01027\n",
      "[epoch 317, batch    17] loss: 141.72867\n",
      "[epoch 317, batch    18] loss: 127.69895\n",
      "[epoch 317, batch    19] loss: 121.66424\n",
      "[epoch 317, batch    20] loss: 142.12307\n",
      "[epoch 317, batch    21] loss: 133.31026\n",
      "[epoch 317, batch    22] loss: 147.40125\n",
      "[epoch 317, batch    23] loss: 130.06794\n",
      "[epoch 317, batch    24] loss: 114.57645\n",
      "[epoch 317, batch    25] loss: 144.92914\n",
      "[epoch 317, batch    26] loss: 143.81470\n",
      "[epoch 317, batch    27] loss: 157.06273\n",
      "[epoch 317, batch    28] loss: 132.48073\n",
      "[epoch 317, batch    29] loss: 131.56532\n",
      "[epoch 317, batch    30] loss: 131.14292\n",
      "[epoch 317, batch    31] loss: 126.02645\n",
      "[epoch 317, batch    32] loss: 33.98910\n",
      "[epoch 318, batch     1] loss: 122.12112\n",
      "[epoch 318, batch     2] loss: 134.56901\n",
      "[epoch 318, batch     3] loss: 131.30961\n",
      "[epoch 318, batch     4] loss: 130.64773\n",
      "[epoch 318, batch     5] loss: 128.23691\n",
      "[epoch 318, batch     6] loss: 118.20355\n",
      "[epoch 318, batch     7] loss: 134.83264\n",
      "[epoch 318, batch     8] loss: 133.58353\n",
      "[epoch 318, batch     9] loss: 136.71404\n",
      "[epoch 318, batch    10] loss: 133.04099\n",
      "[epoch 318, batch    11] loss: 130.69258\n",
      "[epoch 318, batch    12] loss: 125.57692\n",
      "[epoch 318, batch    13] loss: 130.56918\n",
      "[epoch 318, batch    14] loss: 126.02663\n",
      "[epoch 318, batch    15] loss: 145.79067\n",
      "[epoch 318, batch    16] loss: 120.42001\n",
      "[epoch 318, batch    17] loss: 129.10120\n",
      "[epoch 318, batch    18] loss: 126.59872\n",
      "[epoch 318, batch    19] loss: 137.14039\n",
      "[epoch 318, batch    20] loss: 132.66522\n",
      "[epoch 318, batch    21] loss: 137.89147\n",
      "[epoch 318, batch    22] loss: 143.87367\n",
      "[epoch 318, batch    23] loss: 115.71447\n",
      "[epoch 318, batch    24] loss: 128.28146\n",
      "[epoch 318, batch    25] loss: 133.57894\n",
      "[epoch 318, batch    26] loss: 136.08134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 318, batch    27] loss: 136.79061\n",
      "[epoch 318, batch    28] loss: 127.57498\n",
      "[epoch 318, batch    29] loss: 138.90421\n",
      "[epoch 318, batch    30] loss: 133.08431\n",
      "[epoch 318, batch    31] loss: 137.31756\n",
      "[epoch 318, batch    32] loss: 30.49335\n",
      "[epoch 319, batch     1] loss: 140.91507\n",
      "[epoch 319, batch     2] loss: 139.85301\n",
      "[epoch 319, batch     3] loss: 133.51405\n",
      "[epoch 319, batch     4] loss: 128.13375\n",
      "[epoch 319, batch     5] loss: 130.94783\n",
      "[epoch 319, batch     6] loss: 123.22345\n",
      "[epoch 319, batch     7] loss: 128.90640\n",
      "[epoch 319, batch     8] loss: 132.29747\n",
      "[epoch 319, batch     9] loss: 132.50675\n",
      "[epoch 319, batch    10] loss: 142.36599\n",
      "[epoch 319, batch    11] loss: 124.48996\n",
      "[epoch 319, batch    12] loss: 132.61694\n",
      "[epoch 319, batch    13] loss: 121.79694\n",
      "[epoch 319, batch    14] loss: 135.39939\n",
      "[epoch 319, batch    15] loss: 120.16792\n",
      "[epoch 319, batch    16] loss: 139.86999\n",
      "[epoch 319, batch    17] loss: 138.19647\n",
      "[epoch 319, batch    18] loss: 129.78193\n",
      "[epoch 319, batch    19] loss: 128.19965\n",
      "[epoch 319, batch    20] loss: 139.14146\n",
      "[epoch 319, batch    21] loss: 137.59283\n",
      "[epoch 319, batch    22] loss: 135.77974\n",
      "[epoch 319, batch    23] loss: 131.05374\n",
      "[epoch 319, batch    24] loss: 142.62062\n",
      "[epoch 319, batch    25] loss: 129.86745\n",
      "[epoch 319, batch    26] loss: 149.84268\n",
      "[epoch 319, batch    27] loss: 125.89713\n",
      "[epoch 319, batch    28] loss: 137.38274\n",
      "[epoch 319, batch    29] loss: 135.39319\n",
      "[epoch 319, batch    30] loss: 137.05287\n",
      "[epoch 319, batch    31] loss: 127.10863\n",
      "[epoch 319, batch    32] loss: 37.38430\n",
      "[epoch 320, batch     1] loss: 128.87930\n",
      "[epoch 320, batch     2] loss: 139.62295\n",
      "[epoch 320, batch     3] loss: 127.21267\n",
      "[epoch 320, batch     4] loss: 132.06107\n",
      "[epoch 320, batch     5] loss: 133.26193\n",
      "[epoch 320, batch     6] loss: 136.00873\n",
      "[epoch 320, batch     7] loss: 122.46873\n",
      "[epoch 320, batch     8] loss: 126.88322\n",
      "[epoch 320, batch     9] loss: 134.91424\n",
      "[epoch 320, batch    10] loss: 119.55672\n",
      "[epoch 320, batch    11] loss: 134.15310\n",
      "[epoch 320, batch    12] loss: 137.23324\n",
      "[epoch 320, batch    13] loss: 129.20338\n",
      "[epoch 320, batch    14] loss: 127.38854\n",
      "[epoch 320, batch    15] loss: 141.57799\n",
      "[epoch 320, batch    16] loss: 121.76019\n",
      "[epoch 320, batch    17] loss: 127.30067\n",
      "[epoch 320, batch    18] loss: 135.83687\n",
      "[epoch 320, batch    19] loss: 136.42344\n",
      "[epoch 320, batch    20] loss: 128.50741\n",
      "[epoch 320, batch    21] loss: 134.81969\n",
      "[epoch 320, batch    22] loss: 129.74356\n",
      "[epoch 320, batch    23] loss: 134.67410\n",
      "[epoch 320, batch    24] loss: 130.31536\n",
      "[epoch 320, batch    25] loss: 128.58623\n",
      "[epoch 320, batch    26] loss: 151.65854\n",
      "[epoch 320, batch    27] loss: 141.70760\n",
      "[epoch 320, batch    28] loss: 134.04934\n",
      "[epoch 320, batch    29] loss: 147.34863\n",
      "[epoch 320, batch    30] loss: 132.60643\n",
      "[epoch 320, batch    31] loss: 135.65757\n",
      "[epoch 320, batch    32] loss: 36.39088\n",
      "[epoch 321, batch     1] loss: 130.21063\n",
      "[epoch 321, batch     2] loss: 133.83592\n",
      "[epoch 321, batch     3] loss: 128.54872\n",
      "[epoch 321, batch     4] loss: 129.04033\n",
      "[epoch 321, batch     5] loss: 129.87253\n",
      "[epoch 321, batch     6] loss: 140.64980\n",
      "[epoch 321, batch     7] loss: 141.83416\n",
      "[epoch 321, batch     8] loss: 134.34271\n",
      "[epoch 321, batch     9] loss: 139.06596\n",
      "[epoch 321, batch    10] loss: 131.33145\n",
      "[epoch 321, batch    11] loss: 138.69269\n",
      "[epoch 321, batch    12] loss: 128.44627\n",
      "[epoch 321, batch    13] loss: 138.59256\n",
      "[epoch 321, batch    14] loss: 142.41599\n",
      "[epoch 321, batch    15] loss: 115.54446\n",
      "[epoch 321, batch    16] loss: 134.80760\n",
      "[epoch 321, batch    17] loss: 130.07842\n",
      "[epoch 321, batch    18] loss: 138.38355\n",
      "[epoch 321, batch    19] loss: 131.68789\n",
      "[epoch 321, batch    20] loss: 135.14684\n",
      "[epoch 321, batch    21] loss: 117.60066\n",
      "[epoch 321, batch    22] loss: 131.37581\n",
      "[epoch 321, batch    23] loss: 134.43724\n",
      "[epoch 321, batch    24] loss: 133.23252\n",
      "[epoch 321, batch    25] loss: 122.65244\n",
      "[epoch 321, batch    26] loss: 137.81633\n",
      "[epoch 321, batch    27] loss: 135.29467\n",
      "[epoch 321, batch    28] loss: 141.56265\n",
      "[epoch 321, batch    29] loss: 130.79572\n",
      "[epoch 321, batch    30] loss: 119.67909\n",
      "[epoch 321, batch    31] loss: 134.65826\n",
      "[epoch 321, batch    32] loss: 43.38354\n",
      "[epoch 322, batch     1] loss: 147.48994\n",
      "[epoch 322, batch     2] loss: 137.83263\n",
      "[epoch 322, batch     3] loss: 131.89660\n",
      "[epoch 322, batch     4] loss: 140.24041\n",
      "[epoch 322, batch     5] loss: 120.69722\n",
      "[epoch 322, batch     6] loss: 135.61113\n",
      "[epoch 322, batch     7] loss: 131.94754\n",
      "[epoch 322, batch     8] loss: 138.21909\n",
      "[epoch 322, batch     9] loss: 138.64248\n",
      "[epoch 322, batch    10] loss: 129.98641\n",
      "[epoch 322, batch    11] loss: 138.22452\n",
      "[epoch 322, batch    12] loss: 132.37908\n",
      "[epoch 322, batch    13] loss: 124.29563\n",
      "[epoch 322, batch    14] loss: 127.63550\n",
      "[epoch 322, batch    15] loss: 122.87652\n",
      "[epoch 322, batch    16] loss: 137.56673\n",
      "[epoch 322, batch    17] loss: 125.70306\n",
      "[epoch 322, batch    18] loss: 141.46164\n",
      "[epoch 322, batch    19] loss: 124.17405\n",
      "[epoch 322, batch    20] loss: 122.07269\n",
      "[epoch 322, batch    21] loss: 130.36729\n",
      "[epoch 322, batch    22] loss: 116.62466\n",
      "[epoch 322, batch    23] loss: 128.87299\n",
      "[epoch 322, batch    24] loss: 137.48330\n",
      "[epoch 322, batch    25] loss: 124.30465\n",
      "[epoch 322, batch    26] loss: 130.38878\n",
      "[epoch 322, batch    27] loss: 134.68644\n",
      "[epoch 322, batch    28] loss: 137.22671\n",
      "[epoch 322, batch    29] loss: 148.02619\n",
      "[epoch 322, batch    30] loss: 133.57144\n",
      "[epoch 322, batch    31] loss: 125.52501\n",
      "[epoch 322, batch    32] loss: 26.92261\n",
      "[epoch 323, batch     1] loss: 133.78898\n",
      "[epoch 323, batch     2] loss: 139.73576\n",
      "[epoch 323, batch     3] loss: 123.48977\n",
      "[epoch 323, batch     4] loss: 127.53041\n",
      "[epoch 323, batch     5] loss: 128.46777\n",
      "[epoch 323, batch     6] loss: 140.36078\n",
      "[epoch 323, batch     7] loss: 132.17920\n",
      "[epoch 323, batch     8] loss: 129.20545\n",
      "[epoch 323, batch     9] loss: 115.29773\n",
      "[epoch 323, batch    10] loss: 128.29441\n",
      "[epoch 323, batch    11] loss: 134.16943\n",
      "[epoch 323, batch    12] loss: 133.16738\n",
      "[epoch 323, batch    13] loss: 136.19617\n",
      "[epoch 323, batch    14] loss: 139.84132\n",
      "[epoch 323, batch    15] loss: 142.12608\n",
      "[epoch 323, batch    16] loss: 133.19524\n",
      "[epoch 323, batch    17] loss: 131.08768\n",
      "[epoch 323, batch    18] loss: 138.79162\n",
      "[epoch 323, batch    19] loss: 131.33485\n",
      "[epoch 323, batch    20] loss: 123.98997\n",
      "[epoch 323, batch    21] loss: 127.63484\n",
      "[epoch 323, batch    22] loss: 124.09761\n",
      "[epoch 323, batch    23] loss: 119.42135\n",
      "[epoch 323, batch    24] loss: 137.47173\n",
      "[epoch 323, batch    25] loss: 134.62469\n",
      "[epoch 323, batch    26] loss: 137.27036\n",
      "[epoch 323, batch    27] loss: 145.19545\n",
      "[epoch 323, batch    28] loss: 129.95072\n",
      "[epoch 323, batch    29] loss: 126.93829\n",
      "[epoch 323, batch    30] loss: 142.17198\n",
      "[epoch 323, batch    31] loss: 128.63073\n",
      "[epoch 323, batch    32] loss: 37.60049\n",
      "[epoch 324, batch     1] loss: 135.16570\n",
      "[epoch 324, batch     2] loss: 132.33276\n",
      "[epoch 324, batch     3] loss: 118.67931\n",
      "[epoch 324, batch     4] loss: 131.86020\n",
      "[epoch 324, batch     5] loss: 122.58136\n",
      "[epoch 324, batch     6] loss: 135.72696\n",
      "[epoch 324, batch     7] loss: 135.17924\n",
      "[epoch 324, batch     8] loss: 118.81648\n",
      "[epoch 324, batch     9] loss: 133.37941\n",
      "[epoch 324, batch    10] loss: 129.36830\n",
      "[epoch 324, batch    11] loss: 152.73472\n",
      "[epoch 324, batch    12] loss: 141.87447\n",
      "[epoch 324, batch    13] loss: 128.98717\n",
      "[epoch 324, batch    14] loss: 126.77955\n",
      "[epoch 324, batch    15] loss: 125.14696\n",
      "[epoch 324, batch    16] loss: 124.64946\n",
      "[epoch 324, batch    17] loss: 132.54418\n",
      "[epoch 324, batch    18] loss: 131.91126\n",
      "[epoch 324, batch    19] loss: 126.81881\n",
      "[epoch 324, batch    20] loss: 125.18843\n",
      "[epoch 324, batch    21] loss: 130.33286\n",
      "[epoch 324, batch    22] loss: 132.90794\n",
      "[epoch 324, batch    23] loss: 140.53947\n",
      "[epoch 324, batch    24] loss: 136.24968\n",
      "[epoch 324, batch    25] loss: 125.00286\n",
      "[epoch 324, batch    26] loss: 131.49381\n",
      "[epoch 324, batch    27] loss: 138.24901\n",
      "[epoch 324, batch    28] loss: 138.44126\n",
      "[epoch 324, batch    29] loss: 132.30228\n",
      "[epoch 324, batch    30] loss: 135.56406\n",
      "[epoch 324, batch    31] loss: 134.91699\n",
      "[epoch 324, batch    32] loss: 38.33811\n",
      "[epoch 325, batch     1] loss: 137.22587\n",
      "[epoch 325, batch     2] loss: 134.73277\n",
      "[epoch 325, batch     3] loss: 132.80941\n",
      "[epoch 325, batch     4] loss: 129.48180\n",
      "[epoch 325, batch     5] loss: 137.33852\n",
      "[epoch 325, batch     6] loss: 130.88887\n",
      "[epoch 325, batch     7] loss: 126.10028\n",
      "[epoch 325, batch     8] loss: 137.71554\n",
      "[epoch 325, batch     9] loss: 123.15974\n",
      "[epoch 325, batch    10] loss: 133.97969\n",
      "[epoch 325, batch    11] loss: 136.19928\n",
      "[epoch 325, batch    12] loss: 138.10208\n",
      "[epoch 325, batch    13] loss: 132.18106\n",
      "[epoch 325, batch    14] loss: 140.22211\n",
      "[epoch 325, batch    15] loss: 139.32150\n",
      "[epoch 325, batch    16] loss: 120.06157\n",
      "[epoch 325, batch    17] loss: 133.38110\n",
      "[epoch 325, batch    18] loss: 136.30477\n",
      "[epoch 325, batch    19] loss: 129.81229\n",
      "[epoch 325, batch    20] loss: 144.22659\n",
      "[epoch 325, batch    21] loss: 127.26237\n",
      "[epoch 325, batch    22] loss: 131.16514\n",
      "[epoch 325, batch    23] loss: 133.96378\n",
      "[epoch 325, batch    24] loss: 134.29904\n",
      "[epoch 325, batch    25] loss: 137.95152\n",
      "[epoch 325, batch    26] loss: 133.98228\n",
      "[epoch 325, batch    27] loss: 127.92633\n",
      "[epoch 325, batch    28] loss: 132.03728\n",
      "[epoch 325, batch    29] loss: 125.86930\n",
      "[epoch 325, batch    30] loss: 145.63602\n",
      "[epoch 325, batch    31] loss: 119.49092\n",
      "[epoch 325, batch    32] loss: 31.43222\n",
      "[epoch 326, batch     1] loss: 125.87362\n",
      "[epoch 326, batch     2] loss: 131.82279\n",
      "[epoch 326, batch     3] loss: 128.49666\n",
      "[epoch 326, batch     4] loss: 131.65693\n",
      "[epoch 326, batch     5] loss: 128.87017\n",
      "[epoch 326, batch     6] loss: 131.34913\n",
      "[epoch 326, batch     7] loss: 124.55457\n",
      "[epoch 326, batch     8] loss: 123.96973\n",
      "[epoch 326, batch     9] loss: 137.30929\n",
      "[epoch 326, batch    10] loss: 144.76995\n",
      "[epoch 326, batch    11] loss: 136.38109\n",
      "[epoch 326, batch    12] loss: 126.70224\n",
      "[epoch 326, batch    13] loss: 134.49665\n",
      "[epoch 326, batch    14] loss: 129.79407\n",
      "[epoch 326, batch    15] loss: 140.11812\n",
      "[epoch 326, batch    16] loss: 138.83906\n",
      "[epoch 326, batch    17] loss: 152.60364\n",
      "[epoch 326, batch    18] loss: 138.19266\n",
      "[epoch 326, batch    19] loss: 127.16682\n",
      "[epoch 326, batch    20] loss: 136.06112\n",
      "[epoch 326, batch    21] loss: 133.52456\n",
      "[epoch 326, batch    22] loss: 136.65693\n",
      "[epoch 326, batch    23] loss: 127.37955\n",
      "[epoch 326, batch    24] loss: 137.13141\n",
      "[epoch 326, batch    25] loss: 126.70286\n",
      "[epoch 326, batch    26] loss: 126.80827\n",
      "[epoch 326, batch    27] loss: 137.89591\n",
      "[epoch 326, batch    28] loss: 142.23108\n",
      "[epoch 326, batch    29] loss: 125.05606\n",
      "[epoch 326, batch    30] loss: 125.50169\n",
      "[epoch 326, batch    31] loss: 135.40171\n",
      "[epoch 326, batch    32] loss: 31.56642\n",
      "[epoch 327, batch     1] loss: 132.44854\n",
      "[epoch 327, batch     2] loss: 136.68003\n",
      "[epoch 327, batch     3] loss: 137.92326\n",
      "[epoch 327, batch     4] loss: 135.33671\n",
      "[epoch 327, batch     5] loss: 136.67781\n",
      "[epoch 327, batch     6] loss: 137.45430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 327, batch     7] loss: 133.93970\n",
      "[epoch 327, batch     8] loss: 135.06875\n",
      "[epoch 327, batch     9] loss: 139.55238\n",
      "[epoch 327, batch    10] loss: 143.24084\n",
      "[epoch 327, batch    11] loss: 133.04747\n",
      "[epoch 327, batch    12] loss: 134.21013\n",
      "[epoch 327, batch    13] loss: 128.68489\n",
      "[epoch 327, batch    14] loss: 131.54446\n",
      "[epoch 327, batch    15] loss: 128.49888\n",
      "[epoch 327, batch    16] loss: 130.96890\n",
      "[epoch 327, batch    17] loss: 138.39277\n",
      "[epoch 327, batch    18] loss: 124.48811\n",
      "[epoch 327, batch    19] loss: 132.75229\n",
      "[epoch 327, batch    20] loss: 123.62595\n",
      "[epoch 327, batch    21] loss: 126.46417\n",
      "[epoch 327, batch    22] loss: 134.30242\n",
      "[epoch 327, batch    23] loss: 138.27856\n",
      "[epoch 327, batch    24] loss: 143.00832\n",
      "[epoch 327, batch    25] loss: 129.01121\n",
      "[epoch 327, batch    26] loss: 123.20348\n",
      "[epoch 327, batch    27] loss: 138.15737\n",
      "[epoch 327, batch    28] loss: 134.17927\n",
      "[epoch 327, batch    29] loss: 136.28054\n",
      "[epoch 327, batch    30] loss: 139.65935\n",
      "[epoch 327, batch    31] loss: 143.33682\n",
      "[epoch 327, batch    32] loss: 31.13723\n",
      "[epoch 328, batch     1] loss: 126.81252\n",
      "[epoch 328, batch     2] loss: 122.48232\n",
      "[epoch 328, batch     3] loss: 130.05862\n",
      "[epoch 328, batch     4] loss: 143.50252\n",
      "[epoch 328, batch     5] loss: 131.65198\n",
      "[epoch 328, batch     6] loss: 126.79089\n",
      "[epoch 328, batch     7] loss: 129.50037\n",
      "[epoch 328, batch     8] loss: 120.26344\n",
      "[epoch 328, batch     9] loss: 140.24256\n",
      "[epoch 328, batch    10] loss: 131.94093\n",
      "[epoch 328, batch    11] loss: 141.26073\n",
      "[epoch 328, batch    12] loss: 133.58548\n",
      "[epoch 328, batch    13] loss: 144.40650\n",
      "[epoch 328, batch    14] loss: 117.69589\n",
      "[epoch 328, batch    15] loss: 138.31650\n",
      "[epoch 328, batch    16] loss: 124.96852\n",
      "[epoch 328, batch    17] loss: 133.44249\n",
      "[epoch 328, batch    18] loss: 136.11791\n",
      "[epoch 328, batch    19] loss: 143.61554\n",
      "[epoch 328, batch    20] loss: 142.53610\n",
      "[epoch 328, batch    21] loss: 136.19989\n",
      "[epoch 328, batch    22] loss: 138.10121\n",
      "[epoch 328, batch    23] loss: 130.30362\n",
      "[epoch 328, batch    24] loss: 136.98680\n",
      "[epoch 328, batch    25] loss: 137.90752\n",
      "[epoch 328, batch    26] loss: 123.14108\n",
      "[epoch 328, batch    27] loss: 122.96524\n",
      "[epoch 328, batch    28] loss: 133.00748\n",
      "[epoch 328, batch    29] loss: 135.26109\n",
      "[epoch 328, batch    30] loss: 132.25969\n",
      "[epoch 328, batch    31] loss: 134.36876\n",
      "[epoch 328, batch    32] loss: 31.81729\n",
      "[epoch 329, batch     1] loss: 130.31749\n",
      "[epoch 329, batch     2] loss: 132.45888\n",
      "[epoch 329, batch     3] loss: 133.72489\n",
      "[epoch 329, batch     4] loss: 140.41252\n",
      "[epoch 329, batch     5] loss: 131.10067\n",
      "[epoch 329, batch     6] loss: 139.81556\n",
      "[epoch 329, batch     7] loss: 130.40025\n",
      "[epoch 329, batch     8] loss: 125.51334\n",
      "[epoch 329, batch     9] loss: 131.42122\n",
      "[epoch 329, batch    10] loss: 142.78523\n",
      "[epoch 329, batch    11] loss: 124.13435\n",
      "[epoch 329, batch    12] loss: 145.04176\n",
      "[epoch 329, batch    13] loss: 129.20177\n",
      "[epoch 329, batch    14] loss: 126.85244\n",
      "[epoch 329, batch    15] loss: 140.61135\n",
      "[epoch 329, batch    16] loss: 134.33423\n",
      "[epoch 329, batch    17] loss: 128.13433\n",
      "[epoch 329, batch    18] loss: 134.15702\n",
      "[epoch 329, batch    19] loss: 121.94303\n",
      "[epoch 329, batch    20] loss: 126.47012\n",
      "[epoch 329, batch    21] loss: 138.67761\n",
      "[epoch 329, batch    22] loss: 130.79592\n",
      "[epoch 329, batch    23] loss: 126.73292\n",
      "[epoch 329, batch    24] loss: 140.68253\n",
      "[epoch 329, batch    25] loss: 135.19368\n",
      "[epoch 329, batch    26] loss: 127.52825\n",
      "[epoch 329, batch    27] loss: 118.38646\n",
      "[epoch 329, batch    28] loss: 123.54616\n",
      "[epoch 329, batch    29] loss: 133.64896\n",
      "[epoch 329, batch    30] loss: 119.93494\n",
      "[epoch 329, batch    31] loss: 138.35211\n",
      "[epoch 329, batch    32] loss: 32.37552\n",
      "[epoch 330, batch     1] loss: 133.12822\n",
      "[epoch 330, batch     2] loss: 133.78564\n",
      "[epoch 330, batch     3] loss: 126.18975\n",
      "[epoch 330, batch     4] loss: 125.29107\n",
      "[epoch 330, batch     5] loss: 119.07935\n",
      "[epoch 330, batch     6] loss: 126.36587\n",
      "[epoch 330, batch     7] loss: 137.61386\n",
      "[epoch 330, batch     8] loss: 143.20965\n",
      "[epoch 330, batch     9] loss: 131.69529\n",
      "[epoch 330, batch    10] loss: 119.77784\n",
      "[epoch 330, batch    11] loss: 131.55471\n",
      "[epoch 330, batch    12] loss: 131.37328\n",
      "[epoch 330, batch    13] loss: 137.22430\n",
      "[epoch 330, batch    14] loss: 136.32483\n",
      "[epoch 330, batch    15] loss: 126.39109\n",
      "[epoch 330, batch    16] loss: 124.88732\n",
      "[epoch 330, batch    17] loss: 126.13403\n",
      "[epoch 330, batch    18] loss: 132.64328\n",
      "[epoch 330, batch    19] loss: 154.77861\n",
      "[epoch 330, batch    20] loss: 123.32755\n",
      "[epoch 330, batch    21] loss: 113.63985\n",
      "[epoch 330, batch    22] loss: 136.05901\n",
      "[epoch 330, batch    23] loss: 119.15304\n",
      "[epoch 330, batch    24] loss: 128.12604\n",
      "[epoch 330, batch    25] loss: 133.73173\n",
      "[epoch 330, batch    26] loss: 134.88995\n",
      "[epoch 330, batch    27] loss: 128.50484\n",
      "[epoch 330, batch    28] loss: 154.29328\n",
      "[epoch 330, batch    29] loss: 129.93913\n",
      "[epoch 330, batch    30] loss: 143.17419\n",
      "[epoch 330, batch    31] loss: 138.38958\n",
      "[epoch 330, batch    32] loss: 34.74373\n",
      "[epoch 331, batch     1] loss: 147.18444\n",
      "[epoch 331, batch     2] loss: 131.84155\n",
      "[epoch 331, batch     3] loss: 129.34226\n",
      "[epoch 331, batch     4] loss: 136.53824\n",
      "[epoch 331, batch     5] loss: 122.88089\n",
      "[epoch 331, batch     6] loss: 135.76324\n",
      "[epoch 331, batch     7] loss: 133.76522\n",
      "[epoch 331, batch     8] loss: 125.86937\n",
      "[epoch 331, batch     9] loss: 139.03018\n",
      "[epoch 331, batch    10] loss: 128.26075\n",
      "[epoch 331, batch    11] loss: 115.53625\n",
      "[epoch 331, batch    12] loss: 123.99095\n",
      "[epoch 331, batch    13] loss: 131.90324\n",
      "[epoch 331, batch    14] loss: 122.16697\n",
      "[epoch 331, batch    15] loss: 130.48263\n",
      "[epoch 331, batch    16] loss: 144.67854\n",
      "[epoch 331, batch    17] loss: 135.93978\n",
      "[epoch 331, batch    18] loss: 132.79584\n",
      "[epoch 331, batch    19] loss: 135.55166\n",
      "[epoch 331, batch    20] loss: 136.79132\n",
      "[epoch 331, batch    21] loss: 137.25915\n",
      "[epoch 331, batch    22] loss: 123.61372\n",
      "[epoch 331, batch    23] loss: 126.21858\n",
      "[epoch 331, batch    24] loss: 123.77229\n",
      "[epoch 331, batch    25] loss: 146.05755\n",
      "[epoch 331, batch    26] loss: 146.53641\n",
      "[epoch 331, batch    27] loss: 129.69326\n",
      "[epoch 331, batch    28] loss: 148.45603\n",
      "[epoch 331, batch    29] loss: 132.84281\n",
      "[epoch 331, batch    30] loss: 141.48620\n",
      "[epoch 331, batch    31] loss: 126.66193\n",
      "[epoch 331, batch    32] loss: 30.67250\n",
      "[epoch 332, batch     1] loss: 129.07219\n",
      "[epoch 332, batch     2] loss: 132.52291\n",
      "[epoch 332, batch     3] loss: 136.33788\n",
      "[epoch 332, batch     4] loss: 135.81044\n",
      "[epoch 332, batch     5] loss: 117.32269\n",
      "[epoch 332, batch     6] loss: 132.28886\n",
      "[epoch 332, batch     7] loss: 127.06329\n",
      "[epoch 332, batch     8] loss: 124.65281\n",
      "[epoch 332, batch     9] loss: 128.68330\n",
      "[epoch 332, batch    10] loss: 129.43797\n",
      "[epoch 332, batch    11] loss: 137.56750\n",
      "[epoch 332, batch    12] loss: 135.64556\n",
      "[epoch 332, batch    13] loss: 133.74067\n",
      "[epoch 332, batch    14] loss: 131.96301\n",
      "[epoch 332, batch    15] loss: 127.63158\n",
      "[epoch 332, batch    16] loss: 142.24247\n",
      "[epoch 332, batch    17] loss: 115.89647\n",
      "[epoch 332, batch    18] loss: 132.46324\n",
      "[epoch 332, batch    19] loss: 138.97846\n",
      "[epoch 332, batch    20] loss: 125.25827\n",
      "[epoch 332, batch    21] loss: 134.53606\n",
      "[epoch 332, batch    22] loss: 138.53962\n",
      "[epoch 332, batch    23] loss: 134.32225\n",
      "[epoch 332, batch    24] loss: 122.90672\n",
      "[epoch 332, batch    25] loss: 143.53131\n",
      "[epoch 332, batch    26] loss: 133.89510\n",
      "[epoch 332, batch    27] loss: 132.03111\n",
      "[epoch 332, batch    28] loss: 124.26609\n",
      "[epoch 332, batch    29] loss: 124.76532\n",
      "[epoch 332, batch    30] loss: 127.47722\n",
      "[epoch 332, batch    31] loss: 143.96429\n",
      "[epoch 332, batch    32] loss: 32.53633\n",
      "[epoch 333, batch     1] loss: 126.62442\n",
      "[epoch 333, batch     2] loss: 123.36744\n",
      "[epoch 333, batch     3] loss: 129.92279\n",
      "[epoch 333, batch     4] loss: 147.13000\n",
      "[epoch 333, batch     5] loss: 127.56429\n",
      "[epoch 333, batch     6] loss: 122.04447\n",
      "[epoch 333, batch     7] loss: 136.38900\n",
      "[epoch 333, batch     8] loss: 127.00673\n",
      "[epoch 333, batch     9] loss: 129.08502\n",
      "[epoch 333, batch    10] loss: 127.28940\n",
      "[epoch 333, batch    11] loss: 133.12128\n",
      "[epoch 333, batch    12] loss: 136.23205\n",
      "[epoch 333, batch    13] loss: 126.58020\n",
      "[epoch 333, batch    14] loss: 142.89486\n",
      "[epoch 333, batch    15] loss: 146.21395\n",
      "[epoch 333, batch    16] loss: 129.21987\n",
      "[epoch 333, batch    17] loss: 134.24165\n",
      "[epoch 333, batch    18] loss: 127.90613\n",
      "[epoch 333, batch    19] loss: 124.69341\n",
      "[epoch 333, batch    20] loss: 132.25809\n",
      "[epoch 333, batch    21] loss: 128.87134\n",
      "[epoch 333, batch    22] loss: 138.39763\n",
      "[epoch 333, batch    23] loss: 131.58757\n",
      "[epoch 333, batch    24] loss: 144.90094\n",
      "[epoch 333, batch    25] loss: 114.90385\n",
      "[epoch 333, batch    26] loss: 137.40065\n",
      "[epoch 333, batch    27] loss: 132.91365\n",
      "[epoch 333, batch    28] loss: 133.62323\n",
      "[epoch 333, batch    29] loss: 118.22398\n",
      "[epoch 333, batch    30] loss: 137.90585\n",
      "[epoch 333, batch    31] loss: 131.99087\n",
      "[epoch 333, batch    32] loss: 35.16138\n",
      "[epoch 334, batch     1] loss: 122.45707\n",
      "[epoch 334, batch     2] loss: 142.70536\n",
      "[epoch 334, batch     3] loss: 132.54904\n",
      "[epoch 334, batch     4] loss: 122.62197\n",
      "[epoch 334, batch     5] loss: 131.65577\n",
      "[epoch 334, batch     6] loss: 127.01496\n",
      "[epoch 334, batch     7] loss: 131.75777\n",
      "[epoch 334, batch     8] loss: 118.67165\n",
      "[epoch 334, batch     9] loss: 130.45525\n",
      "[epoch 334, batch    10] loss: 140.44926\n",
      "[epoch 334, batch    11] loss: 127.53325\n",
      "[epoch 334, batch    12] loss: 142.48216\n",
      "[epoch 334, batch    13] loss: 138.25428\n",
      "[epoch 334, batch    14] loss: 128.94850\n",
      "[epoch 334, batch    15] loss: 127.00709\n",
      "[epoch 334, batch    16] loss: 122.93912\n",
      "[epoch 334, batch    17] loss: 133.60398\n",
      "[epoch 334, batch    18] loss: 130.27884\n",
      "[epoch 334, batch    19] loss: 131.51957\n",
      "[epoch 334, batch    20] loss: 131.72707\n",
      "[epoch 334, batch    21] loss: 134.29461\n",
      "[epoch 334, batch    22] loss: 124.56308\n",
      "[epoch 334, batch    23] loss: 136.87367\n",
      "[epoch 334, batch    24] loss: 129.94530\n",
      "[epoch 334, batch    25] loss: 124.49812\n",
      "[epoch 334, batch    26] loss: 130.12467\n",
      "[epoch 334, batch    27] loss: 131.12364\n",
      "[epoch 334, batch    28] loss: 144.92955\n",
      "[epoch 334, batch    29] loss: 127.20293\n",
      "[epoch 334, batch    30] loss: 141.76759\n",
      "[epoch 334, batch    31] loss: 135.55087\n",
      "[epoch 334, batch    32] loss: 44.08521\n",
      "[epoch 335, batch     1] loss: 126.14595\n",
      "[epoch 335, batch     2] loss: 133.37943\n",
      "[epoch 335, batch     3] loss: 125.79174\n",
      "[epoch 335, batch     4] loss: 141.72621\n",
      "[epoch 335, batch     5] loss: 139.71339\n",
      "[epoch 335, batch     6] loss: 130.71809\n",
      "[epoch 335, batch     7] loss: 130.18711\n",
      "[epoch 335, batch     8] loss: 129.00897\n",
      "[epoch 335, batch     9] loss: 131.73962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 335, batch    10] loss: 136.71998\n",
      "[epoch 335, batch    11] loss: 129.59941\n",
      "[epoch 335, batch    12] loss: 135.44284\n",
      "[epoch 335, batch    13] loss: 123.99480\n",
      "[epoch 335, batch    14] loss: 127.78994\n",
      "[epoch 335, batch    15] loss: 127.25750\n",
      "[epoch 335, batch    16] loss: 131.23385\n",
      "[epoch 335, batch    17] loss: 136.17194\n",
      "[epoch 335, batch    18] loss: 138.49052\n",
      "[epoch 335, batch    19] loss: 140.57342\n",
      "[epoch 335, batch    20] loss: 135.40948\n",
      "[epoch 335, batch    21] loss: 133.41066\n",
      "[epoch 335, batch    22] loss: 141.80634\n",
      "[epoch 335, batch    23] loss: 130.56432\n",
      "[epoch 335, batch    24] loss: 137.94514\n",
      "[epoch 335, batch    25] loss: 128.23037\n",
      "[epoch 335, batch    26] loss: 135.62404\n",
      "[epoch 335, batch    27] loss: 145.13230\n",
      "[epoch 335, batch    28] loss: 128.39982\n",
      "[epoch 335, batch    29] loss: 125.95585\n",
      "[epoch 335, batch    30] loss: 124.91687\n",
      "[epoch 335, batch    31] loss: 132.42032\n",
      "[epoch 335, batch    32] loss: 33.06689\n",
      "[epoch 336, batch     1] loss: 133.93051\n",
      "[epoch 336, batch     2] loss: 141.19378\n",
      "[epoch 336, batch     3] loss: 132.12890\n",
      "[epoch 336, batch     4] loss: 132.31193\n",
      "[epoch 336, batch     5] loss: 136.57055\n",
      "[epoch 336, batch     6] loss: 126.79472\n",
      "[epoch 336, batch     7] loss: 125.34816\n",
      "[epoch 336, batch     8] loss: 120.16894\n",
      "[epoch 336, batch     9] loss: 140.21673\n",
      "[epoch 336, batch    10] loss: 130.57642\n",
      "[epoch 336, batch    11] loss: 142.56712\n",
      "[epoch 336, batch    12] loss: 142.90846\n",
      "[epoch 336, batch    13] loss: 140.52816\n",
      "[epoch 336, batch    14] loss: 146.13108\n",
      "[epoch 336, batch    15] loss: 124.95021\n",
      "[epoch 336, batch    16] loss: 138.14047\n",
      "[epoch 336, batch    17] loss: 129.76892\n",
      "[epoch 336, batch    18] loss: 123.77937\n",
      "[epoch 336, batch    19] loss: 132.02203\n",
      "[epoch 336, batch    20] loss: 121.57214\n",
      "[epoch 336, batch    21] loss: 118.70524\n",
      "[epoch 336, batch    22] loss: 139.14841\n",
      "[epoch 336, batch    23] loss: 119.88940\n",
      "[epoch 336, batch    24] loss: 127.94045\n",
      "[epoch 336, batch    25] loss: 134.81931\n",
      "[epoch 336, batch    26] loss: 142.46348\n",
      "[epoch 336, batch    27] loss: 154.65285\n",
      "[epoch 336, batch    28] loss: 129.88599\n",
      "[epoch 336, batch    29] loss: 131.18706\n",
      "[epoch 336, batch    30] loss: 138.50250\n",
      "[epoch 336, batch    31] loss: 132.85777\n",
      "[epoch 336, batch    32] loss: 31.85308\n",
      "[epoch 337, batch     1] loss: 149.11770\n",
      "[epoch 337, batch     2] loss: 140.71603\n",
      "[epoch 337, batch     3] loss: 134.19795\n",
      "[epoch 337, batch     4] loss: 122.02055\n",
      "[epoch 337, batch     5] loss: 131.76380\n",
      "[epoch 337, batch     6] loss: 128.62001\n",
      "[epoch 337, batch     7] loss: 130.96287\n",
      "[epoch 337, batch     8] loss: 141.32738\n",
      "[epoch 337, batch     9] loss: 130.84574\n",
      "[epoch 337, batch    10] loss: 135.68953\n",
      "[epoch 337, batch    11] loss: 121.28637\n",
      "[epoch 337, batch    12] loss: 134.53941\n",
      "[epoch 337, batch    13] loss: 136.47591\n",
      "[epoch 337, batch    14] loss: 133.47889\n",
      "[epoch 337, batch    15] loss: 138.67295\n",
      "[epoch 337, batch    16] loss: 135.09102\n",
      "[epoch 337, batch    17] loss: 126.97486\n",
      "[epoch 337, batch    18] loss: 116.09243\n",
      "[epoch 337, batch    19] loss: 129.61819\n",
      "[epoch 337, batch    20] loss: 133.71543\n",
      "[epoch 337, batch    21] loss: 144.35977\n",
      "[epoch 337, batch    22] loss: 128.63263\n",
      "[epoch 337, batch    23] loss: 146.85915\n",
      "[epoch 337, batch    24] loss: 132.98387\n",
      "[epoch 337, batch    25] loss: 119.56035\n",
      "[epoch 337, batch    26] loss: 115.37207\n",
      "[epoch 337, batch    27] loss: 129.17382\n",
      "[epoch 337, batch    28] loss: 136.09737\n",
      "[epoch 337, batch    29] loss: 121.94264\n",
      "[epoch 337, batch    30] loss: 131.87523\n",
      "[epoch 337, batch    31] loss: 132.34977\n",
      "[epoch 337, batch    32] loss: 32.50453\n",
      "[epoch 338, batch     1] loss: 121.15074\n",
      "[epoch 338, batch     2] loss: 136.76969\n",
      "[epoch 338, batch     3] loss: 131.01282\n",
      "[epoch 338, batch     4] loss: 143.56377\n",
      "[epoch 338, batch     5] loss: 148.94507\n",
      "[epoch 338, batch     6] loss: 131.56875\n",
      "[epoch 338, batch     7] loss: 117.53066\n",
      "[epoch 338, batch     8] loss: 122.86518\n",
      "[epoch 338, batch     9] loss: 125.98276\n",
      "[epoch 338, batch    10] loss: 130.98878\n",
      "[epoch 338, batch    11] loss: 116.27456\n",
      "[epoch 338, batch    12] loss: 149.53194\n",
      "[epoch 338, batch    13] loss: 127.94537\n",
      "[epoch 338, batch    14] loss: 136.65137\n",
      "[epoch 338, batch    15] loss: 138.55185\n",
      "[epoch 338, batch    16] loss: 138.03356\n",
      "[epoch 338, batch    17] loss: 122.46679\n",
      "[epoch 338, batch    18] loss: 142.42237\n",
      "[epoch 338, batch    19] loss: 135.03156\n",
      "[epoch 338, batch    20] loss: 139.52819\n",
      "[epoch 338, batch    21] loss: 123.57543\n",
      "[epoch 338, batch    22] loss: 122.99655\n",
      "[epoch 338, batch    23] loss: 134.93047\n",
      "[epoch 338, batch    24] loss: 123.36618\n",
      "[epoch 338, batch    25] loss: 138.79642\n",
      "[epoch 338, batch    26] loss: 130.49455\n",
      "[epoch 338, batch    27] loss: 125.16010\n",
      "[epoch 338, batch    28] loss: 124.10751\n",
      "[epoch 338, batch    29] loss: 137.58788\n",
      "[epoch 338, batch    30] loss: 139.09910\n",
      "[epoch 338, batch    31] loss: 140.19916\n",
      "[epoch 338, batch    32] loss: 29.58525\n",
      "[epoch 339, batch     1] loss: 132.68295\n",
      "[epoch 339, batch     2] loss: 129.21648\n",
      "[epoch 339, batch     3] loss: 124.42448\n",
      "[epoch 339, batch     4] loss: 141.12982\n",
      "[epoch 339, batch     5] loss: 122.56801\n",
      "[epoch 339, batch     6] loss: 134.81687\n",
      "[epoch 339, batch     7] loss: 124.08322\n",
      "[epoch 339, batch     8] loss: 142.06422\n",
      "[epoch 339, batch     9] loss: 116.06882\n",
      "[epoch 339, batch    10] loss: 136.18384\n",
      "[epoch 339, batch    11] loss: 128.90320\n",
      "[epoch 339, batch    12] loss: 123.18654\n",
      "[epoch 339, batch    13] loss: 129.52212\n",
      "[epoch 339, batch    14] loss: 143.17533\n",
      "[epoch 339, batch    15] loss: 132.60659\n",
      "[epoch 339, batch    16] loss: 123.48292\n",
      "[epoch 339, batch    17] loss: 129.23319\n",
      "[epoch 339, batch    18] loss: 143.35450\n",
      "[epoch 339, batch    19] loss: 139.95312\n",
      "[epoch 339, batch    20] loss: 130.02403\n",
      "[epoch 339, batch    21] loss: 136.38678\n",
      "[epoch 339, batch    22] loss: 141.47915\n",
      "[epoch 339, batch    23] loss: 141.57344\n",
      "[epoch 339, batch    24] loss: 134.00445\n",
      "[epoch 339, batch    25] loss: 131.40934\n",
      "[epoch 339, batch    26] loss: 129.76691\n",
      "[epoch 339, batch    27] loss: 142.20495\n",
      "[epoch 339, batch    28] loss: 131.59617\n",
      "[epoch 339, batch    29] loss: 133.20943\n",
      "[epoch 339, batch    30] loss: 133.12976\n",
      "[epoch 339, batch    31] loss: 129.93470\n",
      "[epoch 339, batch    32] loss: 32.96914\n",
      "[epoch 340, batch     1] loss: 133.06290\n",
      "[epoch 340, batch     2] loss: 140.29568\n",
      "[epoch 340, batch     3] loss: 133.92104\n",
      "[epoch 340, batch     4] loss: 130.28825\n",
      "[epoch 340, batch     5] loss: 132.69499\n",
      "[epoch 340, batch     6] loss: 140.38620\n",
      "[epoch 340, batch     7] loss: 125.82539\n",
      "[epoch 340, batch     8] loss: 135.86104\n",
      "[epoch 340, batch     9] loss: 136.69923\n",
      "[epoch 340, batch    10] loss: 128.91737\n",
      "[epoch 340, batch    11] loss: 138.31384\n",
      "[epoch 340, batch    12] loss: 127.80130\n",
      "[epoch 340, batch    13] loss: 143.64120\n",
      "[epoch 340, batch    14] loss: 120.86086\n",
      "[epoch 340, batch    15] loss: 138.50670\n",
      "[epoch 340, batch    16] loss: 128.80756\n",
      "[epoch 340, batch    17] loss: 127.11774\n",
      "[epoch 340, batch    18] loss: 129.41299\n",
      "[epoch 340, batch    19] loss: 134.49388\n",
      "[epoch 340, batch    20] loss: 128.84835\n",
      "[epoch 340, batch    21] loss: 137.45540\n",
      "[epoch 340, batch    22] loss: 127.38723\n",
      "[epoch 340, batch    23] loss: 144.43626\n",
      "[epoch 340, batch    24] loss: 138.23395\n",
      "[epoch 340, batch    25] loss: 131.79527\n",
      "[epoch 340, batch    26] loss: 122.01206\n",
      "[epoch 340, batch    27] loss: 125.41042\n",
      "[epoch 340, batch    28] loss: 144.72899\n",
      "[epoch 340, batch    29] loss: 126.44579\n",
      "[epoch 340, batch    30] loss: 131.78161\n",
      "[epoch 340, batch    31] loss: 125.07034\n",
      "[epoch 340, batch    32] loss: 33.49729\n",
      "[epoch 341, batch     1] loss: 131.79394\n",
      "[epoch 341, batch     2] loss: 123.70882\n",
      "[epoch 341, batch     3] loss: 130.20183\n",
      "[epoch 341, batch     4] loss: 132.55633\n",
      "[epoch 341, batch     5] loss: 139.07969\n",
      "[epoch 341, batch     6] loss: 143.43978\n",
      "[epoch 341, batch     7] loss: 138.25034\n",
      "[epoch 341, batch     8] loss: 134.47918\n",
      "[epoch 341, batch     9] loss: 123.54513\n",
      "[epoch 341, batch    10] loss: 136.11832\n",
      "[epoch 341, batch    11] loss: 139.46728\n",
      "[epoch 341, batch    12] loss: 125.70873\n",
      "[epoch 341, batch    13] loss: 144.18635\n",
      "[epoch 341, batch    14] loss: 138.78993\n",
      "[epoch 341, batch    15] loss: 129.82317\n",
      "[epoch 341, batch    16] loss: 144.71201\n",
      "[epoch 341, batch    17] loss: 126.28176\n",
      "[epoch 341, batch    18] loss: 127.16085\n",
      "[epoch 341, batch    19] loss: 122.22161\n",
      "[epoch 341, batch    20] loss: 128.43010\n",
      "[epoch 341, batch    21] loss: 130.48238\n",
      "[epoch 341, batch    22] loss: 138.06738\n",
      "[epoch 341, batch    23] loss: 127.91034\n",
      "[epoch 341, batch    24] loss: 129.81664\n",
      "[epoch 341, batch    25] loss: 140.40491\n",
      "[epoch 341, batch    26] loss: 133.91679\n",
      "[epoch 341, batch    27] loss: 147.32496\n",
      "[epoch 341, batch    28] loss: 144.65480\n",
      "[epoch 341, batch    29] loss: 126.08166\n",
      "[epoch 341, batch    30] loss: 121.78305\n",
      "[epoch 341, batch    31] loss: 135.20425\n",
      "[epoch 341, batch    32] loss: 33.41277\n",
      "[epoch 342, batch     1] loss: 123.77392\n",
      "[epoch 342, batch     2] loss: 124.24086\n",
      "[epoch 342, batch     3] loss: 129.42803\n",
      "[epoch 342, batch     4] loss: 131.97983\n",
      "[epoch 342, batch     5] loss: 117.67758\n",
      "[epoch 342, batch     6] loss: 134.01417\n",
      "[epoch 342, batch     7] loss: 141.53076\n",
      "[epoch 342, batch     8] loss: 147.70906\n",
      "[epoch 342, batch     9] loss: 137.81092\n",
      "[epoch 342, batch    10] loss: 129.49579\n",
      "[epoch 342, batch    11] loss: 130.05193\n",
      "[epoch 342, batch    12] loss: 143.83352\n",
      "[epoch 342, batch    13] loss: 150.52149\n",
      "[epoch 342, batch    14] loss: 141.34235\n",
      "[epoch 342, batch    15] loss: 130.01255\n",
      "[epoch 342, batch    16] loss: 137.43601\n",
      "[epoch 342, batch    17] loss: 129.08924\n",
      "[epoch 342, batch    18] loss: 128.73716\n",
      "[epoch 342, batch    19] loss: 133.85718\n",
      "[epoch 342, batch    20] loss: 138.49693\n",
      "[epoch 342, batch    21] loss: 133.97379\n",
      "[epoch 342, batch    22] loss: 141.85918\n",
      "[epoch 342, batch    23] loss: 131.47609\n",
      "[epoch 342, batch    24] loss: 119.01102\n",
      "[epoch 342, batch    25] loss: 130.57491\n",
      "[epoch 342, batch    26] loss: 127.07236\n",
      "[epoch 342, batch    27] loss: 132.50851\n",
      "[epoch 342, batch    28] loss: 136.60014\n",
      "[epoch 342, batch    29] loss: 136.23442\n",
      "[epoch 342, batch    30] loss: 134.98573\n",
      "[epoch 342, batch    31] loss: 132.10767\n",
      "[epoch 342, batch    32] loss: 33.09319\n",
      "[epoch 343, batch     1] loss: 136.51788\n",
      "[epoch 343, batch     2] loss: 134.51709\n",
      "[epoch 343, batch     3] loss: 136.63219\n",
      "[epoch 343, batch     4] loss: 127.50934\n",
      "[epoch 343, batch     5] loss: 139.33890\n",
      "[epoch 343, batch     6] loss: 127.98507\n",
      "[epoch 343, batch     7] loss: 140.71995\n",
      "[epoch 343, batch     8] loss: 139.50143\n",
      "[epoch 343, batch     9] loss: 131.27717\n",
      "[epoch 343, batch    10] loss: 126.87741\n",
      "[epoch 343, batch    11] loss: 145.13369\n",
      "[epoch 343, batch    12] loss: 124.93551\n",
      "[epoch 343, batch    13] loss: 125.51526\n",
      "[epoch 343, batch    14] loss: 144.52613\n",
      "[epoch 343, batch    15] loss: 138.17946\n",
      "[epoch 343, batch    16] loss: 131.91385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 343, batch    17] loss: 136.92915\n",
      "[epoch 343, batch    18] loss: 126.71439\n",
      "[epoch 343, batch    19] loss: 121.00196\n",
      "[epoch 343, batch    20] loss: 127.04736\n",
      "[epoch 343, batch    21] loss: 131.10175\n",
      "[epoch 343, batch    22] loss: 134.52542\n",
      "[epoch 343, batch    23] loss: 131.71625\n",
      "[epoch 343, batch    24] loss: 132.60218\n",
      "[epoch 343, batch    25] loss: 123.07730\n",
      "[epoch 343, batch    26] loss: 135.42844\n",
      "[epoch 343, batch    27] loss: 131.62913\n",
      "[epoch 343, batch    28] loss: 122.73568\n",
      "[epoch 343, batch    29] loss: 135.31272\n",
      "[epoch 343, batch    30] loss: 139.91649\n",
      "[epoch 343, batch    31] loss: 137.75559\n",
      "[epoch 343, batch    32] loss: 37.93128\n",
      "[epoch 344, batch     1] loss: 132.00800\n",
      "[epoch 344, batch     2] loss: 137.54515\n",
      "[epoch 344, batch     3] loss: 136.93106\n",
      "[epoch 344, batch     4] loss: 118.82325\n",
      "[epoch 344, batch     5] loss: 115.71696\n",
      "[epoch 344, batch     6] loss: 134.15989\n",
      "[epoch 344, batch     7] loss: 128.70565\n",
      "[epoch 344, batch     8] loss: 126.61724\n",
      "[epoch 344, batch     9] loss: 138.92985\n",
      "[epoch 344, batch    10] loss: 128.77842\n",
      "[epoch 344, batch    11] loss: 127.11500\n",
      "[epoch 344, batch    12] loss: 124.48104\n",
      "[epoch 344, batch    13] loss: 138.39282\n",
      "[epoch 344, batch    14] loss: 140.79100\n",
      "[epoch 344, batch    15] loss: 142.04676\n",
      "[epoch 344, batch    16] loss: 124.09882\n",
      "[epoch 344, batch    17] loss: 124.59889\n",
      "[epoch 344, batch    18] loss: 148.57948\n",
      "[epoch 344, batch    19] loss: 128.56511\n",
      "[epoch 344, batch    20] loss: 135.38463\n",
      "[epoch 344, batch    21] loss: 116.89749\n",
      "[epoch 344, batch    22] loss: 134.91081\n",
      "[epoch 344, batch    23] loss: 136.34005\n",
      "[epoch 344, batch    24] loss: 142.96794\n",
      "[epoch 344, batch    25] loss: 130.97953\n",
      "[epoch 344, batch    26] loss: 138.32851\n",
      "[epoch 344, batch    27] loss: 134.05902\n",
      "[epoch 344, batch    28] loss: 123.01004\n",
      "[epoch 344, batch    29] loss: 136.63899\n",
      "[epoch 344, batch    30] loss: 138.54199\n",
      "[epoch 344, batch    31] loss: 130.50118\n",
      "[epoch 344, batch    32] loss: 31.73064\n",
      "[epoch 345, batch     1] loss: 127.80818\n",
      "[epoch 345, batch     2] loss: 132.15588\n",
      "[epoch 345, batch     3] loss: 131.92941\n",
      "[epoch 345, batch     4] loss: 128.47505\n",
      "[epoch 345, batch     5] loss: 123.92134\n",
      "[epoch 345, batch     6] loss: 124.95506\n",
      "[epoch 345, batch     7] loss: 131.82127\n",
      "[epoch 345, batch     8] loss: 139.92129\n",
      "[epoch 345, batch     9] loss: 137.51927\n",
      "[epoch 345, batch    10] loss: 132.19578\n",
      "[epoch 345, batch    11] loss: 125.13978\n",
      "[epoch 345, batch    12] loss: 127.08876\n",
      "[epoch 345, batch    13] loss: 124.34353\n",
      "[epoch 345, batch    14] loss: 129.36793\n",
      "[epoch 345, batch    15] loss: 134.55294\n",
      "[epoch 345, batch    16] loss: 138.45288\n",
      "[epoch 345, batch    17] loss: 128.08568\n",
      "[epoch 345, batch    18] loss: 146.12913\n",
      "[epoch 345, batch    19] loss: 127.61616\n",
      "[epoch 345, batch    20] loss: 124.13658\n",
      "[epoch 345, batch    21] loss: 130.40378\n",
      "[epoch 345, batch    22] loss: 142.14281\n",
      "[epoch 345, batch    23] loss: 130.47086\n",
      "[epoch 345, batch    24] loss: 133.11313\n",
      "[epoch 345, batch    25] loss: 130.12691\n",
      "[epoch 345, batch    26] loss: 144.67000\n",
      "[epoch 345, batch    27] loss: 136.08844\n",
      "[epoch 345, batch    28] loss: 148.55832\n",
      "[epoch 345, batch    29] loss: 133.76665\n",
      "[epoch 345, batch    30] loss: 122.33759\n",
      "[epoch 345, batch    31] loss: 132.53033\n",
      "[epoch 345, batch    32] loss: 30.84522\n",
      "[epoch 346, batch     1] loss: 134.58652\n",
      "[epoch 346, batch     2] loss: 138.04007\n",
      "[epoch 346, batch     3] loss: 121.38831\n",
      "[epoch 346, batch     4] loss: 123.20945\n",
      "[epoch 346, batch     5] loss: 121.04710\n",
      "[epoch 346, batch     6] loss: 131.72008\n",
      "[epoch 346, batch     7] loss: 131.85335\n",
      "[epoch 346, batch     8] loss: 123.50403\n",
      "[epoch 346, batch     9] loss: 127.66179\n",
      "[epoch 346, batch    10] loss: 142.28446\n",
      "[epoch 346, batch    11] loss: 130.50283\n",
      "[epoch 346, batch    12] loss: 132.42239\n",
      "[epoch 346, batch    13] loss: 136.03327\n",
      "[epoch 346, batch    14] loss: 131.34648\n",
      "[epoch 346, batch    15] loss: 132.61501\n",
      "[epoch 346, batch    16] loss: 134.49500\n",
      "[epoch 346, batch    17] loss: 143.16948\n",
      "[epoch 346, batch    18] loss: 125.93731\n",
      "[epoch 346, batch    19] loss: 122.76228\n",
      "[epoch 346, batch    20] loss: 123.62001\n",
      "[epoch 346, batch    21] loss: 125.92341\n",
      "[epoch 346, batch    22] loss: 133.95082\n",
      "[epoch 346, batch    23] loss: 121.49127\n",
      "[epoch 346, batch    24] loss: 133.87186\n",
      "[epoch 346, batch    25] loss: 132.70041\n",
      "[epoch 346, batch    26] loss: 133.48248\n",
      "[epoch 346, batch    27] loss: 129.62491\n",
      "[epoch 346, batch    28] loss: 134.59057\n",
      "[epoch 346, batch    29] loss: 124.05435\n",
      "[epoch 346, batch    30] loss: 130.08147\n",
      "[epoch 346, batch    31] loss: 124.08761\n",
      "[epoch 346, batch    32] loss: 38.46450\n",
      "[epoch 347, batch     1] loss: 141.59133\n",
      "[epoch 347, batch     2] loss: 151.24991\n",
      "[epoch 347, batch     3] loss: 131.95297\n",
      "[epoch 347, batch     4] loss: 129.09304\n",
      "[epoch 347, batch     5] loss: 120.92049\n",
      "[epoch 347, batch     6] loss: 147.13284\n",
      "[epoch 347, batch     7] loss: 141.40932\n",
      "[epoch 347, batch     8] loss: 119.19130\n",
      "[epoch 347, batch     9] loss: 124.71404\n",
      "[epoch 347, batch    10] loss: 130.47843\n",
      "[epoch 347, batch    11] loss: 129.40758\n",
      "[epoch 347, batch    12] loss: 132.92898\n",
      "[epoch 347, batch    13] loss: 134.22312\n",
      "[epoch 347, batch    14] loss: 132.12734\n",
      "[epoch 347, batch    15] loss: 139.43517\n",
      "[epoch 347, batch    16] loss: 129.75689\n",
      "[epoch 347, batch    17] loss: 129.45955\n",
      "[epoch 347, batch    18] loss: 141.91194\n",
      "[epoch 347, batch    19] loss: 132.25624\n",
      "[epoch 347, batch    20] loss: 131.15946\n",
      "[epoch 347, batch    21] loss: 131.83547\n",
      "[epoch 347, batch    22] loss: 136.18150\n",
      "[epoch 347, batch    23] loss: 122.64467\n",
      "[epoch 347, batch    24] loss: 134.11463\n",
      "[epoch 347, batch    25] loss: 123.39885\n",
      "[epoch 347, batch    26] loss: 134.87411\n",
      "[epoch 347, batch    27] loss: 127.75077\n",
      "[epoch 347, batch    28] loss: 134.08778\n",
      "[epoch 347, batch    29] loss: 139.33241\n",
      "[epoch 347, batch    30] loss: 126.11809\n",
      "[epoch 347, batch    31] loss: 134.51236\n",
      "[epoch 347, batch    32] loss: 32.54892\n",
      "[epoch 348, batch     1] loss: 141.75001\n",
      "[epoch 348, batch     2] loss: 127.18194\n",
      "[epoch 348, batch     3] loss: 125.52147\n",
      "[epoch 348, batch     4] loss: 133.95128\n",
      "[epoch 348, batch     5] loss: 128.78480\n",
      "[epoch 348, batch     6] loss: 128.29981\n",
      "[epoch 348, batch     7] loss: 126.99134\n",
      "[epoch 348, batch     8] loss: 144.66351\n",
      "[epoch 348, batch     9] loss: 126.31322\n",
      "[epoch 348, batch    10] loss: 135.60227\n",
      "[epoch 348, batch    11] loss: 126.63503\n",
      "[epoch 348, batch    12] loss: 128.63144\n",
      "[epoch 348, batch    13] loss: 130.13160\n",
      "[epoch 348, batch    14] loss: 115.85549\n",
      "[epoch 348, batch    15] loss: 137.08457\n",
      "[epoch 348, batch    16] loss: 141.51667\n",
      "[epoch 348, batch    17] loss: 122.96296\n",
      "[epoch 348, batch    18] loss: 129.92225\n",
      "[epoch 348, batch    19] loss: 132.84955\n",
      "[epoch 348, batch    20] loss: 128.04289\n",
      "[epoch 348, batch    21] loss: 134.29373\n",
      "[epoch 348, batch    22] loss: 126.73786\n",
      "[epoch 348, batch    23] loss: 135.61117\n",
      "[epoch 348, batch    24] loss: 138.63290\n",
      "[epoch 348, batch    25] loss: 142.57564\n",
      "[epoch 348, batch    26] loss: 127.57382\n",
      "[epoch 348, batch    27] loss: 125.64221\n",
      "[epoch 348, batch    28] loss: 143.05407\n",
      "[epoch 348, batch    29] loss: 128.72099\n",
      "[epoch 348, batch    30] loss: 135.39331\n",
      "[epoch 348, batch    31] loss: 123.31821\n",
      "[epoch 348, batch    32] loss: 30.03389\n",
      "[epoch 349, batch     1] loss: 145.44571\n",
      "[epoch 349, batch     2] loss: 141.54168\n",
      "[epoch 349, batch     3] loss: 131.56237\n",
      "[epoch 349, batch     4] loss: 131.71233\n",
      "[epoch 349, batch     5] loss: 139.71527\n",
      "[epoch 349, batch     6] loss: 124.20359\n",
      "[epoch 349, batch     7] loss: 130.14982\n",
      "[epoch 349, batch     8] loss: 136.11911\n",
      "[epoch 349, batch     9] loss: 136.41572\n",
      "[epoch 349, batch    10] loss: 119.50236\n",
      "[epoch 349, batch    11] loss: 130.57617\n",
      "[epoch 349, batch    12] loss: 139.19192\n",
      "[epoch 349, batch    13] loss: 121.45322\n",
      "[epoch 349, batch    14] loss: 135.89737\n",
      "[epoch 349, batch    15] loss: 139.77605\n",
      "[epoch 349, batch    16] loss: 135.15883\n",
      "[epoch 349, batch    17] loss: 122.83586\n",
      "[epoch 349, batch    18] loss: 130.42646\n",
      "[epoch 349, batch    19] loss: 125.62704\n",
      "[epoch 349, batch    20] loss: 129.05809\n",
      "[epoch 349, batch    21] loss: 141.33897\n",
      "[epoch 349, batch    22] loss: 136.37009\n",
      "[epoch 349, batch    23] loss: 122.26386\n",
      "[epoch 349, batch    24] loss: 139.84710\n",
      "[epoch 349, batch    25] loss: 130.17132\n",
      "[epoch 349, batch    26] loss: 117.51894\n",
      "[epoch 349, batch    27] loss: 140.40884\n",
      "[epoch 349, batch    28] loss: 131.16223\n",
      "[epoch 349, batch    29] loss: 129.76638\n",
      "[epoch 349, batch    30] loss: 135.25671\n",
      "[epoch 349, batch    31] loss: 141.54230\n",
      "[epoch 349, batch    32] loss: 33.21298\n",
      "[epoch 350, batch     1] loss: 139.99781\n",
      "[epoch 350, batch     2] loss: 125.82694\n",
      "[epoch 350, batch     3] loss: 124.69430\n",
      "[epoch 350, batch     4] loss: 114.87578\n",
      "[epoch 350, batch     5] loss: 146.26941\n",
      "[epoch 350, batch     6] loss: 134.58022\n",
      "[epoch 350, batch     7] loss: 129.79668\n",
      "[epoch 350, batch     8] loss: 136.47579\n",
      "[epoch 350, batch     9] loss: 147.47574\n",
      "[epoch 350, batch    10] loss: 130.25082\n",
      "[epoch 350, batch    11] loss: 139.49679\n",
      "[epoch 350, batch    12] loss: 125.50452\n",
      "[epoch 350, batch    13] loss: 134.13754\n",
      "[epoch 350, batch    14] loss: 130.08981\n",
      "[epoch 350, batch    15] loss: 131.01120\n",
      "[epoch 350, batch    16] loss: 130.41294\n",
      "[epoch 350, batch    17] loss: 119.16960\n",
      "[epoch 350, batch    18] loss: 125.00544\n",
      "[epoch 350, batch    19] loss: 131.90007\n",
      "[epoch 350, batch    20] loss: 137.05962\n",
      "[epoch 350, batch    21] loss: 133.32687\n",
      "[epoch 350, batch    22] loss: 135.28185\n",
      "[epoch 350, batch    23] loss: 134.14989\n",
      "[epoch 350, batch    24] loss: 128.43921\n",
      "[epoch 350, batch    25] loss: 129.12976\n",
      "[epoch 350, batch    26] loss: 131.05557\n",
      "[epoch 350, batch    27] loss: 126.61197\n",
      "[epoch 350, batch    28] loss: 122.35336\n",
      "[epoch 350, batch    29] loss: 135.07865\n",
      "[epoch 350, batch    30] loss: 125.09081\n",
      "[epoch 350, batch    31] loss: 128.40313\n",
      "[epoch 350, batch    32] loss: 35.05656\n",
      "[epoch 351, batch     1] loss: 131.88945\n",
      "[epoch 351, batch     2] loss: 146.37662\n",
      "[epoch 351, batch     3] loss: 121.30255\n",
      "[epoch 351, batch     4] loss: 151.47296\n",
      "[epoch 351, batch     5] loss: 137.32329\n",
      "[epoch 351, batch     6] loss: 135.48342\n",
      "[epoch 351, batch     7] loss: 130.12004\n",
      "[epoch 351, batch     8] loss: 128.32347\n",
      "[epoch 351, batch     9] loss: 130.07740\n",
      "[epoch 351, batch    10] loss: 125.44124\n",
      "[epoch 351, batch    11] loss: 123.06920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 351, batch    12] loss: 129.85533\n",
      "[epoch 351, batch    13] loss: 129.14906\n",
      "[epoch 351, batch    14] loss: 136.64559\n",
      "[epoch 351, batch    15] loss: 140.48591\n",
      "[epoch 351, batch    16] loss: 127.93412\n",
      "[epoch 351, batch    17] loss: 130.56250\n",
      "[epoch 351, batch    18] loss: 136.10476\n",
      "[epoch 351, batch    19] loss: 129.74451\n",
      "[epoch 351, batch    20] loss: 135.76803\n",
      "[epoch 351, batch    21] loss: 129.29043\n",
      "[epoch 351, batch    22] loss: 129.40850\n",
      "[epoch 351, batch    23] loss: 141.54023\n",
      "[epoch 351, batch    24] loss: 131.82769\n",
      "[epoch 351, batch    25] loss: 132.81447\n",
      "[epoch 351, batch    26] loss: 125.64062\n",
      "[epoch 351, batch    27] loss: 133.34207\n",
      "[epoch 351, batch    28] loss: 121.55970\n",
      "[epoch 351, batch    29] loss: 138.79072\n",
      "[epoch 351, batch    30] loss: 134.87808\n",
      "[epoch 351, batch    31] loss: 124.24903\n",
      "[epoch 351, batch    32] loss: 28.32524\n",
      "[epoch 352, batch     1] loss: 132.35880\n",
      "[epoch 352, batch     2] loss: 139.64923\n",
      "[epoch 352, batch     3] loss: 140.14610\n",
      "[epoch 352, batch     4] loss: 132.58265\n",
      "[epoch 352, batch     5] loss: 126.82616\n",
      "[epoch 352, batch     6] loss: 136.53772\n",
      "[epoch 352, batch     7] loss: 114.06860\n",
      "[epoch 352, batch     8] loss: 148.29463\n",
      "[epoch 352, batch     9] loss: 141.81055\n",
      "[epoch 352, batch    10] loss: 141.39896\n",
      "[epoch 352, batch    11] loss: 136.27634\n",
      "[epoch 352, batch    12] loss: 124.70897\n",
      "[epoch 352, batch    13] loss: 118.87595\n",
      "[epoch 352, batch    14] loss: 127.14741\n",
      "[epoch 352, batch    15] loss: 130.45103\n",
      "[epoch 352, batch    16] loss: 134.09460\n",
      "[epoch 352, batch    17] loss: 139.19670\n",
      "[epoch 352, batch    18] loss: 130.65913\n",
      "[epoch 352, batch    19] loss: 126.48089\n",
      "[epoch 352, batch    20] loss: 138.36546\n",
      "[epoch 352, batch    21] loss: 129.24663\n",
      "[epoch 352, batch    22] loss: 136.56221\n",
      "[epoch 352, batch    23] loss: 112.17530\n",
      "[epoch 352, batch    24] loss: 136.43803\n",
      "[epoch 352, batch    25] loss: 133.14922\n",
      "[epoch 352, batch    26] loss: 128.73429\n",
      "[epoch 352, batch    27] loss: 123.94254\n",
      "[epoch 352, batch    28] loss: 131.07089\n",
      "[epoch 352, batch    29] loss: 141.33844\n",
      "[epoch 352, batch    30] loss: 124.32807\n",
      "[epoch 352, batch    31] loss: 132.85631\n",
      "[epoch 352, batch    32] loss: 38.62478\n",
      "[epoch 353, batch     1] loss: 123.13428\n",
      "[epoch 353, batch     2] loss: 146.35716\n",
      "[epoch 353, batch     3] loss: 127.77518\n",
      "[epoch 353, batch     4] loss: 136.40937\n",
      "[epoch 353, batch     5] loss: 125.33490\n",
      "[epoch 353, batch     6] loss: 132.49749\n",
      "[epoch 353, batch     7] loss: 136.94620\n",
      "[epoch 353, batch     8] loss: 127.90807\n",
      "[epoch 353, batch     9] loss: 128.83801\n",
      "[epoch 353, batch    10] loss: 132.92692\n",
      "[epoch 353, batch    11] loss: 117.85505\n",
      "[epoch 353, batch    12] loss: 122.63464\n",
      "[epoch 353, batch    13] loss: 129.87703\n",
      "[epoch 353, batch    14] loss: 130.10673\n",
      "[epoch 353, batch    15] loss: 133.17197\n",
      "[epoch 353, batch    16] loss: 130.27806\n",
      "[epoch 353, batch    17] loss: 132.12983\n",
      "[epoch 353, batch    18] loss: 138.38265\n",
      "[epoch 353, batch    19] loss: 141.57533\n",
      "[epoch 353, batch    20] loss: 144.81386\n",
      "[epoch 353, batch    21] loss: 144.40254\n",
      "[epoch 353, batch    22] loss: 124.17901\n",
      "[epoch 353, batch    23] loss: 153.13924\n",
      "[epoch 353, batch    24] loss: 144.68115\n",
      "[epoch 353, batch    25] loss: 137.62593\n",
      "[epoch 353, batch    26] loss: 123.77082\n",
      "[epoch 353, batch    27] loss: 126.12137\n",
      "[epoch 353, batch    28] loss: 136.24317\n",
      "[epoch 353, batch    29] loss: 125.81283\n",
      "[epoch 353, batch    30] loss: 127.40769\n",
      "[epoch 353, batch    31] loss: 126.40271\n",
      "[epoch 353, batch    32] loss: 35.71574\n",
      "[epoch 354, batch     1] loss: 133.03354\n",
      "[epoch 354, batch     2] loss: 131.22612\n",
      "[epoch 354, batch     3] loss: 133.35371\n",
      "[epoch 354, batch     4] loss: 133.77979\n",
      "[epoch 354, batch     5] loss: 126.65390\n",
      "[epoch 354, batch     6] loss: 134.89548\n",
      "[epoch 354, batch     7] loss: 124.53111\n",
      "[epoch 354, batch     8] loss: 130.46746\n",
      "[epoch 354, batch     9] loss: 140.47212\n",
      "[epoch 354, batch    10] loss: 140.59222\n",
      "[epoch 354, batch    11] loss: 121.03508\n",
      "[epoch 354, batch    12] loss: 129.24040\n",
      "[epoch 354, batch    13] loss: 123.41673\n",
      "[epoch 354, batch    14] loss: 142.01211\n",
      "[epoch 354, batch    15] loss: 126.03346\n",
      "[epoch 354, batch    16] loss: 121.36259\n",
      "[epoch 354, batch    17] loss: 133.17218\n",
      "[epoch 354, batch    18] loss: 133.62592\n",
      "[epoch 354, batch    19] loss: 138.61720\n",
      "[epoch 354, batch    20] loss: 134.43095\n",
      "[epoch 354, batch    21] loss: 129.49056\n",
      "[epoch 354, batch    22] loss: 139.63304\n",
      "[epoch 354, batch    23] loss: 131.64875\n",
      "[epoch 354, batch    24] loss: 134.48991\n",
      "[epoch 354, batch    25] loss: 130.29900\n",
      "[epoch 354, batch    26] loss: 138.96229\n",
      "[epoch 354, batch    27] loss: 139.15245\n",
      "[epoch 354, batch    28] loss: 123.70419\n",
      "[epoch 354, batch    29] loss: 134.47413\n",
      "[epoch 354, batch    30] loss: 129.77983\n",
      "[epoch 354, batch    31] loss: 129.54082\n",
      "[epoch 354, batch    32] loss: 31.11048\n",
      "[epoch 355, batch     1] loss: 134.55130\n",
      "[epoch 355, batch     2] loss: 133.73019\n",
      "[epoch 355, batch     3] loss: 122.72690\n",
      "[epoch 355, batch     4] loss: 136.35596\n",
      "[epoch 355, batch     5] loss: 129.13299\n",
      "[epoch 355, batch     6] loss: 130.77315\n",
      "[epoch 355, batch     7] loss: 124.81653\n",
      "[epoch 355, batch     8] loss: 120.70238\n",
      "[epoch 355, batch     9] loss: 131.77129\n",
      "[epoch 355, batch    10] loss: 143.60526\n",
      "[epoch 355, batch    11] loss: 135.96273\n",
      "[epoch 355, batch    12] loss: 134.65490\n",
      "[epoch 355, batch    13] loss: 133.93726\n",
      "[epoch 355, batch    14] loss: 125.34281\n",
      "[epoch 355, batch    15] loss: 131.70724\n",
      "[epoch 355, batch    16] loss: 132.73979\n",
      "[epoch 355, batch    17] loss: 120.41854\n",
      "[epoch 355, batch    18] loss: 143.72218\n",
      "[epoch 355, batch    19] loss: 134.05558\n",
      "[epoch 355, batch    20] loss: 128.32357\n",
      "[epoch 355, batch    21] loss: 125.83512\n",
      "[epoch 355, batch    22] loss: 144.05398\n",
      "[epoch 355, batch    23] loss: 131.39698\n",
      "[epoch 355, batch    24] loss: 123.99862\n",
      "[epoch 355, batch    25] loss: 138.88893\n",
      "[epoch 355, batch    26] loss: 129.84073\n",
      "[epoch 355, batch    27] loss: 128.61900\n",
      "[epoch 355, batch    28] loss: 122.86271\n",
      "[epoch 355, batch    29] loss: 130.99093\n",
      "[epoch 355, batch    30] loss: 125.41973\n",
      "[epoch 355, batch    31] loss: 134.72733\n",
      "[epoch 355, batch    32] loss: 28.74650\n",
      "[epoch 356, batch     1] loss: 133.54526\n",
      "[epoch 356, batch     2] loss: 134.46353\n",
      "[epoch 356, batch     3] loss: 133.86082\n",
      "[epoch 356, batch     4] loss: 121.74569\n",
      "[epoch 356, batch     5] loss: 150.59108\n",
      "[epoch 356, batch     6] loss: 158.23218\n",
      "[epoch 356, batch     7] loss: 131.18106\n",
      "[epoch 356, batch     8] loss: 138.41538\n",
      "[epoch 356, batch     9] loss: 137.27480\n",
      "[epoch 356, batch    10] loss: 124.00656\n",
      "[epoch 356, batch    11] loss: 122.59290\n",
      "[epoch 356, batch    12] loss: 126.82192\n",
      "[epoch 356, batch    13] loss: 136.02265\n",
      "[epoch 356, batch    14] loss: 124.12630\n",
      "[epoch 356, batch    15] loss: 138.97516\n",
      "[epoch 356, batch    16] loss: 137.24214\n",
      "[epoch 356, batch    17] loss: 130.25724\n",
      "[epoch 356, batch    18] loss: 130.84781\n",
      "[epoch 356, batch    19] loss: 144.19679\n",
      "[epoch 356, batch    20] loss: 141.36416\n",
      "[epoch 356, batch    21] loss: 127.62796\n",
      "[epoch 356, batch    22] loss: 132.13659\n",
      "[epoch 356, batch    23] loss: 124.11308\n",
      "[epoch 356, batch    24] loss: 118.06019\n",
      "[epoch 356, batch    25] loss: 127.78798\n",
      "[epoch 356, batch    26] loss: 144.69737\n",
      "[epoch 356, batch    27] loss: 114.03525\n",
      "[epoch 356, batch    28] loss: 124.08996\n",
      "[epoch 356, batch    29] loss: 136.89174\n",
      "[epoch 356, batch    30] loss: 140.28596\n",
      "[epoch 356, batch    31] loss: 141.08338\n",
      "[epoch 356, batch    32] loss: 33.09389\n",
      "[epoch 357, batch     1] loss: 133.36821\n",
      "[epoch 357, batch     2] loss: 148.36635\n",
      "[epoch 357, batch     3] loss: 123.66099\n",
      "[epoch 357, batch     4] loss: 132.81195\n",
      "[epoch 357, batch     5] loss: 140.79360\n",
      "[epoch 357, batch     6] loss: 134.93439\n",
      "[epoch 357, batch     7] loss: 131.68984\n",
      "[epoch 357, batch     8] loss: 128.86252\n",
      "[epoch 357, batch     9] loss: 118.48969\n",
      "[epoch 357, batch    10] loss: 143.57707\n",
      "[epoch 357, batch    11] loss: 123.28289\n",
      "[epoch 357, batch    12] loss: 133.36621\n",
      "[epoch 357, batch    13] loss: 149.06791\n",
      "[epoch 357, batch    14] loss: 129.37542\n",
      "[epoch 357, batch    15] loss: 133.53206\n",
      "[epoch 357, batch    16] loss: 139.04666\n",
      "[epoch 357, batch    17] loss: 131.55550\n",
      "[epoch 357, batch    18] loss: 127.47032\n",
      "[epoch 357, batch    19] loss: 134.49132\n",
      "[epoch 357, batch    20] loss: 133.07250\n",
      "[epoch 357, batch    21] loss: 137.41863\n",
      "[epoch 357, batch    22] loss: 124.98867\n",
      "[epoch 357, batch    23] loss: 130.74468\n",
      "[epoch 357, batch    24] loss: 122.69778\n",
      "[epoch 357, batch    25] loss: 134.97032\n",
      "[epoch 357, batch    26] loss: 130.82469\n",
      "[epoch 357, batch    27] loss: 134.36518\n",
      "[epoch 357, batch    28] loss: 118.59180\n",
      "[epoch 357, batch    29] loss: 128.63811\n",
      "[epoch 357, batch    30] loss: 125.37156\n",
      "[epoch 357, batch    31] loss: 143.72847\n",
      "[epoch 357, batch    32] loss: 32.37328\n",
      "[epoch 358, batch     1] loss: 144.23990\n",
      "[epoch 358, batch     2] loss: 135.10180\n",
      "[epoch 358, batch     3] loss: 131.25766\n",
      "[epoch 358, batch     4] loss: 140.25729\n",
      "[epoch 358, batch     5] loss: 141.73311\n",
      "[epoch 358, batch     6] loss: 126.76472\n",
      "[epoch 358, batch     7] loss: 143.97662\n",
      "[epoch 358, batch     8] loss: 140.93837\n",
      "[epoch 358, batch     9] loss: 127.08810\n",
      "[epoch 358, batch    10] loss: 140.81386\n",
      "[epoch 358, batch    11] loss: 130.53320\n",
      "[epoch 358, batch    12] loss: 131.01846\n",
      "[epoch 358, batch    13] loss: 132.33956\n",
      "[epoch 358, batch    14] loss: 132.75561\n",
      "[epoch 358, batch    15] loss: 133.87029\n",
      "[epoch 358, batch    16] loss: 143.30075\n",
      "[epoch 358, batch    17] loss: 130.88107\n",
      "[epoch 358, batch    18] loss: 127.14434\n",
      "[epoch 358, batch    19] loss: 134.20545\n",
      "[epoch 358, batch    20] loss: 128.28525\n",
      "[epoch 358, batch    21] loss: 122.28996\n",
      "[epoch 358, batch    22] loss: 128.25383\n",
      "[epoch 358, batch    23] loss: 124.28657\n",
      "[epoch 358, batch    24] loss: 140.28479\n",
      "[epoch 358, batch    25] loss: 137.86843\n",
      "[epoch 358, batch    26] loss: 134.98220\n",
      "[epoch 358, batch    27] loss: 139.08920\n",
      "[epoch 358, batch    28] loss: 119.20069\n",
      "[epoch 358, batch    29] loss: 138.41295\n",
      "[epoch 358, batch    30] loss: 120.33913\n",
      "[epoch 358, batch    31] loss: 147.04755\n",
      "[epoch 358, batch    32] loss: 34.19699\n",
      "[epoch 359, batch     1] loss: 147.54768\n",
      "[epoch 359, batch     2] loss: 132.16838\n",
      "[epoch 359, batch     3] loss: 142.24242\n",
      "[epoch 359, batch     4] loss: 131.50504\n",
      "[epoch 359, batch     5] loss: 130.65635\n",
      "[epoch 359, batch     6] loss: 128.18809\n",
      "[epoch 359, batch     7] loss: 129.84672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 359, batch     8] loss: 124.04135\n",
      "[epoch 359, batch     9] loss: 129.29047\n",
      "[epoch 359, batch    10] loss: 118.79735\n",
      "[epoch 359, batch    11] loss: 145.03390\n",
      "[epoch 359, batch    12] loss: 134.38136\n",
      "[epoch 359, batch    13] loss: 133.51320\n",
      "[epoch 359, batch    14] loss: 135.20175\n",
      "[epoch 359, batch    15] loss: 125.91917\n",
      "[epoch 359, batch    16] loss: 132.15665\n",
      "[epoch 359, batch    17] loss: 153.12567\n",
      "[epoch 359, batch    18] loss: 121.27192\n",
      "[epoch 359, batch    19] loss: 133.29474\n",
      "[epoch 359, batch    20] loss: 136.42538\n",
      "[epoch 359, batch    21] loss: 126.37737\n",
      "[epoch 359, batch    22] loss: 129.20479\n",
      "[epoch 359, batch    23] loss: 130.61536\n",
      "[epoch 359, batch    24] loss: 129.54054\n",
      "[epoch 359, batch    25] loss: 137.53201\n",
      "[epoch 359, batch    26] loss: 136.69392\n",
      "[epoch 359, batch    27] loss: 128.62326\n",
      "[epoch 359, batch    28] loss: 134.81383\n",
      "[epoch 359, batch    29] loss: 131.71583\n",
      "[epoch 359, batch    30] loss: 127.99928\n",
      "[epoch 359, batch    31] loss: 143.04009\n",
      "[epoch 359, batch    32] loss: 31.99391\n",
      "[epoch 360, batch     1] loss: 139.49215\n",
      "[epoch 360, batch     2] loss: 139.02415\n",
      "[epoch 360, batch     3] loss: 125.04365\n",
      "[epoch 360, batch     4] loss: 123.11726\n",
      "[epoch 360, batch     5] loss: 127.05021\n",
      "[epoch 360, batch     6] loss: 131.80005\n",
      "[epoch 360, batch     7] loss: 129.54041\n",
      "[epoch 360, batch     8] loss: 141.48450\n",
      "[epoch 360, batch     9] loss: 144.39607\n",
      "[epoch 360, batch    10] loss: 131.75304\n",
      "[epoch 360, batch    11] loss: 145.04841\n",
      "[epoch 360, batch    12] loss: 125.28717\n",
      "[epoch 360, batch    13] loss: 115.72956\n",
      "[epoch 360, batch    14] loss: 134.63530\n",
      "[epoch 360, batch    15] loss: 128.49586\n",
      "[epoch 360, batch    16] loss: 130.63966\n",
      "[epoch 360, batch    17] loss: 127.28996\n",
      "[epoch 360, batch    18] loss: 142.80867\n",
      "[epoch 360, batch    19] loss: 138.02148\n",
      "[epoch 360, batch    20] loss: 130.00752\n",
      "[epoch 360, batch    21] loss: 124.22118\n",
      "[epoch 360, batch    22] loss: 137.46203\n",
      "[epoch 360, batch    23] loss: 129.94022\n",
      "[epoch 360, batch    24] loss: 141.65731\n",
      "[epoch 360, batch    25] loss: 120.81225\n",
      "[epoch 360, batch    26] loss: 127.32564\n",
      "[epoch 360, batch    27] loss: 139.09113\n",
      "[epoch 360, batch    28] loss: 138.85025\n",
      "[epoch 360, batch    29] loss: 136.39566\n",
      "[epoch 360, batch    30] loss: 142.87052\n",
      "[epoch 360, batch    31] loss: 143.59209\n",
      "[epoch 360, batch    32] loss: 33.51502\n",
      "[epoch 361, batch     1] loss: 138.49685\n",
      "[epoch 361, batch     2] loss: 130.26380\n",
      "[epoch 361, batch     3] loss: 132.66600\n",
      "[epoch 361, batch     4] loss: 133.40884\n",
      "[epoch 361, batch     5] loss: 130.44421\n",
      "[epoch 361, batch     6] loss: 140.66576\n",
      "[epoch 361, batch     7] loss: 136.73717\n",
      "[epoch 361, batch     8] loss: 132.48126\n",
      "[epoch 361, batch     9] loss: 127.83303\n",
      "[epoch 361, batch    10] loss: 124.40264\n",
      "[epoch 361, batch    11] loss: 137.91254\n",
      "[epoch 361, batch    12] loss: 131.71733\n",
      "[epoch 361, batch    13] loss: 128.99885\n",
      "[epoch 361, batch    14] loss: 130.57025\n",
      "[epoch 361, batch    15] loss: 142.25976\n",
      "[epoch 361, batch    16] loss: 137.12928\n",
      "[epoch 361, batch    17] loss: 130.45243\n",
      "[epoch 361, batch    18] loss: 129.81109\n",
      "[epoch 361, batch    19] loss: 126.39562\n",
      "[epoch 361, batch    20] loss: 124.25552\n",
      "[epoch 361, batch    21] loss: 134.20470\n",
      "[epoch 361, batch    22] loss: 143.73024\n",
      "[epoch 361, batch    23] loss: 131.87430\n",
      "[epoch 361, batch    24] loss: 113.02957\n",
      "[epoch 361, batch    25] loss: 132.35231\n",
      "[epoch 361, batch    26] loss: 129.84579\n",
      "[epoch 361, batch    27] loss: 128.64966\n",
      "[epoch 361, batch    28] loss: 141.73156\n",
      "[epoch 361, batch    29] loss: 141.48796\n",
      "[epoch 361, batch    30] loss: 134.46119\n",
      "[epoch 361, batch    31] loss: 133.11557\n",
      "[epoch 361, batch    32] loss: 24.98611\n",
      "[epoch 362, batch     1] loss: 147.71045\n",
      "[epoch 362, batch     2] loss: 129.06308\n",
      "[epoch 362, batch     3] loss: 130.69979\n",
      "[epoch 362, batch     4] loss: 136.31495\n",
      "[epoch 362, batch     5] loss: 137.77533\n",
      "[epoch 362, batch     6] loss: 123.11188\n",
      "[epoch 362, batch     7] loss: 125.94796\n",
      "[epoch 362, batch     8] loss: 129.60152\n",
      "[epoch 362, batch     9] loss: 120.56385\n",
      "[epoch 362, batch    10] loss: 151.81527\n",
      "[epoch 362, batch    11] loss: 130.00657\n",
      "[epoch 362, batch    12] loss: 128.03274\n",
      "[epoch 362, batch    13] loss: 119.01612\n",
      "[epoch 362, batch    14] loss: 138.06103\n",
      "[epoch 362, batch    15] loss: 117.01673\n",
      "[epoch 362, batch    16] loss: 134.37958\n",
      "[epoch 362, batch    17] loss: 143.33493\n",
      "[epoch 362, batch    18] loss: 124.72019\n",
      "[epoch 362, batch    19] loss: 134.69611\n",
      "[epoch 362, batch    20] loss: 129.95186\n",
      "[epoch 362, batch    21] loss: 131.68117\n",
      "[epoch 362, batch    22] loss: 132.62203\n",
      "[epoch 362, batch    23] loss: 128.82763\n",
      "[epoch 362, batch    24] loss: 136.23927\n",
      "[epoch 362, batch    25] loss: 135.13574\n",
      "[epoch 362, batch    26] loss: 126.45448\n",
      "[epoch 362, batch    27] loss: 134.06132\n",
      "[epoch 362, batch    28] loss: 130.61529\n",
      "[epoch 362, batch    29] loss: 138.69020\n",
      "[epoch 362, batch    30] loss: 114.63349\n",
      "[epoch 362, batch    31] loss: 149.35461\n",
      "[epoch 362, batch    32] loss: 35.19182\n",
      "[epoch 363, batch     1] loss: 124.99185\n",
      "[epoch 363, batch     2] loss: 135.15112\n",
      "[epoch 363, batch     3] loss: 151.22455\n",
      "[epoch 363, batch     4] loss: 128.79822\n",
      "[epoch 363, batch     5] loss: 142.49205\n",
      "[epoch 363, batch     6] loss: 124.44275\n",
      "[epoch 363, batch     7] loss: 135.43865\n",
      "[epoch 363, batch     8] loss: 124.39669\n",
      "[epoch 363, batch     9] loss: 131.30829\n",
      "[epoch 363, batch    10] loss: 129.12433\n",
      "[epoch 363, batch    11] loss: 130.51265\n",
      "[epoch 363, batch    12] loss: 130.34648\n",
      "[epoch 363, batch    13] loss: 123.72452\n",
      "[epoch 363, batch    14] loss: 133.61907\n",
      "[epoch 363, batch    15] loss: 138.27710\n",
      "[epoch 363, batch    16] loss: 126.17209\n",
      "[epoch 363, batch    17] loss: 127.58706\n",
      "[epoch 363, batch    18] loss: 124.24781\n",
      "[epoch 363, batch    19] loss: 130.82989\n",
      "[epoch 363, batch    20] loss: 116.91306\n",
      "[epoch 363, batch    21] loss: 120.08917\n",
      "[epoch 363, batch    22] loss: 130.94526\n",
      "[epoch 363, batch    23] loss: 145.73554\n",
      "[epoch 363, batch    24] loss: 144.62965\n",
      "[epoch 363, batch    25] loss: 130.67335\n",
      "[epoch 363, batch    26] loss: 145.68209\n",
      "[epoch 363, batch    27] loss: 130.69691\n",
      "[epoch 363, batch    28] loss: 129.57580\n",
      "[epoch 363, batch    29] loss: 135.30005\n",
      "[epoch 363, batch    30] loss: 132.69076\n",
      "[epoch 363, batch    31] loss: 127.86482\n",
      "[epoch 363, batch    32] loss: 35.15876\n",
      "[epoch 364, batch     1] loss: 138.05527\n",
      "[epoch 364, batch     2] loss: 127.19098\n",
      "[epoch 364, batch     3] loss: 132.20177\n",
      "[epoch 364, batch     4] loss: 141.14926\n",
      "[epoch 364, batch     5] loss: 140.60598\n",
      "[epoch 364, batch     6] loss: 135.93793\n",
      "[epoch 364, batch     7] loss: 141.53232\n",
      "[epoch 364, batch     8] loss: 129.72365\n",
      "[epoch 364, batch     9] loss: 130.50691\n",
      "[epoch 364, batch    10] loss: 134.12993\n",
      "[epoch 364, batch    11] loss: 120.72925\n",
      "[epoch 364, batch    12] loss: 129.13904\n",
      "[epoch 364, batch    13] loss: 130.04156\n",
      "[epoch 364, batch    14] loss: 128.18778\n",
      "[epoch 364, batch    15] loss: 127.89455\n",
      "[epoch 364, batch    16] loss: 132.58264\n",
      "[epoch 364, batch    17] loss: 126.74431\n",
      "[epoch 364, batch    18] loss: 136.44901\n",
      "[epoch 364, batch    19] loss: 132.40045\n",
      "[epoch 364, batch    20] loss: 134.96444\n",
      "[epoch 364, batch    21] loss: 118.25341\n",
      "[epoch 364, batch    22] loss: 140.40861\n",
      "[epoch 364, batch    23] loss: 139.44136\n",
      "[epoch 364, batch    24] loss: 137.68163\n",
      "[epoch 364, batch    25] loss: 108.44636\n",
      "[epoch 364, batch    26] loss: 126.35972\n",
      "[epoch 364, batch    27] loss: 122.35168\n",
      "[epoch 364, batch    28] loss: 124.77832\n",
      "[epoch 364, batch    29] loss: 130.63812\n",
      "[epoch 364, batch    30] loss: 122.80054\n",
      "[epoch 364, batch    31] loss: 131.13415\n",
      "[epoch 364, batch    32] loss: 28.15448\n",
      "[epoch 365, batch     1] loss: 129.55690\n",
      "[epoch 365, batch     2] loss: 120.70607\n",
      "[epoch 365, batch     3] loss: 122.62834\n",
      "[epoch 365, batch     4] loss: 129.41941\n",
      "[epoch 365, batch     5] loss: 126.41532\n",
      "[epoch 365, batch     6] loss: 143.50426\n",
      "[epoch 365, batch     7] loss: 123.76068\n",
      "[epoch 365, batch     8] loss: 133.42686\n",
      "[epoch 365, batch     9] loss: 124.03467\n",
      "[epoch 365, batch    10] loss: 128.04062\n",
      "[epoch 365, batch    11] loss: 130.10841\n",
      "[epoch 365, batch    12] loss: 128.65520\n",
      "[epoch 365, batch    13] loss: 118.50388\n",
      "[epoch 365, batch    14] loss: 136.89858\n",
      "[epoch 365, batch    15] loss: 135.62925\n",
      "[epoch 365, batch    16] loss: 138.14747\n",
      "[epoch 365, batch    17] loss: 130.93374\n",
      "[epoch 365, batch    18] loss: 131.32996\n",
      "[epoch 365, batch    19] loss: 120.74893\n",
      "[epoch 365, batch    20] loss: 123.11023\n",
      "[epoch 365, batch    21] loss: 122.59125\n",
      "[epoch 365, batch    22] loss: 143.77618\n",
      "[epoch 365, batch    23] loss: 124.78511\n",
      "[epoch 365, batch    24] loss: 142.45270\n",
      "[epoch 365, batch    25] loss: 140.72801\n",
      "[epoch 365, batch    26] loss: 125.03415\n",
      "[epoch 365, batch    27] loss: 114.47770\n",
      "[epoch 365, batch    28] loss: 129.45384\n",
      "[epoch 365, batch    29] loss: 140.44286\n",
      "[epoch 365, batch    30] loss: 118.34047\n",
      "[epoch 365, batch    31] loss: 139.73571\n",
      "[epoch 365, batch    32] loss: 31.02588\n",
      "[epoch 366, batch     1] loss: 131.05724\n",
      "[epoch 366, batch     2] loss: 143.55393\n",
      "[epoch 366, batch     3] loss: 134.00977\n",
      "[epoch 366, batch     4] loss: 127.91471\n",
      "[epoch 366, batch     5] loss: 122.38397\n",
      "[epoch 366, batch     6] loss: 129.98635\n",
      "[epoch 366, batch     7] loss: 141.83291\n",
      "[epoch 366, batch     8] loss: 137.40347\n",
      "[epoch 366, batch     9] loss: 140.42404\n",
      "[epoch 366, batch    10] loss: 132.03989\n",
      "[epoch 366, batch    11] loss: 134.80533\n",
      "[epoch 366, batch    12] loss: 133.23470\n",
      "[epoch 366, batch    13] loss: 114.19610\n",
      "[epoch 366, batch    14] loss: 138.14540\n",
      "[epoch 366, batch    15] loss: 138.02450\n",
      "[epoch 366, batch    16] loss: 129.88730\n",
      "[epoch 366, batch    17] loss: 145.96029\n",
      "[epoch 366, batch    18] loss: 121.10470\n",
      "[epoch 366, batch    19] loss: 128.91027\n",
      "[epoch 366, batch    20] loss: 150.23828\n",
      "[epoch 366, batch    21] loss: 129.67223\n",
      "[epoch 366, batch    22] loss: 118.74063\n",
      "[epoch 366, batch    23] loss: 130.24005\n",
      "[epoch 366, batch    24] loss: 144.35143\n",
      "[epoch 366, batch    25] loss: 146.06308\n",
      "[epoch 366, batch    26] loss: 114.63517\n",
      "[epoch 366, batch    27] loss: 144.56955\n",
      "[epoch 366, batch    28] loss: 135.04136\n",
      "[epoch 366, batch    29] loss: 137.27623\n",
      "[epoch 366, batch    30] loss: 141.87121\n",
      "[epoch 366, batch    31] loss: 128.53730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 366, batch    32] loss: 34.49758\n",
      "[epoch 367, batch     1] loss: 128.39445\n",
      "[epoch 367, batch     2] loss: 127.87717\n",
      "[epoch 367, batch     3] loss: 130.79141\n",
      "[epoch 367, batch     4] loss: 130.30822\n",
      "[epoch 367, batch     5] loss: 143.18378\n",
      "[epoch 367, batch     6] loss: 134.59591\n",
      "[epoch 367, batch     7] loss: 128.94899\n",
      "[epoch 367, batch     8] loss: 126.25637\n",
      "[epoch 367, batch     9] loss: 132.25192\n",
      "[epoch 367, batch    10] loss: 134.58759\n",
      "[epoch 367, batch    11] loss: 141.95051\n",
      "[epoch 367, batch    12] loss: 128.30583\n",
      "[epoch 367, batch    13] loss: 125.82873\n",
      "[epoch 367, batch    14] loss: 143.95498\n",
      "[epoch 367, batch    15] loss: 124.22850\n",
      "[epoch 367, batch    16] loss: 115.67649\n",
      "[epoch 367, batch    17] loss: 141.14997\n",
      "[epoch 367, batch    18] loss: 130.54636\n",
      "[epoch 367, batch    19] loss: 128.00646\n",
      "[epoch 367, batch    20] loss: 113.25569\n",
      "[epoch 367, batch    21] loss: 128.32349\n",
      "[epoch 367, batch    22] loss: 128.55434\n",
      "[epoch 367, batch    23] loss: 127.52227\n",
      "[epoch 367, batch    24] loss: 133.41775\n",
      "[epoch 367, batch    25] loss: 137.14035\n",
      "[epoch 367, batch    26] loss: 135.61389\n",
      "[epoch 367, batch    27] loss: 126.02068\n",
      "[epoch 367, batch    28] loss: 141.34626\n",
      "[epoch 367, batch    29] loss: 139.39490\n",
      "[epoch 367, batch    30] loss: 131.18031\n",
      "[epoch 367, batch    31] loss: 124.00235\n",
      "[epoch 367, batch    32] loss: 32.39075\n",
      "[epoch 368, batch     1] loss: 133.20433\n",
      "[epoch 368, batch     2] loss: 133.49016\n",
      "[epoch 368, batch     3] loss: 143.18472\n",
      "[epoch 368, batch     4] loss: 130.82818\n",
      "[epoch 368, batch     5] loss: 133.20925\n",
      "[epoch 368, batch     6] loss: 135.91307\n",
      "[epoch 368, batch     7] loss: 127.17712\n",
      "[epoch 368, batch     8] loss: 126.37440\n",
      "[epoch 368, batch     9] loss: 119.85444\n",
      "[epoch 368, batch    10] loss: 134.06430\n",
      "[epoch 368, batch    11] loss: 115.87214\n",
      "[epoch 368, batch    12] loss: 137.49905\n",
      "[epoch 368, batch    13] loss: 117.66757\n",
      "[epoch 368, batch    14] loss: 126.58707\n",
      "[epoch 368, batch    15] loss: 137.65256\n",
      "[epoch 368, batch    16] loss: 132.27094\n",
      "[epoch 368, batch    17] loss: 142.04983\n",
      "[epoch 368, batch    18] loss: 130.38618\n",
      "[epoch 368, batch    19] loss: 124.27486\n",
      "[epoch 368, batch    20] loss: 119.53659\n",
      "[epoch 368, batch    21] loss: 132.44249\n",
      "[epoch 368, batch    22] loss: 132.57285\n",
      "[epoch 368, batch    23] loss: 133.65131\n",
      "[epoch 368, batch    24] loss: 142.04398\n",
      "[epoch 368, batch    25] loss: 134.25504\n",
      "[epoch 368, batch    26] loss: 135.06079\n",
      "[epoch 368, batch    27] loss: 132.61184\n",
      "[epoch 368, batch    28] loss: 138.59067\n",
      "[epoch 368, batch    29] loss: 151.24062\n",
      "[epoch 368, batch    30] loss: 114.09576\n",
      "[epoch 368, batch    31] loss: 129.35298\n",
      "[epoch 368, batch    32] loss: 29.16193\n",
      "[epoch 369, batch     1] loss: 129.41880\n",
      "[epoch 369, batch     2] loss: 125.38108\n",
      "[epoch 369, batch     3] loss: 132.53481\n",
      "[epoch 369, batch     4] loss: 140.79473\n",
      "[epoch 369, batch     5] loss: 133.80327\n",
      "[epoch 369, batch     6] loss: 134.94311\n",
      "[epoch 369, batch     7] loss: 138.42869\n",
      "[epoch 369, batch     8] loss: 128.76181\n",
      "[epoch 369, batch     9] loss: 127.87270\n",
      "[epoch 369, batch    10] loss: 129.53725\n",
      "[epoch 369, batch    11] loss: 125.31868\n",
      "[epoch 369, batch    12] loss: 131.39113\n",
      "[epoch 369, batch    13] loss: 136.65134\n",
      "[epoch 369, batch    14] loss: 131.58808\n",
      "[epoch 369, batch    15] loss: 149.84105\n",
      "[epoch 369, batch    16] loss: 127.29160\n",
      "[epoch 369, batch    17] loss: 115.38060\n",
      "[epoch 369, batch    18] loss: 143.14318\n",
      "[epoch 369, batch    19] loss: 137.74973\n",
      "[epoch 369, batch    20] loss: 130.11589\n",
      "[epoch 369, batch    21] loss: 121.17676\n",
      "[epoch 369, batch    22] loss: 138.56666\n",
      "[epoch 369, batch    23] loss: 123.12461\n",
      "[epoch 369, batch    24] loss: 132.51597\n",
      "[epoch 369, batch    25] loss: 133.70657\n",
      "[epoch 369, batch    26] loss: 135.18171\n",
      "[epoch 369, batch    27] loss: 139.85682\n",
      "[epoch 369, batch    28] loss: 135.85112\n",
      "[epoch 369, batch    29] loss: 132.27109\n",
      "[epoch 369, batch    30] loss: 140.09304\n",
      "[epoch 369, batch    31] loss: 124.10903\n",
      "[epoch 369, batch    32] loss: 34.16985\n",
      "[epoch 370, batch     1] loss: 125.22531\n",
      "[epoch 370, batch     2] loss: 133.22276\n",
      "[epoch 370, batch     3] loss: 125.55816\n",
      "[epoch 370, batch     4] loss: 144.43336\n",
      "[epoch 370, batch     5] loss: 124.20879\n",
      "[epoch 370, batch     6] loss: 128.94602\n",
      "[epoch 370, batch     7] loss: 129.48381\n",
      "[epoch 370, batch     8] loss: 131.71259\n",
      "[epoch 370, batch     9] loss: 133.49725\n",
      "[epoch 370, batch    10] loss: 132.90971\n",
      "[epoch 370, batch    11] loss: 146.18146\n",
      "[epoch 370, batch    12] loss: 125.54566\n",
      "[epoch 370, batch    13] loss: 144.04412\n",
      "[epoch 370, batch    14] loss: 140.12904\n",
      "[epoch 370, batch    15] loss: 122.15812\n",
      "[epoch 370, batch    16] loss: 132.90217\n",
      "[epoch 370, batch    17] loss: 128.25868\n",
      "[epoch 370, batch    18] loss: 125.23251\n",
      "[epoch 370, batch    19] loss: 140.53749\n",
      "[epoch 370, batch    20] loss: 126.77485\n",
      "[epoch 370, batch    21] loss: 137.55908\n",
      "[epoch 370, batch    22] loss: 147.96521\n",
      "[epoch 370, batch    23] loss: 131.78561\n",
      "[epoch 370, batch    24] loss: 128.52403\n",
      "[epoch 370, batch    25] loss: 128.28048\n",
      "[epoch 370, batch    26] loss: 150.91136\n",
      "[epoch 370, batch    27] loss: 129.52459\n",
      "[epoch 370, batch    28] loss: 143.32931\n",
      "[epoch 370, batch    29] loss: 128.59533\n",
      "[epoch 370, batch    30] loss: 127.51204\n",
      "[epoch 370, batch    31] loss: 139.67918\n",
      "[epoch 370, batch    32] loss: 31.40383\n",
      "[epoch 371, batch     1] loss: 127.02115\n",
      "[epoch 371, batch     2] loss: 124.83157\n",
      "[epoch 371, batch     3] loss: 134.21596\n",
      "[epoch 371, batch     4] loss: 143.54753\n",
      "[epoch 371, batch     5] loss: 129.97455\n",
      "[epoch 371, batch     6] loss: 145.65497\n",
      "[epoch 371, batch     7] loss: 124.50444\n",
      "[epoch 371, batch     8] loss: 125.73180\n",
      "[epoch 371, batch     9] loss: 119.62418\n",
      "[epoch 371, batch    10] loss: 139.73735\n",
      "[epoch 371, batch    11] loss: 143.15581\n",
      "[epoch 371, batch    12] loss: 126.30081\n",
      "[epoch 371, batch    13] loss: 138.62217\n",
      "[epoch 371, batch    14] loss: 137.18020\n",
      "[epoch 371, batch    15] loss: 134.98694\n",
      "[epoch 371, batch    16] loss: 141.16837\n",
      "[epoch 371, batch    17] loss: 131.07337\n",
      "[epoch 371, batch    18] loss: 121.47341\n",
      "[epoch 371, batch    19] loss: 140.30417\n",
      "[epoch 371, batch    20] loss: 140.70497\n",
      "[epoch 371, batch    21] loss: 126.65303\n",
      "[epoch 371, batch    22] loss: 133.05050\n",
      "[epoch 371, batch    23] loss: 130.54441\n",
      "[epoch 371, batch    24] loss: 128.70126\n",
      "[epoch 371, batch    25] loss: 134.95696\n",
      "[epoch 371, batch    26] loss: 128.05024\n",
      "[epoch 371, batch    27] loss: 128.34155\n",
      "[epoch 371, batch    28] loss: 114.00883\n",
      "[epoch 371, batch    29] loss: 137.51882\n",
      "[epoch 371, batch    30] loss: 127.86734\n",
      "[epoch 371, batch    31] loss: 120.33712\n",
      "[epoch 371, batch    32] loss: 28.70338\n",
      "[epoch 372, batch     1] loss: 134.46031\n",
      "[epoch 372, batch     2] loss: 141.53476\n",
      "[epoch 372, batch     3] loss: 126.64921\n",
      "[epoch 372, batch     4] loss: 135.01855\n",
      "[epoch 372, batch     5] loss: 137.04912\n",
      "[epoch 372, batch     6] loss: 142.59727\n",
      "[epoch 372, batch     7] loss: 126.82758\n",
      "[epoch 372, batch     8] loss: 128.14782\n",
      "[epoch 372, batch     9] loss: 130.78369\n",
      "[epoch 372, batch    10] loss: 140.16976\n",
      "[epoch 372, batch    11] loss: 139.40502\n",
      "[epoch 372, batch    12] loss: 135.04009\n",
      "[epoch 372, batch    13] loss: 135.39890\n",
      "[epoch 372, batch    14] loss: 124.82728\n",
      "[epoch 372, batch    15] loss: 119.93911\n",
      "[epoch 372, batch    16] loss: 135.69824\n",
      "[epoch 372, batch    17] loss: 122.27457\n",
      "[epoch 372, batch    18] loss: 125.34021\n",
      "[epoch 372, batch    19] loss: 126.45401\n",
      "[epoch 372, batch    20] loss: 125.82600\n",
      "[epoch 372, batch    21] loss: 134.02187\n",
      "[epoch 372, batch    22] loss: 127.39222\n",
      "[epoch 372, batch    23] loss: 134.82970\n",
      "[epoch 372, batch    24] loss: 131.55072\n",
      "[epoch 372, batch    25] loss: 132.22137\n",
      "[epoch 372, batch    26] loss: 128.05567\n",
      "[epoch 372, batch    27] loss: 145.81988\n",
      "[epoch 372, batch    28] loss: 145.80321\n",
      "[epoch 372, batch    29] loss: 131.20318\n",
      "[epoch 372, batch    30] loss: 130.57443\n",
      "[epoch 372, batch    31] loss: 119.52464\n",
      "[epoch 372, batch    32] loss: 30.16660\n",
      "[epoch 373, batch     1] loss: 134.13889\n",
      "[epoch 373, batch     2] loss: 128.48648\n",
      "[epoch 373, batch     3] loss: 141.88330\n",
      "[epoch 373, batch     4] loss: 130.67407\n",
      "[epoch 373, batch     5] loss: 139.25224\n",
      "[epoch 373, batch     6] loss: 142.20461\n",
      "[epoch 373, batch     7] loss: 138.16058\n",
      "[epoch 373, batch     8] loss: 140.61511\n",
      "[epoch 373, batch     9] loss: 132.49213\n",
      "[epoch 373, batch    10] loss: 144.86985\n",
      "[epoch 373, batch    11] loss: 138.34290\n",
      "[epoch 373, batch    12] loss: 136.75322\n",
      "[epoch 373, batch    13] loss: 133.52506\n",
      "[epoch 373, batch    14] loss: 126.55268\n",
      "[epoch 373, batch    15] loss: 124.21132\n",
      "[epoch 373, batch    16] loss: 132.59612\n",
      "[epoch 373, batch    17] loss: 127.02631\n",
      "[epoch 373, batch    18] loss: 127.92303\n",
      "[epoch 373, batch    19] loss: 150.08514\n",
      "[epoch 373, batch    20] loss: 134.81080\n",
      "[epoch 373, batch    21] loss: 136.27714\n",
      "[epoch 373, batch    22] loss: 132.74143\n",
      "[epoch 373, batch    23] loss: 119.64418\n",
      "[epoch 373, batch    24] loss: 151.26632\n",
      "[epoch 373, batch    25] loss: 120.90137\n",
      "[epoch 373, batch    26] loss: 126.22590\n",
      "[epoch 373, batch    27] loss: 129.04530\n",
      "[epoch 373, batch    28] loss: 130.30921\n",
      "[epoch 373, batch    29] loss: 112.84666\n",
      "[epoch 373, batch    30] loss: 132.52910\n",
      "[epoch 373, batch    31] loss: 125.03306\n",
      "[epoch 373, batch    32] loss: 37.05015\n",
      "[epoch 374, batch     1] loss: 126.11574\n",
      "[epoch 374, batch     2] loss: 123.68778\n",
      "[epoch 374, batch     3] loss: 137.22871\n",
      "[epoch 374, batch     4] loss: 132.53132\n",
      "[epoch 374, batch     5] loss: 137.96880\n",
      "[epoch 374, batch     6] loss: 131.25131\n",
      "[epoch 374, batch     7] loss: 126.80917\n",
      "[epoch 374, batch     8] loss: 133.93173\n",
      "[epoch 374, batch     9] loss: 123.80448\n",
      "[epoch 374, batch    10] loss: 124.14577\n",
      "[epoch 374, batch    11] loss: 128.94743\n",
      "[epoch 374, batch    12] loss: 125.78169\n",
      "[epoch 374, batch    13] loss: 129.76280\n",
      "[epoch 374, batch    14] loss: 140.45165\n",
      "[epoch 374, batch    15] loss: 133.11821\n",
      "[epoch 374, batch    16] loss: 130.36519\n",
      "[epoch 374, batch    17] loss: 137.14813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 374, batch    18] loss: 139.24040\n",
      "[epoch 374, batch    19] loss: 128.18652\n",
      "[epoch 374, batch    20] loss: 149.96449\n",
      "[epoch 374, batch    21] loss: 124.07891\n",
      "[epoch 374, batch    22] loss: 130.27686\n",
      "[epoch 374, batch    23] loss: 128.59368\n",
      "[epoch 374, batch    24] loss: 123.07293\n",
      "[epoch 374, batch    25] loss: 132.84856\n",
      "[epoch 374, batch    26] loss: 128.00155\n",
      "[epoch 374, batch    27] loss: 124.05860\n",
      "[epoch 374, batch    28] loss: 127.41201\n",
      "[epoch 374, batch    29] loss: 150.90964\n",
      "[epoch 374, batch    30] loss: 131.42002\n",
      "[epoch 374, batch    31] loss: 133.47071\n",
      "[epoch 374, batch    32] loss: 33.60267\n",
      "[epoch 375, batch     1] loss: 143.71420\n",
      "[epoch 375, batch     2] loss: 121.65577\n",
      "[epoch 375, batch     3] loss: 114.63442\n",
      "[epoch 375, batch     4] loss: 131.55661\n",
      "[epoch 375, batch     5] loss: 125.28341\n",
      "[epoch 375, batch     6] loss: 134.79998\n",
      "[epoch 375, batch     7] loss: 136.22748\n",
      "[epoch 375, batch     8] loss: 126.33377\n",
      "[epoch 375, batch     9] loss: 135.73215\n",
      "[epoch 375, batch    10] loss: 135.24168\n",
      "[epoch 375, batch    11] loss: 140.80148\n",
      "[epoch 375, batch    12] loss: 133.98734\n",
      "[epoch 375, batch    13] loss: 121.06472\n",
      "[epoch 375, batch    14] loss: 129.87445\n",
      "[epoch 375, batch    15] loss: 127.28563\n",
      "[epoch 375, batch    16] loss: 123.13633\n",
      "[epoch 375, batch    17] loss: 140.40843\n",
      "[epoch 375, batch    18] loss: 127.51866\n",
      "[epoch 375, batch    19] loss: 125.54198\n",
      "[epoch 375, batch    20] loss: 129.83460\n",
      "[epoch 375, batch    21] loss: 141.53389\n",
      "[epoch 375, batch    22] loss: 125.61803\n",
      "[epoch 375, batch    23] loss: 138.68322\n",
      "[epoch 375, batch    24] loss: 133.83650\n",
      "[epoch 375, batch    25] loss: 122.60199\n",
      "[epoch 375, batch    26] loss: 138.34280\n",
      "[epoch 375, batch    27] loss: 139.65294\n",
      "[epoch 375, batch    28] loss: 138.22790\n",
      "[epoch 375, batch    29] loss: 120.71313\n",
      "[epoch 375, batch    30] loss: 141.57515\n",
      "[epoch 375, batch    31] loss: 143.72943\n",
      "[epoch 375, batch    32] loss: 37.54700\n",
      "[epoch 376, batch     1] loss: 128.48970\n",
      "[epoch 376, batch     2] loss: 133.06070\n",
      "[epoch 376, batch     3] loss: 145.47013\n",
      "[epoch 376, batch     4] loss: 154.74294\n",
      "[epoch 376, batch     5] loss: 131.97372\n",
      "[epoch 376, batch     6] loss: 134.52880\n",
      "[epoch 376, batch     7] loss: 134.56545\n",
      "[epoch 376, batch     8] loss: 118.87024\n",
      "[epoch 376, batch     9] loss: 117.37378\n",
      "[epoch 376, batch    10] loss: 126.50402\n",
      "[epoch 376, batch    11] loss: 129.91437\n",
      "[epoch 376, batch    12] loss: 120.23506\n",
      "[epoch 376, batch    13] loss: 146.75507\n",
      "[epoch 376, batch    14] loss: 141.13982\n",
      "[epoch 376, batch    15] loss: 136.88957\n",
      "[epoch 376, batch    16] loss: 130.83561\n",
      "[epoch 376, batch    17] loss: 129.62603\n",
      "[epoch 376, batch    18] loss: 146.07890\n",
      "[epoch 376, batch    19] loss: 130.47161\n",
      "[epoch 376, batch    20] loss: 125.58727\n",
      "[epoch 376, batch    21] loss: 134.70475\n",
      "[epoch 376, batch    22] loss: 138.40458\n",
      "[epoch 376, batch    23] loss: 130.93303\n",
      "[epoch 376, batch    24] loss: 133.54916\n",
      "[epoch 376, batch    25] loss: 134.77844\n",
      "[epoch 376, batch    26] loss: 130.18593\n",
      "[epoch 376, batch    27] loss: 128.68849\n",
      "[epoch 376, batch    28] loss: 121.78760\n",
      "[epoch 376, batch    29] loss: 121.47486\n",
      "[epoch 376, batch    30] loss: 134.88060\n",
      "[epoch 376, batch    31] loss: 148.39096\n",
      "[epoch 376, batch    32] loss: 26.86654\n",
      "[epoch 377, batch     1] loss: 133.53822\n",
      "[epoch 377, batch     2] loss: 143.49379\n",
      "[epoch 377, batch     3] loss: 134.83435\n",
      "[epoch 377, batch     4] loss: 131.72616\n",
      "[epoch 377, batch     5] loss: 137.30643\n",
      "[epoch 377, batch     6] loss: 123.55249\n",
      "[epoch 377, batch     7] loss: 125.76812\n",
      "[epoch 377, batch     8] loss: 135.54939\n",
      "[epoch 377, batch     9] loss: 133.02984\n",
      "[epoch 377, batch    10] loss: 147.26680\n",
      "[epoch 377, batch    11] loss: 134.09393\n",
      "[epoch 377, batch    12] loss: 134.05828\n",
      "[epoch 377, batch    13] loss: 127.69599\n",
      "[epoch 377, batch    14] loss: 131.53830\n",
      "[epoch 377, batch    15] loss: 125.51946\n",
      "[epoch 377, batch    16] loss: 120.13686\n",
      "[epoch 377, batch    17] loss: 128.91290\n",
      "[epoch 377, batch    18] loss: 136.12826\n",
      "[epoch 377, batch    19] loss: 130.95113\n",
      "[epoch 377, batch    20] loss: 140.18533\n",
      "[epoch 377, batch    21] loss: 120.79414\n",
      "[epoch 377, batch    22] loss: 133.59299\n",
      "[epoch 377, batch    23] loss: 122.85192\n",
      "[epoch 377, batch    24] loss: 139.32370\n",
      "[epoch 377, batch    25] loss: 114.44818\n",
      "[epoch 377, batch    26] loss: 125.95668\n",
      "[epoch 377, batch    27] loss: 130.16552\n",
      "[epoch 377, batch    28] loss: 125.83701\n",
      "[epoch 377, batch    29] loss: 134.72533\n",
      "[epoch 377, batch    30] loss: 136.68333\n",
      "[epoch 377, batch    31] loss: 134.48953\n",
      "[epoch 377, batch    32] loss: 31.43153\n",
      "[epoch 378, batch     1] loss: 133.20421\n",
      "[epoch 378, batch     2] loss: 130.40948\n",
      "[epoch 378, batch     3] loss: 124.33608\n",
      "[epoch 378, batch     4] loss: 134.84587\n",
      "[epoch 378, batch     5] loss: 121.46634\n",
      "[epoch 378, batch     6] loss: 144.52397\n",
      "[epoch 378, batch     7] loss: 123.56102\n",
      "[epoch 378, batch     8] loss: 138.24602\n",
      "[epoch 378, batch     9] loss: 137.82580\n",
      "[epoch 378, batch    10] loss: 122.20660\n",
      "[epoch 378, batch    11] loss: 141.43843\n",
      "[epoch 378, batch    12] loss: 123.77241\n",
      "[epoch 378, batch    13] loss: 121.04738\n",
      "[epoch 378, batch    14] loss: 125.78302\n",
      "[epoch 378, batch    15] loss: 125.10493\n",
      "[epoch 378, batch    16] loss: 132.22171\n",
      "[epoch 378, batch    17] loss: 135.59674\n",
      "[epoch 378, batch    18] loss: 144.44336\n",
      "[epoch 378, batch    19] loss: 129.06416\n",
      "[epoch 378, batch    20] loss: 130.25024\n",
      "[epoch 378, batch    21] loss: 131.49798\n",
      "[epoch 378, batch    22] loss: 125.06706\n",
      "[epoch 378, batch    23] loss: 123.31623\n",
      "[epoch 378, batch    24] loss: 125.39887\n",
      "[epoch 378, batch    25] loss: 139.19362\n",
      "[epoch 378, batch    26] loss: 136.06965\n",
      "[epoch 378, batch    27] loss: 121.08428\n",
      "[epoch 378, batch    28] loss: 130.71556\n",
      "[epoch 378, batch    29] loss: 141.90690\n",
      "[epoch 378, batch    30] loss: 135.54743\n",
      "[epoch 378, batch    31] loss: 137.09152\n",
      "[epoch 378, batch    32] loss: 36.78331\n",
      "[epoch 379, batch     1] loss: 125.66605\n",
      "[epoch 379, batch     2] loss: 132.36759\n",
      "[epoch 379, batch     3] loss: 124.94527\n",
      "[epoch 379, batch     4] loss: 131.24614\n",
      "[epoch 379, batch     5] loss: 133.44004\n",
      "[epoch 379, batch     6] loss: 120.99462\n",
      "[epoch 379, batch     7] loss: 136.92415\n",
      "[epoch 379, batch     8] loss: 136.78823\n",
      "[epoch 379, batch     9] loss: 142.02872\n",
      "[epoch 379, batch    10] loss: 134.79333\n",
      "[epoch 379, batch    11] loss: 144.05850\n",
      "[epoch 379, batch    12] loss: 123.84120\n",
      "[epoch 379, batch    13] loss: 123.16896\n",
      "[epoch 379, batch    14] loss: 126.29595\n",
      "[epoch 379, batch    15] loss: 133.04897\n",
      "[epoch 379, batch    16] loss: 132.01271\n",
      "[epoch 379, batch    17] loss: 130.92765\n",
      "[epoch 379, batch    18] loss: 133.65961\n",
      "[epoch 379, batch    19] loss: 141.22826\n",
      "[epoch 379, batch    20] loss: 123.70578\n",
      "[epoch 379, batch    21] loss: 147.78471\n",
      "[epoch 379, batch    22] loss: 135.83993\n",
      "[epoch 379, batch    23] loss: 128.55396\n",
      "[epoch 379, batch    24] loss: 131.77652\n",
      "[epoch 379, batch    25] loss: 137.43728\n",
      "[epoch 379, batch    26] loss: 129.97800\n",
      "[epoch 379, batch    27] loss: 141.38170\n",
      "[epoch 379, batch    28] loss: 145.11966\n",
      "[epoch 379, batch    29] loss: 120.44946\n",
      "[epoch 379, batch    30] loss: 132.81909\n",
      "[epoch 379, batch    31] loss: 131.17497\n",
      "[epoch 379, batch    32] loss: 28.66469\n",
      "[epoch 380, batch     1] loss: 130.46247\n",
      "[epoch 380, batch     2] loss: 137.08999\n",
      "[epoch 380, batch     3] loss: 126.05104\n",
      "[epoch 380, batch     4] loss: 138.58446\n",
      "[epoch 380, batch     5] loss: 141.95266\n",
      "[epoch 380, batch     6] loss: 131.13538\n",
      "[epoch 380, batch     7] loss: 132.98166\n",
      "[epoch 380, batch     8] loss: 134.73135\n",
      "[epoch 380, batch     9] loss: 130.36127\n",
      "[epoch 380, batch    10] loss: 126.53628\n",
      "[epoch 380, batch    11] loss: 125.03521\n",
      "[epoch 380, batch    12] loss: 133.24923\n",
      "[epoch 380, batch    13] loss: 120.68974\n",
      "[epoch 380, batch    14] loss: 123.19480\n",
      "[epoch 380, batch    15] loss: 138.73374\n",
      "[epoch 380, batch    16] loss: 131.68764\n",
      "[epoch 380, batch    17] loss: 124.86516\n",
      "[epoch 380, batch    18] loss: 126.79472\n",
      "[epoch 380, batch    19] loss: 131.77589\n",
      "[epoch 380, batch    20] loss: 135.88476\n",
      "[epoch 380, batch    21] loss: 124.63695\n",
      "[epoch 380, batch    22] loss: 131.57238\n",
      "[epoch 380, batch    23] loss: 141.73718\n",
      "[epoch 380, batch    24] loss: 146.37204\n",
      "[epoch 380, batch    25] loss: 142.03645\n",
      "[epoch 380, batch    26] loss: 133.04710\n",
      "[epoch 380, batch    27] loss: 137.06330\n",
      "[epoch 380, batch    28] loss: 128.25353\n",
      "[epoch 380, batch    29] loss: 136.20627\n",
      "[epoch 380, batch    30] loss: 120.43165\n",
      "[epoch 380, batch    31] loss: 130.39158\n",
      "[epoch 380, batch    32] loss: 35.43347\n",
      "[epoch 381, batch     1] loss: 127.79677\n",
      "[epoch 381, batch     2] loss: 127.53746\n",
      "[epoch 381, batch     3] loss: 126.47323\n",
      "[epoch 381, batch     4] loss: 122.39259\n",
      "[epoch 381, batch     5] loss: 130.38532\n",
      "[epoch 381, batch     6] loss: 135.20492\n",
      "[epoch 381, batch     7] loss: 131.95236\n",
      "[epoch 381, batch     8] loss: 140.99690\n",
      "[epoch 381, batch     9] loss: 122.60132\n",
      "[epoch 381, batch    10] loss: 137.66906\n",
      "[epoch 381, batch    11] loss: 130.27317\n",
      "[epoch 381, batch    12] loss: 137.89590\n",
      "[epoch 381, batch    13] loss: 123.62701\n",
      "[epoch 381, batch    14] loss: 127.34744\n",
      "[epoch 381, batch    15] loss: 133.06811\n",
      "[epoch 381, batch    16] loss: 139.19718\n",
      "[epoch 381, batch    17] loss: 154.39535\n",
      "[epoch 381, batch    18] loss: 129.27098\n",
      "[epoch 381, batch    19] loss: 131.07297\n",
      "[epoch 381, batch    20] loss: 136.38170\n",
      "[epoch 381, batch    21] loss: 128.01583\n",
      "[epoch 381, batch    22] loss: 132.08438\n",
      "[epoch 381, batch    23] loss: 131.23194\n",
      "[epoch 381, batch    24] loss: 129.43457\n",
      "[epoch 381, batch    25] loss: 133.17740\n",
      "[epoch 381, batch    26] loss: 126.50041\n",
      "[epoch 381, batch    27] loss: 143.55061\n",
      "[epoch 381, batch    28] loss: 135.73345\n",
      "[epoch 381, batch    29] loss: 138.45892\n",
      "[epoch 381, batch    30] loss: 130.57819\n",
      "[epoch 381, batch    31] loss: 150.21463\n",
      "[epoch 381, batch    32] loss: 31.68693\n",
      "[epoch 382, batch     1] loss: 136.96361\n",
      "[epoch 382, batch     2] loss: 142.08130\n",
      "[epoch 382, batch     3] loss: 133.04428\n",
      "[epoch 382, batch     4] loss: 144.13131\n",
      "[epoch 382, batch     5] loss: 124.82688\n",
      "[epoch 382, batch     6] loss: 124.98472\n",
      "[epoch 382, batch     7] loss: 140.60778\n",
      "[epoch 382, batch     8] loss: 128.19003\n",
      "[epoch 382, batch     9] loss: 121.82590\n",
      "[epoch 382, batch    10] loss: 125.43760\n",
      "[epoch 382, batch    11] loss: 126.64164\n",
      "[epoch 382, batch    12] loss: 119.56969\n",
      "[epoch 382, batch    13] loss: 135.82436\n",
      "[epoch 382, batch    14] loss: 131.24736\n",
      "[epoch 382, batch    15] loss: 130.10052\n",
      "[epoch 382, batch    16] loss: 122.73182\n",
      "[epoch 382, batch    17] loss: 128.68406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 382, batch    18] loss: 129.24430\n",
      "[epoch 382, batch    19] loss: 127.57164\n",
      "[epoch 382, batch    20] loss: 118.31013\n",
      "[epoch 382, batch    21] loss: 122.07888\n",
      "[epoch 382, batch    22] loss: 138.50056\n",
      "[epoch 382, batch    23] loss: 135.80715\n",
      "[epoch 382, batch    24] loss: 129.71092\n",
      "[epoch 382, batch    25] loss: 127.28895\n",
      "[epoch 382, batch    26] loss: 132.08740\n",
      "[epoch 382, batch    27] loss: 137.69115\n",
      "[epoch 382, batch    28] loss: 136.87966\n",
      "[epoch 382, batch    29] loss: 138.45112\n",
      "[epoch 382, batch    30] loss: 142.55506\n",
      "[epoch 382, batch    31] loss: 126.56092\n",
      "[epoch 382, batch    32] loss: 31.53678\n",
      "[epoch 383, batch     1] loss: 134.11397\n",
      "[epoch 383, batch     2] loss: 137.75038\n",
      "[epoch 383, batch     3] loss: 126.93925\n",
      "[epoch 383, batch     4] loss: 120.96759\n",
      "[epoch 383, batch     5] loss: 126.42768\n",
      "[epoch 383, batch     6] loss: 126.15492\n",
      "[epoch 383, batch     7] loss: 143.16667\n",
      "[epoch 383, batch     8] loss: 127.22789\n",
      "[epoch 383, batch     9] loss: 152.34430\n",
      "[epoch 383, batch    10] loss: 131.31558\n",
      "[epoch 383, batch    11] loss: 118.79980\n",
      "[epoch 383, batch    12] loss: 139.24014\n",
      "[epoch 383, batch    13] loss: 132.82417\n",
      "[epoch 383, batch    14] loss: 129.37699\n",
      "[epoch 383, batch    15] loss: 134.09213\n",
      "[epoch 383, batch    16] loss: 126.91295\n",
      "[epoch 383, batch    17] loss: 144.68756\n",
      "[epoch 383, batch    18] loss: 136.53619\n",
      "[epoch 383, batch    19] loss: 130.66409\n",
      "[epoch 383, batch    20] loss: 139.28335\n",
      "[epoch 383, batch    21] loss: 126.66310\n",
      "[epoch 383, batch    22] loss: 133.62370\n",
      "[epoch 383, batch    23] loss: 140.57379\n",
      "[epoch 383, batch    24] loss: 129.64995\n",
      "[epoch 383, batch    25] loss: 131.73568\n",
      "[epoch 383, batch    26] loss: 137.44543\n",
      "[epoch 383, batch    27] loss: 138.68269\n",
      "[epoch 383, batch    28] loss: 120.06865\n",
      "[epoch 383, batch    29] loss: 126.08628\n",
      "[epoch 383, batch    30] loss: 124.63915\n",
      "[epoch 383, batch    31] loss: 141.99032\n",
      "[epoch 383, batch    32] loss: 35.50182\n",
      "[epoch 384, batch     1] loss: 131.54746\n",
      "[epoch 384, batch     2] loss: 150.33905\n",
      "[epoch 384, batch     3] loss: 132.54304\n",
      "[epoch 384, batch     4] loss: 123.60170\n",
      "[epoch 384, batch     5] loss: 141.58634\n",
      "[epoch 384, batch     6] loss: 130.15368\n",
      "[epoch 384, batch     7] loss: 130.07112\n",
      "[epoch 384, batch     8] loss: 136.75933\n",
      "[epoch 384, batch     9] loss: 133.74614\n",
      "[epoch 384, batch    10] loss: 131.53328\n",
      "[epoch 384, batch    11] loss: 121.82792\n",
      "[epoch 384, batch    12] loss: 132.21430\n",
      "[epoch 384, batch    13] loss: 125.44299\n",
      "[epoch 384, batch    14] loss: 140.54316\n",
      "[epoch 384, batch    15] loss: 131.93916\n",
      "[epoch 384, batch    16] loss: 136.33318\n",
      "[epoch 384, batch    17] loss: 128.14665\n",
      "[epoch 384, batch    18] loss: 134.89321\n",
      "[epoch 384, batch    19] loss: 126.54856\n",
      "[epoch 384, batch    20] loss: 128.13410\n",
      "[epoch 384, batch    21] loss: 129.59538\n",
      "[epoch 384, batch    22] loss: 130.34193\n",
      "[epoch 384, batch    23] loss: 140.95148\n",
      "[epoch 384, batch    24] loss: 135.27606\n",
      "[epoch 384, batch    25] loss: 136.60868\n",
      "[epoch 384, batch    26] loss: 133.53198\n",
      "[epoch 384, batch    27] loss: 145.73000\n",
      "[epoch 384, batch    28] loss: 138.61677\n",
      "[epoch 384, batch    29] loss: 125.01766\n",
      "[epoch 384, batch    30] loss: 133.11555\n",
      "[epoch 384, batch    31] loss: 131.32382\n",
      "[epoch 384, batch    32] loss: 36.66021\n",
      "[epoch 385, batch     1] loss: 128.77799\n",
      "[epoch 385, batch     2] loss: 142.64460\n",
      "[epoch 385, batch     3] loss: 117.50708\n",
      "[epoch 385, batch     4] loss: 139.39643\n",
      "[epoch 385, batch     5] loss: 142.25453\n",
      "[epoch 385, batch     6] loss: 130.95250\n",
      "[epoch 385, batch     7] loss: 134.43247\n",
      "[epoch 385, batch     8] loss: 125.76345\n",
      "[epoch 385, batch     9] loss: 119.67684\n",
      "[epoch 385, batch    10] loss: 149.18639\n",
      "[epoch 385, batch    11] loss: 128.58370\n",
      "[epoch 385, batch    12] loss: 141.29318\n",
      "[epoch 385, batch    13] loss: 141.35604\n",
      "[epoch 385, batch    14] loss: 131.93966\n",
      "[epoch 385, batch    15] loss: 135.21526\n",
      "[epoch 385, batch    16] loss: 138.41590\n",
      "[epoch 385, batch    17] loss: 134.27761\n",
      "[epoch 385, batch    18] loss: 122.88481\n",
      "[epoch 385, batch    19] loss: 140.50855\n",
      "[epoch 385, batch    20] loss: 127.67852\n",
      "[epoch 385, batch    21] loss: 124.24463\n",
      "[epoch 385, batch    22] loss: 131.37647\n",
      "[epoch 385, batch    23] loss: 121.97742\n",
      "[epoch 385, batch    24] loss: 139.96730\n",
      "[epoch 385, batch    25] loss: 131.74856\n",
      "[epoch 385, batch    26] loss: 132.44213\n",
      "[epoch 385, batch    27] loss: 116.28165\n",
      "[epoch 385, batch    28] loss: 122.88712\n",
      "[epoch 385, batch    29] loss: 127.11501\n",
      "[epoch 385, batch    30] loss: 131.27397\n",
      "[epoch 385, batch    31] loss: 124.08783\n",
      "[epoch 385, batch    32] loss: 29.05538\n",
      "[epoch 386, batch     1] loss: 128.15800\n",
      "[epoch 386, batch     2] loss: 135.52214\n",
      "[epoch 386, batch     3] loss: 131.57639\n",
      "[epoch 386, batch     4] loss: 140.69250\n",
      "[epoch 386, batch     5] loss: 131.56305\n",
      "[epoch 386, batch     6] loss: 121.59249\n",
      "[epoch 386, batch     7] loss: 132.94416\n",
      "[epoch 386, batch     8] loss: 124.57587\n",
      "[epoch 386, batch     9] loss: 126.71068\n",
      "[epoch 386, batch    10] loss: 125.67281\n",
      "[epoch 386, batch    11] loss: 135.15038\n",
      "[epoch 386, batch    12] loss: 125.91572\n",
      "[epoch 386, batch    13] loss: 126.59191\n",
      "[epoch 386, batch    14] loss: 131.54222\n",
      "[epoch 386, batch    15] loss: 123.78337\n",
      "[epoch 386, batch    16] loss: 129.71688\n",
      "[epoch 386, batch    17] loss: 132.11837\n",
      "[epoch 386, batch    18] loss: 135.37622\n",
      "[epoch 386, batch    19] loss: 132.41727\n",
      "[epoch 386, batch    20] loss: 132.90054\n",
      "[epoch 386, batch    21] loss: 146.88018\n",
      "[epoch 386, batch    22] loss: 128.19368\n",
      "[epoch 386, batch    23] loss: 115.46270\n",
      "[epoch 386, batch    24] loss: 133.41666\n",
      "[epoch 386, batch    25] loss: 133.07690\n",
      "[epoch 386, batch    26] loss: 132.40896\n",
      "[epoch 386, batch    27] loss: 133.86762\n",
      "[epoch 386, batch    28] loss: 145.48197\n",
      "[epoch 386, batch    29] loss: 135.47261\n",
      "[epoch 386, batch    30] loss: 137.02415\n",
      "[epoch 386, batch    31] loss: 121.69620\n",
      "[epoch 386, batch    32] loss: 33.28082\n",
      "[epoch 387, batch     1] loss: 146.73518\n",
      "[epoch 387, batch     2] loss: 127.33369\n",
      "[epoch 387, batch     3] loss: 127.32645\n",
      "[epoch 387, batch     4] loss: 140.45626\n",
      "[epoch 387, batch     5] loss: 141.96876\n",
      "[epoch 387, batch     6] loss: 129.94425\n",
      "[epoch 387, batch     7] loss: 126.10682\n",
      "[epoch 387, batch     8] loss: 140.45715\n",
      "[epoch 387, batch     9] loss: 123.33595\n",
      "[epoch 387, batch    10] loss: 126.68340\n",
      "[epoch 387, batch    11] loss: 117.53705\n",
      "[epoch 387, batch    12] loss: 125.84475\n",
      "[epoch 387, batch    13] loss: 138.49899\n",
      "[epoch 387, batch    14] loss: 141.57287\n",
      "[epoch 387, batch    15] loss: 125.77342\n",
      "[epoch 387, batch    16] loss: 139.12627\n",
      "[epoch 387, batch    17] loss: 129.00795\n",
      "[epoch 387, batch    18] loss: 121.14981\n",
      "[epoch 387, batch    19] loss: 130.04831\n",
      "[epoch 387, batch    20] loss: 125.14029\n",
      "[epoch 387, batch    21] loss: 124.28576\n",
      "[epoch 387, batch    22] loss: 138.24060\n",
      "[epoch 387, batch    23] loss: 129.01069\n",
      "[epoch 387, batch    24] loss: 133.75255\n",
      "[epoch 387, batch    25] loss: 135.52763\n",
      "[epoch 387, batch    26] loss: 143.05176\n",
      "[epoch 387, batch    27] loss: 132.37416\n",
      "[epoch 387, batch    28] loss: 130.62161\n",
      "[epoch 387, batch    29] loss: 138.69138\n",
      "[epoch 387, batch    30] loss: 135.48480\n",
      "[epoch 387, batch    31] loss: 143.54898\n",
      "[epoch 387, batch    32] loss: 37.24656\n",
      "[epoch 388, batch     1] loss: 132.52059\n",
      "[epoch 388, batch     2] loss: 137.62055\n",
      "[epoch 388, batch     3] loss: 132.11799\n",
      "[epoch 388, batch     4] loss: 130.60262\n",
      "[epoch 388, batch     5] loss: 130.96679\n",
      "[epoch 388, batch     6] loss: 136.44637\n",
      "[epoch 388, batch     7] loss: 131.25331\n",
      "[epoch 388, batch     8] loss: 134.92359\n",
      "[epoch 388, batch     9] loss: 117.28841\n",
      "[epoch 388, batch    10] loss: 125.48938\n",
      "[epoch 388, batch    11] loss: 133.88814\n",
      "[epoch 388, batch    12] loss: 127.23469\n",
      "[epoch 388, batch    13] loss: 136.64239\n",
      "[epoch 388, batch    14] loss: 119.37072\n",
      "[epoch 388, batch    15] loss: 125.59119\n",
      "[epoch 388, batch    16] loss: 130.07461\n",
      "[epoch 388, batch    17] loss: 141.67618\n",
      "[epoch 388, batch    18] loss: 142.17433\n",
      "[epoch 388, batch    19] loss: 121.82595\n",
      "[epoch 388, batch    20] loss: 127.89385\n",
      "[epoch 388, batch    21] loss: 146.76475\n",
      "[epoch 388, batch    22] loss: 132.28147\n",
      "[epoch 388, batch    23] loss: 129.54089\n",
      "[epoch 388, batch    24] loss: 122.21986\n",
      "[epoch 388, batch    25] loss: 120.01027\n",
      "[epoch 388, batch    26] loss: 135.16656\n",
      "[epoch 388, batch    27] loss: 134.84066\n",
      "[epoch 388, batch    28] loss: 130.24588\n",
      "[epoch 388, batch    29] loss: 130.69862\n",
      "[epoch 388, batch    30] loss: 124.37208\n",
      "[epoch 388, batch    31] loss: 127.43012\n",
      "[epoch 388, batch    32] loss: 31.73974\n",
      "[epoch 389, batch     1] loss: 136.31356\n",
      "[epoch 389, batch     2] loss: 125.91345\n",
      "[epoch 389, batch     3] loss: 144.31035\n",
      "[epoch 389, batch     4] loss: 142.27383\n",
      "[epoch 389, batch     5] loss: 126.14957\n",
      "[epoch 389, batch     6] loss: 122.06031\n",
      "[epoch 389, batch     7] loss: 155.65719\n",
      "[epoch 389, batch     8] loss: 118.33247\n",
      "[epoch 389, batch     9] loss: 127.96452\n",
      "[epoch 389, batch    10] loss: 129.77309\n",
      "[epoch 389, batch    11] loss: 123.08527\n",
      "[epoch 389, batch    12] loss: 137.30497\n",
      "[epoch 389, batch    13] loss: 140.09276\n",
      "[epoch 389, batch    14] loss: 132.43921\n",
      "[epoch 389, batch    15] loss: 125.95024\n",
      "[epoch 389, batch    16] loss: 124.16431\n",
      "[epoch 389, batch    17] loss: 133.26137\n",
      "[epoch 389, batch    18] loss: 145.60004\n",
      "[epoch 389, batch    19] loss: 124.57163\n",
      "[epoch 389, batch    20] loss: 126.40692\n",
      "[epoch 389, batch    21] loss: 137.22549\n",
      "[epoch 389, batch    22] loss: 124.30441\n",
      "[epoch 389, batch    23] loss: 131.38471\n",
      "[epoch 389, batch    24] loss: 145.63127\n",
      "[epoch 389, batch    25] loss: 129.96821\n",
      "[epoch 389, batch    26] loss: 131.03373\n",
      "[epoch 389, batch    27] loss: 141.22180\n",
      "[epoch 389, batch    28] loss: 123.88778\n",
      "[epoch 389, batch    29] loss: 133.86192\n",
      "[epoch 389, batch    30] loss: 129.00606\n",
      "[epoch 389, batch    31] loss: 127.28449\n",
      "[epoch 389, batch    32] loss: 33.90543\n",
      "[epoch 390, batch     1] loss: 131.80770\n",
      "[epoch 390, batch     2] loss: 130.23771\n",
      "[epoch 390, batch     3] loss: 118.63575\n",
      "[epoch 390, batch     4] loss: 128.52578\n",
      "[epoch 390, batch     5] loss: 136.39502\n",
      "[epoch 390, batch     6] loss: 125.95484\n",
      "[epoch 390, batch     7] loss: 124.89413\n",
      "[epoch 390, batch     8] loss: 131.81695\n",
      "[epoch 390, batch     9] loss: 141.35636\n",
      "[epoch 390, batch    10] loss: 125.68800\n",
      "[epoch 390, batch    11] loss: 135.40247\n",
      "[epoch 390, batch    12] loss: 150.15183\n",
      "[epoch 390, batch    13] loss: 132.72167\n",
      "[epoch 390, batch    14] loss: 130.95533\n",
      "[epoch 390, batch    15] loss: 137.67716\n",
      "[epoch 390, batch    16] loss: 137.04433\n",
      "[epoch 390, batch    17] loss: 141.10968\n",
      "[epoch 390, batch    18] loss: 142.56174\n",
      "[epoch 390, batch    19] loss: 138.91328\n",
      "[epoch 390, batch    20] loss: 129.68898\n",
      "[epoch 390, batch    21] loss: 125.53385\n",
      "[epoch 390, batch    22] loss: 128.95516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 390, batch    23] loss: 140.96311\n",
      "[epoch 390, batch    24] loss: 124.41608\n",
      "[epoch 390, batch    25] loss: 135.42360\n",
      "[epoch 390, batch    26] loss: 134.20526\n",
      "[epoch 390, batch    27] loss: 138.87987\n",
      "[epoch 390, batch    28] loss: 126.67248\n",
      "[epoch 390, batch    29] loss: 143.62943\n",
      "[epoch 390, batch    30] loss: 131.76229\n",
      "[epoch 390, batch    31] loss: 126.01314\n",
      "[epoch 390, batch    32] loss: 34.03032\n",
      "[epoch 391, batch     1] loss: 136.70172\n",
      "[epoch 391, batch     2] loss: 129.89810\n",
      "[epoch 391, batch     3] loss: 130.97869\n",
      "[epoch 391, batch     4] loss: 135.66167\n",
      "[epoch 391, batch     5] loss: 132.36705\n",
      "[epoch 391, batch     6] loss: 141.10900\n",
      "[epoch 391, batch     7] loss: 139.96444\n",
      "[epoch 391, batch     8] loss: 136.55169\n",
      "[epoch 391, batch     9] loss: 135.03012\n",
      "[epoch 391, batch    10] loss: 127.63236\n",
      "[epoch 391, batch    11] loss: 119.58807\n",
      "[epoch 391, batch    12] loss: 138.60091\n",
      "[epoch 391, batch    13] loss: 129.05881\n",
      "[epoch 391, batch    14] loss: 134.07278\n",
      "[epoch 391, batch    15] loss: 137.58657\n",
      "[epoch 391, batch    16] loss: 134.82594\n",
      "[epoch 391, batch    17] loss: 126.79411\n",
      "[epoch 391, batch    18] loss: 144.22429\n",
      "[epoch 391, batch    19] loss: 133.26894\n",
      "[epoch 391, batch    20] loss: 133.63739\n",
      "[epoch 391, batch    21] loss: 124.65336\n",
      "[epoch 391, batch    22] loss: 129.58729\n",
      "[epoch 391, batch    23] loss: 137.23680\n",
      "[epoch 391, batch    24] loss: 120.67266\n",
      "[epoch 391, batch    25] loss: 136.81676\n",
      "[epoch 391, batch    26] loss: 132.26019\n",
      "[epoch 391, batch    27] loss: 123.79877\n",
      "[epoch 391, batch    28] loss: 135.59608\n",
      "[epoch 391, batch    29] loss: 138.21737\n",
      "[epoch 391, batch    30] loss: 130.51377\n",
      "[epoch 391, batch    31] loss: 134.40047\n",
      "[epoch 391, batch    32] loss: 27.34636\n",
      "[epoch 392, batch     1] loss: 129.99368\n",
      "[epoch 392, batch     2] loss: 127.65777\n",
      "[epoch 392, batch     3] loss: 138.73467\n",
      "[epoch 392, batch     4] loss: 130.29815\n",
      "[epoch 392, batch     5] loss: 132.94705\n",
      "[epoch 392, batch     6] loss: 128.98035\n",
      "[epoch 392, batch     7] loss: 131.32195\n",
      "[epoch 392, batch     8] loss: 137.79248\n",
      "[epoch 392, batch     9] loss: 133.75082\n",
      "[epoch 392, batch    10] loss: 128.69639\n",
      "[epoch 392, batch    11] loss: 124.71003\n",
      "[epoch 392, batch    12] loss: 127.39941\n",
      "[epoch 392, batch    13] loss: 133.24387\n",
      "[epoch 392, batch    14] loss: 146.90601\n",
      "[epoch 392, batch    15] loss: 119.49587\n",
      "[epoch 392, batch    16] loss: 141.05243\n",
      "[epoch 392, batch    17] loss: 137.89809\n",
      "[epoch 392, batch    18] loss: 135.37275\n",
      "[epoch 392, batch    19] loss: 142.59784\n",
      "[epoch 392, batch    20] loss: 145.07477\n",
      "[epoch 392, batch    21] loss: 115.84845\n",
      "[epoch 392, batch    22] loss: 124.94572\n",
      "[epoch 392, batch    23] loss: 122.74217\n",
      "[epoch 392, batch    24] loss: 136.41141\n",
      "[epoch 392, batch    25] loss: 142.31626\n",
      "[epoch 392, batch    26] loss: 145.46384\n",
      "[epoch 392, batch    27] loss: 137.15268\n",
      "[epoch 392, batch    28] loss: 134.56289\n",
      "[epoch 392, batch    29] loss: 131.30104\n",
      "[epoch 392, batch    30] loss: 124.29748\n",
      "[epoch 392, batch    31] loss: 127.08878\n",
      "[epoch 392, batch    32] loss: 38.46919\n",
      "[epoch 393, batch     1] loss: 133.45827\n",
      "[epoch 393, batch     2] loss: 122.91203\n",
      "[epoch 393, batch     3] loss: 124.97885\n",
      "[epoch 393, batch     4] loss: 126.49244\n",
      "[epoch 393, batch     5] loss: 129.28054\n",
      "[epoch 393, batch     6] loss: 137.85482\n",
      "[epoch 393, batch     7] loss: 149.53339\n",
      "[epoch 393, batch     8] loss: 125.78857\n",
      "[epoch 393, batch     9] loss: 118.99983\n",
      "[epoch 393, batch    10] loss: 136.14091\n",
      "[epoch 393, batch    11] loss: 133.57029\n",
      "[epoch 393, batch    12] loss: 132.86597\n",
      "[epoch 393, batch    13] loss: 123.78538\n",
      "[epoch 393, batch    14] loss: 118.31093\n",
      "[epoch 393, batch    15] loss: 133.60018\n",
      "[epoch 393, batch    16] loss: 132.11356\n",
      "[epoch 393, batch    17] loss: 140.44185\n",
      "[epoch 393, batch    18] loss: 127.66210\n",
      "[epoch 393, batch    19] loss: 121.33784\n",
      "[epoch 393, batch    20] loss: 138.55489\n",
      "[epoch 393, batch    21] loss: 120.17861\n",
      "[epoch 393, batch    22] loss: 127.50110\n",
      "[epoch 393, batch    23] loss: 135.91524\n",
      "[epoch 393, batch    24] loss: 137.28536\n",
      "[epoch 393, batch    25] loss: 122.25602\n",
      "[epoch 393, batch    26] loss: 128.62462\n",
      "[epoch 393, batch    27] loss: 138.04633\n",
      "[epoch 393, batch    28] loss: 150.44616\n",
      "[epoch 393, batch    29] loss: 121.42967\n",
      "[epoch 393, batch    30] loss: 129.00634\n",
      "[epoch 393, batch    31] loss: 129.40169\n",
      "[epoch 393, batch    32] loss: 40.91131\n",
      "[epoch 394, batch     1] loss: 132.56747\n",
      "[epoch 394, batch     2] loss: 131.69294\n",
      "[epoch 394, batch     3] loss: 142.41331\n",
      "[epoch 394, batch     4] loss: 128.90944\n",
      "[epoch 394, batch     5] loss: 126.03535\n",
      "[epoch 394, batch     6] loss: 136.91611\n",
      "[epoch 394, batch     7] loss: 133.19073\n",
      "[epoch 394, batch     8] loss: 126.12257\n",
      "[epoch 394, batch     9] loss: 119.73055\n",
      "[epoch 394, batch    10] loss: 139.66751\n",
      "[epoch 394, batch    11] loss: 123.43750\n",
      "[epoch 394, batch    12] loss: 142.26406\n",
      "[epoch 394, batch    13] loss: 116.07775\n",
      "[epoch 394, batch    14] loss: 125.31594\n",
      "[epoch 394, batch    15] loss: 128.51251\n",
      "[epoch 394, batch    16] loss: 119.42499\n",
      "[epoch 394, batch    17] loss: 124.66716\n",
      "[epoch 394, batch    18] loss: 138.27348\n",
      "[epoch 394, batch    19] loss: 136.53602\n",
      "[epoch 394, batch    20] loss: 151.30182\n",
      "[epoch 394, batch    21] loss: 139.56154\n",
      "[epoch 394, batch    22] loss: 129.73208\n",
      "[epoch 394, batch    23] loss: 128.52882\n",
      "[epoch 394, batch    24] loss: 132.86857\n",
      "[epoch 394, batch    25] loss: 132.02214\n",
      "[epoch 394, batch    26] loss: 129.72964\n",
      "[epoch 394, batch    27] loss: 124.67889\n",
      "[epoch 394, batch    28] loss: 133.46447\n",
      "[epoch 394, batch    29] loss: 129.55281\n",
      "[epoch 394, batch    30] loss: 140.05374\n",
      "[epoch 394, batch    31] loss: 132.34973\n",
      "[epoch 394, batch    32] loss: 32.34405\n",
      "[epoch 395, batch     1] loss: 124.69626\n",
      "[epoch 395, batch     2] loss: 131.61929\n",
      "[epoch 395, batch     3] loss: 127.26468\n",
      "[epoch 395, batch     4] loss: 127.88631\n",
      "[epoch 395, batch     5] loss: 132.79154\n",
      "[epoch 395, batch     6] loss: 130.94554\n",
      "[epoch 395, batch     7] loss: 126.73425\n",
      "[epoch 395, batch     8] loss: 123.23660\n",
      "[epoch 395, batch     9] loss: 138.61734\n",
      "[epoch 395, batch    10] loss: 122.44447\n",
      "[epoch 395, batch    11] loss: 123.09469\n",
      "[epoch 395, batch    12] loss: 120.81963\n",
      "[epoch 395, batch    13] loss: 135.68737\n",
      "[epoch 395, batch    14] loss: 132.64578\n",
      "[epoch 395, batch    15] loss: 128.18939\n",
      "[epoch 395, batch    16] loss: 139.07125\n",
      "[epoch 395, batch    17] loss: 129.53039\n",
      "[epoch 395, batch    18] loss: 157.95052\n",
      "[epoch 395, batch    19] loss: 134.29902\n",
      "[epoch 395, batch    20] loss: 127.60931\n",
      "[epoch 395, batch    21] loss: 135.07502\n",
      "[epoch 395, batch    22] loss: 128.22833\n",
      "[epoch 395, batch    23] loss: 135.41215\n",
      "[epoch 395, batch    24] loss: 135.98693\n",
      "[epoch 395, batch    25] loss: 125.28673\n",
      "[epoch 395, batch    26] loss: 142.71856\n",
      "[epoch 395, batch    27] loss: 133.72495\n",
      "[epoch 395, batch    28] loss: 135.15076\n",
      "[epoch 395, batch    29] loss: 139.33205\n",
      "[epoch 395, batch    30] loss: 140.11689\n",
      "[epoch 395, batch    31] loss: 139.36395\n",
      "[epoch 395, batch    32] loss: 41.61812\n",
      "[epoch 396, batch     1] loss: 129.46361\n",
      "[epoch 396, batch     2] loss: 135.12086\n",
      "[epoch 396, batch     3] loss: 126.34959\n",
      "[epoch 396, batch     4] loss: 140.04190\n",
      "[epoch 396, batch     5] loss: 132.93117\n",
      "[epoch 396, batch     6] loss: 134.70939\n",
      "[epoch 396, batch     7] loss: 121.41432\n",
      "[epoch 396, batch     8] loss: 120.35870\n",
      "[epoch 396, batch     9] loss: 148.20172\n",
      "[epoch 396, batch    10] loss: 136.41213\n",
      "[epoch 396, batch    11] loss: 130.87871\n",
      "[epoch 396, batch    12] loss: 133.86286\n",
      "[epoch 396, batch    13] loss: 140.29848\n",
      "[epoch 396, batch    14] loss: 130.02341\n",
      "[epoch 396, batch    15] loss: 135.40476\n",
      "[epoch 396, batch    16] loss: 125.93738\n",
      "[epoch 396, batch    17] loss: 126.02479\n",
      "[epoch 396, batch    18] loss: 135.23128\n",
      "[epoch 396, batch    19] loss: 142.14112\n",
      "[epoch 396, batch    20] loss: 137.24920\n",
      "[epoch 396, batch    21] loss: 128.41750\n",
      "[epoch 396, batch    22] loss: 132.09711\n",
      "[epoch 396, batch    23] loss: 134.68449\n",
      "[epoch 396, batch    24] loss: 134.68865\n",
      "[epoch 396, batch    25] loss: 139.27242\n",
      "[epoch 396, batch    26] loss: 127.10221\n",
      "[epoch 396, batch    27] loss: 127.09345\n",
      "[epoch 396, batch    28] loss: 149.75932\n",
      "[epoch 396, batch    29] loss: 135.35254\n",
      "[epoch 396, batch    30] loss: 135.48343\n",
      "[epoch 396, batch    31] loss: 123.72729\n",
      "[epoch 396, batch    32] loss: 27.67910\n",
      "[epoch 397, batch     1] loss: 133.89272\n",
      "[epoch 397, batch     2] loss: 131.47569\n",
      "[epoch 397, batch     3] loss: 120.77701\n",
      "[epoch 397, batch     4] loss: 140.60304\n",
      "[epoch 397, batch     5] loss: 139.93437\n",
      "[epoch 397, batch     6] loss: 132.83825\n",
      "[epoch 397, batch     7] loss: 129.51706\n",
      "[epoch 397, batch     8] loss: 144.77759\n",
      "[epoch 397, batch     9] loss: 114.14297\n",
      "[epoch 397, batch    10] loss: 135.73029\n",
      "[epoch 397, batch    11] loss: 139.17279\n",
      "[epoch 397, batch    12] loss: 129.86876\n",
      "[epoch 397, batch    13] loss: 126.03595\n",
      "[epoch 397, batch    14] loss: 134.60763\n",
      "[epoch 397, batch    15] loss: 132.24865\n",
      "[epoch 397, batch    16] loss: 134.71237\n",
      "[epoch 397, batch    17] loss: 134.97679\n",
      "[epoch 397, batch    18] loss: 127.91104\n",
      "[epoch 397, batch    19] loss: 140.17313\n",
      "[epoch 397, batch    20] loss: 134.62268\n",
      "[epoch 397, batch    21] loss: 133.99253\n",
      "[epoch 397, batch    22] loss: 134.60390\n",
      "[epoch 397, batch    23] loss: 134.38349\n",
      "[epoch 397, batch    24] loss: 146.38057\n",
      "[epoch 397, batch    25] loss: 131.32503\n",
      "[epoch 397, batch    26] loss: 121.50989\n",
      "[epoch 397, batch    27] loss: 133.97504\n",
      "[epoch 397, batch    28] loss: 130.63836\n",
      "[epoch 397, batch    29] loss: 148.55346\n",
      "[epoch 397, batch    30] loss: 127.33369\n",
      "[epoch 397, batch    31] loss: 126.56614\n",
      "[epoch 397, batch    32] loss: 28.61451\n",
      "[epoch 398, batch     1] loss: 138.14683\n",
      "[epoch 398, batch     2] loss: 129.04130\n",
      "[epoch 398, batch     3] loss: 125.18964\n",
      "[epoch 398, batch     4] loss: 140.57123\n",
      "[epoch 398, batch     5] loss: 142.32155\n",
      "[epoch 398, batch     6] loss: 130.36824\n",
      "[epoch 398, batch     7] loss: 127.35415\n",
      "[epoch 398, batch     8] loss: 133.13947\n",
      "[epoch 398, batch     9] loss: 131.22585\n",
      "[epoch 398, batch    10] loss: 129.54919\n",
      "[epoch 398, batch    11] loss: 130.35239\n",
      "[epoch 398, batch    12] loss: 124.25309\n",
      "[epoch 398, batch    13] loss: 138.65109\n",
      "[epoch 398, batch    14] loss: 133.63610\n",
      "[epoch 398, batch    15] loss: 140.81110\n",
      "[epoch 398, batch    16] loss: 127.26300\n",
      "[epoch 398, batch    17] loss: 124.98918\n",
      "[epoch 398, batch    18] loss: 134.48530\n",
      "[epoch 398, batch    19] loss: 140.15626\n",
      "[epoch 398, batch    20] loss: 120.66975\n",
      "[epoch 398, batch    21] loss: 123.32218\n",
      "[epoch 398, batch    22] loss: 132.10075\n",
      "[epoch 398, batch    23] loss: 141.83051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 398, batch    24] loss: 139.90823\n",
      "[epoch 398, batch    25] loss: 112.40771\n",
      "[epoch 398, batch    26] loss: 129.84449\n",
      "[epoch 398, batch    27] loss: 134.05242\n",
      "[epoch 398, batch    28] loss: 142.39038\n",
      "[epoch 398, batch    29] loss: 130.14158\n",
      "[epoch 398, batch    30] loss: 119.90869\n",
      "[epoch 398, batch    31] loss: 131.95682\n",
      "[epoch 398, batch    32] loss: 38.23271\n",
      "[epoch 399, batch     1] loss: 119.62573\n",
      "[epoch 399, batch     2] loss: 141.25232\n",
      "[epoch 399, batch     3] loss: 140.21859\n",
      "[epoch 399, batch     4] loss: 125.45244\n",
      "[epoch 399, batch     5] loss: 124.02472\n",
      "[epoch 399, batch     6] loss: 134.91622\n",
      "[epoch 399, batch     7] loss: 125.77970\n",
      "[epoch 399, batch     8] loss: 136.98579\n",
      "[epoch 399, batch     9] loss: 141.42610\n",
      "[epoch 399, batch    10] loss: 133.82769\n",
      "[epoch 399, batch    11] loss: 137.81675\n",
      "[epoch 399, batch    12] loss: 138.86168\n",
      "[epoch 399, batch    13] loss: 128.58454\n",
      "[epoch 399, batch    14] loss: 124.03317\n",
      "[epoch 399, batch    15] loss: 131.95297\n",
      "[epoch 399, batch    16] loss: 129.33158\n",
      "[epoch 399, batch    17] loss: 148.74224\n",
      "[epoch 399, batch    18] loss: 133.42400\n",
      "[epoch 399, batch    19] loss: 136.47352\n",
      "[epoch 399, batch    20] loss: 123.13791\n",
      "[epoch 399, batch    21] loss: 119.94298\n",
      "[epoch 399, batch    22] loss: 134.55144\n",
      "[epoch 399, batch    23] loss: 136.89428\n",
      "[epoch 399, batch    24] loss: 145.45036\n",
      "[epoch 399, batch    25] loss: 117.40765\n",
      "[epoch 399, batch    26] loss: 131.82133\n",
      "[epoch 399, batch    27] loss: 124.81410\n",
      "[epoch 399, batch    28] loss: 130.35683\n",
      "[epoch 399, batch    29] loss: 132.52911\n",
      "[epoch 399, batch    30] loss: 138.56375\n",
      "[epoch 399, batch    31] loss: 124.57416\n",
      "[epoch 399, batch    32] loss: 35.27732\n",
      "[epoch 400, batch     1] loss: 127.88236\n",
      "[epoch 400, batch     2] loss: 125.56396\n",
      "[epoch 400, batch     3] loss: 132.61492\n",
      "[epoch 400, batch     4] loss: 136.02908\n",
      "[epoch 400, batch     5] loss: 131.86195\n",
      "[epoch 400, batch     6] loss: 140.50447\n",
      "[epoch 400, batch     7] loss: 138.07542\n",
      "[epoch 400, batch     8] loss: 132.37280\n",
      "[epoch 400, batch     9] loss: 129.13218\n",
      "[epoch 400, batch    10] loss: 141.74461\n",
      "[epoch 400, batch    11] loss: 133.97270\n",
      "[epoch 400, batch    12] loss: 137.31000\n",
      "[epoch 400, batch    13] loss: 138.18179\n",
      "[epoch 400, batch    14] loss: 128.30013\n",
      "[epoch 400, batch    15] loss: 126.63230\n",
      "[epoch 400, batch    16] loss: 128.57990\n",
      "[epoch 400, batch    17] loss: 122.88189\n",
      "[epoch 400, batch    18] loss: 141.88272\n",
      "[epoch 400, batch    19] loss: 131.26315\n",
      "[epoch 400, batch    20] loss: 135.00291\n",
      "[epoch 400, batch    21] loss: 129.85756\n",
      "[epoch 400, batch    22] loss: 131.27745\n",
      "[epoch 400, batch    23] loss: 131.98348\n",
      "[epoch 400, batch    24] loss: 130.91783\n",
      "[epoch 400, batch    25] loss: 129.63446\n",
      "[epoch 400, batch    26] loss: 129.24048\n",
      "[epoch 400, batch    27] loss: 130.43945\n",
      "[epoch 400, batch    28] loss: 142.96513\n",
      "[epoch 400, batch    29] loss: 128.19715\n",
      "[epoch 400, batch    30] loss: 149.28365\n",
      "[epoch 400, batch    31] loss: 135.48190\n",
      "[epoch 400, batch    32] loss: 30.30070\n",
      "[epoch 401, batch     1] loss: 131.38119\n",
      "[epoch 401, batch     2] loss: 132.03117\n",
      "[epoch 401, batch     3] loss: 120.08772\n",
      "[epoch 401, batch     4] loss: 139.27660\n",
      "[epoch 401, batch     5] loss: 123.68487\n",
      "[epoch 401, batch     6] loss: 137.55519\n",
      "[epoch 401, batch     7] loss: 130.84395\n",
      "[epoch 401, batch     8] loss: 137.12358\n",
      "[epoch 401, batch     9] loss: 130.79039\n",
      "[epoch 401, batch    10] loss: 147.92130\n",
      "[epoch 401, batch    11] loss: 158.27693\n",
      "[epoch 401, batch    12] loss: 132.70856\n",
      "[epoch 401, batch    13] loss: 145.28295\n",
      "[epoch 401, batch    14] loss: 131.39404\n",
      "[epoch 401, batch    15] loss: 127.99973\n",
      "[epoch 401, batch    16] loss: 138.88613\n",
      "[epoch 401, batch    17] loss: 132.06837\n",
      "[epoch 401, batch    18] loss: 125.19031\n",
      "[epoch 401, batch    19] loss: 129.72820\n",
      "[epoch 401, batch    20] loss: 126.16919\n",
      "[epoch 401, batch    21] loss: 130.02504\n",
      "[epoch 401, batch    22] loss: 129.28465\n",
      "[epoch 401, batch    23] loss: 116.53749\n",
      "[epoch 401, batch    24] loss: 133.19147\n",
      "[epoch 401, batch    25] loss: 140.03526\n",
      "[epoch 401, batch    26] loss: 132.91304\n",
      "[epoch 401, batch    27] loss: 127.29258\n",
      "[epoch 401, batch    28] loss: 131.03595\n",
      "[epoch 401, batch    29] loss: 129.05297\n",
      "[epoch 401, batch    30] loss: 133.89263\n",
      "[epoch 401, batch    31] loss: 125.19710\n",
      "[epoch 401, batch    32] loss: 33.23157\n",
      "[epoch 402, batch     1] loss: 128.33014\n",
      "[epoch 402, batch     2] loss: 139.15162\n",
      "[epoch 402, batch     3] loss: 143.14780\n",
      "[epoch 402, batch     4] loss: 136.99700\n",
      "[epoch 402, batch     5] loss: 139.68748\n",
      "[epoch 402, batch     6] loss: 122.15247\n",
      "[epoch 402, batch     7] loss: 125.23352\n",
      "[epoch 402, batch     8] loss: 138.38078\n",
      "[epoch 402, batch     9] loss: 123.51206\n",
      "[epoch 402, batch    10] loss: 137.99730\n",
      "[epoch 402, batch    11] loss: 122.36908\n",
      "[epoch 402, batch    12] loss: 124.01500\n",
      "[epoch 402, batch    13] loss: 120.50853\n",
      "[epoch 402, batch    14] loss: 133.11198\n",
      "[epoch 402, batch    15] loss: 131.73963\n",
      "[epoch 402, batch    16] loss: 117.76148\n",
      "[epoch 402, batch    17] loss: 127.00087\n",
      "[epoch 402, batch    18] loss: 131.62513\n",
      "[epoch 402, batch    19] loss: 135.42743\n",
      "[epoch 402, batch    20] loss: 133.31694\n",
      "[epoch 402, batch    21] loss: 142.47898\n",
      "[epoch 402, batch    22] loss: 140.92522\n",
      "[epoch 402, batch    23] loss: 131.18987\n",
      "[epoch 402, batch    24] loss: 134.57621\n",
      "[epoch 402, batch    25] loss: 138.73653\n",
      "[epoch 402, batch    26] loss: 125.28892\n",
      "[epoch 402, batch    27] loss: 133.72026\n",
      "[epoch 402, batch    28] loss: 125.29974\n",
      "[epoch 402, batch    29] loss: 116.50249\n",
      "[epoch 402, batch    30] loss: 140.07106\n",
      "[epoch 402, batch    31] loss: 128.35111\n",
      "[epoch 402, batch    32] loss: 31.71262\n",
      "[epoch 403, batch     1] loss: 123.20998\n",
      "[epoch 403, batch     2] loss: 133.88778\n",
      "[epoch 403, batch     3] loss: 119.54949\n",
      "[epoch 403, batch     4] loss: 146.33834\n",
      "[epoch 403, batch     5] loss: 116.12208\n",
      "[epoch 403, batch     6] loss: 140.29371\n",
      "[epoch 403, batch     7] loss: 125.55877\n",
      "[epoch 403, batch     8] loss: 128.76234\n",
      "[epoch 403, batch     9] loss: 143.25293\n",
      "[epoch 403, batch    10] loss: 137.16507\n",
      "[epoch 403, batch    11] loss: 131.93830\n",
      "[epoch 403, batch    12] loss: 138.19332\n",
      "[epoch 403, batch    13] loss: 125.65207\n",
      "[epoch 403, batch    14] loss: 133.65497\n",
      "[epoch 403, batch    15] loss: 128.84984\n",
      "[epoch 403, batch    16] loss: 128.16635\n",
      "[epoch 403, batch    17] loss: 136.14110\n",
      "[epoch 403, batch    18] loss: 128.48855\n",
      "[epoch 403, batch    19] loss: 135.82103\n",
      "[epoch 403, batch    20] loss: 129.96736\n",
      "[epoch 403, batch    21] loss: 126.92044\n",
      "[epoch 403, batch    22] loss: 127.35191\n",
      "[epoch 403, batch    23] loss: 128.40883\n",
      "[epoch 403, batch    24] loss: 144.36215\n",
      "[epoch 403, batch    25] loss: 116.35667\n",
      "[epoch 403, batch    26] loss: 142.51388\n",
      "[epoch 403, batch    27] loss: 140.78699\n",
      "[epoch 403, batch    28] loss: 132.38760\n",
      "[epoch 403, batch    29] loss: 134.70332\n",
      "[epoch 403, batch    30] loss: 134.43488\n",
      "[epoch 403, batch    31] loss: 148.61826\n",
      "[epoch 403, batch    32] loss: 27.45222\n",
      "[epoch 404, batch     1] loss: 123.22314\n",
      "[epoch 404, batch     2] loss: 137.25584\n",
      "[epoch 404, batch     3] loss: 114.97590\n",
      "[epoch 404, batch     4] loss: 137.39423\n",
      "[epoch 404, batch     5] loss: 132.70557\n",
      "[epoch 404, batch     6] loss: 137.52586\n",
      "[epoch 404, batch     7] loss: 132.09173\n",
      "[epoch 404, batch     8] loss: 137.93038\n",
      "[epoch 404, batch     9] loss: 129.80594\n",
      "[epoch 404, batch    10] loss: 130.26205\n",
      "[epoch 404, batch    11] loss: 145.82150\n",
      "[epoch 404, batch    12] loss: 130.68016\n",
      "[epoch 404, batch    13] loss: 126.35047\n",
      "[epoch 404, batch    14] loss: 128.82708\n",
      "[epoch 404, batch    15] loss: 143.27409\n",
      "[epoch 404, batch    16] loss: 126.44121\n",
      "[epoch 404, batch    17] loss: 129.39922\n",
      "[epoch 404, batch    18] loss: 131.35387\n",
      "[epoch 404, batch    19] loss: 136.46224\n",
      "[epoch 404, batch    20] loss: 127.58572\n",
      "[epoch 404, batch    21] loss: 149.67378\n",
      "[epoch 404, batch    22] loss: 121.75732\n",
      "[epoch 404, batch    23] loss: 134.73328\n",
      "[epoch 404, batch    24] loss: 119.24357\n",
      "[epoch 404, batch    25] loss: 116.72481\n",
      "[epoch 404, batch    26] loss: 138.11823\n",
      "[epoch 404, batch    27] loss: 121.77166\n",
      "[epoch 404, batch    28] loss: 145.71738\n",
      "[epoch 404, batch    29] loss: 128.30151\n",
      "[epoch 404, batch    30] loss: 129.09840\n",
      "[epoch 404, batch    31] loss: 135.40211\n",
      "[epoch 404, batch    32] loss: 36.87896\n",
      "[epoch 405, batch     1] loss: 139.57284\n",
      "[epoch 405, batch     2] loss: 117.17858\n",
      "[epoch 405, batch     3] loss: 129.62153\n",
      "[epoch 405, batch     4] loss: 148.91400\n",
      "[epoch 405, batch     5] loss: 132.59518\n",
      "[epoch 405, batch     6] loss: 123.16653\n",
      "[epoch 405, batch     7] loss: 137.11307\n",
      "[epoch 405, batch     8] loss: 140.45551\n",
      "[epoch 405, batch     9] loss: 127.98204\n",
      "[epoch 405, batch    10] loss: 134.53059\n",
      "[epoch 405, batch    11] loss: 134.74945\n",
      "[epoch 405, batch    12] loss: 122.49711\n",
      "[epoch 405, batch    13] loss: 133.65643\n",
      "[epoch 405, batch    14] loss: 118.46534\n",
      "[epoch 405, batch    15] loss: 133.68785\n",
      "[epoch 405, batch    16] loss: 130.67023\n",
      "[epoch 405, batch    17] loss: 128.09945\n",
      "[epoch 405, batch    18] loss: 131.36892\n",
      "[epoch 405, batch    19] loss: 136.39277\n",
      "[epoch 405, batch    20] loss: 135.71517\n",
      "[epoch 405, batch    21] loss: 129.60308\n",
      "[epoch 405, batch    22] loss: 138.11432\n",
      "[epoch 405, batch    23] loss: 121.68548\n",
      "[epoch 405, batch    24] loss: 133.49070\n",
      "[epoch 405, batch    25] loss: 127.80905\n",
      "[epoch 405, batch    26] loss: 124.87600\n",
      "[epoch 405, batch    27] loss: 135.31613\n",
      "[epoch 405, batch    28] loss: 129.23311\n",
      "[epoch 405, batch    29] loss: 115.45430\n",
      "[epoch 405, batch    30] loss: 134.60931\n",
      "[epoch 405, batch    31] loss: 131.21356\n",
      "[epoch 405, batch    32] loss: 36.94766\n",
      "[epoch 406, batch     1] loss: 125.39083\n",
      "[epoch 406, batch     2] loss: 137.83285\n",
      "[epoch 406, batch     3] loss: 134.63151\n",
      "[epoch 406, batch     4] loss: 126.62562\n",
      "[epoch 406, batch     5] loss: 128.84572\n",
      "[epoch 406, batch     6] loss: 135.11818\n",
      "[epoch 406, batch     7] loss: 127.68258\n",
      "[epoch 406, batch     8] loss: 148.14414\n",
      "[epoch 406, batch     9] loss: 121.68348\n",
      "[epoch 406, batch    10] loss: 136.57823\n",
      "[epoch 406, batch    11] loss: 131.75019\n",
      "[epoch 406, batch    12] loss: 139.15354\n",
      "[epoch 406, batch    13] loss: 132.71136\n",
      "[epoch 406, batch    14] loss: 126.15637\n",
      "[epoch 406, batch    15] loss: 135.80365\n",
      "[epoch 406, batch    16] loss: 122.79880\n",
      "[epoch 406, batch    17] loss: 136.04075\n",
      "[epoch 406, batch    18] loss: 141.84326\n",
      "[epoch 406, batch    19] loss: 123.69523\n",
      "[epoch 406, batch    20] loss: 133.75294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 406, batch    21] loss: 138.53267\n",
      "[epoch 406, batch    22] loss: 136.80535\n",
      "[epoch 406, batch    23] loss: 128.72982\n",
      "[epoch 406, batch    24] loss: 129.57778\n",
      "[epoch 406, batch    25] loss: 138.44241\n",
      "[epoch 406, batch    26] loss: 138.27877\n",
      "[epoch 406, batch    27] loss: 123.16564\n",
      "[epoch 406, batch    28] loss: 117.82745\n",
      "[epoch 406, batch    29] loss: 123.86049\n",
      "[epoch 406, batch    30] loss: 118.89184\n",
      "[epoch 406, batch    31] loss: 130.69468\n",
      "[epoch 406, batch    32] loss: 25.79834\n",
      "[epoch 407, batch     1] loss: 137.40289\n",
      "[epoch 407, batch     2] loss: 116.75329\n",
      "[epoch 407, batch     3] loss: 133.81198\n",
      "[epoch 407, batch     4] loss: 136.48773\n",
      "[epoch 407, batch     5] loss: 136.23979\n",
      "[epoch 407, batch     6] loss: 125.06965\n",
      "[epoch 407, batch     7] loss: 121.38989\n",
      "[epoch 407, batch     8] loss: 131.71873\n",
      "[epoch 407, batch     9] loss: 124.05030\n",
      "[epoch 407, batch    10] loss: 132.97520\n",
      "[epoch 407, batch    11] loss: 125.43651\n",
      "[epoch 407, batch    12] loss: 133.70569\n",
      "[epoch 407, batch    13] loss: 133.73991\n",
      "[epoch 407, batch    14] loss: 145.43065\n",
      "[epoch 407, batch    15] loss: 129.46715\n",
      "[epoch 407, batch    16] loss: 134.79693\n",
      "[epoch 407, batch    17] loss: 151.16243\n",
      "[epoch 407, batch    18] loss: 128.20047\n",
      "[epoch 407, batch    19] loss: 118.85569\n",
      "[epoch 407, batch    20] loss: 137.63143\n",
      "[epoch 407, batch    21] loss: 131.49310\n",
      "[epoch 407, batch    22] loss: 134.04410\n",
      "[epoch 407, batch    23] loss: 145.60763\n",
      "[epoch 407, batch    24] loss: 126.93991\n",
      "[epoch 407, batch    25] loss: 132.83958\n",
      "[epoch 407, batch    26] loss: 142.08099\n",
      "[epoch 407, batch    27] loss: 130.53168\n",
      "[epoch 407, batch    28] loss: 123.37131\n",
      "[epoch 407, batch    29] loss: 130.66300\n",
      "[epoch 407, batch    30] loss: 126.77486\n",
      "[epoch 407, batch    31] loss: 134.98023\n",
      "[epoch 407, batch    32] loss: 31.99849\n",
      "[epoch 408, batch     1] loss: 137.58303\n",
      "[epoch 408, batch     2] loss: 127.43367\n",
      "[epoch 408, batch     3] loss: 128.65125\n",
      "[epoch 408, batch     4] loss: 140.52674\n",
      "[epoch 408, batch     5] loss: 144.36972\n",
      "[epoch 408, batch     6] loss: 140.24611\n",
      "[epoch 408, batch     7] loss: 124.87802\n",
      "[epoch 408, batch     8] loss: 144.01320\n",
      "[epoch 408, batch     9] loss: 133.86887\n",
      "[epoch 408, batch    10] loss: 133.02106\n",
      "[epoch 408, batch    11] loss: 133.72001\n",
      "[epoch 408, batch    12] loss: 129.26641\n",
      "[epoch 408, batch    13] loss: 134.84906\n",
      "[epoch 408, batch    14] loss: 131.08034\n",
      "[epoch 408, batch    15] loss: 134.90153\n",
      "[epoch 408, batch    16] loss: 134.09237\n",
      "[epoch 408, batch    17] loss: 120.99078\n",
      "[epoch 408, batch    18] loss: 128.28919\n",
      "[epoch 408, batch    19] loss: 139.43543\n",
      "[epoch 408, batch    20] loss: 119.34003\n",
      "[epoch 408, batch    21] loss: 148.70246\n",
      "[epoch 408, batch    22] loss: 131.35865\n",
      "[epoch 408, batch    23] loss: 129.59106\n",
      "[epoch 408, batch    24] loss: 129.47178\n",
      "[epoch 408, batch    25] loss: 123.62566\n",
      "[epoch 408, batch    26] loss: 125.81499\n",
      "[epoch 408, batch    27] loss: 121.90306\n",
      "[epoch 408, batch    28] loss: 136.66584\n",
      "[epoch 408, batch    29] loss: 143.16554\n",
      "[epoch 408, batch    30] loss: 127.35851\n",
      "[epoch 408, batch    31] loss: 120.92713\n",
      "[epoch 408, batch    32] loss: 33.66534\n",
      "[epoch 409, batch     1] loss: 134.91688\n",
      "[epoch 409, batch     2] loss: 137.06346\n",
      "[epoch 409, batch     3] loss: 130.79965\n",
      "[epoch 409, batch     4] loss: 145.84587\n",
      "[epoch 409, batch     5] loss: 132.40736\n",
      "[epoch 409, batch     6] loss: 125.47247\n",
      "[epoch 409, batch     7] loss: 132.94268\n",
      "[epoch 409, batch     8] loss: 130.82357\n",
      "[epoch 409, batch     9] loss: 125.55962\n",
      "[epoch 409, batch    10] loss: 122.62957\n",
      "[epoch 409, batch    11] loss: 125.33239\n",
      "[epoch 409, batch    12] loss: 143.59487\n",
      "[epoch 409, batch    13] loss: 146.07028\n",
      "[epoch 409, batch    14] loss: 138.15942\n",
      "[epoch 409, batch    15] loss: 143.00034\n",
      "[epoch 409, batch    16] loss: 144.54749\n",
      "[epoch 409, batch    17] loss: 130.77723\n",
      "[epoch 409, batch    18] loss: 131.98929\n",
      "[epoch 409, batch    19] loss: 129.23258\n",
      "[epoch 409, batch    20] loss: 128.93254\n",
      "[epoch 409, batch    21] loss: 138.44797\n",
      "[epoch 409, batch    22] loss: 129.19898\n",
      "[epoch 409, batch    23] loss: 125.76862\n",
      "[epoch 409, batch    24] loss: 131.09190\n",
      "[epoch 409, batch    25] loss: 140.50332\n",
      "[epoch 409, batch    26] loss: 143.78355\n",
      "[epoch 409, batch    27] loss: 136.76865\n",
      "[epoch 409, batch    28] loss: 145.07554\n",
      "[epoch 409, batch    29] loss: 125.64781\n",
      "[epoch 409, batch    30] loss: 120.83231\n",
      "[epoch 409, batch    31] loss: 122.50379\n",
      "[epoch 409, batch    32] loss: 34.23693\n",
      "[epoch 410, batch     1] loss: 134.78065\n",
      "[epoch 410, batch     2] loss: 129.43965\n",
      "[epoch 410, batch     3] loss: 146.71682\n",
      "[epoch 410, batch     4] loss: 137.45928\n",
      "[epoch 410, batch     5] loss: 121.09766\n",
      "[epoch 410, batch     6] loss: 125.91741\n",
      "[epoch 410, batch     7] loss: 153.49836\n",
      "[epoch 410, batch     8] loss: 134.50000\n",
      "[epoch 410, batch     9] loss: 136.59413\n",
      "[epoch 410, batch    10] loss: 128.46109\n",
      "[epoch 410, batch    11] loss: 137.50303\n",
      "[epoch 410, batch    12] loss: 133.81643\n",
      "[epoch 410, batch    13] loss: 135.67476\n",
      "[epoch 410, batch    14] loss: 130.69873\n",
      "[epoch 410, batch    15] loss: 131.90986\n",
      "[epoch 410, batch    16] loss: 134.17013\n",
      "[epoch 410, batch    17] loss: 140.04699\n",
      "[epoch 410, batch    18] loss: 121.75357\n",
      "[epoch 410, batch    19] loss: 137.87932\n",
      "[epoch 410, batch    20] loss: 133.28458\n",
      "[epoch 410, batch    21] loss: 128.35887\n",
      "[epoch 410, batch    22] loss: 133.48979\n",
      "[epoch 410, batch    23] loss: 147.31642\n",
      "[epoch 410, batch    24] loss: 131.69310\n",
      "[epoch 410, batch    25] loss: 135.78533\n",
      "[epoch 410, batch    26] loss: 133.75307\n",
      "[epoch 410, batch    27] loss: 122.04835\n",
      "[epoch 410, batch    28] loss: 122.28990\n",
      "[epoch 410, batch    29] loss: 136.76102\n",
      "[epoch 410, batch    30] loss: 133.42382\n",
      "[epoch 410, batch    31] loss: 129.85156\n",
      "[epoch 410, batch    32] loss: 31.11178\n",
      "[epoch 411, batch     1] loss: 145.99633\n",
      "[epoch 411, batch     2] loss: 121.31757\n",
      "[epoch 411, batch     3] loss: 126.77122\n",
      "[epoch 411, batch     4] loss: 129.25907\n",
      "[epoch 411, batch     5] loss: 127.60508\n",
      "[epoch 411, batch     6] loss: 135.34394\n",
      "[epoch 411, batch     7] loss: 131.18251\n",
      "[epoch 411, batch     8] loss: 141.48550\n",
      "[epoch 411, batch     9] loss: 128.27174\n",
      "[epoch 411, batch    10] loss: 131.74505\n",
      "[epoch 411, batch    11] loss: 135.66122\n",
      "[epoch 411, batch    12] loss: 112.63884\n",
      "[epoch 411, batch    13] loss: 126.25439\n",
      "[epoch 411, batch    14] loss: 135.18783\n",
      "[epoch 411, batch    15] loss: 137.83720\n",
      "[epoch 411, batch    16] loss: 125.99683\n",
      "[epoch 411, batch    17] loss: 130.90075\n",
      "[epoch 411, batch    18] loss: 130.30739\n",
      "[epoch 411, batch    19] loss: 132.69129\n",
      "[epoch 411, batch    20] loss: 137.64723\n",
      "[epoch 411, batch    21] loss: 128.00974\n",
      "[epoch 411, batch    22] loss: 144.12281\n",
      "[epoch 411, batch    23] loss: 130.23877\n",
      "[epoch 411, batch    24] loss: 124.00685\n",
      "[epoch 411, batch    25] loss: 136.57994\n",
      "[epoch 411, batch    26] loss: 130.72116\n",
      "[epoch 411, batch    27] loss: 151.78740\n",
      "[epoch 411, batch    28] loss: 132.95165\n",
      "[epoch 411, batch    29] loss: 126.64128\n",
      "[epoch 411, batch    30] loss: 119.57557\n",
      "[epoch 411, batch    31] loss: 127.88421\n",
      "[epoch 411, batch    32] loss: 39.01894\n",
      "[epoch 412, batch     1] loss: 130.98138\n",
      "[epoch 412, batch     2] loss: 149.74581\n",
      "[epoch 412, batch     3] loss: 134.18065\n",
      "[epoch 412, batch     4] loss: 147.30950\n",
      "[epoch 412, batch     5] loss: 133.32946\n",
      "[epoch 412, batch     6] loss: 121.59698\n",
      "[epoch 412, batch     7] loss: 126.99153\n",
      "[epoch 412, batch     8] loss: 133.20727\n",
      "[epoch 412, batch     9] loss: 118.12561\n",
      "[epoch 412, batch    10] loss: 144.71196\n",
      "[epoch 412, batch    11] loss: 116.88861\n",
      "[epoch 412, batch    12] loss: 137.16879\n",
      "[epoch 412, batch    13] loss: 128.12280\n",
      "[epoch 412, batch    14] loss: 134.62470\n",
      "[epoch 412, batch    15] loss: 133.20855\n",
      "[epoch 412, batch    16] loss: 131.68964\n",
      "[epoch 412, batch    17] loss: 142.22511\n",
      "[epoch 412, batch    18] loss: 138.79203\n",
      "[epoch 412, batch    19] loss: 130.93585\n",
      "[epoch 412, batch    20] loss: 129.45018\n",
      "[epoch 412, batch    21] loss: 113.70175\n",
      "[epoch 412, batch    22] loss: 131.80785\n",
      "[epoch 412, batch    23] loss: 123.88089\n",
      "[epoch 412, batch    24] loss: 124.35983\n",
      "[epoch 412, batch    25] loss: 126.48088\n",
      "[epoch 412, batch    26] loss: 130.00160\n",
      "[epoch 412, batch    27] loss: 137.62931\n",
      "[epoch 412, batch    28] loss: 128.13764\n",
      "[epoch 412, batch    29] loss: 125.92943\n",
      "[epoch 412, batch    30] loss: 128.87455\n",
      "[epoch 412, batch    31] loss: 135.93503\n",
      "[epoch 412, batch    32] loss: 31.83978\n",
      "[epoch 413, batch     1] loss: 137.44034\n",
      "[epoch 413, batch     2] loss: 127.02673\n",
      "[epoch 413, batch     3] loss: 132.78998\n",
      "[epoch 413, batch     4] loss: 136.56884\n",
      "[epoch 413, batch     5] loss: 137.03300\n",
      "[epoch 413, batch     6] loss: 141.06442\n",
      "[epoch 413, batch     7] loss: 135.77895\n",
      "[epoch 413, batch     8] loss: 123.05921\n",
      "[epoch 413, batch     9] loss: 133.65486\n",
      "[epoch 413, batch    10] loss: 129.67767\n",
      "[epoch 413, batch    11] loss: 131.60758\n",
      "[epoch 413, batch    12] loss: 118.31938\n",
      "[epoch 413, batch    13] loss: 135.41381\n",
      "[epoch 413, batch    14] loss: 138.36985\n",
      "[epoch 413, batch    15] loss: 137.59635\n",
      "[epoch 413, batch    16] loss: 134.73784\n",
      "[epoch 413, batch    17] loss: 133.65215\n",
      "[epoch 413, batch    18] loss: 131.65935\n",
      "[epoch 413, batch    19] loss: 135.16855\n",
      "[epoch 413, batch    20] loss: 135.61812\n",
      "[epoch 413, batch    21] loss: 142.24644\n",
      "[epoch 413, batch    22] loss: 129.66663\n",
      "[epoch 413, batch    23] loss: 132.85269\n",
      "[epoch 413, batch    24] loss: 142.85336\n",
      "[epoch 413, batch    25] loss: 122.88859\n",
      "[epoch 413, batch    26] loss: 127.46781\n",
      "[epoch 413, batch    27] loss: 127.21919\n",
      "[epoch 413, batch    28] loss: 130.12493\n",
      "[epoch 413, batch    29] loss: 136.62567\n",
      "[epoch 413, batch    30] loss: 124.30651\n",
      "[epoch 413, batch    31] loss: 134.75107\n",
      "[epoch 413, batch    32] loss: 30.16259\n",
      "[epoch 414, batch     1] loss: 132.85397\n",
      "[epoch 414, batch     2] loss: 137.05339\n",
      "[epoch 414, batch     3] loss: 128.99814\n",
      "[epoch 414, batch     4] loss: 124.13955\n",
      "[epoch 414, batch     5] loss: 127.66693\n",
      "[epoch 414, batch     6] loss: 121.04548\n",
      "[epoch 414, batch     7] loss: 128.47330\n",
      "[epoch 414, batch     8] loss: 136.15082\n",
      "[epoch 414, batch     9] loss: 134.60568\n",
      "[epoch 414, batch    10] loss: 109.47205\n",
      "[epoch 414, batch    11] loss: 143.09850\n",
      "[epoch 414, batch    12] loss: 138.60431\n",
      "[epoch 414, batch    13] loss: 136.59065\n",
      "[epoch 414, batch    14] loss: 131.30821\n",
      "[epoch 414, batch    15] loss: 136.17025\n",
      "[epoch 414, batch    16] loss: 142.89157\n",
      "[epoch 414, batch    17] loss: 138.73816\n",
      "[epoch 414, batch    18] loss: 139.51509\n",
      "[epoch 414, batch    19] loss: 140.03745\n",
      "[epoch 414, batch    20] loss: 150.97124\n",
      "[epoch 414, batch    21] loss: 131.32794\n",
      "[epoch 414, batch    22] loss: 125.67570\n",
      "[epoch 414, batch    23] loss: 127.85971\n",
      "[epoch 414, batch    24] loss: 140.27916\n",
      "[epoch 414, batch    25] loss: 128.24855\n",
      "[epoch 414, batch    26] loss: 131.30096\n",
      "[epoch 414, batch    27] loss: 121.95410\n",
      "[epoch 414, batch    28] loss: 133.87522\n",
      "[epoch 414, batch    29] loss: 126.81877\n",
      "[epoch 414, batch    30] loss: 142.45286\n",
      "[epoch 414, batch    31] loss: 127.20028\n",
      "[epoch 414, batch    32] loss: 33.97893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 415, batch     1] loss: 133.63399\n",
      "[epoch 415, batch     2] loss: 130.84524\n",
      "[epoch 415, batch     3] loss: 142.23642\n",
      "[epoch 415, batch     4] loss: 134.94645\n",
      "[epoch 415, batch     5] loss: 130.37987\n",
      "[epoch 415, batch     6] loss: 138.90882\n",
      "[epoch 415, batch     7] loss: 126.83678\n",
      "[epoch 415, batch     8] loss: 141.55025\n",
      "[epoch 415, batch     9] loss: 139.36766\n",
      "[epoch 415, batch    10] loss: 134.19082\n",
      "[epoch 415, batch    11] loss: 118.86211\n",
      "[epoch 415, batch    12] loss: 121.51039\n",
      "[epoch 415, batch    13] loss: 143.51590\n",
      "[epoch 415, batch    14] loss: 139.00563\n",
      "[epoch 415, batch    15] loss: 126.99177\n",
      "[epoch 415, batch    16] loss: 133.86323\n",
      "[epoch 415, batch    17] loss: 143.75359\n",
      "[epoch 415, batch    18] loss: 130.37467\n",
      "[epoch 415, batch    19] loss: 117.37439\n",
      "[epoch 415, batch    20] loss: 130.64502\n",
      "[epoch 415, batch    21] loss: 146.61942\n",
      "[epoch 415, batch    22] loss: 149.47967\n",
      "[epoch 415, batch    23] loss: 119.80721\n",
      "[epoch 415, batch    24] loss: 130.98764\n",
      "[epoch 415, batch    25] loss: 137.49172\n",
      "[epoch 415, batch    26] loss: 132.55328\n",
      "[epoch 415, batch    27] loss: 132.16344\n",
      "[epoch 415, batch    28] loss: 136.07974\n",
      "[epoch 415, batch    29] loss: 117.54283\n",
      "[epoch 415, batch    30] loss: 140.44786\n",
      "[epoch 415, batch    31] loss: 124.43755\n",
      "[epoch 415, batch    32] loss: 37.17807\n",
      "[epoch 416, batch     1] loss: 140.60653\n",
      "[epoch 416, batch     2] loss: 131.77690\n",
      "[epoch 416, batch     3] loss: 120.49259\n",
      "[epoch 416, batch     4] loss: 138.42487\n",
      "[epoch 416, batch     5] loss: 136.79074\n",
      "[epoch 416, batch     6] loss: 125.51469\n",
      "[epoch 416, batch     7] loss: 133.88656\n",
      "[epoch 416, batch     8] loss: 135.87494\n",
      "[epoch 416, batch     9] loss: 126.93441\n",
      "[epoch 416, batch    10] loss: 136.22608\n",
      "[epoch 416, batch    11] loss: 131.90559\n",
      "[epoch 416, batch    12] loss: 141.46713\n",
      "[epoch 416, batch    13] loss: 138.74849\n",
      "[epoch 416, batch    14] loss: 132.11488\n",
      "[epoch 416, batch    15] loss: 128.40106\n",
      "[epoch 416, batch    16] loss: 143.88246\n",
      "[epoch 416, batch    17] loss: 121.82501\n",
      "[epoch 416, batch    18] loss: 132.18857\n",
      "[epoch 416, batch    19] loss: 119.72141\n",
      "[epoch 416, batch    20] loss: 139.56208\n",
      "[epoch 416, batch    21] loss: 129.14193\n",
      "[epoch 416, batch    22] loss: 121.17808\n",
      "[epoch 416, batch    23] loss: 136.28977\n",
      "[epoch 416, batch    24] loss: 131.00808\n",
      "[epoch 416, batch    25] loss: 145.09917\n",
      "[epoch 416, batch    26] loss: 137.09263\n",
      "[epoch 416, batch    27] loss: 124.11707\n",
      "[epoch 416, batch    28] loss: 125.80730\n",
      "[epoch 416, batch    29] loss: 129.08987\n",
      "[epoch 416, batch    30] loss: 131.69930\n",
      "[epoch 416, batch    31] loss: 133.77889\n",
      "[epoch 416, batch    32] loss: 35.87031\n",
      "[epoch 417, batch     1] loss: 133.43565\n",
      "[epoch 417, batch     2] loss: 128.88728\n",
      "[epoch 417, batch     3] loss: 127.66358\n",
      "[epoch 417, batch     4] loss: 130.97573\n",
      "[epoch 417, batch     5] loss: 121.00860\n",
      "[epoch 417, batch     6] loss: 147.30102\n",
      "[epoch 417, batch     7] loss: 144.68245\n",
      "[epoch 417, batch     8] loss: 125.74132\n",
      "[epoch 417, batch     9] loss: 132.26826\n",
      "[epoch 417, batch    10] loss: 125.20723\n",
      "[epoch 417, batch    11] loss: 146.43747\n",
      "[epoch 417, batch    12] loss: 130.30835\n",
      "[epoch 417, batch    13] loss: 151.88859\n",
      "[epoch 417, batch    14] loss: 121.67286\n",
      "[epoch 417, batch    15] loss: 138.11069\n",
      "[epoch 417, batch    16] loss: 133.87910\n",
      "[epoch 417, batch    17] loss: 130.33926\n",
      "[epoch 417, batch    18] loss: 129.24854\n",
      "[epoch 417, batch    19] loss: 127.43085\n",
      "[epoch 417, batch    20] loss: 132.10210\n",
      "[epoch 417, batch    21] loss: 132.35273\n",
      "[epoch 417, batch    22] loss: 130.02242\n",
      "[epoch 417, batch    23] loss: 128.44110\n",
      "[epoch 417, batch    24] loss: 133.77658\n",
      "[epoch 417, batch    25] loss: 128.36281\n",
      "[epoch 417, batch    26] loss: 144.63675\n",
      "[epoch 417, batch    27] loss: 142.43873\n",
      "[epoch 417, batch    28] loss: 143.36533\n",
      "[epoch 417, batch    29] loss: 133.91198\n",
      "[epoch 417, batch    30] loss: 133.41917\n",
      "[epoch 417, batch    31] loss: 126.51807\n",
      "[epoch 417, batch    32] loss: 31.38835\n",
      "[epoch 418, batch     1] loss: 134.66832\n",
      "[epoch 418, batch     2] loss: 129.49127\n",
      "[epoch 418, batch     3] loss: 131.25559\n",
      "[epoch 418, batch     4] loss: 143.46284\n",
      "[epoch 418, batch     5] loss: 128.81002\n",
      "[epoch 418, batch     6] loss: 133.43785\n",
      "[epoch 418, batch     7] loss: 130.11703\n",
      "[epoch 418, batch     8] loss: 130.60298\n",
      "[epoch 418, batch     9] loss: 121.24090\n",
      "[epoch 418, batch    10] loss: 136.07686\n",
      "[epoch 418, batch    11] loss: 128.62314\n",
      "[epoch 418, batch    12] loss: 126.73765\n",
      "[epoch 418, batch    13] loss: 134.39026\n",
      "[epoch 418, batch    14] loss: 135.12602\n",
      "[epoch 418, batch    15] loss: 135.14331\n",
      "[epoch 418, batch    16] loss: 126.20661\n",
      "[epoch 418, batch    17] loss: 131.92191\n",
      "[epoch 418, batch    18] loss: 147.74514\n",
      "[epoch 418, batch    19] loss: 131.93962\n",
      "[epoch 418, batch    20] loss: 131.33807\n",
      "[epoch 418, batch    21] loss: 128.89952\n",
      "[epoch 418, batch    22] loss: 132.67701\n",
      "[epoch 418, batch    23] loss: 135.52650\n",
      "[epoch 418, batch    24] loss: 133.19083\n",
      "[epoch 418, batch    25] loss: 130.58025\n",
      "[epoch 418, batch    26] loss: 136.36060\n",
      "[epoch 418, batch    27] loss: 125.97926\n",
      "[epoch 418, batch    28] loss: 139.07454\n",
      "[epoch 418, batch    29] loss: 140.19377\n",
      "[epoch 418, batch    30] loss: 130.45277\n",
      "[epoch 418, batch    31] loss: 124.81683\n",
      "[epoch 418, batch    32] loss: 30.34252\n",
      "[epoch 419, batch     1] loss: 138.70253\n",
      "[epoch 419, batch     2] loss: 132.61104\n",
      "[epoch 419, batch     3] loss: 140.25720\n",
      "[epoch 419, batch     4] loss: 121.13597\n",
      "[epoch 419, batch     5] loss: 125.09285\n",
      "[epoch 419, batch     6] loss: 131.66330\n",
      "[epoch 419, batch     7] loss: 126.52868\n",
      "[epoch 419, batch     8] loss: 126.78021\n",
      "[epoch 419, batch     9] loss: 142.44862\n",
      "[epoch 419, batch    10] loss: 128.24542\n",
      "[epoch 419, batch    11] loss: 134.00335\n",
      "[epoch 419, batch    12] loss: 124.26982\n",
      "[epoch 419, batch    13] loss: 144.14076\n",
      "[epoch 419, batch    14] loss: 128.32071\n",
      "[epoch 419, batch    15] loss: 138.53655\n",
      "[epoch 419, batch    16] loss: 144.07157\n",
      "[epoch 419, batch    17] loss: 136.66775\n",
      "[epoch 419, batch    18] loss: 146.54691\n",
      "[epoch 419, batch    19] loss: 136.03378\n",
      "[epoch 419, batch    20] loss: 121.15544\n",
      "[epoch 419, batch    21] loss: 139.95214\n",
      "[epoch 419, batch    22] loss: 131.60333\n",
      "[epoch 419, batch    23] loss: 117.86277\n",
      "[epoch 419, batch    24] loss: 125.58489\n",
      "[epoch 419, batch    25] loss: 128.45595\n",
      "[epoch 419, batch    26] loss: 136.90399\n",
      "[epoch 419, batch    27] loss: 150.39726\n",
      "[epoch 419, batch    28] loss: 139.70417\n",
      "[epoch 419, batch    29] loss: 148.21271\n",
      "[epoch 419, batch    30] loss: 132.00861\n",
      "[epoch 419, batch    31] loss: 132.44367\n",
      "[epoch 419, batch    32] loss: 42.97129\n",
      "[epoch 420, batch     1] loss: 135.95023\n",
      "[epoch 420, batch     2] loss: 132.84246\n",
      "[epoch 420, batch     3] loss: 129.35976\n",
      "[epoch 420, batch     4] loss: 138.96833\n",
      "[epoch 420, batch     5] loss: 133.83794\n",
      "[epoch 420, batch     6] loss: 141.07753\n",
      "[epoch 420, batch     7] loss: 134.04665\n",
      "[epoch 420, batch     8] loss: 128.94155\n",
      "[epoch 420, batch     9] loss: 115.24666\n",
      "[epoch 420, batch    10] loss: 124.70270\n",
      "[epoch 420, batch    11] loss: 131.73415\n",
      "[epoch 420, batch    12] loss: 130.43747\n",
      "[epoch 420, batch    13] loss: 122.30060\n",
      "[epoch 420, batch    14] loss: 144.53202\n",
      "[epoch 420, batch    15] loss: 131.45942\n",
      "[epoch 420, batch    16] loss: 127.56167\n",
      "[epoch 420, batch    17] loss: 129.57132\n",
      "[epoch 420, batch    18] loss: 131.10156\n",
      "[epoch 420, batch    19] loss: 126.08320\n",
      "[epoch 420, batch    20] loss: 137.39181\n",
      "[epoch 420, batch    21] loss: 128.19509\n",
      "[epoch 420, batch    22] loss: 138.20798\n",
      "[epoch 420, batch    23] loss: 151.36442\n",
      "[epoch 420, batch    24] loss: 126.69909\n",
      "[epoch 420, batch    25] loss: 127.16472\n",
      "[epoch 420, batch    26] loss: 141.55335\n",
      "[epoch 420, batch    27] loss: 132.57418\n",
      "[epoch 420, batch    28] loss: 127.59921\n",
      "[epoch 420, batch    29] loss: 126.26995\n",
      "[epoch 420, batch    30] loss: 124.35771\n",
      "[epoch 420, batch    31] loss: 135.39147\n",
      "[epoch 420, batch    32] loss: 33.29035\n",
      "[epoch 421, batch     1] loss: 138.23203\n",
      "[epoch 421, batch     2] loss: 131.39577\n",
      "[epoch 421, batch     3] loss: 135.66077\n",
      "[epoch 421, batch     4] loss: 137.32950\n",
      "[epoch 421, batch     5] loss: 120.33013\n",
      "[epoch 421, batch     6] loss: 128.22411\n",
      "[epoch 421, batch     7] loss: 127.47325\n",
      "[epoch 421, batch     8] loss: 130.70236\n",
      "[epoch 421, batch     9] loss: 133.37972\n",
      "[epoch 421, batch    10] loss: 140.62332\n",
      "[epoch 421, batch    11] loss: 124.46205\n",
      "[epoch 421, batch    12] loss: 133.81602\n",
      "[epoch 421, batch    13] loss: 132.52764\n",
      "[epoch 421, batch    14] loss: 124.79421\n",
      "[epoch 421, batch    15] loss: 127.88079\n",
      "[epoch 421, batch    16] loss: 140.91642\n",
      "[epoch 421, batch    17] loss: 134.21312\n",
      "[epoch 421, batch    18] loss: 114.68249\n",
      "[epoch 421, batch    19] loss: 137.70164\n",
      "[epoch 421, batch    20] loss: 133.40589\n",
      "[epoch 421, batch    21] loss: 131.98536\n",
      "[epoch 421, batch    22] loss: 123.89764\n",
      "[epoch 421, batch    23] loss: 139.37959\n",
      "[epoch 421, batch    24] loss: 139.87910\n",
      "[epoch 421, batch    25] loss: 123.16541\n",
      "[epoch 421, batch    26] loss: 129.32719\n",
      "[epoch 421, batch    27] loss: 138.32143\n",
      "[epoch 421, batch    28] loss: 132.17778\n",
      "[epoch 421, batch    29] loss: 132.22326\n",
      "[epoch 421, batch    30] loss: 140.85145\n",
      "[epoch 421, batch    31] loss: 137.27532\n",
      "[epoch 421, batch    32] loss: 33.31256\n",
      "[epoch 422, batch     1] loss: 124.18314\n",
      "[epoch 422, batch     2] loss: 132.80593\n",
      "[epoch 422, batch     3] loss: 133.97923\n",
      "[epoch 422, batch     4] loss: 129.98285\n",
      "[epoch 422, batch     5] loss: 138.35220\n",
      "[epoch 422, batch     6] loss: 134.24634\n",
      "[epoch 422, batch     7] loss: 125.34671\n",
      "[epoch 422, batch     8] loss: 134.32762\n",
      "[epoch 422, batch     9] loss: 140.21710\n",
      "[epoch 422, batch    10] loss: 117.75890\n",
      "[epoch 422, batch    11] loss: 130.37497\n",
      "[epoch 422, batch    12] loss: 130.53637\n",
      "[epoch 422, batch    13] loss: 140.00409\n",
      "[epoch 422, batch    14] loss: 122.82694\n",
      "[epoch 422, batch    15] loss: 142.95201\n",
      "[epoch 422, batch    16] loss: 126.77898\n",
      "[epoch 422, batch    17] loss: 135.42753\n",
      "[epoch 422, batch    18] loss: 151.72851\n",
      "[epoch 422, batch    19] loss: 122.94387\n",
      "[epoch 422, batch    20] loss: 131.73231\n",
      "[epoch 422, batch    21] loss: 132.83836\n",
      "[epoch 422, batch    22] loss: 136.61303\n",
      "[epoch 422, batch    23] loss: 125.26654\n",
      "[epoch 422, batch    24] loss: 126.14994\n",
      "[epoch 422, batch    25] loss: 145.69281\n",
      "[epoch 422, batch    26] loss: 129.43572\n",
      "[epoch 422, batch    27] loss: 129.35607\n",
      "[epoch 422, batch    28] loss: 140.61343\n",
      "[epoch 422, batch    29] loss: 133.71716\n",
      "[epoch 422, batch    30] loss: 125.33686\n",
      "[epoch 422, batch    31] loss: 124.62439\n",
      "[epoch 422, batch    32] loss: 32.95791\n",
      "[epoch 423, batch     1] loss: 128.30664\n",
      "[epoch 423, batch     2] loss: 135.44796\n",
      "[epoch 423, batch     3] loss: 128.69118\n",
      "[epoch 423, batch     4] loss: 133.25386\n",
      "[epoch 423, batch     5] loss: 119.23060\n",
      "[epoch 423, batch     6] loss: 131.81888\n",
      "[epoch 423, batch     7] loss: 144.27209\n",
      "[epoch 423, batch     8] loss: 131.03991\n",
      "[epoch 423, batch     9] loss: 145.21443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 423, batch    10] loss: 141.85858\n",
      "[epoch 423, batch    11] loss: 134.28510\n",
      "[epoch 423, batch    12] loss: 139.86213\n",
      "[epoch 423, batch    13] loss: 131.25410\n",
      "[epoch 423, batch    14] loss: 128.71139\n",
      "[epoch 423, batch    15] loss: 130.23261\n",
      "[epoch 423, batch    16] loss: 121.06911\n",
      "[epoch 423, batch    17] loss: 119.11888\n",
      "[epoch 423, batch    18] loss: 141.10259\n",
      "[epoch 423, batch    19] loss: 140.59259\n",
      "[epoch 423, batch    20] loss: 140.48867\n",
      "[epoch 423, batch    21] loss: 141.49703\n",
      "[epoch 423, batch    22] loss: 133.31655\n",
      "[epoch 423, batch    23] loss: 128.82480\n",
      "[epoch 423, batch    24] loss: 137.01503\n",
      "[epoch 423, batch    25] loss: 143.90468\n",
      "[epoch 423, batch    26] loss: 130.62049\n",
      "[epoch 423, batch    27] loss: 139.05743\n",
      "[epoch 423, batch    28] loss: 134.66395\n",
      "[epoch 423, batch    29] loss: 132.74757\n",
      "[epoch 423, batch    30] loss: 142.34272\n",
      "[epoch 423, batch    31] loss: 132.26379\n",
      "[epoch 423, batch    32] loss: 35.42932\n",
      "[epoch 424, batch     1] loss: 127.41820\n",
      "[epoch 424, batch     2] loss: 133.92617\n",
      "[epoch 424, batch     3] loss: 123.03819\n",
      "[epoch 424, batch     4] loss: 136.31574\n",
      "[epoch 424, batch     5] loss: 132.51803\n",
      "[epoch 424, batch     6] loss: 130.70653\n",
      "[epoch 424, batch     7] loss: 126.08528\n",
      "[epoch 424, batch     8] loss: 135.43414\n",
      "[epoch 424, batch     9] loss: 118.23747\n",
      "[epoch 424, batch    10] loss: 131.66739\n",
      "[epoch 424, batch    11] loss: 146.43117\n",
      "[epoch 424, batch    12] loss: 142.46957\n",
      "[epoch 424, batch    13] loss: 129.74462\n",
      "[epoch 424, batch    14] loss: 132.45662\n",
      "[epoch 424, batch    15] loss: 118.36923\n",
      "[epoch 424, batch    16] loss: 138.41845\n",
      "[epoch 424, batch    17] loss: 129.78204\n",
      "[epoch 424, batch    18] loss: 134.68059\n",
      "[epoch 424, batch    19] loss: 126.98600\n",
      "[epoch 424, batch    20] loss: 136.89198\n",
      "[epoch 424, batch    21] loss: 129.76425\n",
      "[epoch 424, batch    22] loss: 133.42820\n",
      "[epoch 424, batch    23] loss: 138.71326\n",
      "[epoch 424, batch    24] loss: 124.06660\n",
      "[epoch 424, batch    25] loss: 131.14265\n",
      "[epoch 424, batch    26] loss: 137.82819\n",
      "[epoch 424, batch    27] loss: 127.43032\n",
      "[epoch 424, batch    28] loss: 134.10624\n",
      "[epoch 424, batch    29] loss: 132.18334\n",
      "[epoch 424, batch    30] loss: 125.26142\n",
      "[epoch 424, batch    31] loss: 135.57525\n",
      "[epoch 424, batch    32] loss: 30.37685\n",
      "[epoch 425, batch     1] loss: 135.47472\n",
      "[epoch 425, batch     2] loss: 133.12160\n",
      "[epoch 425, batch     3] loss: 137.47717\n",
      "[epoch 425, batch     4] loss: 128.83867\n",
      "[epoch 425, batch     5] loss: 119.19542\n",
      "[epoch 425, batch     6] loss: 129.80957\n",
      "[epoch 425, batch     7] loss: 138.17141\n",
      "[epoch 425, batch     8] loss: 137.57135\n",
      "[epoch 425, batch     9] loss: 116.66932\n",
      "[epoch 425, batch    10] loss: 125.11973\n",
      "[epoch 425, batch    11] loss: 138.26489\n",
      "[epoch 425, batch    12] loss: 129.38179\n",
      "[epoch 425, batch    13] loss: 130.42222\n",
      "[epoch 425, batch    14] loss: 137.94377\n",
      "[epoch 425, batch    15] loss: 133.63571\n",
      "[epoch 425, batch    16] loss: 123.85442\n",
      "[epoch 425, batch    17] loss: 140.79614\n",
      "[epoch 425, batch    18] loss: 147.70983\n",
      "[epoch 425, batch    19] loss: 122.75769\n",
      "[epoch 425, batch    20] loss: 139.23825\n",
      "[epoch 425, batch    21] loss: 122.09092\n",
      "[epoch 425, batch    22] loss: 135.38363\n",
      "[epoch 425, batch    23] loss: 126.58458\n",
      "[epoch 425, batch    24] loss: 136.60068\n",
      "[epoch 425, batch    25] loss: 135.18680\n",
      "[epoch 425, batch    26] loss: 131.86209\n",
      "[epoch 425, batch    27] loss: 146.45667\n",
      "[epoch 425, batch    28] loss: 136.35391\n",
      "[epoch 425, batch    29] loss: 136.46145\n",
      "[epoch 425, batch    30] loss: 141.55823\n",
      "[epoch 425, batch    31] loss: 142.40906\n",
      "[epoch 425, batch    32] loss: 34.23904\n",
      "[epoch 426, batch     1] loss: 116.77034\n",
      "[epoch 426, batch     2] loss: 127.14302\n",
      "[epoch 426, batch     3] loss: 132.20870\n",
      "[epoch 426, batch     4] loss: 128.75032\n",
      "[epoch 426, batch     5] loss: 122.47037\n",
      "[epoch 426, batch     6] loss: 145.58027\n",
      "[epoch 426, batch     7] loss: 133.10756\n",
      "[epoch 426, batch     8] loss: 131.66980\n",
      "[epoch 426, batch     9] loss: 131.57192\n",
      "[epoch 426, batch    10] loss: 117.77704\n",
      "[epoch 426, batch    11] loss: 130.55298\n",
      "[epoch 426, batch    12] loss: 126.58342\n",
      "[epoch 426, batch    13] loss: 141.35486\n",
      "[epoch 426, batch    14] loss: 130.78886\n",
      "[epoch 426, batch    15] loss: 131.29965\n",
      "[epoch 426, batch    16] loss: 138.58636\n",
      "[epoch 426, batch    17] loss: 122.33928\n",
      "[epoch 426, batch    18] loss: 135.67762\n",
      "[epoch 426, batch    19] loss: 127.64102\n",
      "[epoch 426, batch    20] loss: 142.68772\n",
      "[epoch 426, batch    21] loss: 133.39799\n",
      "[epoch 426, batch    22] loss: 128.87686\n",
      "[epoch 426, batch    23] loss: 134.61867\n",
      "[epoch 426, batch    24] loss: 120.72424\n",
      "[epoch 426, batch    25] loss: 127.31853\n",
      "[epoch 426, batch    26] loss: 125.29458\n",
      "[epoch 426, batch    27] loss: 136.54656\n",
      "[epoch 426, batch    28] loss: 122.77163\n",
      "[epoch 426, batch    29] loss: 121.25551\n",
      "[epoch 426, batch    30] loss: 126.69433\n",
      "[epoch 426, batch    31] loss: 133.55375\n",
      "[epoch 426, batch    32] loss: 29.40644\n",
      "[epoch 427, batch     1] loss: 129.74818\n",
      "[epoch 427, batch     2] loss: 126.11357\n",
      "[epoch 427, batch     3] loss: 131.67719\n",
      "[epoch 427, batch     4] loss: 118.10141\n",
      "[epoch 427, batch     5] loss: 141.70087\n",
      "[epoch 427, batch     6] loss: 131.43015\n",
      "[epoch 427, batch     7] loss: 121.14133\n",
      "[epoch 427, batch     8] loss: 131.25562\n",
      "[epoch 427, batch     9] loss: 122.20177\n",
      "[epoch 427, batch    10] loss: 141.50338\n",
      "[epoch 427, batch    11] loss: 135.99559\n",
      "[epoch 427, batch    12] loss: 126.76195\n",
      "[epoch 427, batch    13] loss: 126.91840\n",
      "[epoch 427, batch    14] loss: 139.46589\n",
      "[epoch 427, batch    15] loss: 121.65168\n",
      "[epoch 427, batch    16] loss: 129.98317\n",
      "[epoch 427, batch    17] loss: 129.53339\n",
      "[epoch 427, batch    18] loss: 130.21825\n",
      "[epoch 427, batch    19] loss: 129.15517\n",
      "[epoch 427, batch    20] loss: 129.13736\n",
      "[epoch 427, batch    21] loss: 145.47269\n",
      "[epoch 427, batch    22] loss: 132.50392\n",
      "[epoch 427, batch    23] loss: 150.23463\n",
      "[epoch 427, batch    24] loss: 127.67863\n",
      "[epoch 427, batch    25] loss: 125.41397\n",
      "[epoch 427, batch    26] loss: 132.47082\n",
      "[epoch 427, batch    27] loss: 137.68308\n",
      "[epoch 427, batch    28] loss: 129.08713\n",
      "[epoch 427, batch    29] loss: 134.39255\n",
      "[epoch 427, batch    30] loss: 138.54479\n",
      "[epoch 427, batch    31] loss: 128.14958\n",
      "[epoch 427, batch    32] loss: 40.15603\n",
      "[epoch 428, batch     1] loss: 112.85508\n",
      "[epoch 428, batch     2] loss: 129.82382\n",
      "[epoch 428, batch     3] loss: 134.68115\n",
      "[epoch 428, batch     4] loss: 130.55795\n",
      "[epoch 428, batch     5] loss: 119.05346\n",
      "[epoch 428, batch     6] loss: 138.96984\n",
      "[epoch 428, batch     7] loss: 122.76327\n",
      "[epoch 428, batch     8] loss: 130.68893\n",
      "[epoch 428, batch     9] loss: 136.11590\n",
      "[epoch 428, batch    10] loss: 124.73855\n",
      "[epoch 428, batch    11] loss: 133.18531\n",
      "[epoch 428, batch    12] loss: 136.04481\n",
      "[epoch 428, batch    13] loss: 126.93657\n",
      "[epoch 428, batch    14] loss: 135.80686\n",
      "[epoch 428, batch    15] loss: 123.35249\n",
      "[epoch 428, batch    16] loss: 142.42508\n",
      "[epoch 428, batch    17] loss: 142.07271\n",
      "[epoch 428, batch    18] loss: 136.53087\n",
      "[epoch 428, batch    19] loss: 139.89024\n",
      "[epoch 428, batch    20] loss: 132.18145\n",
      "[epoch 428, batch    21] loss: 128.87834\n",
      "[epoch 428, batch    22] loss: 134.11545\n",
      "[epoch 428, batch    23] loss: 132.56116\n",
      "[epoch 428, batch    24] loss: 138.70896\n",
      "[epoch 428, batch    25] loss: 136.37333\n",
      "[epoch 428, batch    26] loss: 131.08839\n",
      "[epoch 428, batch    27] loss: 135.67927\n",
      "[epoch 428, batch    28] loss: 135.08480\n",
      "[epoch 428, batch    29] loss: 130.79985\n",
      "[epoch 428, batch    30] loss: 135.14881\n",
      "[epoch 428, batch    31] loss: 128.98415\n",
      "[epoch 428, batch    32] loss: 36.32958\n",
      "[epoch 429, batch     1] loss: 138.11602\n",
      "[epoch 429, batch     2] loss: 134.88659\n",
      "[epoch 429, batch     3] loss: 132.83143\n",
      "[epoch 429, batch     4] loss: 131.67464\n",
      "[epoch 429, batch     5] loss: 133.56978\n",
      "[epoch 429, batch     6] loss: 129.46743\n",
      "[epoch 429, batch     7] loss: 129.33696\n",
      "[epoch 429, batch     8] loss: 141.63231\n",
      "[epoch 429, batch     9] loss: 138.82106\n",
      "[epoch 429, batch    10] loss: 137.86821\n",
      "[epoch 429, batch    11] loss: 148.32760\n",
      "[epoch 429, batch    12] loss: 133.20413\n",
      "[epoch 429, batch    13] loss: 130.40922\n",
      "[epoch 429, batch    14] loss: 120.94405\n",
      "[epoch 429, batch    15] loss: 128.96156\n",
      "[epoch 429, batch    16] loss: 136.83328\n",
      "[epoch 429, batch    17] loss: 121.29701\n",
      "[epoch 429, batch    18] loss: 129.82161\n",
      "[epoch 429, batch    19] loss: 141.03323\n",
      "[epoch 429, batch    20] loss: 124.48690\n",
      "[epoch 429, batch    21] loss: 129.59461\n",
      "[epoch 429, batch    22] loss: 133.74753\n",
      "[epoch 429, batch    23] loss: 123.97994\n",
      "[epoch 429, batch    24] loss: 131.59141\n",
      "[epoch 429, batch    25] loss: 155.37116\n",
      "[epoch 429, batch    26] loss: 122.32773\n",
      "[epoch 429, batch    27] loss: 131.13805\n",
      "[epoch 429, batch    28] loss: 154.57247\n",
      "[epoch 429, batch    29] loss: 129.61389\n",
      "[epoch 429, batch    30] loss: 137.56755\n",
      "[epoch 429, batch    31] loss: 128.67478\n",
      "[epoch 429, batch    32] loss: 26.49242\n",
      "[epoch 430, batch     1] loss: 133.80131\n",
      "[epoch 430, batch     2] loss: 128.97700\n",
      "[epoch 430, batch     3] loss: 129.40950\n",
      "[epoch 430, batch     4] loss: 124.77657\n",
      "[epoch 430, batch     5] loss: 122.29671\n",
      "[epoch 430, batch     6] loss: 139.49971\n",
      "[epoch 430, batch     7] loss: 128.57447\n",
      "[epoch 430, batch     8] loss: 136.58582\n",
      "[epoch 430, batch     9] loss: 137.13617\n",
      "[epoch 430, batch    10] loss: 125.77537\n",
      "[epoch 430, batch    11] loss: 128.65138\n",
      "[epoch 430, batch    12] loss: 132.17971\n",
      "[epoch 430, batch    13] loss: 118.03753\n",
      "[epoch 430, batch    14] loss: 134.49648\n",
      "[epoch 430, batch    15] loss: 125.57393\n",
      "[epoch 430, batch    16] loss: 136.18891\n",
      "[epoch 430, batch    17] loss: 124.13892\n",
      "[epoch 430, batch    18] loss: 133.24326\n",
      "[epoch 430, batch    19] loss: 131.94604\n",
      "[epoch 430, batch    20] loss: 140.10882\n",
      "[epoch 430, batch    21] loss: 123.15724\n",
      "[epoch 430, batch    22] loss: 136.68837\n",
      "[epoch 430, batch    23] loss: 138.45517\n",
      "[epoch 430, batch    24] loss: 136.53235\n",
      "[epoch 430, batch    25] loss: 147.42545\n",
      "[epoch 430, batch    26] loss: 134.95510\n",
      "[epoch 430, batch    27] loss: 143.56721\n",
      "[epoch 430, batch    28] loss: 134.88557\n",
      "[epoch 430, batch    29] loss: 131.62699\n",
      "[epoch 430, batch    30] loss: 137.11773\n",
      "[epoch 430, batch    31] loss: 123.10732\n",
      "[epoch 430, batch    32] loss: 35.95997\n",
      "[epoch 431, batch     1] loss: 144.71853\n",
      "[epoch 431, batch     2] loss: 141.03282\n",
      "[epoch 431, batch     3] loss: 121.36840\n",
      "[epoch 431, batch     4] loss: 132.10664\n",
      "[epoch 431, batch     5] loss: 133.93669\n",
      "[epoch 431, batch     6] loss: 135.60641\n",
      "[epoch 431, batch     7] loss: 156.45842\n",
      "[epoch 431, batch     8] loss: 133.51299\n",
      "[epoch 431, batch     9] loss: 138.84100\n",
      "[epoch 431, batch    10] loss: 124.66380\n",
      "[epoch 431, batch    11] loss: 120.81668\n",
      "[epoch 431, batch    12] loss: 122.98211\n",
      "[epoch 431, batch    13] loss: 143.63577\n",
      "[epoch 431, batch    14] loss: 146.43129\n",
      "[epoch 431, batch    15] loss: 130.11579\n",
      "[epoch 431, batch    16] loss: 126.99823\n",
      "[epoch 431, batch    17] loss: 140.56931\n",
      "[epoch 431, batch    18] loss: 127.24838\n",
      "[epoch 431, batch    19] loss: 130.03103\n",
      "[epoch 431, batch    20] loss: 124.23856\n",
      "[epoch 431, batch    21] loss: 134.59458\n",
      "[epoch 431, batch    22] loss: 127.33332\n",
      "[epoch 431, batch    23] loss: 127.81993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 431, batch    24] loss: 130.19567\n",
      "[epoch 431, batch    25] loss: 127.05535\n",
      "[epoch 431, batch    26] loss: 136.90742\n",
      "[epoch 431, batch    27] loss: 136.91969\n",
      "[epoch 431, batch    28] loss: 142.81098\n",
      "[epoch 431, batch    29] loss: 135.23760\n",
      "[epoch 431, batch    30] loss: 122.98451\n",
      "[epoch 431, batch    31] loss: 122.95914\n",
      "[epoch 431, batch    32] loss: 32.46058\n",
      "[epoch 432, batch     1] loss: 130.90401\n",
      "[epoch 432, batch     2] loss: 135.26340\n",
      "[epoch 432, batch     3] loss: 117.16449\n",
      "[epoch 432, batch     4] loss: 138.66861\n",
      "[epoch 432, batch     5] loss: 138.47972\n",
      "[epoch 432, batch     6] loss: 132.48533\n",
      "[epoch 432, batch     7] loss: 128.83332\n",
      "[epoch 432, batch     8] loss: 128.64660\n",
      "[epoch 432, batch     9] loss: 119.15684\n",
      "[epoch 432, batch    10] loss: 141.72939\n",
      "[epoch 432, batch    11] loss: 129.57181\n",
      "[epoch 432, batch    12] loss: 142.80555\n",
      "[epoch 432, batch    13] loss: 137.72311\n",
      "[epoch 432, batch    14] loss: 136.80165\n",
      "[epoch 432, batch    15] loss: 130.54883\n",
      "[epoch 432, batch    16] loss: 138.93570\n",
      "[epoch 432, batch    17] loss: 140.70576\n",
      "[epoch 432, batch    18] loss: 129.34707\n",
      "[epoch 432, batch    19] loss: 131.61081\n",
      "[epoch 432, batch    20] loss: 134.89864\n",
      "[epoch 432, batch    21] loss: 133.99654\n",
      "[epoch 432, batch    22] loss: 123.63911\n",
      "[epoch 432, batch    23] loss: 123.11913\n",
      "[epoch 432, batch    24] loss: 131.66452\n",
      "[epoch 432, batch    25] loss: 127.17760\n",
      "[epoch 432, batch    26] loss: 138.38612\n",
      "[epoch 432, batch    27] loss: 124.47677\n",
      "[epoch 432, batch    28] loss: 128.44966\n",
      "[epoch 432, batch    29] loss: 121.05465\n",
      "[epoch 432, batch    30] loss: 126.57823\n",
      "[epoch 432, batch    31] loss: 128.26589\n",
      "[epoch 432, batch    32] loss: 31.75757\n",
      "[epoch 433, batch     1] loss: 134.54776\n",
      "[epoch 433, batch     2] loss: 137.76146\n",
      "[epoch 433, batch     3] loss: 134.51253\n",
      "[epoch 433, batch     4] loss: 152.02421\n",
      "[epoch 433, batch     5] loss: 133.26756\n",
      "[epoch 433, batch     6] loss: 132.07743\n",
      "[epoch 433, batch     7] loss: 121.50791\n",
      "[epoch 433, batch     8] loss: 139.23237\n",
      "[epoch 433, batch     9] loss: 126.89948\n",
      "[epoch 433, batch    10] loss: 121.73868\n",
      "[epoch 433, batch    11] loss: 138.23591\n",
      "[epoch 433, batch    12] loss: 123.70551\n",
      "[epoch 433, batch    13] loss: 136.51045\n",
      "[epoch 433, batch    14] loss: 131.28497\n",
      "[epoch 433, batch    15] loss: 139.58931\n",
      "[epoch 433, batch    16] loss: 137.37268\n",
      "[epoch 433, batch    17] loss: 118.31840\n",
      "[epoch 433, batch    18] loss: 127.42465\n",
      "[epoch 433, batch    19] loss: 128.32507\n",
      "[epoch 433, batch    20] loss: 130.74705\n",
      "[epoch 433, batch    21] loss: 145.10131\n",
      "[epoch 433, batch    22] loss: 132.92398\n",
      "[epoch 433, batch    23] loss: 130.19899\n",
      "[epoch 433, batch    24] loss: 122.28953\n",
      "[epoch 433, batch    25] loss: 128.93868\n",
      "[epoch 433, batch    26] loss: 125.92860\n",
      "[epoch 433, batch    27] loss: 131.89817\n",
      "[epoch 433, batch    28] loss: 122.21760\n",
      "[epoch 433, batch    29] loss: 120.70241\n",
      "[epoch 433, batch    30] loss: 126.99924\n",
      "[epoch 433, batch    31] loss: 147.62172\n",
      "[epoch 433, batch    32] loss: 27.45751\n",
      "[epoch 434, batch     1] loss: 121.61638\n",
      "[epoch 434, batch     2] loss: 133.14234\n",
      "[epoch 434, batch     3] loss: 140.85014\n",
      "[epoch 434, batch     4] loss: 133.53253\n",
      "[epoch 434, batch     5] loss: 134.32480\n",
      "[epoch 434, batch     6] loss: 131.44760\n",
      "[epoch 434, batch     7] loss: 138.20834\n",
      "[epoch 434, batch     8] loss: 137.05846\n",
      "[epoch 434, batch     9] loss: 128.13635\n",
      "[epoch 434, batch    10] loss: 125.33464\n",
      "[epoch 434, batch    11] loss: 144.38234\n",
      "[epoch 434, batch    12] loss: 128.15433\n",
      "[epoch 434, batch    13] loss: 142.86626\n",
      "[epoch 434, batch    14] loss: 122.85438\n",
      "[epoch 434, batch    15] loss: 127.33660\n",
      "[epoch 434, batch    16] loss: 129.12763\n",
      "[epoch 434, batch    17] loss: 132.68083\n",
      "[epoch 434, batch    18] loss: 127.27838\n",
      "[epoch 434, batch    19] loss: 137.83256\n",
      "[epoch 434, batch    20] loss: 124.33803\n",
      "[epoch 434, batch    21] loss: 142.35752\n",
      "[epoch 434, batch    22] loss: 132.45622\n",
      "[epoch 434, batch    23] loss: 118.74645\n",
      "[epoch 434, batch    24] loss: 135.22202\n",
      "[epoch 434, batch    25] loss: 139.59088\n",
      "[epoch 434, batch    26] loss: 134.71332\n",
      "[epoch 434, batch    27] loss: 125.72214\n",
      "[epoch 434, batch    28] loss: 134.32852\n",
      "[epoch 434, batch    29] loss: 127.43352\n",
      "[epoch 434, batch    30] loss: 121.14129\n",
      "[epoch 434, batch    31] loss: 130.71336\n",
      "[epoch 434, batch    32] loss: 25.06218\n",
      "[epoch 435, batch     1] loss: 148.82516\n",
      "[epoch 435, batch     2] loss: 150.06324\n",
      "[epoch 435, batch     3] loss: 136.17341\n",
      "[epoch 435, batch     4] loss: 135.62947\n",
      "[epoch 435, batch     5] loss: 134.93218\n",
      "[epoch 435, batch     6] loss: 136.43091\n",
      "[epoch 435, batch     7] loss: 126.98143\n",
      "[epoch 435, batch     8] loss: 135.17174\n",
      "[epoch 435, batch     9] loss: 118.46021\n",
      "[epoch 435, batch    10] loss: 130.33415\n",
      "[epoch 435, batch    11] loss: 125.65853\n",
      "[epoch 435, batch    12] loss: 137.65167\n",
      "[epoch 435, batch    13] loss: 121.01933\n",
      "[epoch 435, batch    14] loss: 137.52821\n",
      "[epoch 435, batch    15] loss: 136.34903\n",
      "[epoch 435, batch    16] loss: 137.48512\n",
      "[epoch 435, batch    17] loss: 132.33123\n",
      "[epoch 435, batch    18] loss: 141.20000\n",
      "[epoch 435, batch    19] loss: 119.09298\n",
      "[epoch 435, batch    20] loss: 126.22201\n",
      "[epoch 435, batch    21] loss: 148.87097\n",
      "[epoch 435, batch    22] loss: 128.53053\n",
      "[epoch 435, batch    23] loss: 116.53805\n",
      "[epoch 435, batch    24] loss: 126.44521\n",
      "[epoch 435, batch    25] loss: 147.68961\n",
      "[epoch 435, batch    26] loss: 138.16626\n",
      "[epoch 435, batch    27] loss: 140.45690\n",
      "[epoch 435, batch    28] loss: 127.08410\n",
      "[epoch 435, batch    29] loss: 142.36507\n",
      "[epoch 435, batch    30] loss: 128.28651\n",
      "[epoch 435, batch    31] loss: 140.40857\n",
      "[epoch 435, batch    32] loss: 32.62817\n",
      "[epoch 436, batch     1] loss: 121.70487\n",
      "[epoch 436, batch     2] loss: 132.41920\n",
      "[epoch 436, batch     3] loss: 139.59565\n",
      "[epoch 436, batch     4] loss: 134.03113\n",
      "[epoch 436, batch     5] loss: 152.81715\n",
      "[epoch 436, batch     6] loss: 155.78430\n",
      "[epoch 436, batch     7] loss: 128.80703\n",
      "[epoch 436, batch     8] loss: 123.58370\n",
      "[epoch 436, batch     9] loss: 126.52712\n",
      "[epoch 436, batch    10] loss: 144.57846\n",
      "[epoch 436, batch    11] loss: 120.82102\n",
      "[epoch 436, batch    12] loss: 128.86304\n",
      "[epoch 436, batch    13] loss: 114.14693\n",
      "[epoch 436, batch    14] loss: 127.38877\n",
      "[epoch 436, batch    15] loss: 132.22676\n",
      "[epoch 436, batch    16] loss: 127.57743\n",
      "[epoch 436, batch    17] loss: 121.43169\n",
      "[epoch 436, batch    18] loss: 142.04714\n",
      "[epoch 436, batch    19] loss: 127.97574\n",
      "[epoch 436, batch    20] loss: 131.47947\n",
      "[epoch 436, batch    21] loss: 141.14274\n",
      "[epoch 436, batch    22] loss: 139.57032\n",
      "[epoch 436, batch    23] loss: 125.19728\n",
      "[epoch 436, batch    24] loss: 127.20239\n",
      "[epoch 436, batch    25] loss: 135.19568\n",
      "[epoch 436, batch    26] loss: 138.78448\n",
      "[epoch 436, batch    27] loss: 125.54032\n",
      "[epoch 436, batch    28] loss: 133.74048\n",
      "[epoch 436, batch    29] loss: 130.65796\n",
      "[epoch 436, batch    30] loss: 135.04579\n",
      "[epoch 436, batch    31] loss: 123.05132\n",
      "[epoch 436, batch    32] loss: 30.50590\n",
      "[epoch 437, batch     1] loss: 123.21169\n",
      "[epoch 437, batch     2] loss: 143.76659\n",
      "[epoch 437, batch     3] loss: 131.14046\n",
      "[epoch 437, batch     4] loss: 133.79534\n",
      "[epoch 437, batch     5] loss: 124.47772\n",
      "[epoch 437, batch     6] loss: 134.34985\n",
      "[epoch 437, batch     7] loss: 131.60510\n",
      "[epoch 437, batch     8] loss: 133.71554\n",
      "[epoch 437, batch     9] loss: 132.60447\n",
      "[epoch 437, batch    10] loss: 118.63755\n",
      "[epoch 437, batch    11] loss: 135.98980\n",
      "[epoch 437, batch    12] loss: 133.34121\n",
      "[epoch 437, batch    13] loss: 132.55551\n",
      "[epoch 437, batch    14] loss: 126.53134\n",
      "[epoch 437, batch    15] loss: 130.82039\n",
      "[epoch 437, batch    16] loss: 138.60581\n",
      "[epoch 437, batch    17] loss: 129.68745\n",
      "[epoch 437, batch    18] loss: 134.44852\n",
      "[epoch 437, batch    19] loss: 122.92377\n",
      "[epoch 437, batch    20] loss: 123.86050\n",
      "[epoch 437, batch    21] loss: 131.23616\n",
      "[epoch 437, batch    22] loss: 122.85061\n",
      "[epoch 437, batch    23] loss: 119.49061\n",
      "[epoch 437, batch    24] loss: 136.25900\n",
      "[epoch 437, batch    25] loss: 124.06289\n",
      "[epoch 437, batch    26] loss: 128.73216\n",
      "[epoch 437, batch    27] loss: 128.54320\n",
      "[epoch 437, batch    28] loss: 126.06459\n",
      "[epoch 437, batch    29] loss: 139.46150\n",
      "[epoch 437, batch    30] loss: 145.97862\n",
      "[epoch 437, batch    31] loss: 133.71907\n",
      "[epoch 437, batch    32] loss: 33.19732\n",
      "[epoch 438, batch     1] loss: 128.95111\n",
      "[epoch 438, batch     2] loss: 114.73636\n",
      "[epoch 438, batch     3] loss: 132.43130\n",
      "[epoch 438, batch     4] loss: 138.21206\n",
      "[epoch 438, batch     5] loss: 120.95066\n",
      "[epoch 438, batch     6] loss: 119.58987\n",
      "[epoch 438, batch     7] loss: 131.68314\n",
      "[epoch 438, batch     8] loss: 122.82182\n",
      "[epoch 438, batch     9] loss: 131.51937\n",
      "[epoch 438, batch    10] loss: 134.56728\n",
      "[epoch 438, batch    11] loss: 126.99351\n",
      "[epoch 438, batch    12] loss: 136.92539\n",
      "[epoch 438, batch    13] loss: 131.88853\n",
      "[epoch 438, batch    14] loss: 117.16968\n",
      "[epoch 438, batch    15] loss: 123.47255\n",
      "[epoch 438, batch    16] loss: 125.23312\n",
      "[epoch 438, batch    17] loss: 130.69324\n",
      "[epoch 438, batch    18] loss: 137.09726\n",
      "[epoch 438, batch    19] loss: 122.31306\n",
      "[epoch 438, batch    20] loss: 132.69706\n",
      "[epoch 438, batch    21] loss: 133.78834\n",
      "[epoch 438, batch    22] loss: 132.08773\n",
      "[epoch 438, batch    23] loss: 138.29909\n",
      "[epoch 438, batch    24] loss: 133.36583\n",
      "[epoch 438, batch    25] loss: 119.34848\n",
      "[epoch 438, batch    26] loss: 129.60770\n",
      "[epoch 438, batch    27] loss: 136.45801\n",
      "[epoch 438, batch    28] loss: 151.13835\n",
      "[epoch 438, batch    29] loss: 135.38072\n",
      "[epoch 438, batch    30] loss: 124.06592\n",
      "[epoch 438, batch    31] loss: 148.04640\n",
      "[epoch 438, batch    32] loss: 28.49685\n",
      "[epoch 439, batch     1] loss: 119.93265\n",
      "[epoch 439, batch     2] loss: 121.46169\n",
      "[epoch 439, batch     3] loss: 145.07156\n",
      "[epoch 439, batch     4] loss: 122.81661\n",
      "[epoch 439, batch     5] loss: 137.95296\n",
      "[epoch 439, batch     6] loss: 142.93513\n",
      "[epoch 439, batch     7] loss: 123.68472\n",
      "[epoch 439, batch     8] loss: 128.06928\n",
      "[epoch 439, batch     9] loss: 132.63672\n",
      "[epoch 439, batch    10] loss: 124.18886\n",
      "[epoch 439, batch    11] loss: 127.29357\n",
      "[epoch 439, batch    12] loss: 121.22409\n",
      "[epoch 439, batch    13] loss: 129.26019\n",
      "[epoch 439, batch    14] loss: 127.51883\n",
      "[epoch 439, batch    15] loss: 135.81747\n",
      "[epoch 439, batch    16] loss: 136.55548\n",
      "[epoch 439, batch    17] loss: 129.01146\n",
      "[epoch 439, batch    18] loss: 137.99435\n",
      "[epoch 439, batch    19] loss: 138.39501\n",
      "[epoch 439, batch    20] loss: 122.46355\n",
      "[epoch 439, batch    21] loss: 134.44469\n",
      "[epoch 439, batch    22] loss: 122.45342\n",
      "[epoch 439, batch    23] loss: 129.79815\n",
      "[epoch 439, batch    24] loss: 138.40748\n",
      "[epoch 439, batch    25] loss: 120.37853\n",
      "[epoch 439, batch    26] loss: 142.91469\n",
      "[epoch 439, batch    27] loss: 138.80368\n",
      "[epoch 439, batch    28] loss: 125.62223\n",
      "[epoch 439, batch    29] loss: 139.39057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 439, batch    30] loss: 132.94997\n",
      "[epoch 439, batch    31] loss: 128.30496\n",
      "[epoch 439, batch    32] loss: 28.53456\n",
      "[epoch 440, batch     1] loss: 130.51865\n",
      "[epoch 440, batch     2] loss: 130.35978\n",
      "[epoch 440, batch     3] loss: 136.95735\n",
      "[epoch 440, batch     4] loss: 128.34018\n",
      "[epoch 440, batch     5] loss: 130.94204\n",
      "[epoch 440, batch     6] loss: 124.18499\n",
      "[epoch 440, batch     7] loss: 133.09982\n",
      "[epoch 440, batch     8] loss: 143.01650\n",
      "[epoch 440, batch     9] loss: 125.18398\n",
      "[epoch 440, batch    10] loss: 138.45457\n",
      "[epoch 440, batch    11] loss: 123.16383\n",
      "[epoch 440, batch    12] loss: 136.59650\n",
      "[epoch 440, batch    13] loss: 129.64834\n",
      "[epoch 440, batch    14] loss: 126.23060\n",
      "[epoch 440, batch    15] loss: 134.09143\n",
      "[epoch 440, batch    16] loss: 126.51690\n",
      "[epoch 440, batch    17] loss: 126.65009\n",
      "[epoch 440, batch    18] loss: 128.07589\n",
      "[epoch 440, batch    19] loss: 124.88926\n",
      "[epoch 440, batch    20] loss: 127.50137\n",
      "[epoch 440, batch    21] loss: 137.10010\n",
      "[epoch 440, batch    22] loss: 126.79213\n",
      "[epoch 440, batch    23] loss: 143.96104\n",
      "[epoch 440, batch    24] loss: 134.95005\n",
      "[epoch 440, batch    25] loss: 133.07214\n",
      "[epoch 440, batch    26] loss: 139.93673\n",
      "[epoch 440, batch    27] loss: 128.54428\n",
      "[epoch 440, batch    28] loss: 127.69623\n",
      "[epoch 440, batch    29] loss: 128.13885\n",
      "[epoch 440, batch    30] loss: 133.14687\n",
      "[epoch 440, batch    31] loss: 150.04523\n",
      "[epoch 440, batch    32] loss: 33.32492\n",
      "[epoch 441, batch     1] loss: 139.44764\n",
      "[epoch 441, batch     2] loss: 127.98495\n",
      "[epoch 441, batch     3] loss: 133.64525\n",
      "[epoch 441, batch     4] loss: 140.24430\n",
      "[epoch 441, batch     5] loss: 140.76980\n",
      "[epoch 441, batch     6] loss: 123.01904\n",
      "[epoch 441, batch     7] loss: 146.37993\n",
      "[epoch 441, batch     8] loss: 139.78219\n",
      "[epoch 441, batch     9] loss: 122.99704\n",
      "[epoch 441, batch    10] loss: 130.61336\n",
      "[epoch 441, batch    11] loss: 135.92023\n",
      "[epoch 441, batch    12] loss: 122.17618\n",
      "[epoch 441, batch    13] loss: 141.60050\n",
      "[epoch 441, batch    14] loss: 133.58078\n",
      "[epoch 441, batch    15] loss: 124.05180\n",
      "[epoch 441, batch    16] loss: 137.21675\n",
      "[epoch 441, batch    17] loss: 112.14171\n",
      "[epoch 441, batch    18] loss: 125.13817\n",
      "[epoch 441, batch    19] loss: 149.90134\n",
      "[epoch 441, batch    20] loss: 130.75675\n",
      "[epoch 441, batch    21] loss: 136.23191\n",
      "[epoch 441, batch    22] loss: 128.41936\n",
      "[epoch 441, batch    23] loss: 124.00223\n",
      "[epoch 441, batch    24] loss: 128.98820\n",
      "[epoch 441, batch    25] loss: 133.77161\n",
      "[epoch 441, batch    26] loss: 130.49204\n",
      "[epoch 441, batch    27] loss: 135.33432\n",
      "[epoch 441, batch    28] loss: 125.39532\n",
      "[epoch 441, batch    29] loss: 125.96995\n",
      "[epoch 441, batch    30] loss: 126.28630\n",
      "[epoch 441, batch    31] loss: 137.34353\n",
      "[epoch 441, batch    32] loss: 32.54884\n",
      "[epoch 442, batch     1] loss: 142.26136\n",
      "[epoch 442, batch     2] loss: 123.41758\n",
      "[epoch 442, batch     3] loss: 125.53684\n",
      "[epoch 442, batch     4] loss: 131.62854\n",
      "[epoch 442, batch     5] loss: 127.51960\n",
      "[epoch 442, batch     6] loss: 146.17834\n",
      "[epoch 442, batch     7] loss: 129.02462\n",
      "[epoch 442, batch     8] loss: 140.77862\n",
      "[epoch 442, batch     9] loss: 137.28892\n",
      "[epoch 442, batch    10] loss: 122.98717\n",
      "[epoch 442, batch    11] loss: 117.38053\n",
      "[epoch 442, batch    12] loss: 133.59516\n",
      "[epoch 442, batch    13] loss: 123.90221\n",
      "[epoch 442, batch    14] loss: 141.85630\n",
      "[epoch 442, batch    15] loss: 130.46563\n",
      "[epoch 442, batch    16] loss: 128.05294\n",
      "[epoch 442, batch    17] loss: 142.52158\n",
      "[epoch 442, batch    18] loss: 137.16520\n",
      "[epoch 442, batch    19] loss: 139.12085\n",
      "[epoch 442, batch    20] loss: 126.53650\n",
      "[epoch 442, batch    21] loss: 134.76060\n",
      "[epoch 442, batch    22] loss: 122.97837\n",
      "[epoch 442, batch    23] loss: 122.97413\n",
      "[epoch 442, batch    24] loss: 138.63008\n",
      "[epoch 442, batch    25] loss: 123.28498\n",
      "[epoch 442, batch    26] loss: 137.96288\n",
      "[epoch 442, batch    27] loss: 132.06633\n",
      "[epoch 442, batch    28] loss: 129.40729\n",
      "[epoch 442, batch    29] loss: 120.12824\n",
      "[epoch 442, batch    30] loss: 134.84434\n",
      "[epoch 442, batch    31] loss: 142.98728\n",
      "[epoch 442, batch    32] loss: 30.65774\n",
      "[epoch 443, batch     1] loss: 129.12816\n",
      "[epoch 443, batch     2] loss: 126.48900\n",
      "[epoch 443, batch     3] loss: 128.76497\n",
      "[epoch 443, batch     4] loss: 130.51676\n",
      "[epoch 443, batch     5] loss: 148.95472\n",
      "[epoch 443, batch     6] loss: 133.86861\n",
      "[epoch 443, batch     7] loss: 119.69064\n",
      "[epoch 443, batch     8] loss: 151.45972\n",
      "[epoch 443, batch     9] loss: 134.46653\n",
      "[epoch 443, batch    10] loss: 134.77444\n",
      "[epoch 443, batch    11] loss: 141.06533\n",
      "[epoch 443, batch    12] loss: 135.98141\n",
      "[epoch 443, batch    13] loss: 126.98123\n",
      "[epoch 443, batch    14] loss: 136.29430\n",
      "[epoch 443, batch    15] loss: 130.94509\n",
      "[epoch 443, batch    16] loss: 131.23914\n",
      "[epoch 443, batch    17] loss: 132.75204\n",
      "[epoch 443, batch    18] loss: 123.64596\n",
      "[epoch 443, batch    19] loss: 141.87645\n",
      "[epoch 443, batch    20] loss: 143.73477\n",
      "[epoch 443, batch    21] loss: 132.97079\n",
      "[epoch 443, batch    22] loss: 134.60063\n",
      "[epoch 443, batch    23] loss: 134.27578\n",
      "[epoch 443, batch    24] loss: 125.66011\n",
      "[epoch 443, batch    25] loss: 119.70157\n",
      "[epoch 443, batch    26] loss: 137.18277\n",
      "[epoch 443, batch    27] loss: 132.81591\n",
      "[epoch 443, batch    28] loss: 145.70401\n",
      "[epoch 443, batch    29] loss: 143.48956\n",
      "[epoch 443, batch    30] loss: 126.28299\n",
      "[epoch 443, batch    31] loss: 133.82229\n",
      "[epoch 443, batch    32] loss: 42.83298\n",
      "[epoch 444, batch     1] loss: 127.70910\n",
      "[epoch 444, batch     2] loss: 134.60625\n",
      "[epoch 444, batch     3] loss: 129.31388\n",
      "[epoch 444, batch     4] loss: 130.14212\n",
      "[epoch 444, batch     5] loss: 130.05668\n",
      "[epoch 444, batch     6] loss: 131.11820\n",
      "[epoch 444, batch     7] loss: 130.64638\n",
      "[epoch 444, batch     8] loss: 121.71086\n",
      "[epoch 444, batch     9] loss: 146.28547\n",
      "[epoch 444, batch    10] loss: 132.53657\n",
      "[epoch 444, batch    11] loss: 135.64865\n",
      "[epoch 444, batch    12] loss: 131.77131\n",
      "[epoch 444, batch    13] loss: 133.75129\n",
      "[epoch 444, batch    14] loss: 125.67971\n",
      "[epoch 444, batch    15] loss: 138.19283\n",
      "[epoch 444, batch    16] loss: 127.28255\n",
      "[epoch 444, batch    17] loss: 121.53738\n",
      "[epoch 444, batch    18] loss: 142.39420\n",
      "[epoch 444, batch    19] loss: 143.36516\n",
      "[epoch 444, batch    20] loss: 131.59073\n",
      "[epoch 444, batch    21] loss: 131.36426\n",
      "[epoch 444, batch    22] loss: 130.63407\n",
      "[epoch 444, batch    23] loss: 133.66948\n",
      "[epoch 444, batch    24] loss: 135.27460\n",
      "[epoch 444, batch    25] loss: 132.23859\n",
      "[epoch 444, batch    26] loss: 114.06872\n",
      "[epoch 444, batch    27] loss: 137.61519\n",
      "[epoch 444, batch    28] loss: 130.75578\n",
      "[epoch 444, batch    29] loss: 133.94825\n",
      "[epoch 444, batch    30] loss: 129.65787\n",
      "[epoch 444, batch    31] loss: 122.93411\n",
      "[epoch 444, batch    32] loss: 28.54568\n",
      "[epoch 445, batch     1] loss: 131.75306\n",
      "[epoch 445, batch     2] loss: 138.74569\n",
      "[epoch 445, batch     3] loss: 143.09124\n",
      "[epoch 445, batch     4] loss: 131.49120\n",
      "[epoch 445, batch     5] loss: 119.52364\n",
      "[epoch 445, batch     6] loss: 134.17990\n",
      "[epoch 445, batch     7] loss: 124.29297\n",
      "[epoch 445, batch     8] loss: 121.83418\n",
      "[epoch 445, batch     9] loss: 126.21877\n",
      "[epoch 445, batch    10] loss: 115.16740\n",
      "[epoch 445, batch    11] loss: 134.85092\n",
      "[epoch 445, batch    12] loss: 154.38725\n",
      "[epoch 445, batch    13] loss: 126.63616\n",
      "[epoch 445, batch    14] loss: 137.49333\n",
      "[epoch 445, batch    15] loss: 148.25148\n",
      "[epoch 445, batch    16] loss: 126.14588\n",
      "[epoch 445, batch    17] loss: 129.93893\n",
      "[epoch 445, batch    18] loss: 135.05496\n",
      "[epoch 445, batch    19] loss: 125.26108\n",
      "[epoch 445, batch    20] loss: 130.98873\n",
      "[epoch 445, batch    21] loss: 127.20548\n",
      "[epoch 445, batch    22] loss: 136.46781\n",
      "[epoch 445, batch    23] loss: 131.54048\n",
      "[epoch 445, batch    24] loss: 133.02034\n",
      "[epoch 445, batch    25] loss: 137.97064\n",
      "[epoch 445, batch    26] loss: 131.02399\n",
      "[epoch 445, batch    27] loss: 140.64842\n",
      "[epoch 445, batch    28] loss: 127.85427\n",
      "[epoch 445, batch    29] loss: 129.91751\n",
      "[epoch 445, batch    30] loss: 131.28509\n",
      "[epoch 445, batch    31] loss: 129.10708\n",
      "[epoch 445, batch    32] loss: 37.79129\n",
      "[epoch 446, batch     1] loss: 130.71236\n",
      "[epoch 446, batch     2] loss: 123.57937\n",
      "[epoch 446, batch     3] loss: 125.06442\n",
      "[epoch 446, batch     4] loss: 141.87237\n",
      "[epoch 446, batch     5] loss: 146.58059\n",
      "[epoch 446, batch     6] loss: 135.58639\n",
      "[epoch 446, batch     7] loss: 124.00376\n",
      "[epoch 446, batch     8] loss: 136.74742\n",
      "[epoch 446, batch     9] loss: 129.86369\n",
      "[epoch 446, batch    10] loss: 129.20444\n",
      "[epoch 446, batch    11] loss: 136.47118\n",
      "[epoch 446, batch    12] loss: 135.98428\n",
      "[epoch 446, batch    13] loss: 144.16404\n",
      "[epoch 446, batch    14] loss: 138.08112\n",
      "[epoch 446, batch    15] loss: 133.74183\n",
      "[epoch 446, batch    16] loss: 121.59332\n",
      "[epoch 446, batch    17] loss: 139.71638\n",
      "[epoch 446, batch    18] loss: 136.60117\n",
      "[epoch 446, batch    19] loss: 135.50236\n",
      "[epoch 446, batch    20] loss: 136.02669\n",
      "[epoch 446, batch    21] loss: 116.22214\n",
      "[epoch 446, batch    22] loss: 144.95587\n",
      "[epoch 446, batch    23] loss: 138.77974\n",
      "[epoch 446, batch    24] loss: 128.93899\n",
      "[epoch 446, batch    25] loss: 133.51599\n",
      "[epoch 446, batch    26] loss: 126.58733\n",
      "[epoch 446, batch    27] loss: 131.12968\n",
      "[epoch 446, batch    28] loss: 145.12200\n",
      "[epoch 446, batch    29] loss: 123.70813\n",
      "[epoch 446, batch    30] loss: 129.54972\n",
      "[epoch 446, batch    31] loss: 139.19649\n",
      "[epoch 446, batch    32] loss: 28.92135\n",
      "[epoch 447, batch     1] loss: 133.13768\n",
      "[epoch 447, batch     2] loss: 121.87094\n",
      "[epoch 447, batch     3] loss: 128.64258\n",
      "[epoch 447, batch     4] loss: 126.90403\n",
      "[epoch 447, batch     5] loss: 129.72554\n",
      "[epoch 447, batch     6] loss: 131.75703\n",
      "[epoch 447, batch     7] loss: 132.56446\n",
      "[epoch 447, batch     8] loss: 123.04133\n",
      "[epoch 447, batch     9] loss: 131.08843\n",
      "[epoch 447, batch    10] loss: 138.90324\n",
      "[epoch 447, batch    11] loss: 128.47840\n",
      "[epoch 447, batch    12] loss: 136.56919\n",
      "[epoch 447, batch    13] loss: 131.45644\n",
      "[epoch 447, batch    14] loss: 129.57290\n",
      "[epoch 447, batch    15] loss: 131.72598\n",
      "[epoch 447, batch    16] loss: 124.43410\n",
      "[epoch 447, batch    17] loss: 140.59705\n",
      "[epoch 447, batch    18] loss: 132.60545\n",
      "[epoch 447, batch    19] loss: 142.63047\n",
      "[epoch 447, batch    20] loss: 140.45542\n",
      "[epoch 447, batch    21] loss: 129.97334\n",
      "[epoch 447, batch    22] loss: 122.92142\n",
      "[epoch 447, batch    23] loss: 133.13912\n",
      "[epoch 447, batch    24] loss: 132.17691\n",
      "[epoch 447, batch    25] loss: 137.62916\n",
      "[epoch 447, batch    26] loss: 125.85039\n",
      "[epoch 447, batch    27] loss: 126.86661\n",
      "[epoch 447, batch    28] loss: 137.95860\n",
      "[epoch 447, batch    29] loss: 136.70547\n",
      "[epoch 447, batch    30] loss: 130.14660\n",
      "[epoch 447, batch    31] loss: 134.52382\n",
      "[epoch 447, batch    32] loss: 33.82069\n",
      "[epoch 448, batch     1] loss: 130.98910\n",
      "[epoch 448, batch     2] loss: 127.91718\n",
      "[epoch 448, batch     3] loss: 136.60477\n",
      "[epoch 448, batch     4] loss: 139.26098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 448, batch     5] loss: 115.43237\n",
      "[epoch 448, batch     6] loss: 128.70814\n",
      "[epoch 448, batch     7] loss: 130.89683\n",
      "[epoch 448, batch     8] loss: 127.55137\n",
      "[epoch 448, batch     9] loss: 143.95104\n",
      "[epoch 448, batch    10] loss: 127.59143\n",
      "[epoch 448, batch    11] loss: 121.73157\n",
      "[epoch 448, batch    12] loss: 123.07362\n",
      "[epoch 448, batch    13] loss: 124.01428\n",
      "[epoch 448, batch    14] loss: 135.73322\n",
      "[epoch 448, batch    15] loss: 128.11855\n",
      "[epoch 448, batch    16] loss: 147.43304\n",
      "[epoch 448, batch    17] loss: 129.84629\n",
      "[epoch 448, batch    18] loss: 128.30405\n",
      "[epoch 448, batch    19] loss: 129.70668\n",
      "[epoch 448, batch    20] loss: 140.08002\n",
      "[epoch 448, batch    21] loss: 138.55339\n",
      "[epoch 448, batch    22] loss: 126.66114\n",
      "[epoch 448, batch    23] loss: 129.80316\n",
      "[epoch 448, batch    24] loss: 132.31317\n",
      "[epoch 448, batch    25] loss: 146.36259\n",
      "[epoch 448, batch    26] loss: 131.73770\n",
      "[epoch 448, batch    27] loss: 127.37984\n",
      "[epoch 448, batch    28] loss: 131.13578\n",
      "[epoch 448, batch    29] loss: 152.97697\n",
      "[epoch 448, batch    30] loss: 125.68323\n",
      "[epoch 448, batch    31] loss: 130.39744\n",
      "[epoch 448, batch    32] loss: 35.89616\n",
      "[epoch 449, batch     1] loss: 126.61982\n",
      "[epoch 449, batch     2] loss: 134.78861\n",
      "[epoch 449, batch     3] loss: 139.05924\n",
      "[epoch 449, batch     4] loss: 130.25092\n",
      "[epoch 449, batch     5] loss: 132.20387\n",
      "[epoch 449, batch     6] loss: 119.50454\n",
      "[epoch 449, batch     7] loss: 133.94015\n",
      "[epoch 449, batch     8] loss: 122.71750\n",
      "[epoch 449, batch     9] loss: 136.08281\n",
      "[epoch 449, batch    10] loss: 135.68706\n",
      "[epoch 449, batch    11] loss: 133.24745\n",
      "[epoch 449, batch    12] loss: 132.78718\n",
      "[epoch 449, batch    13] loss: 122.09150\n",
      "[epoch 449, batch    14] loss: 126.33250\n",
      "[epoch 449, batch    15] loss: 132.93794\n",
      "[epoch 449, batch    16] loss: 131.81295\n",
      "[epoch 449, batch    17] loss: 134.98674\n",
      "[epoch 449, batch    18] loss: 121.06131\n",
      "[epoch 449, batch    19] loss: 137.52418\n",
      "[epoch 449, batch    20] loss: 133.02289\n",
      "[epoch 449, batch    21] loss: 134.31958\n",
      "[epoch 449, batch    22] loss: 136.92130\n",
      "[epoch 449, batch    23] loss: 142.13074\n",
      "[epoch 449, batch    24] loss: 132.24110\n",
      "[epoch 449, batch    25] loss: 138.11072\n",
      "[epoch 449, batch    26] loss: 136.03836\n",
      "[epoch 449, batch    27] loss: 127.07943\n",
      "[epoch 449, batch    28] loss: 128.38982\n",
      "[epoch 449, batch    29] loss: 120.37451\n",
      "[epoch 449, batch    30] loss: 149.29649\n",
      "[epoch 449, batch    31] loss: 127.89502\n",
      "[epoch 449, batch    32] loss: 30.97000\n",
      "[epoch 450, batch     1] loss: 133.15230\n",
      "[epoch 450, batch     2] loss: 142.39165\n",
      "[epoch 450, batch     3] loss: 137.56046\n",
      "[epoch 450, batch     4] loss: 122.07698\n",
      "[epoch 450, batch     5] loss: 129.94112\n",
      "[epoch 450, batch     6] loss: 132.30470\n",
      "[epoch 450, batch     7] loss: 137.95551\n",
      "[epoch 450, batch     8] loss: 135.73983\n",
      "[epoch 450, batch     9] loss: 130.81260\n",
      "[epoch 450, batch    10] loss: 127.72527\n",
      "[epoch 450, batch    11] loss: 144.55989\n",
      "[epoch 450, batch    12] loss: 137.57574\n",
      "[epoch 450, batch    13] loss: 116.88266\n",
      "[epoch 450, batch    14] loss: 135.53788\n",
      "[epoch 450, batch    15] loss: 150.43152\n",
      "[epoch 450, batch    16] loss: 128.71416\n",
      "[epoch 450, batch    17] loss: 113.71891\n",
      "[epoch 450, batch    18] loss: 132.95068\n",
      "[epoch 450, batch    19] loss: 119.56648\n",
      "[epoch 450, batch    20] loss: 131.46986\n",
      "[epoch 450, batch    21] loss: 142.36690\n",
      "[epoch 450, batch    22] loss: 128.35743\n",
      "[epoch 450, batch    23] loss: 137.05294\n",
      "[epoch 450, batch    24] loss: 142.18195\n",
      "[epoch 450, batch    25] loss: 123.67008\n",
      "[epoch 450, batch    26] loss: 127.61158\n",
      "[epoch 450, batch    27] loss: 146.83694\n",
      "[epoch 450, batch    28] loss: 137.06926\n",
      "[epoch 450, batch    29] loss: 126.40540\n",
      "[epoch 450, batch    30] loss: 141.98792\n",
      "[epoch 450, batch    31] loss: 138.36170\n",
      "[epoch 450, batch    32] loss: 36.14950\n",
      "[epoch 451, batch     1] loss: 131.21160\n",
      "[epoch 451, batch     2] loss: 129.49229\n",
      "[epoch 451, batch     3] loss: 123.57675\n",
      "[epoch 451, batch     4] loss: 131.66332\n",
      "[epoch 451, batch     5] loss: 138.88620\n",
      "[epoch 451, batch     6] loss: 117.62252\n",
      "[epoch 451, batch     7] loss: 143.56764\n",
      "[epoch 451, batch     8] loss: 117.38441\n",
      "[epoch 451, batch     9] loss: 131.26015\n",
      "[epoch 451, batch    10] loss: 152.29520\n",
      "[epoch 451, batch    11] loss: 135.48727\n",
      "[epoch 451, batch    12] loss: 123.97870\n",
      "[epoch 451, batch    13] loss: 126.06011\n",
      "[epoch 451, batch    14] loss: 139.01316\n",
      "[epoch 451, batch    15] loss: 128.00479\n",
      "[epoch 451, batch    16] loss: 127.43238\n",
      "[epoch 451, batch    17] loss: 127.57148\n",
      "[epoch 451, batch    18] loss: 126.07372\n",
      "[epoch 451, batch    19] loss: 124.63422\n",
      "[epoch 451, batch    20] loss: 128.43559\n",
      "[epoch 451, batch    21] loss: 149.95360\n",
      "[epoch 451, batch    22] loss: 128.85247\n",
      "[epoch 451, batch    23] loss: 128.14254\n",
      "[epoch 451, batch    24] loss: 129.43052\n",
      "[epoch 451, batch    25] loss: 135.76734\n",
      "[epoch 451, batch    26] loss: 128.18894\n",
      "[epoch 451, batch    27] loss: 138.28056\n",
      "[epoch 451, batch    28] loss: 119.77836\n",
      "[epoch 451, batch    29] loss: 139.21111\n",
      "[epoch 451, batch    30] loss: 129.34150\n",
      "[epoch 451, batch    31] loss: 146.25398\n",
      "[epoch 451, batch    32] loss: 36.42869\n",
      "[epoch 452, batch     1] loss: 135.69076\n",
      "[epoch 452, batch     2] loss: 132.05700\n",
      "[epoch 452, batch     3] loss: 135.63565\n",
      "[epoch 452, batch     4] loss: 116.13740\n",
      "[epoch 452, batch     5] loss: 126.55088\n",
      "[epoch 452, batch     6] loss: 133.37219\n",
      "[epoch 452, batch     7] loss: 130.59097\n",
      "[epoch 452, batch     8] loss: 133.92991\n",
      "[epoch 452, batch     9] loss: 123.19481\n",
      "[epoch 452, batch    10] loss: 143.06385\n",
      "[epoch 452, batch    11] loss: 148.92377\n",
      "[epoch 452, batch    12] loss: 149.41949\n",
      "[epoch 452, batch    13] loss: 124.16219\n",
      "[epoch 452, batch    14] loss: 128.44396\n",
      "[epoch 452, batch    15] loss: 129.24274\n",
      "[epoch 452, batch    16] loss: 126.44229\n",
      "[epoch 452, batch    17] loss: 143.92566\n",
      "[epoch 452, batch    18] loss: 131.19769\n",
      "[epoch 452, batch    19] loss: 146.46511\n",
      "[epoch 452, batch    20] loss: 134.34774\n",
      "[epoch 452, batch    21] loss: 124.47627\n",
      "[epoch 452, batch    22] loss: 145.97428\n",
      "[epoch 452, batch    23] loss: 135.16374\n",
      "[epoch 452, batch    24] loss: 132.97325\n",
      "[epoch 452, batch    25] loss: 131.22738\n",
      "[epoch 452, batch    26] loss: 135.80755\n",
      "[epoch 452, batch    27] loss: 124.45085\n",
      "[epoch 452, batch    28] loss: 144.74183\n",
      "[epoch 452, batch    29] loss: 118.13687\n",
      "[epoch 452, batch    30] loss: 127.64896\n",
      "[epoch 452, batch    31] loss: 137.87946\n",
      "[epoch 452, batch    32] loss: 34.75866\n",
      "[epoch 453, batch     1] loss: 140.69257\n",
      "[epoch 453, batch     2] loss: 116.48494\n",
      "[epoch 453, batch     3] loss: 136.66406\n",
      "[epoch 453, batch     4] loss: 136.45474\n",
      "[epoch 453, batch     5] loss: 126.47103\n",
      "[epoch 453, batch     6] loss: 131.46431\n",
      "[epoch 453, batch     7] loss: 139.24978\n",
      "[epoch 453, batch     8] loss: 138.16041\n",
      "[epoch 453, batch     9] loss: 133.12449\n",
      "[epoch 453, batch    10] loss: 131.57006\n",
      "[epoch 453, batch    11] loss: 145.29216\n",
      "[epoch 453, batch    12] loss: 131.99111\n",
      "[epoch 453, batch    13] loss: 134.62944\n",
      "[epoch 453, batch    14] loss: 132.84300\n",
      "[epoch 453, batch    15] loss: 126.21364\n",
      "[epoch 453, batch    16] loss: 130.54163\n",
      "[epoch 453, batch    17] loss: 126.57877\n",
      "[epoch 453, batch    18] loss: 135.13614\n",
      "[epoch 453, batch    19] loss: 127.83852\n",
      "[epoch 453, batch    20] loss: 130.55284\n",
      "[epoch 453, batch    21] loss: 133.65511\n",
      "[epoch 453, batch    22] loss: 117.04235\n",
      "[epoch 453, batch    23] loss: 125.11465\n",
      "[epoch 453, batch    24] loss: 143.05479\n",
      "[epoch 453, batch    25] loss: 125.46606\n",
      "[epoch 453, batch    26] loss: 124.24363\n",
      "[epoch 453, batch    27] loss: 116.11266\n",
      "[epoch 453, batch    28] loss: 124.53813\n",
      "[epoch 453, batch    29] loss: 132.40753\n",
      "[epoch 453, batch    30] loss: 139.89544\n",
      "[epoch 453, batch    31] loss: 142.51256\n",
      "[epoch 453, batch    32] loss: 30.97864\n",
      "[epoch 454, batch     1] loss: 143.06416\n",
      "[epoch 454, batch     2] loss: 134.60863\n",
      "[epoch 454, batch     3] loss: 118.82896\n",
      "[epoch 454, batch     4] loss: 141.80782\n",
      "[epoch 454, batch     5] loss: 139.41334\n",
      "[epoch 454, batch     6] loss: 135.57525\n",
      "[epoch 454, batch     7] loss: 131.32981\n",
      "[epoch 454, batch     8] loss: 133.13532\n",
      "[epoch 454, batch     9] loss: 134.47197\n",
      "[epoch 454, batch    10] loss: 125.50314\n",
      "[epoch 454, batch    11] loss: 120.22489\n",
      "[epoch 454, batch    12] loss: 126.42806\n",
      "[epoch 454, batch    13] loss: 132.00725\n",
      "[epoch 454, batch    14] loss: 120.77045\n",
      "[epoch 454, batch    15] loss: 135.00755\n",
      "[epoch 454, batch    16] loss: 130.09934\n",
      "[epoch 454, batch    17] loss: 130.04133\n",
      "[epoch 454, batch    18] loss: 135.97531\n",
      "[epoch 454, batch    19] loss: 135.27192\n",
      "[epoch 454, batch    20] loss: 132.03811\n",
      "[epoch 454, batch    21] loss: 139.77814\n",
      "[epoch 454, batch    22] loss: 139.11908\n",
      "[epoch 454, batch    23] loss: 129.22580\n",
      "[epoch 454, batch    24] loss: 127.15102\n",
      "[epoch 454, batch    25] loss: 129.14413\n",
      "[epoch 454, batch    26] loss: 133.96330\n",
      "[epoch 454, batch    27] loss: 144.17637\n",
      "[epoch 454, batch    28] loss: 127.21772\n",
      "[epoch 454, batch    29] loss: 131.91728\n",
      "[epoch 454, batch    30] loss: 123.02016\n",
      "[epoch 454, batch    31] loss: 132.99532\n",
      "[epoch 454, batch    32] loss: 38.07666\n",
      "[epoch 455, batch     1] loss: 138.61287\n",
      "[epoch 455, batch     2] loss: 127.48016\n",
      "[epoch 455, batch     3] loss: 128.14732\n",
      "[epoch 455, batch     4] loss: 135.49398\n",
      "[epoch 455, batch     5] loss: 127.29502\n",
      "[epoch 455, batch     6] loss: 123.50457\n",
      "[epoch 455, batch     7] loss: 132.56302\n",
      "[epoch 455, batch     8] loss: 134.23231\n",
      "[epoch 455, batch     9] loss: 132.03419\n",
      "[epoch 455, batch    10] loss: 124.34644\n",
      "[epoch 455, batch    11] loss: 131.02081\n",
      "[epoch 455, batch    12] loss: 134.88632\n",
      "[epoch 455, batch    13] loss: 130.24875\n",
      "[epoch 455, batch    14] loss: 141.88558\n",
      "[epoch 455, batch    15] loss: 133.83246\n",
      "[epoch 455, batch    16] loss: 124.01890\n",
      "[epoch 455, batch    17] loss: 118.44052\n",
      "[epoch 455, batch    18] loss: 131.11606\n",
      "[epoch 455, batch    19] loss: 119.35125\n",
      "[epoch 455, batch    20] loss: 136.67671\n",
      "[epoch 455, batch    21] loss: 122.50213\n",
      "[epoch 455, batch    22] loss: 130.44712\n",
      "[epoch 455, batch    23] loss: 123.67787\n",
      "[epoch 455, batch    24] loss: 139.71361\n",
      "[epoch 455, batch    25] loss: 125.77689\n",
      "[epoch 455, batch    26] loss: 132.18183\n",
      "[epoch 455, batch    27] loss: 140.61766\n",
      "[epoch 455, batch    28] loss: 121.58991\n",
      "[epoch 455, batch    29] loss: 125.63401\n",
      "[epoch 455, batch    30] loss: 129.10344\n",
      "[epoch 455, batch    31] loss: 138.62211\n",
      "[epoch 455, batch    32] loss: 28.96338\n",
      "[epoch 456, batch     1] loss: 130.97924\n",
      "[epoch 456, batch     2] loss: 133.80312\n",
      "[epoch 456, batch     3] loss: 140.93389\n",
      "[epoch 456, batch     4] loss: 132.74467\n",
      "[epoch 456, batch     5] loss: 129.24528\n",
      "[epoch 456, batch     6] loss: 123.74317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 456, batch     7] loss: 133.72924\n",
      "[epoch 456, batch     8] loss: 142.86156\n",
      "[epoch 456, batch     9] loss: 130.20309\n",
      "[epoch 456, batch    10] loss: 139.96116\n",
      "[epoch 456, batch    11] loss: 132.28445\n",
      "[epoch 456, batch    12] loss: 135.73724\n",
      "[epoch 456, batch    13] loss: 124.44931\n",
      "[epoch 456, batch    14] loss: 134.06204\n",
      "[epoch 456, batch    15] loss: 137.22799\n",
      "[epoch 456, batch    16] loss: 136.02886\n",
      "[epoch 456, batch    17] loss: 126.03363\n",
      "[epoch 456, batch    18] loss: 135.34502\n",
      "[epoch 456, batch    19] loss: 133.76126\n",
      "[epoch 456, batch    20] loss: 132.59095\n",
      "[epoch 456, batch    21] loss: 142.00078\n",
      "[epoch 456, batch    22] loss: 133.13564\n",
      "[epoch 456, batch    23] loss: 139.06307\n",
      "[epoch 456, batch    24] loss: 122.82201\n",
      "[epoch 456, batch    25] loss: 139.51096\n",
      "[epoch 456, batch    26] loss: 120.56070\n",
      "[epoch 456, batch    27] loss: 127.91621\n",
      "[epoch 456, batch    28] loss: 126.27151\n",
      "[epoch 456, batch    29] loss: 124.64015\n",
      "[epoch 456, batch    30] loss: 136.23572\n",
      "[epoch 456, batch    31] loss: 131.90662\n",
      "[epoch 456, batch    32] loss: 37.12239\n",
      "[epoch 457, batch     1] loss: 128.98001\n",
      "[epoch 457, batch     2] loss: 122.36882\n",
      "[epoch 457, batch     3] loss: 143.93146\n",
      "[epoch 457, batch     4] loss: 125.10516\n",
      "[epoch 457, batch     5] loss: 127.91822\n",
      "[epoch 457, batch     6] loss: 127.62770\n",
      "[epoch 457, batch     7] loss: 124.33470\n",
      "[epoch 457, batch     8] loss: 130.38991\n",
      "[epoch 457, batch     9] loss: 151.28730\n",
      "[epoch 457, batch    10] loss: 139.63008\n",
      "[epoch 457, batch    11] loss: 137.58548\n",
      "[epoch 457, batch    12] loss: 132.69007\n",
      "[epoch 457, batch    13] loss: 123.44404\n",
      "[epoch 457, batch    14] loss: 134.07621\n",
      "[epoch 457, batch    15] loss: 130.54304\n",
      "[epoch 457, batch    16] loss: 144.46036\n",
      "[epoch 457, batch    17] loss: 137.18094\n",
      "[epoch 457, batch    18] loss: 126.05990\n",
      "[epoch 457, batch    19] loss: 123.42202\n",
      "[epoch 457, batch    20] loss: 131.11145\n",
      "[epoch 457, batch    21] loss: 140.30512\n",
      "[epoch 457, batch    22] loss: 135.45143\n",
      "[epoch 457, batch    23] loss: 118.84452\n",
      "[epoch 457, batch    24] loss: 143.10879\n",
      "[epoch 457, batch    25] loss: 136.96168\n",
      "[epoch 457, batch    26] loss: 135.11185\n",
      "[epoch 457, batch    27] loss: 136.07222\n",
      "[epoch 457, batch    28] loss: 128.37242\n",
      "[epoch 457, batch    29] loss: 132.96909\n",
      "[epoch 457, batch    30] loss: 135.67172\n",
      "[epoch 457, batch    31] loss: 127.17302\n",
      "[epoch 457, batch    32] loss: 32.26635\n",
      "[epoch 458, batch     1] loss: 132.88260\n",
      "[epoch 458, batch     2] loss: 130.56442\n",
      "[epoch 458, batch     3] loss: 134.38168\n",
      "[epoch 458, batch     4] loss: 123.78643\n",
      "[epoch 458, batch     5] loss: 143.35817\n",
      "[epoch 458, batch     6] loss: 137.80015\n",
      "[epoch 458, batch     7] loss: 128.35967\n",
      "[epoch 458, batch     8] loss: 127.04057\n",
      "[epoch 458, batch     9] loss: 128.73355\n",
      "[epoch 458, batch    10] loss: 139.00095\n",
      "[epoch 458, batch    11] loss: 125.50794\n",
      "[epoch 458, batch    12] loss: 136.50475\n",
      "[epoch 458, batch    13] loss: 129.96779\n",
      "[epoch 458, batch    14] loss: 127.94212\n",
      "[epoch 458, batch    15] loss: 136.46249\n",
      "[epoch 458, batch    16] loss: 149.70065\n",
      "[epoch 458, batch    17] loss: 126.08542\n",
      "[epoch 458, batch    18] loss: 130.71108\n",
      "[epoch 458, batch    19] loss: 128.07550\n",
      "[epoch 458, batch    20] loss: 134.27631\n",
      "[epoch 458, batch    21] loss: 132.46762\n",
      "[epoch 458, batch    22] loss: 124.27692\n",
      "[epoch 458, batch    23] loss: 131.42551\n",
      "[epoch 458, batch    24] loss: 130.72665\n",
      "[epoch 458, batch    25] loss: 125.83815\n",
      "[epoch 458, batch    26] loss: 132.96275\n",
      "[epoch 458, batch    27] loss: 135.47400\n",
      "[epoch 458, batch    28] loss: 115.78952\n",
      "[epoch 458, batch    29] loss: 126.79827\n",
      "[epoch 458, batch    30] loss: 126.26405\n",
      "[epoch 458, batch    31] loss: 131.76845\n",
      "[epoch 458, batch    32] loss: 31.74903\n",
      "[epoch 459, batch     1] loss: 144.27921\n",
      "[epoch 459, batch     2] loss: 127.15405\n",
      "[epoch 459, batch     3] loss: 121.34147\n",
      "[epoch 459, batch     4] loss: 138.03830\n",
      "[epoch 459, batch     5] loss: 136.54688\n",
      "[epoch 459, batch     6] loss: 151.72783\n",
      "[epoch 459, batch     7] loss: 138.26839\n",
      "[epoch 459, batch     8] loss: 123.91897\n",
      "[epoch 459, batch     9] loss: 125.28514\n",
      "[epoch 459, batch    10] loss: 122.85603\n",
      "[epoch 459, batch    11] loss: 132.95750\n",
      "[epoch 459, batch    12] loss: 125.87618\n",
      "[epoch 459, batch    13] loss: 112.89629\n",
      "[epoch 459, batch    14] loss: 135.22967\n",
      "[epoch 459, batch    15] loss: 129.45766\n",
      "[epoch 459, batch    16] loss: 120.93060\n",
      "[epoch 459, batch    17] loss: 122.62260\n",
      "[epoch 459, batch    18] loss: 143.86781\n",
      "[epoch 459, batch    19] loss: 143.86108\n",
      "[epoch 459, batch    20] loss: 129.66693\n",
      "[epoch 459, batch    21] loss: 126.69172\n",
      "[epoch 459, batch    22] loss: 132.66265\n",
      "[epoch 459, batch    23] loss: 132.68509\n",
      "[epoch 459, batch    24] loss: 129.60948\n",
      "[epoch 459, batch    25] loss: 132.81924\n",
      "[epoch 459, batch    26] loss: 132.27290\n",
      "[epoch 459, batch    27] loss: 126.32403\n",
      "[epoch 459, batch    28] loss: 128.19199\n",
      "[epoch 459, batch    29] loss: 137.76309\n",
      "[epoch 459, batch    30] loss: 134.45828\n",
      "[epoch 459, batch    31] loss: 145.26245\n",
      "[epoch 459, batch    32] loss: 31.12298\n",
      "[epoch 460, batch     1] loss: 134.14342\n",
      "[epoch 460, batch     2] loss: 129.62733\n",
      "[epoch 460, batch     3] loss: 140.16371\n",
      "[epoch 460, batch     4] loss: 121.70529\n",
      "[epoch 460, batch     5] loss: 143.01603\n",
      "[epoch 460, batch     6] loss: 128.00150\n",
      "[epoch 460, batch     7] loss: 135.36653\n",
      "[epoch 460, batch     8] loss: 130.79289\n",
      "[epoch 460, batch     9] loss: 124.87644\n",
      "[epoch 460, batch    10] loss: 130.11968\n",
      "[epoch 460, batch    11] loss: 128.62868\n",
      "[epoch 460, batch    12] loss: 132.37679\n",
      "[epoch 460, batch    13] loss: 130.15717\n",
      "[epoch 460, batch    14] loss: 123.79586\n",
      "[epoch 460, batch    15] loss: 136.70645\n",
      "[epoch 460, batch    16] loss: 135.12910\n",
      "[epoch 460, batch    17] loss: 138.04550\n",
      "[epoch 460, batch    18] loss: 128.84346\n",
      "[epoch 460, batch    19] loss: 130.12483\n",
      "[epoch 460, batch    20] loss: 125.34382\n",
      "[epoch 460, batch    21] loss: 121.04180\n",
      "[epoch 460, batch    22] loss: 137.86013\n",
      "[epoch 460, batch    23] loss: 126.95525\n",
      "[epoch 460, batch    24] loss: 129.62466\n",
      "[epoch 460, batch    25] loss: 139.61033\n",
      "[epoch 460, batch    26] loss: 125.55322\n",
      "[epoch 460, batch    27] loss: 142.13569\n",
      "[epoch 460, batch    28] loss: 138.47104\n",
      "[epoch 460, batch    29] loss: 123.35487\n",
      "[epoch 460, batch    30] loss: 126.67444\n",
      "[epoch 460, batch    31] loss: 146.55731\n",
      "[epoch 460, batch    32] loss: 33.98069\n",
      "[epoch 461, batch     1] loss: 128.75686\n",
      "[epoch 461, batch     2] loss: 130.02209\n",
      "[epoch 461, batch     3] loss: 124.26981\n",
      "[epoch 461, batch     4] loss: 133.83723\n",
      "[epoch 461, batch     5] loss: 149.12063\n",
      "[epoch 461, batch     6] loss: 139.54796\n",
      "[epoch 461, batch     7] loss: 139.40858\n",
      "[epoch 461, batch     8] loss: 130.86129\n",
      "[epoch 461, batch     9] loss: 129.89429\n",
      "[epoch 461, batch    10] loss: 125.01315\n",
      "[epoch 461, batch    11] loss: 125.86383\n",
      "[epoch 461, batch    12] loss: 120.29196\n",
      "[epoch 461, batch    13] loss: 135.84598\n",
      "[epoch 461, batch    14] loss: 121.24954\n",
      "[epoch 461, batch    15] loss: 139.59515\n",
      "[epoch 461, batch    16] loss: 127.77499\n",
      "[epoch 461, batch    17] loss: 126.16890\n",
      "[epoch 461, batch    18] loss: 130.67699\n",
      "[epoch 461, batch    19] loss: 131.86236\n",
      "[epoch 461, batch    20] loss: 148.18787\n",
      "[epoch 461, batch    21] loss: 124.67069\n",
      "[epoch 461, batch    22] loss: 145.21436\n",
      "[epoch 461, batch    23] loss: 123.98524\n",
      "[epoch 461, batch    24] loss: 128.34665\n",
      "[epoch 461, batch    25] loss: 125.33626\n",
      "[epoch 461, batch    26] loss: 139.38015\n",
      "[epoch 461, batch    27] loss: 133.94208\n",
      "[epoch 461, batch    28] loss: 136.36757\n",
      "[epoch 461, batch    29] loss: 127.01750\n",
      "[epoch 461, batch    30] loss: 131.87490\n",
      "[epoch 461, batch    31] loss: 126.40518\n",
      "[epoch 461, batch    32] loss: 31.30454\n",
      "[epoch 462, batch     1] loss: 134.92557\n",
      "[epoch 462, batch     2] loss: 122.52775\n",
      "[epoch 462, batch     3] loss: 138.63277\n",
      "[epoch 462, batch     4] loss: 131.46372\n",
      "[epoch 462, batch     5] loss: 122.05153\n",
      "[epoch 462, batch     6] loss: 118.22786\n",
      "[epoch 462, batch     7] loss: 118.78358\n",
      "[epoch 462, batch     8] loss: 129.77661\n",
      "[epoch 462, batch     9] loss: 146.71865\n",
      "[epoch 462, batch    10] loss: 134.03716\n",
      "[epoch 462, batch    11] loss: 139.81526\n",
      "[epoch 462, batch    12] loss: 140.93675\n",
      "[epoch 462, batch    13] loss: 137.66904\n",
      "[epoch 462, batch    14] loss: 129.18840\n",
      "[epoch 462, batch    15] loss: 130.79593\n",
      "[epoch 462, batch    16] loss: 125.81424\n",
      "[epoch 462, batch    17] loss: 132.54332\n",
      "[epoch 462, batch    18] loss: 130.45339\n",
      "[epoch 462, batch    19] loss: 121.49633\n",
      "[epoch 462, batch    20] loss: 135.17720\n",
      "[epoch 462, batch    21] loss: 139.67926\n",
      "[epoch 462, batch    22] loss: 147.80180\n",
      "[epoch 462, batch    23] loss: 128.23634\n",
      "[epoch 462, batch    24] loss: 144.36908\n",
      "[epoch 462, batch    25] loss: 122.47486\n",
      "[epoch 462, batch    26] loss: 122.18243\n",
      "[epoch 462, batch    27] loss: 138.23598\n",
      "[epoch 462, batch    28] loss: 139.18214\n",
      "[epoch 462, batch    29] loss: 127.61117\n",
      "[epoch 462, batch    30] loss: 138.82810\n",
      "[epoch 462, batch    31] loss: 128.10888\n",
      "[epoch 462, batch    32] loss: 25.93946\n",
      "[epoch 463, batch     1] loss: 128.78953\n",
      "[epoch 463, batch     2] loss: 124.66435\n",
      "[epoch 463, batch     3] loss: 126.82967\n",
      "[epoch 463, batch     4] loss: 129.15937\n",
      "[epoch 463, batch     5] loss: 120.24518\n",
      "[epoch 463, batch     6] loss: 132.20304\n",
      "[epoch 463, batch     7] loss: 127.85676\n",
      "[epoch 463, batch     8] loss: 129.99242\n",
      "[epoch 463, batch     9] loss: 129.51819\n",
      "[epoch 463, batch    10] loss: 120.47008\n",
      "[epoch 463, batch    11] loss: 125.77436\n",
      "[epoch 463, batch    12] loss: 126.51205\n",
      "[epoch 463, batch    13] loss: 137.32787\n",
      "[epoch 463, batch    14] loss: 152.54796\n",
      "[epoch 463, batch    15] loss: 131.85349\n",
      "[epoch 463, batch    16] loss: 132.68448\n",
      "[epoch 463, batch    17] loss: 132.72650\n",
      "[epoch 463, batch    18] loss: 141.22890\n",
      "[epoch 463, batch    19] loss: 127.47505\n",
      "[epoch 463, batch    20] loss: 149.68080\n",
      "[epoch 463, batch    21] loss: 130.59720\n",
      "[epoch 463, batch    22] loss: 134.47102\n",
      "[epoch 463, batch    23] loss: 128.53059\n",
      "[epoch 463, batch    24] loss: 134.24233\n",
      "[epoch 463, batch    25] loss: 129.77938\n",
      "[epoch 463, batch    26] loss: 129.96820\n",
      "[epoch 463, batch    27] loss: 135.46193\n",
      "[epoch 463, batch    28] loss: 130.42023\n",
      "[epoch 463, batch    29] loss: 132.78297\n",
      "[epoch 463, batch    30] loss: 121.68068\n",
      "[epoch 463, batch    31] loss: 134.46574\n",
      "[epoch 463, batch    32] loss: 28.21685\n",
      "[epoch 464, batch     1] loss: 121.56920\n",
      "[epoch 464, batch     2] loss: 139.08944\n",
      "[epoch 464, batch     3] loss: 130.36444\n",
      "[epoch 464, batch     4] loss: 134.41220\n",
      "[epoch 464, batch     5] loss: 143.39266\n",
      "[epoch 464, batch     6] loss: 131.41045\n",
      "[epoch 464, batch     7] loss: 128.32539\n",
      "[epoch 464, batch     8] loss: 133.69447\n",
      "[epoch 464, batch     9] loss: 117.45513\n",
      "[epoch 464, batch    10] loss: 130.99604\n",
      "[epoch 464, batch    11] loss: 134.10090\n",
      "[epoch 464, batch    12] loss: 130.74583\n",
      "[epoch 464, batch    13] loss: 137.87173\n",
      "[epoch 464, batch    14] loss: 128.55701\n",
      "[epoch 464, batch    15] loss: 121.93097\n",
      "[epoch 464, batch    16] loss: 129.09854\n",
      "[epoch 464, batch    17] loss: 136.86092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 464, batch    18] loss: 143.12349\n",
      "[epoch 464, batch    19] loss: 127.31913\n",
      "[epoch 464, batch    20] loss: 125.66360\n",
      "[epoch 464, batch    21] loss: 134.23198\n",
      "[epoch 464, batch    22] loss: 126.48547\n",
      "[epoch 464, batch    23] loss: 129.94630\n",
      "[epoch 464, batch    24] loss: 139.01291\n",
      "[epoch 464, batch    25] loss: 140.65150\n",
      "[epoch 464, batch    26] loss: 138.30387\n",
      "[epoch 464, batch    27] loss: 133.39918\n",
      "[epoch 464, batch    28] loss: 140.74534\n",
      "[epoch 464, batch    29] loss: 120.40034\n",
      "[epoch 464, batch    30] loss: 125.06123\n",
      "[epoch 464, batch    31] loss: 145.36534\n",
      "[epoch 464, batch    32] loss: 30.87253\n",
      "[epoch 465, batch     1] loss: 140.22031\n",
      "[epoch 465, batch     2] loss: 132.01943\n",
      "[epoch 465, batch     3] loss: 135.74306\n",
      "[epoch 465, batch     4] loss: 133.63073\n",
      "[epoch 465, batch     5] loss: 129.43922\n",
      "[epoch 465, batch     6] loss: 136.22475\n",
      "[epoch 465, batch     7] loss: 134.25884\n",
      "[epoch 465, batch     8] loss: 125.91321\n",
      "[epoch 465, batch     9] loss: 134.09897\n",
      "[epoch 465, batch    10] loss: 138.54713\n",
      "[epoch 465, batch    11] loss: 138.13967\n",
      "[epoch 465, batch    12] loss: 131.58989\n",
      "[epoch 465, batch    13] loss: 136.83884\n",
      "[epoch 465, batch    14] loss: 128.15311\n",
      "[epoch 465, batch    15] loss: 138.97844\n",
      "[epoch 465, batch    16] loss: 130.26667\n",
      "[epoch 465, batch    17] loss: 135.18876\n",
      "[epoch 465, batch    18] loss: 138.43858\n",
      "[epoch 465, batch    19] loss: 117.53368\n",
      "[epoch 465, batch    20] loss: 125.71170\n",
      "[epoch 465, batch    21] loss: 125.08831\n",
      "[epoch 465, batch    22] loss: 134.17226\n",
      "[epoch 465, batch    23] loss: 132.75986\n",
      "[epoch 465, batch    24] loss: 138.78931\n",
      "[epoch 465, batch    25] loss: 141.61114\n",
      "[epoch 465, batch    26] loss: 132.88498\n",
      "[epoch 465, batch    27] loss: 128.28895\n",
      "[epoch 465, batch    28] loss: 131.12826\n",
      "[epoch 465, batch    29] loss: 133.20163\n",
      "[epoch 465, batch    30] loss: 134.44371\n",
      "[epoch 465, batch    31] loss: 122.00793\n",
      "[epoch 465, batch    32] loss: 33.28167\n",
      "[epoch 466, batch     1] loss: 132.55728\n",
      "[epoch 466, batch     2] loss: 133.26179\n",
      "[epoch 466, batch     3] loss: 127.90318\n",
      "[epoch 466, batch     4] loss: 132.15406\n",
      "[epoch 466, batch     5] loss: 126.85802\n",
      "[epoch 466, batch     6] loss: 132.43363\n",
      "[epoch 466, batch     7] loss: 119.95165\n",
      "[epoch 466, batch     8] loss: 132.64937\n",
      "[epoch 466, batch     9] loss: 129.37164\n",
      "[epoch 466, batch    10] loss: 120.90466\n",
      "[epoch 466, batch    11] loss: 117.64728\n",
      "[epoch 466, batch    12] loss: 146.66433\n",
      "[epoch 466, batch    13] loss: 122.19711\n",
      "[epoch 466, batch    14] loss: 132.52856\n",
      "[epoch 466, batch    15] loss: 135.70195\n",
      "[epoch 466, batch    16] loss: 132.60069\n",
      "[epoch 466, batch    17] loss: 120.83953\n",
      "[epoch 466, batch    18] loss: 131.19770\n",
      "[epoch 466, batch    19] loss: 137.87541\n",
      "[epoch 466, batch    20] loss: 121.78373\n",
      "[epoch 466, batch    21] loss: 143.80603\n",
      "[epoch 466, batch    22] loss: 126.87608\n",
      "[epoch 466, batch    23] loss: 124.18894\n",
      "[epoch 466, batch    24] loss: 138.70388\n",
      "[epoch 466, batch    25] loss: 136.47001\n",
      "[epoch 466, batch    26] loss: 139.19093\n",
      "[epoch 466, batch    27] loss: 130.70817\n",
      "[epoch 466, batch    28] loss: 140.77289\n",
      "[epoch 466, batch    29] loss: 136.38557\n",
      "[epoch 466, batch    30] loss: 131.15921\n",
      "[epoch 466, batch    31] loss: 128.88278\n",
      "[epoch 466, batch    32] loss: 35.65589\n",
      "[epoch 467, batch     1] loss: 131.96779\n",
      "[epoch 467, batch     2] loss: 124.99054\n",
      "[epoch 467, batch     3] loss: 130.75079\n",
      "[epoch 467, batch     4] loss: 125.44726\n",
      "[epoch 467, batch     5] loss: 136.93974\n",
      "[epoch 467, batch     6] loss: 140.62493\n",
      "[epoch 467, batch     7] loss: 123.91727\n",
      "[epoch 467, batch     8] loss: 138.07891\n",
      "[epoch 467, batch     9] loss: 120.12872\n",
      "[epoch 467, batch    10] loss: 135.61982\n",
      "[epoch 467, batch    11] loss: 127.28437\n",
      "[epoch 467, batch    12] loss: 115.34805\n",
      "[epoch 467, batch    13] loss: 135.31080\n",
      "[epoch 467, batch    14] loss: 136.16237\n",
      "[epoch 467, batch    15] loss: 141.79573\n",
      "[epoch 467, batch    16] loss: 120.14629\n",
      "[epoch 467, batch    17] loss: 153.51057\n",
      "[epoch 467, batch    18] loss: 133.54437\n",
      "[epoch 467, batch    19] loss: 126.81042\n",
      "[epoch 467, batch    20] loss: 128.76497\n",
      "[epoch 467, batch    21] loss: 128.79475\n",
      "[epoch 467, batch    22] loss: 120.67701\n",
      "[epoch 467, batch    23] loss: 127.11742\n",
      "[epoch 467, batch    24] loss: 115.75427\n",
      "[epoch 467, batch    25] loss: 137.53109\n",
      "[epoch 467, batch    26] loss: 144.81407\n",
      "[epoch 467, batch    27] loss: 124.11063\n",
      "[epoch 467, batch    28] loss: 133.98996\n",
      "[epoch 467, batch    29] loss: 136.82172\n",
      "[epoch 467, batch    30] loss: 136.33959\n",
      "[epoch 467, batch    31] loss: 129.37806\n",
      "[epoch 467, batch    32] loss: 37.16847\n",
      "[epoch 468, batch     1] loss: 131.20236\n",
      "[epoch 468, batch     2] loss: 133.47365\n",
      "[epoch 468, batch     3] loss: 148.28718\n",
      "[epoch 468, batch     4] loss: 142.02671\n",
      "[epoch 468, batch     5] loss: 128.88058\n",
      "[epoch 468, batch     6] loss: 117.85671\n",
      "[epoch 468, batch     7] loss: 130.26466\n",
      "[epoch 468, batch     8] loss: 141.93960\n",
      "[epoch 468, batch     9] loss: 150.72316\n",
      "[epoch 468, batch    10] loss: 126.21753\n",
      "[epoch 468, batch    11] loss: 128.52774\n",
      "[epoch 468, batch    12] loss: 127.48674\n",
      "[epoch 468, batch    13] loss: 132.53109\n",
      "[epoch 468, batch    14] loss: 119.23108\n",
      "[epoch 468, batch    15] loss: 130.99665\n",
      "[epoch 468, batch    16] loss: 124.29382\n",
      "[epoch 468, batch    17] loss: 140.44888\n",
      "[epoch 468, batch    18] loss: 133.40280\n",
      "[epoch 468, batch    19] loss: 128.81794\n",
      "[epoch 468, batch    20] loss: 131.21219\n",
      "[epoch 468, batch    21] loss: 116.05677\n",
      "[epoch 468, batch    22] loss: 136.39236\n",
      "[epoch 468, batch    23] loss: 131.11577\n",
      "[epoch 468, batch    24] loss: 127.02713\n",
      "[epoch 468, batch    25] loss: 141.70521\n",
      "[epoch 468, batch    26] loss: 134.24126\n",
      "[epoch 468, batch    27] loss: 150.66955\n",
      "[epoch 468, batch    28] loss: 127.72190\n",
      "[epoch 468, batch    29] loss: 129.57067\n",
      "[epoch 468, batch    30] loss: 119.31988\n",
      "[epoch 468, batch    31] loss: 133.41905\n",
      "[epoch 468, batch    32] loss: 33.27809\n",
      "[epoch 469, batch     1] loss: 127.75659\n",
      "[epoch 469, batch     2] loss: 133.41916\n",
      "[epoch 469, batch     3] loss: 142.17127\n",
      "[epoch 469, batch     4] loss: 120.28434\n",
      "[epoch 469, batch     5] loss: 138.71917\n",
      "[epoch 469, batch     6] loss: 129.41317\n",
      "[epoch 469, batch     7] loss: 130.42194\n",
      "[epoch 469, batch     8] loss: 129.43469\n",
      "[epoch 469, batch     9] loss: 140.93143\n",
      "[epoch 469, batch    10] loss: 141.38297\n",
      "[epoch 469, batch    11] loss: 137.79323\n",
      "[epoch 469, batch    12] loss: 119.11207\n",
      "[epoch 469, batch    13] loss: 142.28899\n",
      "[epoch 469, batch    14] loss: 135.15620\n",
      "[epoch 469, batch    15] loss: 135.75809\n",
      "[epoch 469, batch    16] loss: 127.71279\n",
      "[epoch 469, batch    17] loss: 143.12646\n",
      "[epoch 469, batch    18] loss: 135.18231\n",
      "[epoch 469, batch    19] loss: 130.24993\n",
      "[epoch 469, batch    20] loss: 144.98842\n",
      "[epoch 469, batch    21] loss: 138.89968\n",
      "[epoch 469, batch    22] loss: 127.01538\n",
      "[epoch 469, batch    23] loss: 143.26996\n",
      "[epoch 469, batch    24] loss: 132.10719\n",
      "[epoch 469, batch    25] loss: 136.96858\n",
      "[epoch 469, batch    26] loss: 128.60491\n",
      "[epoch 469, batch    27] loss: 134.55699\n",
      "[epoch 469, batch    28] loss: 129.40787\n",
      "[epoch 469, batch    29] loss: 135.10693\n",
      "[epoch 469, batch    30] loss: 126.81592\n",
      "[epoch 469, batch    31] loss: 131.96331\n",
      "[epoch 469, batch    32] loss: 31.16350\n",
      "[epoch 470, batch     1] loss: 137.86811\n",
      "[epoch 470, batch     2] loss: 131.10872\n",
      "[epoch 470, batch     3] loss: 132.21421\n",
      "[epoch 470, batch     4] loss: 129.75247\n",
      "[epoch 470, batch     5] loss: 121.01174\n",
      "[epoch 470, batch     6] loss: 123.34664\n",
      "[epoch 470, batch     7] loss: 133.72514\n",
      "[epoch 470, batch     8] loss: 125.73358\n",
      "[epoch 470, batch     9] loss: 131.38923\n",
      "[epoch 470, batch    10] loss: 129.62984\n",
      "[epoch 470, batch    11] loss: 139.90983\n",
      "[epoch 470, batch    12] loss: 134.17704\n",
      "[epoch 470, batch    13] loss: 137.01105\n",
      "[epoch 470, batch    14] loss: 135.20589\n",
      "[epoch 470, batch    15] loss: 141.41502\n",
      "[epoch 470, batch    16] loss: 130.06161\n",
      "[epoch 470, batch    17] loss: 137.38494\n",
      "[epoch 470, batch    18] loss: 122.67732\n",
      "[epoch 470, batch    19] loss: 129.14645\n",
      "[epoch 470, batch    20] loss: 116.58478\n",
      "[epoch 470, batch    21] loss: 130.74163\n",
      "[epoch 470, batch    22] loss: 131.28694\n",
      "[epoch 470, batch    23] loss: 121.65776\n",
      "[epoch 470, batch    24] loss: 123.95845\n",
      "[epoch 470, batch    25] loss: 143.99586\n",
      "[epoch 470, batch    26] loss: 134.80452\n",
      "[epoch 470, batch    27] loss: 134.37705\n",
      "[epoch 470, batch    28] loss: 135.51664\n",
      "[epoch 470, batch    29] loss: 137.99648\n",
      "[epoch 470, batch    30] loss: 121.04847\n",
      "[epoch 470, batch    31] loss: 138.92113\n",
      "[epoch 470, batch    32] loss: 33.52576\n",
      "[epoch 471, batch     1] loss: 138.21016\n",
      "[epoch 471, batch     2] loss: 131.56901\n",
      "[epoch 471, batch     3] loss: 141.42210\n",
      "[epoch 471, batch     4] loss: 132.16510\n",
      "[epoch 471, batch     5] loss: 125.64937\n",
      "[epoch 471, batch     6] loss: 127.04592\n",
      "[epoch 471, batch     7] loss: 132.29907\n",
      "[epoch 471, batch     8] loss: 131.92473\n",
      "[epoch 471, batch     9] loss: 121.59148\n",
      "[epoch 471, batch    10] loss: 139.44875\n",
      "[epoch 471, batch    11] loss: 134.99258\n",
      "[epoch 471, batch    12] loss: 118.64396\n",
      "[epoch 471, batch    13] loss: 135.02622\n",
      "[epoch 471, batch    14] loss: 136.16022\n",
      "[epoch 471, batch    15] loss: 126.68058\n",
      "[epoch 471, batch    16] loss: 135.33483\n",
      "[epoch 471, batch    17] loss: 127.18019\n",
      "[epoch 471, batch    18] loss: 138.39856\n",
      "[epoch 471, batch    19] loss: 127.98393\n",
      "[epoch 471, batch    20] loss: 138.17147\n",
      "[epoch 471, batch    21] loss: 132.62296\n",
      "[epoch 471, batch    22] loss: 127.58343\n",
      "[epoch 471, batch    23] loss: 137.44897\n",
      "[epoch 471, batch    24] loss: 134.98589\n",
      "[epoch 471, batch    25] loss: 128.50816\n",
      "[epoch 471, batch    26] loss: 131.79585\n",
      "[epoch 471, batch    27] loss: 144.64683\n",
      "[epoch 471, batch    28] loss: 138.20287\n",
      "[epoch 471, batch    29] loss: 144.76275\n",
      "[epoch 471, batch    30] loss: 135.53400\n",
      "[epoch 471, batch    31] loss: 117.85909\n",
      "[epoch 471, batch    32] loss: 32.64516\n",
      "[epoch 472, batch     1] loss: 147.93642\n",
      "[epoch 472, batch     2] loss: 134.88526\n",
      "[epoch 472, batch     3] loss: 141.79926\n",
      "[epoch 472, batch     4] loss: 126.37697\n",
      "[epoch 472, batch     5] loss: 115.72825\n",
      "[epoch 472, batch     6] loss: 123.41432\n",
      "[epoch 472, batch     7] loss: 136.52180\n",
      "[epoch 472, batch     8] loss: 131.45850\n",
      "[epoch 472, batch     9] loss: 144.45280\n",
      "[epoch 472, batch    10] loss: 137.39335\n",
      "[epoch 472, batch    11] loss: 135.40719\n",
      "[epoch 472, batch    12] loss: 134.90854\n",
      "[epoch 472, batch    13] loss: 128.07037\n",
      "[epoch 472, batch    14] loss: 138.79017\n",
      "[epoch 472, batch    15] loss: 125.89157\n",
      "[epoch 472, batch    16] loss: 134.40638\n",
      "[epoch 472, batch    17] loss: 140.52389\n",
      "[epoch 472, batch    18] loss: 134.86736\n",
      "[epoch 472, batch    19] loss: 125.87295\n",
      "[epoch 472, batch    20] loss: 121.51623\n",
      "[epoch 472, batch    21] loss: 137.81346\n",
      "[epoch 472, batch    22] loss: 138.07682\n",
      "[epoch 472, batch    23] loss: 125.63864\n",
      "[epoch 472, batch    24] loss: 138.55709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 472, batch    25] loss: 136.09094\n",
      "[epoch 472, batch    26] loss: 142.94024\n",
      "[epoch 472, batch    27] loss: 138.93333\n",
      "[epoch 472, batch    28] loss: 142.83225\n",
      "[epoch 472, batch    29] loss: 124.47489\n",
      "[epoch 472, batch    30] loss: 132.45237\n",
      "[epoch 472, batch    31] loss: 126.05520\n",
      "[epoch 472, batch    32] loss: 31.08297\n",
      "[epoch 473, batch     1] loss: 128.78128\n",
      "[epoch 473, batch     2] loss: 129.64335\n",
      "[epoch 473, batch     3] loss: 127.58101\n",
      "[epoch 473, batch     4] loss: 123.58829\n",
      "[epoch 473, batch     5] loss: 134.68845\n",
      "[epoch 473, batch     6] loss: 116.05171\n",
      "[epoch 473, batch     7] loss: 136.13110\n",
      "[epoch 473, batch     8] loss: 143.55630\n",
      "[epoch 473, batch     9] loss: 132.87333\n",
      "[epoch 473, batch    10] loss: 138.68695\n",
      "[epoch 473, batch    11] loss: 132.24218\n",
      "[epoch 473, batch    12] loss: 134.42356\n",
      "[epoch 473, batch    13] loss: 127.26844\n",
      "[epoch 473, batch    14] loss: 114.08831\n",
      "[epoch 473, batch    15] loss: 122.45931\n",
      "[epoch 473, batch    16] loss: 130.28187\n",
      "[epoch 473, batch    17] loss: 135.79255\n",
      "[epoch 473, batch    18] loss: 125.02822\n",
      "[epoch 473, batch    19] loss: 151.40418\n",
      "[epoch 473, batch    20] loss: 127.91938\n",
      "[epoch 473, batch    21] loss: 124.15419\n",
      "[epoch 473, batch    22] loss: 135.92692\n",
      "[epoch 473, batch    23] loss: 124.28415\n",
      "[epoch 473, batch    24] loss: 136.54481\n",
      "[epoch 473, batch    25] loss: 132.83056\n",
      "[epoch 473, batch    26] loss: 138.97841\n",
      "[epoch 473, batch    27] loss: 139.45005\n",
      "[epoch 473, batch    28] loss: 127.59730\n",
      "[epoch 473, batch    29] loss: 128.71213\n",
      "[epoch 473, batch    30] loss: 140.14984\n",
      "[epoch 473, batch    31] loss: 138.55525\n",
      "[epoch 473, batch    32] loss: 32.94157\n",
      "[epoch 474, batch     1] loss: 123.56347\n",
      "[epoch 474, batch     2] loss: 126.36104\n",
      "[epoch 474, batch     3] loss: 140.66493\n",
      "[epoch 474, batch     4] loss: 141.26637\n",
      "[epoch 474, batch     5] loss: 115.09223\n",
      "[epoch 474, batch     6] loss: 138.35815\n",
      "[epoch 474, batch     7] loss: 137.23694\n",
      "[epoch 474, batch     8] loss: 129.19221\n",
      "[epoch 474, batch     9] loss: 134.03947\n",
      "[epoch 474, batch    10] loss: 141.26297\n",
      "[epoch 474, batch    11] loss: 121.03921\n",
      "[epoch 474, batch    12] loss: 135.45428\n",
      "[epoch 474, batch    13] loss: 137.96126\n",
      "[epoch 474, batch    14] loss: 128.20203\n",
      "[epoch 474, batch    15] loss: 137.82703\n",
      "[epoch 474, batch    16] loss: 125.37872\n",
      "[epoch 474, batch    17] loss: 127.83107\n",
      "[epoch 474, batch    18] loss: 120.87716\n",
      "[epoch 474, batch    19] loss: 127.49519\n",
      "[epoch 474, batch    20] loss: 150.55302\n",
      "[epoch 474, batch    21] loss: 132.02530\n",
      "[epoch 474, batch    22] loss: 123.91460\n",
      "[epoch 474, batch    23] loss: 133.04435\n",
      "[epoch 474, batch    24] loss: 133.08703\n",
      "[epoch 474, batch    25] loss: 139.13229\n",
      "[epoch 474, batch    26] loss: 125.13917\n",
      "[epoch 474, batch    27] loss: 136.12839\n",
      "[epoch 474, batch    28] loss: 125.93096\n",
      "[epoch 474, batch    29] loss: 118.55962\n",
      "[epoch 474, batch    30] loss: 125.21636\n",
      "[epoch 474, batch    31] loss: 130.90730\n",
      "[epoch 474, batch    32] loss: 33.53516\n",
      "[epoch 475, batch     1] loss: 131.98236\n",
      "[epoch 475, batch     2] loss: 131.81795\n",
      "[epoch 475, batch     3] loss: 124.60295\n",
      "[epoch 475, batch     4] loss: 124.02199\n",
      "[epoch 475, batch     5] loss: 138.83923\n",
      "[epoch 475, batch     6] loss: 138.52790\n",
      "[epoch 475, batch     7] loss: 135.37787\n",
      "[epoch 475, batch     8] loss: 128.75605\n",
      "[epoch 475, batch     9] loss: 135.03663\n",
      "[epoch 475, batch    10] loss: 129.60564\n",
      "[epoch 475, batch    11] loss: 134.13752\n",
      "[epoch 475, batch    12] loss: 131.06252\n",
      "[epoch 475, batch    13] loss: 135.02395\n",
      "[epoch 475, batch    14] loss: 131.89902\n",
      "[epoch 475, batch    15] loss: 138.46527\n",
      "[epoch 475, batch    16] loss: 136.91719\n",
      "[epoch 475, batch    17] loss: 125.77344\n",
      "[epoch 475, batch    18] loss: 129.57438\n",
      "[epoch 475, batch    19] loss: 130.30082\n",
      "[epoch 475, batch    20] loss: 130.58918\n",
      "[epoch 475, batch    21] loss: 138.57595\n",
      "[epoch 475, batch    22] loss: 132.36253\n",
      "[epoch 475, batch    23] loss: 129.30278\n",
      "[epoch 475, batch    24] loss: 126.84221\n",
      "[epoch 475, batch    25] loss: 125.07499\n",
      "[epoch 475, batch    26] loss: 136.16670\n",
      "[epoch 475, batch    27] loss: 132.02871\n",
      "[epoch 475, batch    28] loss: 130.83790\n",
      "[epoch 475, batch    29] loss: 125.54924\n",
      "[epoch 475, batch    30] loss: 143.00374\n",
      "[epoch 475, batch    31] loss: 134.41684\n",
      "[epoch 475, batch    32] loss: 37.96580\n",
      "[epoch 476, batch     1] loss: 125.18399\n",
      "[epoch 476, batch     2] loss: 124.52895\n",
      "[epoch 476, batch     3] loss: 114.41136\n",
      "[epoch 476, batch     4] loss: 138.97497\n",
      "[epoch 476, batch     5] loss: 140.68775\n",
      "[epoch 476, batch     6] loss: 127.78514\n",
      "[epoch 476, batch     7] loss: 132.32877\n",
      "[epoch 476, batch     8] loss: 143.19755\n",
      "[epoch 476, batch     9] loss: 132.62257\n",
      "[epoch 476, batch    10] loss: 121.52803\n",
      "[epoch 476, batch    11] loss: 132.47972\n",
      "[epoch 476, batch    12] loss: 119.49025\n",
      "[epoch 476, batch    13] loss: 127.78850\n",
      "[epoch 476, batch    14] loss: 133.85952\n",
      "[epoch 476, batch    15] loss: 144.83393\n",
      "[epoch 476, batch    16] loss: 128.34600\n",
      "[epoch 476, batch    17] loss: 128.42509\n",
      "[epoch 476, batch    18] loss: 122.99686\n",
      "[epoch 476, batch    19] loss: 117.20295\n",
      "[epoch 476, batch    20] loss: 129.05236\n",
      "[epoch 476, batch    21] loss: 128.80584\n",
      "[epoch 476, batch    22] loss: 127.68577\n",
      "[epoch 476, batch    23] loss: 144.97816\n",
      "[epoch 476, batch    24] loss: 130.46158\n",
      "[epoch 476, batch    25] loss: 139.35286\n",
      "[epoch 476, batch    26] loss: 125.73691\n",
      "[epoch 476, batch    27] loss: 131.53597\n",
      "[epoch 476, batch    28] loss: 123.91681\n",
      "[epoch 476, batch    29] loss: 137.30972\n",
      "[epoch 476, batch    30] loss: 129.49713\n",
      "[epoch 476, batch    31] loss: 137.27980\n",
      "[epoch 476, batch    32] loss: 38.57240\n",
      "[epoch 477, batch     1] loss: 122.43522\n",
      "[epoch 477, batch     2] loss: 145.37941\n",
      "[epoch 477, batch     3] loss: 124.56671\n",
      "[epoch 477, batch     4] loss: 135.27375\n",
      "[epoch 477, batch     5] loss: 132.16289\n",
      "[epoch 477, batch     6] loss: 123.87551\n",
      "[epoch 477, batch     7] loss: 122.76795\n",
      "[epoch 477, batch     8] loss: 132.53612\n",
      "[epoch 477, batch     9] loss: 139.79208\n",
      "[epoch 477, batch    10] loss: 121.22618\n",
      "[epoch 477, batch    11] loss: 145.03719\n",
      "[epoch 477, batch    12] loss: 123.98149\n",
      "[epoch 477, batch    13] loss: 137.24609\n",
      "[epoch 477, batch    14] loss: 142.01117\n",
      "[epoch 477, batch    15] loss: 136.42304\n",
      "[epoch 477, batch    16] loss: 131.55466\n",
      "[epoch 477, batch    17] loss: 117.54591\n",
      "[epoch 477, batch    18] loss: 134.72530\n",
      "[epoch 477, batch    19] loss: 138.85362\n",
      "[epoch 477, batch    20] loss: 136.55481\n",
      "[epoch 477, batch    21] loss: 124.41326\n",
      "[epoch 477, batch    22] loss: 131.51921\n",
      "[epoch 477, batch    23] loss: 143.18774\n",
      "[epoch 477, batch    24] loss: 126.65751\n",
      "[epoch 477, batch    25] loss: 138.90278\n",
      "[epoch 477, batch    26] loss: 135.72331\n",
      "[epoch 477, batch    27] loss: 138.97603\n",
      "[epoch 477, batch    28] loss: 120.49986\n",
      "[epoch 477, batch    29] loss: 120.65764\n",
      "[epoch 477, batch    30] loss: 133.62287\n",
      "[epoch 477, batch    31] loss: 126.58810\n",
      "[epoch 477, batch    32] loss: 21.53771\n",
      "[epoch 478, batch     1] loss: 135.65095\n",
      "[epoch 478, batch     2] loss: 130.00941\n",
      "[epoch 478, batch     3] loss: 143.67114\n",
      "[epoch 478, batch     4] loss: 122.86734\n",
      "[epoch 478, batch     5] loss: 132.75293\n",
      "[epoch 478, batch     6] loss: 142.74625\n",
      "[epoch 478, batch     7] loss: 134.30345\n",
      "[epoch 478, batch     8] loss: 134.03341\n",
      "[epoch 478, batch     9] loss: 132.25508\n",
      "[epoch 478, batch    10] loss: 130.79407\n",
      "[epoch 478, batch    11] loss: 133.37205\n",
      "[epoch 478, batch    12] loss: 136.90453\n",
      "[epoch 478, batch    13] loss: 126.70256\n",
      "[epoch 478, batch    14] loss: 130.12491\n",
      "[epoch 478, batch    15] loss: 125.26692\n",
      "[epoch 478, batch    16] loss: 139.44398\n",
      "[epoch 478, batch    17] loss: 133.38551\n",
      "[epoch 478, batch    18] loss: 138.94914\n",
      "[epoch 478, batch    19] loss: 138.36949\n",
      "[epoch 478, batch    20] loss: 134.90017\n",
      "[epoch 478, batch    21] loss: 127.98034\n",
      "[epoch 478, batch    22] loss: 145.01734\n",
      "[epoch 478, batch    23] loss: 134.11022\n",
      "[epoch 478, batch    24] loss: 124.05405\n",
      "[epoch 478, batch    25] loss: 125.32236\n",
      "[epoch 478, batch    26] loss: 120.03447\n",
      "[epoch 478, batch    27] loss: 136.70195\n",
      "[epoch 478, batch    28] loss: 134.17459\n",
      "[epoch 478, batch    29] loss: 139.83816\n",
      "[epoch 478, batch    30] loss: 125.34250\n",
      "[epoch 478, batch    31] loss: 131.99296\n",
      "[epoch 478, batch    32] loss: 35.55620\n",
      "[epoch 479, batch     1] loss: 127.93081\n",
      "[epoch 479, batch     2] loss: 132.75947\n",
      "[epoch 479, batch     3] loss: 141.13456\n",
      "[epoch 479, batch     4] loss: 129.58550\n",
      "[epoch 479, batch     5] loss: 146.75172\n",
      "[epoch 479, batch     6] loss: 136.48396\n",
      "[epoch 479, batch     7] loss: 135.29610\n",
      "[epoch 479, batch     8] loss: 132.36072\n",
      "[epoch 479, batch     9] loss: 120.19296\n",
      "[epoch 479, batch    10] loss: 125.91649\n",
      "[epoch 479, batch    11] loss: 129.89044\n",
      "[epoch 479, batch    12] loss: 143.29187\n",
      "[epoch 479, batch    13] loss: 136.39015\n",
      "[epoch 479, batch    14] loss: 134.16495\n",
      "[epoch 479, batch    15] loss: 129.90451\n",
      "[epoch 479, batch    16] loss: 135.31043\n",
      "[epoch 479, batch    17] loss: 132.49365\n",
      "[epoch 479, batch    18] loss: 135.78924\n",
      "[epoch 479, batch    19] loss: 135.86820\n",
      "[epoch 479, batch    20] loss: 134.31720\n",
      "[epoch 479, batch    21] loss: 131.89144\n",
      "[epoch 479, batch    22] loss: 127.44202\n",
      "[epoch 479, batch    23] loss: 132.09163\n",
      "[epoch 479, batch    24] loss: 136.63648\n",
      "[epoch 479, batch    25] loss: 125.60570\n",
      "[epoch 479, batch    26] loss: 143.91864\n",
      "[epoch 479, batch    27] loss: 129.24773\n",
      "[epoch 479, batch    28] loss: 138.54086\n",
      "[epoch 479, batch    29] loss: 125.58920\n",
      "[epoch 479, batch    30] loss: 136.52297\n",
      "[epoch 479, batch    31] loss: 137.38029\n",
      "[epoch 479, batch    32] loss: 28.14537\n",
      "[epoch 480, batch     1] loss: 135.89425\n",
      "[epoch 480, batch     2] loss: 127.25126\n",
      "[epoch 480, batch     3] loss: 123.00262\n",
      "[epoch 480, batch     4] loss: 129.07891\n",
      "[epoch 480, batch     5] loss: 127.98408\n",
      "[epoch 480, batch     6] loss: 127.09102\n",
      "[epoch 480, batch     7] loss: 126.56727\n",
      "[epoch 480, batch     8] loss: 131.94922\n",
      "[epoch 480, batch     9] loss: 132.55325\n",
      "[epoch 480, batch    10] loss: 121.66272\n",
      "[epoch 480, batch    11] loss: 139.04728\n",
      "[epoch 480, batch    12] loss: 122.33889\n",
      "[epoch 480, batch    13] loss: 136.46299\n",
      "[epoch 480, batch    14] loss: 112.65226\n",
      "[epoch 480, batch    15] loss: 146.42938\n",
      "[epoch 480, batch    16] loss: 120.62703\n",
      "[epoch 480, batch    17] loss: 137.15132\n",
      "[epoch 480, batch    18] loss: 116.65595\n",
      "[epoch 480, batch    19] loss: 129.21882\n",
      "[epoch 480, batch    20] loss: 139.15422\n",
      "[epoch 480, batch    21] loss: 117.03931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 480, batch    22] loss: 130.04059\n",
      "[epoch 480, batch    23] loss: 125.10660\n",
      "[epoch 480, batch    24] loss: 126.60793\n",
      "[epoch 480, batch    25] loss: 136.66793\n",
      "[epoch 480, batch    26] loss: 136.44647\n",
      "[epoch 480, batch    27] loss: 137.74691\n",
      "[epoch 480, batch    28] loss: 131.03560\n",
      "[epoch 480, batch    29] loss: 132.89555\n",
      "[epoch 480, batch    30] loss: 140.88420\n",
      "[epoch 480, batch    31] loss: 132.83117\n",
      "[epoch 480, batch    32] loss: 28.57131\n",
      "[epoch 481, batch     1] loss: 131.43681\n",
      "[epoch 481, batch     2] loss: 128.60967\n",
      "[epoch 481, batch     3] loss: 127.68925\n",
      "[epoch 481, batch     4] loss: 142.29921\n",
      "[epoch 481, batch     5] loss: 125.21686\n",
      "[epoch 481, batch     6] loss: 129.06098\n",
      "[epoch 481, batch     7] loss: 135.62431\n",
      "[epoch 481, batch     8] loss: 131.54143\n",
      "[epoch 481, batch     9] loss: 118.61228\n",
      "[epoch 481, batch    10] loss: 129.41736\n",
      "[epoch 481, batch    11] loss: 148.49549\n",
      "[epoch 481, batch    12] loss: 125.35264\n",
      "[epoch 481, batch    13] loss: 134.03253\n",
      "[epoch 481, batch    14] loss: 129.05028\n",
      "[epoch 481, batch    15] loss: 127.20416\n",
      "[epoch 481, batch    16] loss: 130.61884\n",
      "[epoch 481, batch    17] loss: 131.69908\n",
      "[epoch 481, batch    18] loss: 129.60330\n",
      "[epoch 481, batch    19] loss: 133.02378\n",
      "[epoch 481, batch    20] loss: 137.52190\n",
      "[epoch 481, batch    21] loss: 141.76574\n",
      "[epoch 481, batch    22] loss: 147.79807\n",
      "[epoch 481, batch    23] loss: 133.74327\n",
      "[epoch 481, batch    24] loss: 131.96282\n",
      "[epoch 481, batch    25] loss: 129.84221\n",
      "[epoch 481, batch    26] loss: 119.18133\n",
      "[epoch 481, batch    27] loss: 132.73711\n",
      "[epoch 481, batch    28] loss: 142.02563\n",
      "[epoch 481, batch    29] loss: 126.22596\n",
      "[epoch 481, batch    30] loss: 130.83915\n",
      "[epoch 481, batch    31] loss: 127.22479\n",
      "[epoch 481, batch    32] loss: 27.54797\n",
      "[epoch 482, batch     1] loss: 131.51972\n",
      "[epoch 482, batch     2] loss: 128.55575\n",
      "[epoch 482, batch     3] loss: 130.28423\n",
      "[epoch 482, batch     4] loss: 126.46312\n",
      "[epoch 482, batch     5] loss: 120.74483\n",
      "[epoch 482, batch     6] loss: 134.90195\n",
      "[epoch 482, batch     7] loss: 129.19669\n",
      "[epoch 482, batch     8] loss: 144.20176\n",
      "[epoch 482, batch     9] loss: 139.64179\n",
      "[epoch 482, batch    10] loss: 122.28817\n",
      "[epoch 482, batch    11] loss: 130.83680\n",
      "[epoch 482, batch    12] loss: 137.80151\n",
      "[epoch 482, batch    13] loss: 158.89834\n",
      "[epoch 482, batch    14] loss: 124.26907\n",
      "[epoch 482, batch    15] loss: 125.61225\n",
      "[epoch 482, batch    16] loss: 128.79061\n",
      "[epoch 482, batch    17] loss: 136.56896\n",
      "[epoch 482, batch    18] loss: 140.69397\n",
      "[epoch 482, batch    19] loss: 124.94190\n",
      "[epoch 482, batch    20] loss: 135.66490\n",
      "[epoch 482, batch    21] loss: 125.97384\n",
      "[epoch 482, batch    22] loss: 126.01291\n",
      "[epoch 482, batch    23] loss: 125.28345\n",
      "[epoch 482, batch    24] loss: 129.41230\n",
      "[epoch 482, batch    25] loss: 126.15996\n",
      "[epoch 482, batch    26] loss: 122.22157\n",
      "[epoch 482, batch    27] loss: 139.45892\n",
      "[epoch 482, batch    28] loss: 128.26586\n",
      "[epoch 482, batch    29] loss: 129.78569\n",
      "[epoch 482, batch    30] loss: 125.40465\n",
      "[epoch 482, batch    31] loss: 139.85449\n",
      "[epoch 482, batch    32] loss: 31.21016\n",
      "[epoch 483, batch     1] loss: 122.36390\n",
      "[epoch 483, batch     2] loss: 126.74049\n",
      "[epoch 483, batch     3] loss: 124.84033\n",
      "[epoch 483, batch     4] loss: 129.96633\n",
      "[epoch 483, batch     5] loss: 131.06760\n",
      "[epoch 483, batch     6] loss: 130.73407\n",
      "[epoch 483, batch     7] loss: 145.61763\n",
      "[epoch 483, batch     8] loss: 116.90497\n",
      "[epoch 483, batch     9] loss: 133.24082\n",
      "[epoch 483, batch    10] loss: 134.85898\n",
      "[epoch 483, batch    11] loss: 136.21634\n",
      "[epoch 483, batch    12] loss: 117.97036\n",
      "[epoch 483, batch    13] loss: 138.43355\n",
      "[epoch 483, batch    14] loss: 137.03028\n",
      "[epoch 483, batch    15] loss: 138.14444\n",
      "[epoch 483, batch    16] loss: 140.71282\n",
      "[epoch 483, batch    17] loss: 122.56507\n",
      "[epoch 483, batch    18] loss: 136.82818\n",
      "[epoch 483, batch    19] loss: 132.69126\n",
      "[epoch 483, batch    20] loss: 132.23094\n",
      "[epoch 483, batch    21] loss: 130.54118\n",
      "[epoch 483, batch    22] loss: 138.59807\n",
      "[epoch 483, batch    23] loss: 133.72003\n",
      "[epoch 483, batch    24] loss: 132.39116\n",
      "[epoch 483, batch    25] loss: 120.64661\n",
      "[epoch 483, batch    26] loss: 148.37969\n",
      "[epoch 483, batch    27] loss: 132.10020\n",
      "[epoch 483, batch    28] loss: 133.11054\n",
      "[epoch 483, batch    29] loss: 127.88999\n",
      "[epoch 483, batch    30] loss: 131.10439\n",
      "[epoch 483, batch    31] loss: 129.68923\n",
      "[epoch 483, batch    32] loss: 31.02914\n",
      "[epoch 484, batch     1] loss: 127.10586\n",
      "[epoch 484, batch     2] loss: 123.43612\n",
      "[epoch 484, batch     3] loss: 127.35988\n",
      "[epoch 484, batch     4] loss: 141.17603\n",
      "[epoch 484, batch     5] loss: 128.65091\n",
      "[epoch 484, batch     6] loss: 137.62837\n",
      "[epoch 484, batch     7] loss: 142.35958\n",
      "[epoch 484, batch     8] loss: 135.78270\n",
      "[epoch 484, batch     9] loss: 128.45066\n",
      "[epoch 484, batch    10] loss: 128.00004\n",
      "[epoch 484, batch    11] loss: 125.39979\n",
      "[epoch 484, batch    12] loss: 144.07827\n",
      "[epoch 484, batch    13] loss: 129.67150\n",
      "[epoch 484, batch    14] loss: 133.20463\n",
      "[epoch 484, batch    15] loss: 126.85072\n",
      "[epoch 484, batch    16] loss: 125.02623\n",
      "[epoch 484, batch    17] loss: 140.96109\n",
      "[epoch 484, batch    18] loss: 122.03234\n",
      "[epoch 484, batch    19] loss: 120.06886\n",
      "[epoch 484, batch    20] loss: 110.42664\n",
      "[epoch 484, batch    21] loss: 132.41720\n",
      "[epoch 484, batch    22] loss: 132.69993\n",
      "[epoch 484, batch    23] loss: 131.48761\n",
      "[epoch 484, batch    24] loss: 139.65025\n",
      "[epoch 484, batch    25] loss: 145.50937\n",
      "[epoch 484, batch    26] loss: 125.88723\n",
      "[epoch 484, batch    27] loss: 131.72838\n",
      "[epoch 484, batch    28] loss: 126.66555\n",
      "[epoch 484, batch    29] loss: 136.09135\n",
      "[epoch 484, batch    30] loss: 123.44414\n",
      "[epoch 484, batch    31] loss: 134.18176\n",
      "[epoch 484, batch    32] loss: 30.61829\n",
      "[epoch 485, batch     1] loss: 120.33432\n",
      "[epoch 485, batch     2] loss: 130.81306\n",
      "[epoch 485, batch     3] loss: 134.89958\n",
      "[epoch 485, batch     4] loss: 128.57332\n",
      "[epoch 485, batch     5] loss: 134.26128\n",
      "[epoch 485, batch     6] loss: 131.27889\n",
      "[epoch 485, batch     7] loss: 133.86733\n",
      "[epoch 485, batch     8] loss: 122.98646\n",
      "[epoch 485, batch     9] loss: 132.70315\n",
      "[epoch 485, batch    10] loss: 137.43747\n",
      "[epoch 485, batch    11] loss: 132.89554\n",
      "[epoch 485, batch    12] loss: 118.87673\n",
      "[epoch 485, batch    13] loss: 136.04657\n",
      "[epoch 485, batch    14] loss: 142.27893\n",
      "[epoch 485, batch    15] loss: 130.68014\n",
      "[epoch 485, batch    16] loss: 117.43167\n",
      "[epoch 485, batch    17] loss: 133.06652\n",
      "[epoch 485, batch    18] loss: 137.58656\n",
      "[epoch 485, batch    19] loss: 130.59409\n",
      "[epoch 485, batch    20] loss: 131.89498\n",
      "[epoch 485, batch    21] loss: 149.86017\n",
      "[epoch 485, batch    22] loss: 129.09928\n",
      "[epoch 485, batch    23] loss: 131.47466\n",
      "[epoch 485, batch    24] loss: 142.15999\n",
      "[epoch 485, batch    25] loss: 140.86641\n",
      "[epoch 485, batch    26] loss: 129.90775\n",
      "[epoch 485, batch    27] loss: 136.57263\n",
      "[epoch 485, batch    28] loss: 130.72928\n",
      "[epoch 485, batch    29] loss: 133.95324\n",
      "[epoch 485, batch    30] loss: 131.25458\n",
      "[epoch 485, batch    31] loss: 141.30904\n",
      "[epoch 485, batch    32] loss: 40.20738\n",
      "[epoch 486, batch     1] loss: 132.41830\n",
      "[epoch 486, batch     2] loss: 123.75120\n",
      "[epoch 486, batch     3] loss: 123.12427\n",
      "[epoch 486, batch     4] loss: 126.04996\n",
      "[epoch 486, batch     5] loss: 121.92958\n",
      "[epoch 486, batch     6] loss: 141.39409\n",
      "[epoch 486, batch     7] loss: 128.43019\n",
      "[epoch 486, batch     8] loss: 140.36526\n",
      "[epoch 486, batch     9] loss: 132.51514\n",
      "[epoch 486, batch    10] loss: 118.48609\n",
      "[epoch 486, batch    11] loss: 129.61001\n",
      "[epoch 486, batch    12] loss: 129.18533\n",
      "[epoch 486, batch    13] loss: 129.51352\n",
      "[epoch 486, batch    14] loss: 131.40606\n",
      "[epoch 486, batch    15] loss: 127.72254\n",
      "[epoch 486, batch    16] loss: 135.77705\n",
      "[epoch 486, batch    17] loss: 135.52133\n",
      "[epoch 486, batch    18] loss: 136.83465\n",
      "[epoch 486, batch    19] loss: 137.96422\n",
      "[epoch 486, batch    20] loss: 133.31764\n",
      "[epoch 486, batch    21] loss: 130.57854\n",
      "[epoch 486, batch    22] loss: 144.19594\n",
      "[epoch 486, batch    23] loss: 138.21530\n",
      "[epoch 486, batch    24] loss: 127.42454\n",
      "[epoch 486, batch    25] loss: 131.33915\n",
      "[epoch 486, batch    26] loss: 129.99624\n",
      "[epoch 486, batch    27] loss: 144.78872\n",
      "[epoch 486, batch    28] loss: 124.35322\n",
      "[epoch 486, batch    29] loss: 140.58381\n",
      "[epoch 486, batch    30] loss: 138.76458\n",
      "[epoch 486, batch    31] loss: 124.32734\n",
      "[epoch 486, batch    32] loss: 31.17362\n",
      "[epoch 487, batch     1] loss: 129.98097\n",
      "[epoch 487, batch     2] loss: 126.21589\n",
      "[epoch 487, batch     3] loss: 141.66237\n",
      "[epoch 487, batch     4] loss: 133.57416\n",
      "[epoch 487, batch     5] loss: 128.64162\n",
      "[epoch 487, batch     6] loss: 125.45883\n",
      "[epoch 487, batch     7] loss: 130.82294\n",
      "[epoch 487, batch     8] loss: 134.09112\n",
      "[epoch 487, batch     9] loss: 141.62253\n",
      "[epoch 487, batch    10] loss: 121.43044\n",
      "[epoch 487, batch    11] loss: 138.70977\n",
      "[epoch 487, batch    12] loss: 127.34789\n",
      "[epoch 487, batch    13] loss: 117.59522\n",
      "[epoch 487, batch    14] loss: 134.44790\n",
      "[epoch 487, batch    15] loss: 134.34683\n",
      "[epoch 487, batch    16] loss: 133.64618\n",
      "[epoch 487, batch    17] loss: 121.82483\n",
      "[epoch 487, batch    18] loss: 120.59204\n",
      "[epoch 487, batch    19] loss: 135.95908\n",
      "[epoch 487, batch    20] loss: 133.89109\n",
      "[epoch 487, batch    21] loss: 129.54595\n",
      "[epoch 487, batch    22] loss: 142.35985\n",
      "[epoch 487, batch    23] loss: 134.50911\n",
      "[epoch 487, batch    24] loss: 128.10075\n",
      "[epoch 487, batch    25] loss: 137.11028\n",
      "[epoch 487, batch    26] loss: 119.10275\n",
      "[epoch 487, batch    27] loss: 123.10380\n",
      "[epoch 487, batch    28] loss: 138.44405\n",
      "[epoch 487, batch    29] loss: 132.12092\n",
      "[epoch 487, batch    30] loss: 144.97475\n",
      "[epoch 487, batch    31] loss: 132.09552\n",
      "[epoch 487, batch    32] loss: 28.81695\n",
      "[epoch 488, batch     1] loss: 125.82706\n",
      "[epoch 488, batch     2] loss: 144.36520\n",
      "[epoch 488, batch     3] loss: 137.94678\n",
      "[epoch 488, batch     4] loss: 139.37654\n",
      "[epoch 488, batch     5] loss: 136.54148\n",
      "[epoch 488, batch     6] loss: 133.61986\n",
      "[epoch 488, batch     7] loss: 121.07150\n",
      "[epoch 488, batch     8] loss: 140.02972\n",
      "[epoch 488, batch     9] loss: 132.06427\n",
      "[epoch 488, batch    10] loss: 139.77910\n",
      "[epoch 488, batch    11] loss: 122.06031\n",
      "[epoch 488, batch    12] loss: 129.65212\n",
      "[epoch 488, batch    13] loss: 130.65077\n",
      "[epoch 488, batch    14] loss: 138.82019\n",
      "[epoch 488, batch    15] loss: 129.22286\n",
      "[epoch 488, batch    16] loss: 131.90076\n",
      "[epoch 488, batch    17] loss: 124.71342\n",
      "[epoch 488, batch    18] loss: 131.01227\n",
      "[epoch 488, batch    19] loss: 144.38017\n",
      "[epoch 488, batch    20] loss: 140.77441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 488, batch    21] loss: 136.82496\n",
      "[epoch 488, batch    22] loss: 133.94079\n",
      "[epoch 488, batch    23] loss: 137.26789\n",
      "[epoch 488, batch    24] loss: 115.67202\n",
      "[epoch 488, batch    25] loss: 129.02841\n",
      "[epoch 488, batch    26] loss: 126.98520\n",
      "[epoch 488, batch    27] loss: 124.33523\n",
      "[epoch 488, batch    28] loss: 131.84724\n",
      "[epoch 488, batch    29] loss: 118.45162\n",
      "[epoch 488, batch    30] loss: 126.60927\n",
      "[epoch 488, batch    31] loss: 117.88896\n",
      "[epoch 488, batch    32] loss: 31.63106\n",
      "[epoch 489, batch     1] loss: 132.63521\n",
      "[epoch 489, batch     2] loss: 128.83719\n",
      "[epoch 489, batch     3] loss: 122.59419\n",
      "[epoch 489, batch     4] loss: 123.69304\n",
      "[epoch 489, batch     5] loss: 125.18276\n",
      "[epoch 489, batch     6] loss: 144.27240\n",
      "[epoch 489, batch     7] loss: 122.17241\n",
      "[epoch 489, batch     8] loss: 130.34779\n",
      "[epoch 489, batch     9] loss: 137.50368\n",
      "[epoch 489, batch    10] loss: 130.66327\n",
      "[epoch 489, batch    11] loss: 126.79670\n",
      "[epoch 489, batch    12] loss: 147.55585\n",
      "[epoch 489, batch    13] loss: 131.56110\n",
      "[epoch 489, batch    14] loss: 150.33336\n",
      "[epoch 489, batch    15] loss: 128.36665\n",
      "[epoch 489, batch    16] loss: 133.67553\n",
      "[epoch 489, batch    17] loss: 135.94370\n",
      "[epoch 489, batch    18] loss: 118.66383\n",
      "[epoch 489, batch    19] loss: 132.24206\n",
      "[epoch 489, batch    20] loss: 125.39124\n",
      "[epoch 489, batch    21] loss: 149.79034\n",
      "[epoch 489, batch    22] loss: 131.42258\n",
      "[epoch 489, batch    23] loss: 120.96586\n",
      "[epoch 489, batch    24] loss: 130.94404\n",
      "[epoch 489, batch    25] loss: 145.97253\n",
      "[epoch 489, batch    26] loss: 124.75033\n",
      "[epoch 489, batch    27] loss: 134.39031\n",
      "[epoch 489, batch    28] loss: 139.76989\n",
      "[epoch 489, batch    29] loss: 113.71690\n",
      "[epoch 489, batch    30] loss: 128.76879\n",
      "[epoch 489, batch    31] loss: 128.55255\n",
      "[epoch 489, batch    32] loss: 31.39903\n",
      "[epoch 490, batch     1] loss: 138.39944\n",
      "[epoch 490, batch     2] loss: 131.77520\n",
      "[epoch 490, batch     3] loss: 135.14937\n",
      "[epoch 490, batch     4] loss: 123.68317\n",
      "[epoch 490, batch     5] loss: 134.60245\n",
      "[epoch 490, batch     6] loss: 141.13774\n",
      "[epoch 490, batch     7] loss: 129.41203\n",
      "[epoch 490, batch     8] loss: 120.51416\n",
      "[epoch 490, batch     9] loss: 132.97345\n",
      "[epoch 490, batch    10] loss: 128.45439\n",
      "[epoch 490, batch    11] loss: 119.16219\n",
      "[epoch 490, batch    12] loss: 130.31688\n",
      "[epoch 490, batch    13] loss: 142.68864\n",
      "[epoch 490, batch    14] loss: 134.67638\n",
      "[epoch 490, batch    15] loss: 122.84670\n",
      "[epoch 490, batch    16] loss: 129.36223\n",
      "[epoch 490, batch    17] loss: 131.36896\n",
      "[epoch 490, batch    18] loss: 126.40265\n",
      "[epoch 490, batch    19] loss: 135.21025\n",
      "[epoch 490, batch    20] loss: 124.27342\n",
      "[epoch 490, batch    21] loss: 129.95360\n",
      "[epoch 490, batch    22] loss: 135.01723\n",
      "[epoch 490, batch    23] loss: 119.51569\n",
      "[epoch 490, batch    24] loss: 134.52979\n",
      "[epoch 490, batch    25] loss: 140.92678\n",
      "[epoch 490, batch    26] loss: 123.87682\n",
      "[epoch 490, batch    27] loss: 129.12198\n",
      "[epoch 490, batch    28] loss: 142.39132\n",
      "[epoch 490, batch    29] loss: 123.13879\n",
      "[epoch 490, batch    30] loss: 134.36255\n",
      "[epoch 490, batch    31] loss: 128.26628\n",
      "[epoch 490, batch    32] loss: 37.50139\n",
      "[epoch 491, batch     1] loss: 126.03647\n",
      "[epoch 491, batch     2] loss: 132.09916\n",
      "[epoch 491, batch     3] loss: 134.34638\n",
      "[epoch 491, batch     4] loss: 123.08217\n",
      "[epoch 491, batch     5] loss: 142.74227\n",
      "[epoch 491, batch     6] loss: 136.06396\n",
      "[epoch 491, batch     7] loss: 130.49592\n",
      "[epoch 491, batch     8] loss: 129.70353\n",
      "[epoch 491, batch     9] loss: 122.89285\n",
      "[epoch 491, batch    10] loss: 135.50631\n",
      "[epoch 491, batch    11] loss: 124.80817\n",
      "[epoch 491, batch    12] loss: 126.92183\n",
      "[epoch 491, batch    13] loss: 133.44115\n",
      "[epoch 491, batch    14] loss: 134.77268\n",
      "[epoch 491, batch    15] loss: 126.80578\n",
      "[epoch 491, batch    16] loss: 128.33596\n",
      "[epoch 491, batch    17] loss: 121.43748\n",
      "[epoch 491, batch    18] loss: 124.14319\n",
      "[epoch 491, batch    19] loss: 133.76013\n",
      "[epoch 491, batch    20] loss: 137.94505\n",
      "[epoch 491, batch    21] loss: 139.72042\n",
      "[epoch 491, batch    22] loss: 132.03258\n",
      "[epoch 491, batch    23] loss: 142.71220\n",
      "[epoch 491, batch    24] loss: 132.95446\n",
      "[epoch 491, batch    25] loss: 137.41881\n",
      "[epoch 491, batch    26] loss: 141.83987\n",
      "[epoch 491, batch    27] loss: 135.60593\n",
      "[epoch 491, batch    28] loss: 131.02911\n",
      "[epoch 491, batch    29] loss: 127.97909\n",
      "[epoch 491, batch    30] loss: 137.55993\n",
      "[epoch 491, batch    31] loss: 132.10438\n",
      "[epoch 491, batch    32] loss: 34.68544\n",
      "[epoch 492, batch     1] loss: 129.68011\n",
      "[epoch 492, batch     2] loss: 134.40399\n",
      "[epoch 492, batch     3] loss: 129.75571\n",
      "[epoch 492, batch     4] loss: 127.57462\n",
      "[epoch 492, batch     5] loss: 124.78236\n",
      "[epoch 492, batch     6] loss: 118.68736\n",
      "[epoch 492, batch     7] loss: 135.00381\n",
      "[epoch 492, batch     8] loss: 141.67275\n",
      "[epoch 492, batch     9] loss: 129.55550\n",
      "[epoch 492, batch    10] loss: 157.82978\n",
      "[epoch 492, batch    11] loss: 128.21171\n",
      "[epoch 492, batch    12] loss: 117.22847\n",
      "[epoch 492, batch    13] loss: 159.29316\n",
      "[epoch 492, batch    14] loss: 128.81111\n",
      "[epoch 492, batch    15] loss: 126.50248\n",
      "[epoch 492, batch    16] loss: 132.49988\n",
      "[epoch 492, batch    17] loss: 124.97395\n",
      "[epoch 492, batch    18] loss: 148.34258\n",
      "[epoch 492, batch    19] loss: 128.48682\n",
      "[epoch 492, batch    20] loss: 140.94579\n",
      "[epoch 492, batch    21] loss: 122.13864\n",
      "[epoch 492, batch    22] loss: 130.43804\n",
      "[epoch 492, batch    23] loss: 124.13900\n",
      "[epoch 492, batch    24] loss: 125.73640\n",
      "[epoch 492, batch    25] loss: 138.57651\n",
      "[epoch 492, batch    26] loss: 141.12387\n",
      "[epoch 492, batch    27] loss: 127.03864\n",
      "[epoch 492, batch    28] loss: 131.10870\n",
      "[epoch 492, batch    29] loss: 130.36237\n",
      "[epoch 492, batch    30] loss: 129.24373\n",
      "[epoch 492, batch    31] loss: 124.73898\n",
      "[epoch 492, batch    32] loss: 32.52198\n",
      "[epoch 493, batch     1] loss: 133.09770\n",
      "[epoch 493, batch     2] loss: 127.24356\n",
      "[epoch 493, batch     3] loss: 128.72686\n",
      "[epoch 493, batch     4] loss: 143.27043\n",
      "[epoch 493, batch     5] loss: 123.21350\n",
      "[epoch 493, batch     6] loss: 133.59989\n",
      "[epoch 493, batch     7] loss: 126.45363\n",
      "[epoch 493, batch     8] loss: 122.51225\n",
      "[epoch 493, batch     9] loss: 129.40859\n",
      "[epoch 493, batch    10] loss: 151.35533\n",
      "[epoch 493, batch    11] loss: 125.91921\n",
      "[epoch 493, batch    12] loss: 135.01650\n",
      "[epoch 493, batch    13] loss: 129.85429\n",
      "[epoch 493, batch    14] loss: 127.54115\n",
      "[epoch 493, batch    15] loss: 133.62934\n",
      "[epoch 493, batch    16] loss: 125.85291\n",
      "[epoch 493, batch    17] loss: 142.33573\n",
      "[epoch 493, batch    18] loss: 134.52606\n",
      "[epoch 493, batch    19] loss: 137.60397\n",
      "[epoch 493, batch    20] loss: 130.72844\n",
      "[epoch 493, batch    21] loss: 130.61512\n",
      "[epoch 493, batch    22] loss: 118.40898\n",
      "[epoch 493, batch    23] loss: 126.89607\n",
      "[epoch 493, batch    24] loss: 123.79972\n",
      "[epoch 493, batch    25] loss: 136.86584\n",
      "[epoch 493, batch    26] loss: 127.80832\n",
      "[epoch 493, batch    27] loss: 140.12667\n",
      "[epoch 493, batch    28] loss: 122.07934\n",
      "[epoch 493, batch    29] loss: 122.96888\n",
      "[epoch 493, batch    30] loss: 142.74625\n",
      "[epoch 493, batch    31] loss: 124.52452\n",
      "[epoch 493, batch    32] loss: 29.06669\n",
      "[epoch 494, batch     1] loss: 141.08578\n",
      "[epoch 494, batch     2] loss: 140.89748\n",
      "[epoch 494, batch     3] loss: 131.09295\n",
      "[epoch 494, batch     4] loss: 146.18894\n",
      "[epoch 494, batch     5] loss: 125.49879\n",
      "[epoch 494, batch     6] loss: 128.25254\n",
      "[epoch 494, batch     7] loss: 115.28000\n",
      "[epoch 494, batch     8] loss: 128.59532\n",
      "[epoch 494, batch     9] loss: 132.24171\n",
      "[epoch 494, batch    10] loss: 131.24092\n",
      "[epoch 494, batch    11] loss: 128.90909\n",
      "[epoch 494, batch    12] loss: 122.33769\n",
      "[epoch 494, batch    13] loss: 124.44348\n",
      "[epoch 494, batch    14] loss: 129.93252\n",
      "[epoch 494, batch    15] loss: 131.11359\n",
      "[epoch 494, batch    16] loss: 125.84521\n",
      "[epoch 494, batch    17] loss: 149.21556\n",
      "[epoch 494, batch    18] loss: 133.43564\n",
      "[epoch 494, batch    19] loss: 137.74661\n",
      "[epoch 494, batch    20] loss: 131.31091\n",
      "[epoch 494, batch    21] loss: 140.75035\n",
      "[epoch 494, batch    22] loss: 142.04524\n",
      "[epoch 494, batch    23] loss: 130.40716\n",
      "[epoch 494, batch    24] loss: 125.57147\n",
      "[epoch 494, batch    25] loss: 128.09819\n",
      "[epoch 494, batch    26] loss: 139.72228\n",
      "[epoch 494, batch    27] loss: 117.56492\n",
      "[epoch 494, batch    28] loss: 122.19838\n",
      "[epoch 494, batch    29] loss: 130.15984\n",
      "[epoch 494, batch    30] loss: 143.12677\n",
      "[epoch 494, batch    31] loss: 123.44593\n",
      "[epoch 494, batch    32] loss: 32.22928\n",
      "[epoch 495, batch     1] loss: 131.34605\n",
      "[epoch 495, batch     2] loss: 129.65991\n",
      "[epoch 495, batch     3] loss: 129.60227\n",
      "[epoch 495, batch     4] loss: 132.07205\n",
      "[epoch 495, batch     5] loss: 134.37554\n",
      "[epoch 495, batch     6] loss: 141.29815\n",
      "[epoch 495, batch     7] loss: 134.98050\n",
      "[epoch 495, batch     8] loss: 141.10304\n",
      "[epoch 495, batch     9] loss: 140.06902\n",
      "[epoch 495, batch    10] loss: 138.31629\n",
      "[epoch 495, batch    11] loss: 130.89091\n",
      "[epoch 495, batch    12] loss: 129.37775\n",
      "[epoch 495, batch    13] loss: 135.58006\n",
      "[epoch 495, batch    14] loss: 137.13251\n",
      "[epoch 495, batch    15] loss: 142.15208\n",
      "[epoch 495, batch    16] loss: 121.03468\n",
      "[epoch 495, batch    17] loss: 130.29095\n",
      "[epoch 495, batch    18] loss: 139.79590\n",
      "[epoch 495, batch    19] loss: 130.81851\n",
      "[epoch 495, batch    20] loss: 132.08768\n",
      "[epoch 495, batch    21] loss: 142.77877\n",
      "[epoch 495, batch    22] loss: 126.49524\n",
      "[epoch 495, batch    23] loss: 140.61692\n",
      "[epoch 495, batch    24] loss: 132.90624\n",
      "[epoch 495, batch    25] loss: 138.16995\n",
      "[epoch 495, batch    26] loss: 138.35093\n",
      "[epoch 495, batch    27] loss: 125.32200\n",
      "[epoch 495, batch    28] loss: 130.57548\n",
      "[epoch 495, batch    29] loss: 128.54931\n",
      "[epoch 495, batch    30] loss: 121.14197\n",
      "[epoch 495, batch    31] loss: 131.62258\n",
      "[epoch 495, batch    32] loss: 33.76204\n",
      "[epoch 496, batch     1] loss: 122.40518\n",
      "[epoch 496, batch     2] loss: 125.88234\n",
      "[epoch 496, batch     3] loss: 127.30087\n",
      "[epoch 496, batch     4] loss: 143.90624\n",
      "[epoch 496, batch     5] loss: 130.55140\n",
      "[epoch 496, batch     6] loss: 132.97955\n",
      "[epoch 496, batch     7] loss: 122.63445\n",
      "[epoch 496, batch     8] loss: 139.31781\n",
      "[epoch 496, batch     9] loss: 122.13624\n",
      "[epoch 496, batch    10] loss: 126.31212\n",
      "[epoch 496, batch    11] loss: 131.76300\n",
      "[epoch 496, batch    12] loss: 143.13280\n",
      "[epoch 496, batch    13] loss: 125.50601\n",
      "[epoch 496, batch    14] loss: 134.65711\n",
      "[epoch 496, batch    15] loss: 137.38121\n",
      "[epoch 496, batch    16] loss: 139.86648\n",
      "[epoch 496, batch    17] loss: 131.82087\n",
      "[epoch 496, batch    18] loss: 129.85391\n",
      "[epoch 496, batch    19] loss: 136.03156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 496, batch    20] loss: 124.21207\n",
      "[epoch 496, batch    21] loss: 133.53818\n",
      "[epoch 496, batch    22] loss: 133.54083\n",
      "[epoch 496, batch    23] loss: 131.41445\n",
      "[epoch 496, batch    24] loss: 121.42795\n",
      "[epoch 496, batch    25] loss: 130.05595\n",
      "[epoch 496, batch    26] loss: 124.35992\n",
      "[epoch 496, batch    27] loss: 125.67556\n",
      "[epoch 496, batch    28] loss: 139.04855\n",
      "[epoch 496, batch    29] loss: 129.54129\n",
      "[epoch 496, batch    30] loss: 116.40021\n",
      "[epoch 496, batch    31] loss: 121.87334\n",
      "[epoch 496, batch    32] loss: 34.99680\n",
      "[epoch 497, batch     1] loss: 131.85708\n",
      "[epoch 497, batch     2] loss: 133.04322\n",
      "[epoch 497, batch     3] loss: 141.15884\n",
      "[epoch 497, batch     4] loss: 151.52462\n",
      "[epoch 497, batch     5] loss: 124.48456\n",
      "[epoch 497, batch     6] loss: 151.24102\n",
      "[epoch 497, batch     7] loss: 145.43663\n",
      "[epoch 497, batch     8] loss: 142.32305\n",
      "[epoch 497, batch     9] loss: 127.33552\n",
      "[epoch 497, batch    10] loss: 137.01998\n",
      "[epoch 497, batch    11] loss: 142.77013\n",
      "[epoch 497, batch    12] loss: 135.62107\n",
      "[epoch 497, batch    13] loss: 136.59899\n",
      "[epoch 497, batch    14] loss: 117.99843\n",
      "[epoch 497, batch    15] loss: 139.21865\n",
      "[epoch 497, batch    16] loss: 124.52761\n",
      "[epoch 497, batch    17] loss: 135.53555\n",
      "[epoch 497, batch    18] loss: 132.21510\n",
      "[epoch 497, batch    19] loss: 117.53129\n",
      "[epoch 497, batch    20] loss: 152.72910\n",
      "[epoch 497, batch    21] loss: 133.80891\n",
      "[epoch 497, batch    22] loss: 134.61857\n",
      "[epoch 497, batch    23] loss: 127.83509\n",
      "[epoch 497, batch    24] loss: 124.26570\n",
      "[epoch 497, batch    25] loss: 136.12103\n",
      "[epoch 497, batch    26] loss: 131.13111\n",
      "[epoch 497, batch    27] loss: 128.79695\n",
      "[epoch 497, batch    28] loss: 140.66742\n",
      "[epoch 497, batch    29] loss: 124.19334\n",
      "[epoch 497, batch    30] loss: 125.04798\n",
      "[epoch 497, batch    31] loss: 124.92338\n",
      "[epoch 497, batch    32] loss: 38.84172\n",
      "[epoch 498, batch     1] loss: 128.60399\n",
      "[epoch 498, batch     2] loss: 135.35910\n",
      "[epoch 498, batch     3] loss: 132.99562\n",
      "[epoch 498, batch     4] loss: 143.53152\n",
      "[epoch 498, batch     5] loss: 118.36991\n",
      "[epoch 498, batch     6] loss: 134.42053\n",
      "[epoch 498, batch     7] loss: 123.90981\n",
      "[epoch 498, batch     8] loss: 139.71262\n",
      "[epoch 498, batch     9] loss: 128.24673\n",
      "[epoch 498, batch    10] loss: 142.98942\n",
      "[epoch 498, batch    11] loss: 131.31884\n",
      "[epoch 498, batch    12] loss: 139.56602\n",
      "[epoch 498, batch    13] loss: 124.33420\n",
      "[epoch 498, batch    14] loss: 126.32945\n",
      "[epoch 498, batch    15] loss: 120.99212\n",
      "[epoch 498, batch    16] loss: 127.67937\n",
      "[epoch 498, batch    17] loss: 133.12523\n",
      "[epoch 498, batch    18] loss: 146.18146\n",
      "[epoch 498, batch    19] loss: 147.29475\n",
      "[epoch 498, batch    20] loss: 130.46438\n",
      "[epoch 498, batch    21] loss: 146.13714\n",
      "[epoch 498, batch    22] loss: 133.95765\n",
      "[epoch 498, batch    23] loss: 128.56682\n",
      "[epoch 498, batch    24] loss: 133.41281\n",
      "[epoch 498, batch    25] loss: 132.19891\n",
      "[epoch 498, batch    26] loss: 130.88045\n",
      "[epoch 498, batch    27] loss: 143.69873\n",
      "[epoch 498, batch    28] loss: 129.53428\n",
      "[epoch 498, batch    29] loss: 139.36597\n",
      "[epoch 498, batch    30] loss: 138.90298\n",
      "[epoch 498, batch    31] loss: 123.68367\n",
      "[epoch 498, batch    32] loss: 28.99422\n",
      "[epoch 499, batch     1] loss: 130.74473\n",
      "[epoch 499, batch     2] loss: 131.32190\n",
      "[epoch 499, batch     3] loss: 139.19472\n",
      "[epoch 499, batch     4] loss: 143.04275\n",
      "[epoch 499, batch     5] loss: 120.79965\n",
      "[epoch 499, batch     6] loss: 131.50171\n",
      "[epoch 499, batch     7] loss: 143.59590\n",
      "[epoch 499, batch     8] loss: 133.14558\n",
      "[epoch 499, batch     9] loss: 128.93625\n",
      "[epoch 499, batch    10] loss: 133.61277\n",
      "[epoch 499, batch    11] loss: 135.68956\n",
      "[epoch 499, batch    12] loss: 131.43824\n",
      "[epoch 499, batch    13] loss: 140.09318\n",
      "[epoch 499, batch    14] loss: 136.15944\n",
      "[epoch 499, batch    15] loss: 131.67853\n",
      "[epoch 499, batch    16] loss: 139.85348\n",
      "[epoch 499, batch    17] loss: 133.03667\n",
      "[epoch 499, batch    18] loss: 129.06585\n",
      "[epoch 499, batch    19] loss: 122.78390\n",
      "[epoch 499, batch    20] loss: 130.60671\n",
      "[epoch 499, batch    21] loss: 133.32931\n",
      "[epoch 499, batch    22] loss: 129.36567\n",
      "[epoch 499, batch    23] loss: 128.92594\n",
      "[epoch 499, batch    24] loss: 125.49268\n",
      "[epoch 499, batch    25] loss: 151.19451\n",
      "[epoch 499, batch    26] loss: 129.70984\n",
      "[epoch 499, batch    27] loss: 137.45192\n",
      "[epoch 499, batch    28] loss: 140.42099\n",
      "[epoch 499, batch    29] loss: 119.67034\n",
      "[epoch 499, batch    30] loss: 130.00870\n",
      "[epoch 499, batch    31] loss: 127.51705\n",
      "[epoch 499, batch    32] loss: 39.54576\n",
      "[epoch 500, batch     1] loss: 121.52896\n",
      "[epoch 500, batch     2] loss: 128.49134\n",
      "[epoch 500, batch     3] loss: 123.30299\n",
      "[epoch 500, batch     4] loss: 118.88627\n",
      "[epoch 500, batch     5] loss: 125.48724\n",
      "[epoch 500, batch     6] loss: 137.60423\n",
      "[epoch 500, batch     7] loss: 130.25481\n",
      "[epoch 500, batch     8] loss: 123.51736\n",
      "[epoch 500, batch     9] loss: 133.87083\n",
      "[epoch 500, batch    10] loss: 118.83751\n",
      "[epoch 500, batch    11] loss: 124.64605\n",
      "[epoch 500, batch    12] loss: 125.04151\n",
      "[epoch 500, batch    13] loss: 128.97157\n",
      "[epoch 500, batch    14] loss: 133.03782\n",
      "[epoch 500, batch    15] loss: 130.81478\n",
      "[epoch 500, batch    16] loss: 126.69819\n",
      "[epoch 500, batch    17] loss: 132.00470\n",
      "[epoch 500, batch    18] loss: 136.27643\n",
      "[epoch 500, batch    19] loss: 131.61880\n",
      "[epoch 500, batch    20] loss: 144.38091\n",
      "[epoch 500, batch    21] loss: 125.97266\n",
      "[epoch 500, batch    22] loss: 135.28030\n",
      "[epoch 500, batch    23] loss: 125.51519\n",
      "[epoch 500, batch    24] loss: 139.85236\n",
      "[epoch 500, batch    25] loss: 134.73278\n",
      "[epoch 500, batch    26] loss: 143.70312\n",
      "[epoch 500, batch    27] loss: 145.47541\n",
      "[epoch 500, batch    28] loss: 142.10136\n",
      "[epoch 500, batch    29] loss: 143.31143\n",
      "[epoch 500, batch    30] loss: 124.96667\n",
      "[epoch 500, batch    31] loss: 129.25142\n",
      "[epoch 500, batch    32] loss: 34.89204\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lvm = train1(lvm, data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response_net_param:  Parameter containing:\n",
      "tensor([[ 0.4792],\n",
      "        [-0.3045],\n",
      "        [ 0.6838]], dtype=torch.float64, requires_grad=True)\n",
      "iv model param weight:  Parameter containing:\n",
      "tensor([[ 0.2548, -0.4975,  0.3106, -0.0810]], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "iv model param bias:  Parameter containing:\n",
      "tensor([-1.0516], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print('response_net_param: ', lvm.response.response_net[0].weight)\n",
    "print('iv model param weight: ', lvm.ivm.z_logscale_fc.weight)\n",
    "print('iv model param bias: ', lvm.ivm.z_logscale_fc.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0890])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(torch.tensor([0.0853]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response_net_param weight:  Parameter containing:\n",
      "tensor([[ 0.4792],\n",
      "        [-0.3045],\n",
      "        [ 0.6838]], dtype=torch.float64, requires_grad=True)\n",
      "response_net_param bias:  Parameter containing:\n",
      "tensor([ 0.2886, -0.2728,  0.2260], dtype=torch.float64, requires_grad=True)\n",
      "iv model param weight:  Parameter containing:\n",
      "tensor([[ 0.2548, -0.4975,  0.3106, -0.0810]], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "iv model param bias:  Parameter containing:\n",
      "tensor([-1.0516], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print('response_net_param weight: ', lvm.response.response_net[0].weight)\n",
    "print('response_net_param bias: ', lvm.response.response_net[0].bias)\n",
    "print('iv model param weight: ', lvm.ivm.z_logscale_fc.weight)\n",
    "print('iv model param bias: ', lvm.ivm.z_logscale_fc.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, batch     1] loss: 3.56997\n",
      "[epoch 1, batch     2] loss: 3.84232\n",
      "[epoch 1, batch     3] loss: 5.12216\n",
      "[epoch 1, batch     4] loss: 3.64778\n",
      "[epoch 1, batch     5] loss: 3.75157\n",
      "[epoch 1, batch     6] loss: 3.43986\n",
      "[epoch 1, batch     7] loss: 3.07126\n",
      "[epoch 1, batch     8] loss: 4.72419\n",
      "[epoch 1, batch     9] loss: 4.07713\n",
      "[epoch 1, batch    10] loss: 3.42169\n",
      "[epoch 1, batch    11] loss: 2.43185\n",
      "[epoch 1, batch    12] loss: 3.18508\n",
      "[epoch 1, batch    13] loss: 4.38101\n",
      "[epoch 1, batch    14] loss: 3.83436\n",
      "[epoch 1, batch    15] loss: 3.44037\n",
      "[epoch 1, batch    16] loss: 3.76272\n",
      "[epoch 1, batch    17] loss: 2.92068\n",
      "[epoch 1, batch    18] loss: 3.27118\n",
      "[epoch 1, batch    19] loss: 3.24782\n",
      "[epoch 1, batch    20] loss: 3.28059\n",
      "[epoch 1, batch    21] loss: 3.81895\n",
      "[epoch 1, batch    22] loss: 3.59377\n",
      "[epoch 1, batch    23] loss: 3.85409\n",
      "[epoch 1, batch    24] loss: 3.36099\n",
      "[epoch 1, batch    25] loss: 4.68395\n",
      "[epoch 1, batch    26] loss: 3.72900\n",
      "[epoch 1, batch    27] loss: 3.10758\n",
      "[epoch 1, batch    28] loss: 3.44196\n",
      "[epoch 1, batch    29] loss: 3.89449\n",
      "[epoch 1, batch    30] loss: 3.38902\n",
      "[epoch 1, batch    31] loss: 3.50195\n",
      "[epoch 1, batch    32] loss: 2.19856\n",
      "[epoch 2, batch     1] loss: 4.30787\n",
      "[epoch 2, batch     2] loss: 3.53240\n",
      "[epoch 2, batch     3] loss: 3.69213\n",
      "[epoch 2, batch     4] loss: 3.30115\n",
      "[epoch 2, batch     5] loss: 3.29456\n",
      "[epoch 2, batch     6] loss: 3.60930\n",
      "[epoch 2, batch     7] loss: 3.76515\n",
      "[epoch 2, batch     8] loss: 3.65906\n",
      "[epoch 2, batch     9] loss: 3.03117\n",
      "[epoch 2, batch    10] loss: 3.42659\n",
      "[epoch 2, batch    11] loss: 4.07225\n",
      "[epoch 2, batch    12] loss: 2.96531\n",
      "[epoch 2, batch    13] loss: 3.61210\n",
      "[epoch 2, batch    14] loss: 3.82378\n",
      "[epoch 2, batch    15] loss: 3.15589\n",
      "[epoch 2, batch    16] loss: 4.12848\n",
      "[epoch 2, batch    17] loss: 3.31123\n",
      "[epoch 2, batch    18] loss: 3.56684\n",
      "[epoch 2, batch    19] loss: 3.46682\n",
      "[epoch 2, batch    20] loss: 3.70271\n",
      "[epoch 2, batch    21] loss: 3.09916\n",
      "[epoch 2, batch    22] loss: 3.50050\n",
      "[epoch 2, batch    23] loss: 4.19281\n",
      "[epoch 2, batch    24] loss: 3.76733\n",
      "[epoch 2, batch    25] loss: 3.27592\n",
      "[epoch 2, batch    26] loss: 2.94040\n",
      "[epoch 2, batch    27] loss: 3.26769\n",
      "[epoch 2, batch    28] loss: 2.96978\n",
      "[epoch 2, batch    29] loss: 3.40246\n",
      "[epoch 2, batch    30] loss: 4.24710\n",
      "[epoch 2, batch    31] loss: 4.72086\n",
      "[epoch 2, batch    32] loss: 3.82172\n",
      "[epoch 3, batch     1] loss: 3.19666\n",
      "[epoch 3, batch     2] loss: 4.09046\n",
      "[epoch 3, batch     3] loss: 3.28510\n",
      "[epoch 3, batch     4] loss: 2.49375\n",
      "[epoch 3, batch     5] loss: 3.39922\n",
      "[epoch 3, batch     6] loss: 3.64957\n",
      "[epoch 3, batch     7] loss: 2.97944\n",
      "[epoch 3, batch     8] loss: 3.84722\n",
      "[epoch 3, batch     9] loss: 3.84083\n",
      "[epoch 3, batch    10] loss: 3.62667\n",
      "[epoch 3, batch    11] loss: 3.51570\n",
      "[epoch 3, batch    12] loss: 3.81345\n",
      "[epoch 3, batch    13] loss: 3.49304\n",
      "[epoch 3, batch    14] loss: 4.22545\n",
      "[epoch 3, batch    15] loss: 3.62350\n",
      "[epoch 3, batch    16] loss: 3.98833\n",
      "[epoch 3, batch    17] loss: 3.15051\n",
      "[epoch 3, batch    18] loss: 3.67230\n",
      "[epoch 3, batch    19] loss: 4.07252\n",
      "[epoch 3, batch    20] loss: 3.19402\n",
      "[epoch 3, batch    21] loss: 3.65543\n",
      "[epoch 3, batch    22] loss: 4.39702\n",
      "[epoch 3, batch    23] loss: 2.80799\n",
      "[epoch 3, batch    24] loss: 3.71831\n",
      "[epoch 3, batch    25] loss: 3.36346\n",
      "[epoch 3, batch    26] loss: 4.50347\n",
      "[epoch 3, batch    27] loss: 2.80219\n",
      "[epoch 3, batch    28] loss: 3.23415\n",
      "[epoch 3, batch    29] loss: 3.01434\n",
      "[epoch 3, batch    30] loss: 3.01177\n",
      "[epoch 3, batch    31] loss: 4.05635\n",
      "[epoch 3, batch    32] loss: 2.98838\n",
      "[epoch 4, batch     1] loss: 4.02704\n",
      "[epoch 4, batch     2] loss: 3.60287\n",
      "[epoch 4, batch     3] loss: 3.46626\n",
      "[epoch 4, batch     4] loss: 3.07522\n",
      "[epoch 4, batch     5] loss: 3.07464\n",
      "[epoch 4, batch     6] loss: 2.85081\n",
      "[epoch 4, batch     7] loss: 3.41740\n",
      "[epoch 4, batch     8] loss: 3.33174\n",
      "[epoch 4, batch     9] loss: 3.60984\n",
      "[epoch 4, batch    10] loss: 3.47104\n",
      "[epoch 4, batch    11] loss: 2.58825\n",
      "[epoch 4, batch    12] loss: 3.23577\n",
      "[epoch 4, batch    13] loss: 3.11169\n",
      "[epoch 4, batch    14] loss: 2.93590\n",
      "[epoch 4, batch    15] loss: 4.41656\n",
      "[epoch 4, batch    16] loss: 4.16320\n",
      "[epoch 4, batch    17] loss: 3.61584\n",
      "[epoch 4, batch    18] loss: 4.29002\n",
      "[epoch 4, batch    19] loss: 2.87895\n",
      "[epoch 4, batch    20] loss: 3.42567\n",
      "[epoch 4, batch    21] loss: 3.58147\n",
      "[epoch 4, batch    22] loss: 4.38891\n",
      "[epoch 4, batch    23] loss: 3.58138\n",
      "[epoch 4, batch    24] loss: 4.04443\n",
      "[epoch 4, batch    25] loss: 2.97914\n",
      "[epoch 4, batch    26] loss: 3.58669\n",
      "[epoch 4, batch    27] loss: 3.84746\n",
      "[epoch 4, batch    28] loss: 3.62129\n",
      "[epoch 4, batch    29] loss: 3.16245\n",
      "[epoch 4, batch    30] loss: 3.66805\n",
      "[epoch 4, batch    31] loss: 3.91398\n",
      "[epoch 4, batch    32] loss: 2.66480\n",
      "[epoch 5, batch     1] loss: 3.21387\n",
      "[epoch 5, batch     2] loss: 4.23690\n",
      "[epoch 5, batch     3] loss: 3.61699\n",
      "[epoch 5, batch     4] loss: 3.58142\n",
      "[epoch 5, batch     5] loss: 2.81222\n",
      "[epoch 5, batch     6] loss: 3.62093\n",
      "[epoch 5, batch     7] loss: 4.06335\n",
      "[epoch 5, batch     8] loss: 3.02659\n",
      "[epoch 5, batch     9] loss: 3.19479\n",
      "[epoch 5, batch    10] loss: 3.75644\n",
      "[epoch 5, batch    11] loss: 3.15754\n",
      "[epoch 5, batch    12] loss: 3.52153\n",
      "[epoch 5, batch    13] loss: 3.87127\n",
      "[epoch 5, batch    14] loss: 2.85480\n",
      "[epoch 5, batch    15] loss: 3.92942\n",
      "[epoch 5, batch    16] loss: 3.14082\n",
      "[epoch 5, batch    17] loss: 3.95916\n",
      "[epoch 5, batch    18] loss: 4.59855\n",
      "[epoch 5, batch    19] loss: 3.00558\n",
      "[epoch 5, batch    20] loss: 3.16064\n",
      "[epoch 5, batch    21] loss: 3.73142\n",
      "[epoch 5, batch    22] loss: 3.38982\n",
      "[epoch 5, batch    23] loss: 3.88215\n",
      "[epoch 5, batch    24] loss: 3.64091\n",
      "[epoch 5, batch    25] loss: 4.09179\n",
      "[epoch 5, batch    26] loss: 2.90560\n",
      "[epoch 5, batch    27] loss: 3.50574\n",
      "[epoch 5, batch    28] loss: 3.51274\n",
      "[epoch 5, batch    29] loss: 2.46686\n",
      "[epoch 5, batch    30] loss: 2.73876\n",
      "[epoch 5, batch    31] loss: 3.93145\n",
      "[epoch 5, batch    32] loss: 4.06830\n",
      "[epoch 6, batch     1] loss: 2.39685\n",
      "[epoch 6, batch     2] loss: 3.15208\n",
      "[epoch 6, batch     3] loss: 3.90271\n",
      "[epoch 6, batch     4] loss: 4.19331\n",
      "[epoch 6, batch     5] loss: 2.75690\n",
      "[epoch 6, batch     6] loss: 3.06001\n",
      "[epoch 6, batch     7] loss: 3.10932\n",
      "[epoch 6, batch     8] loss: 3.58007\n",
      "[epoch 6, batch     9] loss: 3.92685\n",
      "[epoch 6, batch    10] loss: 4.78076\n",
      "[epoch 6, batch    11] loss: 4.39041\n",
      "[epoch 6, batch    12] loss: 3.92739\n",
      "[epoch 6, batch    13] loss: 3.55908\n",
      "[epoch 6, batch    14] loss: 4.01716\n",
      "[epoch 6, batch    15] loss: 4.27130\n",
      "[epoch 6, batch    16] loss: 3.52435\n",
      "[epoch 6, batch    17] loss: 3.51009\n",
      "[epoch 6, batch    18] loss: 3.21720\n",
      "[epoch 6, batch    19] loss: 2.93784\n",
      "[epoch 6, batch    20] loss: 3.70049\n",
      "[epoch 6, batch    21] loss: 2.61563\n",
      "[epoch 6, batch    22] loss: 4.07695\n",
      "[epoch 6, batch    23] loss: 3.77563\n",
      "[epoch 6, batch    24] loss: 2.99674\n",
      "[epoch 6, batch    25] loss: 2.92663\n",
      "[epoch 6, batch    26] loss: 3.53018\n",
      "[epoch 6, batch    27] loss: 3.18436\n",
      "[epoch 6, batch    28] loss: 2.94723\n",
      "[epoch 6, batch    29] loss: 3.31429\n",
      "[epoch 6, batch    30] loss: 3.26077\n",
      "[epoch 6, batch    31] loss: 3.25068\n",
      "[epoch 6, batch    32] loss: 4.10629\n",
      "[epoch 7, batch     1] loss: 2.70727\n",
      "[epoch 7, batch     2] loss: 3.97410\n",
      "[epoch 7, batch     3] loss: 3.24630\n",
      "[epoch 7, batch     4] loss: 2.78918\n",
      "[epoch 7, batch     5] loss: 3.97315\n",
      "[epoch 7, batch     6] loss: 3.18824\n",
      "[epoch 7, batch     7] loss: 4.13489\n",
      "[epoch 7, batch     8] loss: 3.57860\n",
      "[epoch 7, batch     9] loss: 3.78183\n",
      "[epoch 7, batch    10] loss: 2.58426\n",
      "[epoch 7, batch    11] loss: 2.81068\n",
      "[epoch 7, batch    12] loss: 3.29442\n",
      "[epoch 7, batch    13] loss: 2.68067\n",
      "[epoch 7, batch    14] loss: 3.88896\n",
      "[epoch 7, batch    15] loss: 3.32233\n",
      "[epoch 7, batch    16] loss: 3.52788\n",
      "[epoch 7, batch    17] loss: 3.73838\n",
      "[epoch 7, batch    18] loss: 3.47262\n",
      "[epoch 7, batch    19] loss: 4.35330\n",
      "[epoch 7, batch    20] loss: 3.52473\n",
      "[epoch 7, batch    21] loss: 3.76872\n",
      "[epoch 7, batch    22] loss: 2.96255\n",
      "[epoch 7, batch    23] loss: 2.91552\n",
      "[epoch 7, batch    24] loss: 3.61124\n",
      "[epoch 7, batch    25] loss: 4.31820\n",
      "[epoch 7, batch    26] loss: 4.43159\n",
      "[epoch 7, batch    27] loss: 3.13795\n",
      "[epoch 7, batch    28] loss: 2.63005\n",
      "[epoch 7, batch    29] loss: 3.17600\n",
      "[epoch 7, batch    30] loss: 3.98503\n",
      "[epoch 7, batch    31] loss: 3.97957\n",
      "[epoch 7, batch    32] loss: 4.57177\n",
      "[epoch 8, batch     1] loss: 4.06152\n",
      "[epoch 8, batch     2] loss: 4.07485\n",
      "[epoch 8, batch     3] loss: 3.20019\n",
      "[epoch 8, batch     4] loss: 3.12033\n",
      "[epoch 8, batch     5] loss: 3.89415\n",
      "[epoch 8, batch     6] loss: 3.57112\n",
      "[epoch 8, batch     7] loss: 3.32963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 8, batch     8] loss: 2.38372\n",
      "[epoch 8, batch     9] loss: 3.80268\n",
      "[epoch 8, batch    10] loss: 3.49084\n",
      "[epoch 8, batch    11] loss: 3.67348\n",
      "[epoch 8, batch    12] loss: 3.71586\n",
      "[epoch 8, batch    13] loss: 3.39920\n",
      "[epoch 8, batch    14] loss: 3.40048\n",
      "[epoch 8, batch    15] loss: 3.65262\n",
      "[epoch 8, batch    16] loss: 3.48049\n",
      "[epoch 8, batch    17] loss: 3.55995\n",
      "[epoch 8, batch    18] loss: 3.28881\n",
      "[epoch 8, batch    19] loss: 2.60544\n",
      "[epoch 8, batch    20] loss: 3.78246\n",
      "[epoch 8, batch    21] loss: 3.55168\n",
      "[epoch 8, batch    22] loss: 4.00912\n",
      "[epoch 8, batch    23] loss: 3.06060\n",
      "[epoch 8, batch    24] loss: 3.48057\n",
      "[epoch 8, batch    25] loss: 3.43790\n",
      "[epoch 8, batch    26] loss: 3.71999\n",
      "[epoch 8, batch    27] loss: 3.62593\n",
      "[epoch 8, batch    28] loss: 3.12173\n",
      "[epoch 8, batch    29] loss: 3.77127\n",
      "[epoch 8, batch    30] loss: 3.76810\n",
      "[epoch 8, batch    31] loss: 2.81746\n",
      "[epoch 8, batch    32] loss: 2.61009\n",
      "[epoch 9, batch     1] loss: 3.17454\n",
      "[epoch 9, batch     2] loss: 3.30920\n",
      "[epoch 9, batch     3] loss: 4.09198\n",
      "[epoch 9, batch     4] loss: 4.11273\n",
      "[epoch 9, batch     5] loss: 3.61516\n",
      "[epoch 9, batch     6] loss: 3.17121\n",
      "[epoch 9, batch     7] loss: 3.10609\n",
      "[epoch 9, batch     8] loss: 4.34042\n",
      "[epoch 9, batch     9] loss: 4.17534\n",
      "[epoch 9, batch    10] loss: 3.34803\n",
      "[epoch 9, batch    11] loss: 3.10399\n",
      "[epoch 9, batch    12] loss: 3.25630\n",
      "[epoch 9, batch    13] loss: 3.11142\n",
      "[epoch 9, batch    14] loss: 3.39156\n",
      "[epoch 9, batch    15] loss: 3.17586\n",
      "[epoch 9, batch    16] loss: 3.61757\n",
      "[epoch 9, batch    17] loss: 3.10293\n",
      "[epoch 9, batch    18] loss: 2.89120\n",
      "[epoch 9, batch    19] loss: 3.29051\n",
      "[epoch 9, batch    20] loss: 3.03239\n",
      "[epoch 9, batch    21] loss: 3.62096\n",
      "[epoch 9, batch    22] loss: 3.53891\n",
      "[epoch 9, batch    23] loss: 3.23461\n",
      "[epoch 9, batch    24] loss: 2.07258\n",
      "[epoch 9, batch    25] loss: 3.61497\n",
      "[epoch 9, batch    26] loss: 3.42145\n",
      "[epoch 9, batch    27] loss: 3.77290\n",
      "[epoch 9, batch    28] loss: 4.45676\n",
      "[epoch 9, batch    29] loss: 3.75576\n",
      "[epoch 9, batch    30] loss: 3.49450\n",
      "[epoch 9, batch    31] loss: 4.33873\n",
      "[epoch 9, batch    32] loss: 2.50054\n",
      "[epoch 10, batch     1] loss: 3.88717\n",
      "[epoch 10, batch     2] loss: 3.20398\n",
      "[epoch 10, batch     3] loss: 4.05903\n",
      "[epoch 10, batch     4] loss: 3.72361\n",
      "[epoch 10, batch     5] loss: 3.64576\n",
      "[epoch 10, batch     6] loss: 3.39246\n",
      "[epoch 10, batch     7] loss: 3.93500\n",
      "[epoch 10, batch     8] loss: 3.52891\n",
      "[epoch 10, batch     9] loss: 4.46494\n",
      "[epoch 10, batch    10] loss: 3.44889\n",
      "[epoch 10, batch    11] loss: 3.54747\n",
      "[epoch 10, batch    12] loss: 3.51928\n",
      "[epoch 10, batch    13] loss: 3.27038\n",
      "[epoch 10, batch    14] loss: 2.96330\n",
      "[epoch 10, batch    15] loss: 2.67525\n",
      "[epoch 10, batch    16] loss: 2.95222\n",
      "[epoch 10, batch    17] loss: 2.18941\n",
      "[epoch 10, batch    18] loss: 4.01697\n",
      "[epoch 10, batch    19] loss: 3.60024\n",
      "[epoch 10, batch    20] loss: 3.53625\n",
      "[epoch 10, batch    21] loss: 3.73803\n",
      "[epoch 10, batch    22] loss: 3.09269\n",
      "[epoch 10, batch    23] loss: 4.29477\n",
      "[epoch 10, batch    24] loss: 3.15055\n",
      "[epoch 10, batch    25] loss: 3.04039\n",
      "[epoch 10, batch    26] loss: 3.35929\n",
      "[epoch 10, batch    27] loss: 3.00209\n",
      "[epoch 10, batch    28] loss: 3.35629\n",
      "[epoch 10, batch    29] loss: 4.20065\n",
      "[epoch 10, batch    30] loss: 3.81616\n",
      "[epoch 10, batch    31] loss: 2.89093\n",
      "[epoch 10, batch    32] loss: 2.93969\n",
      "[epoch 11, batch     1] loss: 4.36319\n",
      "[epoch 11, batch     2] loss: 3.36288\n",
      "[epoch 11, batch     3] loss: 3.16958\n",
      "[epoch 11, batch     4] loss: 3.55935\n",
      "[epoch 11, batch     5] loss: 3.47692\n",
      "[epoch 11, batch     6] loss: 2.62857\n",
      "[epoch 11, batch     7] loss: 2.61957\n",
      "[epoch 11, batch     8] loss: 3.49887\n",
      "[epoch 11, batch     9] loss: 3.65531\n",
      "[epoch 11, batch    10] loss: 3.41422\n",
      "[epoch 11, batch    11] loss: 3.71809\n",
      "[epoch 11, batch    12] loss: 3.47965\n",
      "[epoch 11, batch    13] loss: 3.40837\n",
      "[epoch 11, batch    14] loss: 3.04418\n",
      "[epoch 11, batch    15] loss: 3.17562\n",
      "[epoch 11, batch    16] loss: 3.46392\n",
      "[epoch 11, batch    17] loss: 2.46372\n",
      "[epoch 11, batch    18] loss: 3.48814\n",
      "[epoch 11, batch    19] loss: 4.49742\n",
      "[epoch 11, batch    20] loss: 2.43793\n",
      "[epoch 11, batch    21] loss: 4.12487\n",
      "[epoch 11, batch    22] loss: 4.18259\n",
      "[epoch 11, batch    23] loss: 2.92480\n",
      "[epoch 11, batch    24] loss: 3.08651\n",
      "[epoch 11, batch    25] loss: 3.11068\n",
      "[epoch 11, batch    26] loss: 3.80233\n",
      "[epoch 11, batch    27] loss: 3.00784\n",
      "[epoch 11, batch    28] loss: 4.06869\n",
      "[epoch 11, batch    29] loss: 3.54059\n",
      "[epoch 11, batch    30] loss: 3.65289\n",
      "[epoch 11, batch    31] loss: 5.07162\n",
      "[epoch 11, batch    32] loss: 2.39626\n",
      "[epoch 12, batch     1] loss: 3.26367\n",
      "[epoch 12, batch     2] loss: 3.23057\n",
      "[epoch 12, batch     3] loss: 3.61663\n",
      "[epoch 12, batch     4] loss: 3.24945\n",
      "[epoch 12, batch     5] loss: 3.69422\n",
      "[epoch 12, batch     6] loss: 3.08028\n",
      "[epoch 12, batch     7] loss: 3.32622\n",
      "[epoch 12, batch     8] loss: 2.71974\n",
      "[epoch 12, batch     9] loss: 4.32347\n",
      "[epoch 12, batch    10] loss: 3.04192\n",
      "[epoch 12, batch    11] loss: 3.71794\n",
      "[epoch 12, batch    12] loss: 3.00999\n",
      "[epoch 12, batch    13] loss: 3.34411\n",
      "[epoch 12, batch    14] loss: 3.82366\n",
      "[epoch 12, batch    15] loss: 3.87530\n",
      "[epoch 12, batch    16] loss: 2.62913\n",
      "[epoch 12, batch    17] loss: 3.81369\n",
      "[epoch 12, batch    18] loss: 3.49989\n",
      "[epoch 12, batch    19] loss: 4.17308\n",
      "[epoch 12, batch    20] loss: 4.59103\n",
      "[epoch 12, batch    21] loss: 3.52000\n",
      "[epoch 12, batch    22] loss: 3.11297\n",
      "[epoch 12, batch    23] loss: 3.69278\n",
      "[epoch 12, batch    24] loss: 2.90530\n",
      "[epoch 12, batch    25] loss: 3.11914\n",
      "[epoch 12, batch    26] loss: 3.38085\n",
      "[epoch 12, batch    27] loss: 3.39003\n",
      "[epoch 12, batch    28] loss: 3.25893\n",
      "[epoch 12, batch    29] loss: 3.78491\n",
      "[epoch 12, batch    30] loss: 4.28570\n",
      "[epoch 12, batch    31] loss: 2.91822\n",
      "[epoch 12, batch    32] loss: 2.30260\n",
      "[epoch 13, batch     1] loss: 3.69905\n",
      "[epoch 13, batch     2] loss: 3.17221\n",
      "[epoch 13, batch     3] loss: 3.68491\n",
      "[epoch 13, batch     4] loss: 2.80825\n",
      "[epoch 13, batch     5] loss: 3.26354\n",
      "[epoch 13, batch     6] loss: 4.29300\n",
      "[epoch 13, batch     7] loss: 3.22748\n",
      "[epoch 13, batch     8] loss: 3.47163\n",
      "[epoch 13, batch     9] loss: 3.46365\n",
      "[epoch 13, batch    10] loss: 3.75107\n",
      "[epoch 13, batch    11] loss: 2.29103\n",
      "[epoch 13, batch    12] loss: 3.49210\n",
      "[epoch 13, batch    13] loss: 2.93077\n",
      "[epoch 13, batch    14] loss: 4.01531\n",
      "[epoch 13, batch    15] loss: 3.67003\n",
      "[epoch 13, batch    16] loss: 3.66269\n",
      "[epoch 13, batch    17] loss: 2.83344\n",
      "[epoch 13, batch    18] loss: 3.04073\n",
      "[epoch 13, batch    19] loss: 3.76630\n",
      "[epoch 13, batch    20] loss: 4.42968\n",
      "[epoch 13, batch    21] loss: 4.15986\n",
      "[epoch 13, batch    22] loss: 3.53622\n",
      "[epoch 13, batch    23] loss: 3.47140\n",
      "[epoch 13, batch    24] loss: 3.92834\n",
      "[epoch 13, batch    25] loss: 2.61681\n",
      "[epoch 13, batch    26] loss: 3.10566\n",
      "[epoch 13, batch    27] loss: 3.70009\n",
      "[epoch 13, batch    28] loss: 3.36206\n",
      "[epoch 13, batch    29] loss: 3.64333\n",
      "[epoch 13, batch    30] loss: 3.57501\n",
      "[epoch 13, batch    31] loss: 2.96500\n",
      "[epoch 13, batch    32] loss: 3.13150\n",
      "[epoch 14, batch     1] loss: 3.50156\n",
      "[epoch 14, batch     2] loss: 3.80786\n",
      "[epoch 14, batch     3] loss: 3.49606\n",
      "[epoch 14, batch     4] loss: 3.09150\n",
      "[epoch 14, batch     5] loss: 2.98423\n",
      "[epoch 14, batch     6] loss: 4.05349\n",
      "[epoch 14, batch     7] loss: 3.12287\n",
      "[epoch 14, batch     8] loss: 3.31929\n",
      "[epoch 14, batch     9] loss: 3.47305\n",
      "[epoch 14, batch    10] loss: 3.19534\n",
      "[epoch 14, batch    11] loss: 3.47984\n",
      "[epoch 14, batch    12] loss: 3.89932\n",
      "[epoch 14, batch    13] loss: 4.41635\n",
      "[epoch 14, batch    14] loss: 4.24855\n",
      "[epoch 14, batch    15] loss: 2.85259\n",
      "[epoch 14, batch    16] loss: 3.41588\n",
      "[epoch 14, batch    17] loss: 3.89070\n",
      "[epoch 14, batch    18] loss: 3.41105\n",
      "[epoch 14, batch    19] loss: 3.75336\n",
      "[epoch 14, batch    20] loss: 3.59363\n",
      "[epoch 14, batch    21] loss: 3.64819\n",
      "[epoch 14, batch    22] loss: 2.89357\n",
      "[epoch 14, batch    23] loss: 2.81921\n",
      "[epoch 14, batch    24] loss: 4.41052\n",
      "[epoch 14, batch    25] loss: 2.65253\n",
      "[epoch 14, batch    26] loss: 2.45888\n",
      "[epoch 14, batch    27] loss: 2.70538\n",
      "[epoch 14, batch    28] loss: 3.89751\n",
      "[epoch 14, batch    29] loss: 2.86704\n",
      "[epoch 14, batch    30] loss: 3.97287\n",
      "[epoch 14, batch    31] loss: 3.30313\n",
      "[epoch 14, batch    32] loss: 4.17634\n",
      "[epoch 15, batch     1] loss: 3.34936\n",
      "[epoch 15, batch     2] loss: 3.01720\n",
      "[epoch 15, batch     3] loss: 3.34889\n",
      "[epoch 15, batch     4] loss: 3.49283\n",
      "[epoch 15, batch     5] loss: 2.95740\n",
      "[epoch 15, batch     6] loss: 3.30971\n",
      "[epoch 15, batch     7] loss: 3.78705\n",
      "[epoch 15, batch     8] loss: 3.96957\n",
      "[epoch 15, batch     9] loss: 3.02767\n",
      "[epoch 15, batch    10] loss: 3.80182\n",
      "[epoch 15, batch    11] loss: 4.10503\n",
      "[epoch 15, batch    12] loss: 2.40940\n",
      "[epoch 15, batch    13] loss: 3.80638\n",
      "[epoch 15, batch    14] loss: 2.52823\n",
      "[epoch 15, batch    15] loss: 4.02303\n",
      "[epoch 15, batch    16] loss: 3.27712\n",
      "[epoch 15, batch    17] loss: 3.63209\n",
      "[epoch 15, batch    18] loss: 3.59937\n",
      "[epoch 15, batch    19] loss: 3.95974\n",
      "[epoch 15, batch    20] loss: 3.61806\n",
      "[epoch 15, batch    21] loss: 2.53981\n",
      "[epoch 15, batch    22] loss: 3.99914\n",
      "[epoch 15, batch    23] loss: 3.60405\n",
      "[epoch 15, batch    24] loss: 3.49866\n",
      "[epoch 15, batch    25] loss: 3.67840\n",
      "[epoch 15, batch    26] loss: 2.80273\n",
      "[epoch 15, batch    27] loss: 3.61975\n",
      "[epoch 15, batch    28] loss: 3.38039\n",
      "[epoch 15, batch    29] loss: 3.14974\n",
      "[epoch 15, batch    30] loss: 2.75558\n",
      "[epoch 15, batch    31] loss: 4.06837\n",
      "[epoch 15, batch    32] loss: 5.56869\n",
      "[epoch 16, batch     1] loss: 3.80077\n",
      "[epoch 16, batch     2] loss: 3.81562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 16, batch     3] loss: 3.78128\n",
      "[epoch 16, batch     4] loss: 3.20267\n",
      "[epoch 16, batch     5] loss: 3.40009\n",
      "[epoch 16, batch     6] loss: 4.02927\n",
      "[epoch 16, batch     7] loss: 2.93419\n",
      "[epoch 16, batch     8] loss: 3.77976\n",
      "[epoch 16, batch     9] loss: 3.81438\n",
      "[epoch 16, batch    10] loss: 2.38130\n",
      "[epoch 16, batch    11] loss: 3.00561\n",
      "[epoch 16, batch    12] loss: 3.30733\n",
      "[epoch 16, batch    13] loss: 3.73348\n",
      "[epoch 16, batch    14] loss: 3.27596\n",
      "[epoch 16, batch    15] loss: 3.81214\n",
      "[epoch 16, batch    16] loss: 3.05167\n",
      "[epoch 16, batch    17] loss: 3.09711\n",
      "[epoch 16, batch    18] loss: 3.53212\n",
      "[epoch 16, batch    19] loss: 3.62146\n",
      "[epoch 16, batch    20] loss: 2.97541\n",
      "[epoch 16, batch    21] loss: 3.37123\n",
      "[epoch 16, batch    22] loss: 4.76796\n",
      "[epoch 16, batch    23] loss: 3.37477\n",
      "[epoch 16, batch    24] loss: 3.57181\n",
      "[epoch 16, batch    25] loss: 3.10058\n",
      "[epoch 16, batch    26] loss: 2.90859\n",
      "[epoch 16, batch    27] loss: 3.94674\n",
      "[epoch 16, batch    28] loss: 3.85028\n",
      "[epoch 16, batch    29] loss: 3.12425\n",
      "[epoch 16, batch    30] loss: 2.48235\n",
      "[epoch 16, batch    31] loss: 3.39859\n",
      "[epoch 16, batch    32] loss: 4.41995\n",
      "[epoch 17, batch     1] loss: 3.70940\n",
      "[epoch 17, batch     2] loss: 3.02083\n",
      "[epoch 17, batch     3] loss: 2.70688\n",
      "[epoch 17, batch     4] loss: 3.59549\n",
      "[epoch 17, batch     5] loss: 3.38029\n",
      "[epoch 17, batch     6] loss: 3.75186\n",
      "[epoch 17, batch     7] loss: 3.98709\n",
      "[epoch 17, batch     8] loss: 4.03510\n",
      "[epoch 17, batch     9] loss: 2.91962\n",
      "[epoch 17, batch    10] loss: 3.26966\n",
      "[epoch 17, batch    11] loss: 3.87707\n",
      "[epoch 17, batch    12] loss: 3.48907\n",
      "[epoch 17, batch    13] loss: 3.91989\n",
      "[epoch 17, batch    14] loss: 3.83261\n",
      "[epoch 17, batch    15] loss: 3.34062\n",
      "[epoch 17, batch    16] loss: 3.96020\n",
      "[epoch 17, batch    17] loss: 3.46570\n",
      "[epoch 17, batch    18] loss: 3.03754\n",
      "[epoch 17, batch    19] loss: 2.72989\n",
      "[epoch 17, batch    20] loss: 3.89793\n",
      "[epoch 17, batch    21] loss: 3.16949\n",
      "[epoch 17, batch    22] loss: 3.44437\n",
      "[epoch 17, batch    23] loss: 2.97538\n",
      "[epoch 17, batch    24] loss: 2.56377\n",
      "[epoch 17, batch    25] loss: 2.99942\n",
      "[epoch 17, batch    26] loss: 4.13081\n",
      "[epoch 17, batch    27] loss: 3.18715\n",
      "[epoch 17, batch    28] loss: 3.59304\n",
      "[epoch 17, batch    29] loss: 3.19489\n",
      "[epoch 17, batch    30] loss: 3.44102\n",
      "[epoch 17, batch    31] loss: 4.29167\n",
      "[epoch 17, batch    32] loss: 1.12192\n",
      "[epoch 18, batch     1] loss: 3.88877\n",
      "[epoch 18, batch     2] loss: 3.14519\n",
      "[epoch 18, batch     3] loss: 4.00023\n",
      "[epoch 18, batch     4] loss: 3.21606\n",
      "[epoch 18, batch     5] loss: 3.72076\n",
      "[epoch 18, batch     6] loss: 2.92145\n",
      "[epoch 18, batch     7] loss: 3.23101\n",
      "[epoch 18, batch     8] loss: 3.78507\n",
      "[epoch 18, batch     9] loss: 3.64138\n",
      "[epoch 18, batch    10] loss: 3.26233\n",
      "[epoch 18, batch    11] loss: 2.89961\n",
      "[epoch 18, batch    12] loss: 3.28760\n",
      "[epoch 18, batch    13] loss: 3.24353\n",
      "[epoch 18, batch    14] loss: 2.68607\n",
      "[epoch 18, batch    15] loss: 2.91621\n",
      "[epoch 18, batch    16] loss: 4.25083\n",
      "[epoch 18, batch    17] loss: 3.42769\n",
      "[epoch 18, batch    18] loss: 3.80751\n",
      "[epoch 18, batch    19] loss: 3.77984\n",
      "[epoch 18, batch    20] loss: 3.78871\n",
      "[epoch 18, batch    21] loss: 3.07690\n",
      "[epoch 18, batch    22] loss: 2.71941\n",
      "[epoch 18, batch    23] loss: 3.59555\n",
      "[epoch 18, batch    24] loss: 4.48743\n",
      "[epoch 18, batch    25] loss: 3.43793\n",
      "[epoch 18, batch    26] loss: 2.69726\n",
      "[epoch 18, batch    27] loss: 3.41340\n",
      "[epoch 18, batch    28] loss: 3.71643\n",
      "[epoch 18, batch    29] loss: 3.59767\n",
      "[epoch 18, batch    30] loss: 2.43818\n",
      "[epoch 18, batch    31] loss: 3.99021\n",
      "[epoch 18, batch    32] loss: 3.83525\n",
      "[epoch 19, batch     1] loss: 4.45284\n",
      "[epoch 19, batch     2] loss: 3.91918\n",
      "[epoch 19, batch     3] loss: 4.00574\n",
      "[epoch 19, batch     4] loss: 3.28835\n",
      "[epoch 19, batch     5] loss: 2.96123\n",
      "[epoch 19, batch     6] loss: 3.86426\n",
      "[epoch 19, batch     7] loss: 2.81337\n",
      "[epoch 19, batch     8] loss: 2.72213\n",
      "[epoch 19, batch     9] loss: 4.09840\n",
      "[epoch 19, batch    10] loss: 3.36447\n",
      "[epoch 19, batch    11] loss: 2.73469\n",
      "[epoch 19, batch    12] loss: 4.19510\n",
      "[epoch 19, batch    13] loss: 3.88426\n",
      "[epoch 19, batch    14] loss: 2.73506\n",
      "[epoch 19, batch    15] loss: 4.20693\n",
      "[epoch 19, batch    16] loss: 3.33638\n",
      "[epoch 19, batch    17] loss: 2.61436\n",
      "[epoch 19, batch    18] loss: 3.15149\n",
      "[epoch 19, batch    19] loss: 3.35964\n",
      "[epoch 19, batch    20] loss: 2.59287\n",
      "[epoch 19, batch    21] loss: 3.10495\n",
      "[epoch 19, batch    22] loss: 3.61400\n",
      "[epoch 19, batch    23] loss: 3.35114\n",
      "[epoch 19, batch    24] loss: 4.42353\n",
      "[epoch 19, batch    25] loss: 3.66473\n",
      "[epoch 19, batch    26] loss: 3.14128\n",
      "[epoch 19, batch    27] loss: 4.26254\n",
      "[epoch 19, batch    28] loss: 3.45561\n",
      "[epoch 19, batch    29] loss: 2.30126\n",
      "[epoch 19, batch    30] loss: 3.80680\n",
      "[epoch 19, batch    31] loss: 2.92485\n",
      "[epoch 19, batch    32] loss: 2.18348\n",
      "[epoch 20, batch     1] loss: 3.37579\n",
      "[epoch 20, batch     2] loss: 3.78539\n",
      "[epoch 20, batch     3] loss: 4.26557\n",
      "[epoch 20, batch     4] loss: 3.34970\n",
      "[epoch 20, batch     5] loss: 2.65674\n",
      "[epoch 20, batch     6] loss: 3.08100\n",
      "[epoch 20, batch     7] loss: 3.20496\n",
      "[epoch 20, batch     8] loss: 3.64392\n",
      "[epoch 20, batch     9] loss: 3.30346\n",
      "[epoch 20, batch    10] loss: 3.27097\n",
      "[epoch 20, batch    11] loss: 2.55514\n",
      "[epoch 20, batch    12] loss: 3.32043\n",
      "[epoch 20, batch    13] loss: 3.20646\n",
      "[epoch 20, batch    14] loss: 3.39895\n",
      "[epoch 20, batch    15] loss: 2.89766\n",
      "[epoch 20, batch    16] loss: 2.59897\n",
      "[epoch 20, batch    17] loss: 3.40144\n",
      "[epoch 20, batch    18] loss: 4.24234\n",
      "[epoch 20, batch    19] loss: 3.36734\n",
      "[epoch 20, batch    20] loss: 3.07687\n",
      "[epoch 20, batch    21] loss: 3.71393\n",
      "[epoch 20, batch    22] loss: 3.66712\n",
      "[epoch 20, batch    23] loss: 3.26331\n",
      "[epoch 20, batch    24] loss: 4.02155\n",
      "[epoch 20, batch    25] loss: 3.39277\n",
      "[epoch 20, batch    26] loss: 3.65654\n",
      "[epoch 20, batch    27] loss: 3.38259\n",
      "[epoch 20, batch    28] loss: 3.32292\n",
      "[epoch 20, batch    29] loss: 4.01273\n",
      "[epoch 20, batch    30] loss: 3.11993\n",
      "[epoch 20, batch    31] loss: 4.30624\n",
      "[epoch 20, batch    32] loss: 3.49594\n",
      "[epoch 21, batch     1] loss: 3.59751\n",
      "[epoch 21, batch     2] loss: 3.33876\n",
      "[epoch 21, batch     3] loss: 3.74585\n",
      "[epoch 21, batch     4] loss: 3.65553\n",
      "[epoch 21, batch     5] loss: 3.04560\n",
      "[epoch 21, batch     6] loss: 2.91990\n",
      "[epoch 21, batch     7] loss: 3.87180\n",
      "[epoch 21, batch     8] loss: 4.09243\n",
      "[epoch 21, batch     9] loss: 4.38342\n",
      "[epoch 21, batch    10] loss: 3.37969\n",
      "[epoch 21, batch    11] loss: 3.39182\n",
      "[epoch 21, batch    12] loss: 3.45007\n",
      "[epoch 21, batch    13] loss: 3.10176\n",
      "[epoch 21, batch    14] loss: 3.98589\n",
      "[epoch 21, batch    15] loss: 4.44900\n",
      "[epoch 21, batch    16] loss: 3.66912\n",
      "[epoch 21, batch    17] loss: 2.89351\n",
      "[epoch 21, batch    18] loss: 3.39100\n",
      "[epoch 21, batch    19] loss: 3.73376\n",
      "[epoch 21, batch    20] loss: 2.88142\n",
      "[epoch 21, batch    21] loss: 3.19736\n",
      "[epoch 21, batch    22] loss: 3.06220\n",
      "[epoch 21, batch    23] loss: 3.10066\n",
      "[epoch 21, batch    24] loss: 4.15742\n",
      "[epoch 21, batch    25] loss: 3.48737\n",
      "[epoch 21, batch    26] loss: 3.41057\n",
      "[epoch 21, batch    27] loss: 3.33735\n",
      "[epoch 21, batch    28] loss: 3.01384\n",
      "[epoch 21, batch    29] loss: 2.18567\n",
      "[epoch 21, batch    30] loss: 2.77810\n",
      "[epoch 21, batch    31] loss: 2.82006\n",
      "[epoch 21, batch    32] loss: 4.09793\n",
      "[epoch 22, batch     1] loss: 3.48052\n",
      "[epoch 22, batch     2] loss: 2.85696\n",
      "[epoch 22, batch     3] loss: 2.34963\n",
      "[epoch 22, batch     4] loss: 2.77024\n",
      "[epoch 22, batch     5] loss: 3.72135\n",
      "[epoch 22, batch     6] loss: 2.42223\n",
      "[epoch 22, batch     7] loss: 3.48845\n",
      "[epoch 22, batch     8] loss: 2.98893\n",
      "[epoch 22, batch     9] loss: 3.42782\n",
      "[epoch 22, batch    10] loss: 3.45717\n",
      "[epoch 22, batch    11] loss: 3.15784\n",
      "[epoch 22, batch    12] loss: 3.56191\n",
      "[epoch 22, batch    13] loss: 4.20657\n",
      "[epoch 22, batch    14] loss: 3.12664\n",
      "[epoch 22, batch    15] loss: 3.81169\n",
      "[epoch 22, batch    16] loss: 3.63226\n",
      "[epoch 22, batch    17] loss: 2.88964\n",
      "[epoch 22, batch    18] loss: 3.25679\n",
      "[epoch 22, batch    19] loss: 3.47235\n",
      "[epoch 22, batch    20] loss: 3.96937\n",
      "[epoch 22, batch    21] loss: 3.85515\n",
      "[epoch 22, batch    22] loss: 3.41074\n",
      "[epoch 22, batch    23] loss: 3.81070\n",
      "[epoch 22, batch    24] loss: 3.16226\n",
      "[epoch 22, batch    25] loss: 3.49680\n",
      "[epoch 22, batch    26] loss: 3.29672\n",
      "[epoch 22, batch    27] loss: 3.42899\n",
      "[epoch 22, batch    28] loss: 3.90231\n",
      "[epoch 22, batch    29] loss: 2.81280\n",
      "[epoch 22, batch    30] loss: 4.03119\n",
      "[epoch 22, batch    31] loss: 4.23577\n",
      "[epoch 22, batch    32] loss: 3.85561\n",
      "[epoch 23, batch     1] loss: 3.96595\n",
      "[epoch 23, batch     2] loss: 2.77885\n",
      "[epoch 23, batch     3] loss: 4.17576\n",
      "[epoch 23, batch     4] loss: 3.70375\n",
      "[epoch 23, batch     5] loss: 3.85592\n",
      "[epoch 23, batch     6] loss: 4.05716\n",
      "[epoch 23, batch     7] loss: 3.25913\n",
      "[epoch 23, batch     8] loss: 3.70265\n",
      "[epoch 23, batch     9] loss: 3.20038\n",
      "[epoch 23, batch    10] loss: 3.02759\n",
      "[epoch 23, batch    11] loss: 3.72693\n",
      "[epoch 23, batch    12] loss: 3.09193\n",
      "[epoch 23, batch    13] loss: 3.36170\n",
      "[epoch 23, batch    14] loss: 3.49710\n",
      "[epoch 23, batch    15] loss: 3.71790\n",
      "[epoch 23, batch    16] loss: 4.95548\n",
      "[epoch 23, batch    17] loss: 3.17970\n",
      "[epoch 23, batch    18] loss: 3.12590\n",
      "[epoch 23, batch    19] loss: 2.85590\n",
      "[epoch 23, batch    20] loss: 3.48810\n",
      "[epoch 23, batch    21] loss: 4.11979\n",
      "[epoch 23, batch    22] loss: 3.11035\n",
      "[epoch 23, batch    23] loss: 3.04740\n",
      "[epoch 23, batch    24] loss: 3.47562\n",
      "[epoch 23, batch    25] loss: 2.84497\n",
      "[epoch 23, batch    26] loss: 2.79849\n",
      "[epoch 23, batch    27] loss: 2.30750\n",
      "[epoch 23, batch    28] loss: 2.85765\n",
      "[epoch 23, batch    29] loss: 3.10068\n",
      "[epoch 23, batch    30] loss: 4.53418\n",
      "[epoch 23, batch    31] loss: 2.98144\n",
      "[epoch 23, batch    32] loss: 1.56075\n",
      "[epoch 24, batch     1] loss: 3.00865\n",
      "[epoch 24, batch     2] loss: 3.51731\n",
      "[epoch 24, batch     3] loss: 3.13604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 24, batch     4] loss: 3.77685\n",
      "[epoch 24, batch     5] loss: 3.35307\n",
      "[epoch 24, batch     6] loss: 3.69245\n",
      "[epoch 24, batch     7] loss: 3.82004\n",
      "[epoch 24, batch     8] loss: 3.43432\n",
      "[epoch 24, batch     9] loss: 3.28199\n",
      "[epoch 24, batch    10] loss: 3.91248\n",
      "[epoch 24, batch    11] loss: 2.79394\n",
      "[epoch 24, batch    12] loss: 4.39061\n",
      "[epoch 24, batch    13] loss: 3.61430\n",
      "[epoch 24, batch    14] loss: 2.83681\n",
      "[epoch 24, batch    15] loss: 3.90331\n",
      "[epoch 24, batch    16] loss: 3.85110\n",
      "[epoch 24, batch    17] loss: 3.53132\n",
      "[epoch 24, batch    18] loss: 3.49472\n",
      "[epoch 24, batch    19] loss: 3.67094\n",
      "[epoch 24, batch    20] loss: 3.07641\n",
      "[epoch 24, batch    21] loss: 2.61299\n",
      "[epoch 24, batch    22] loss: 3.21452\n",
      "[epoch 24, batch    23] loss: 3.57969\n",
      "[epoch 24, batch    24] loss: 3.24383\n",
      "[epoch 24, batch    25] loss: 2.83855\n",
      "[epoch 24, batch    26] loss: 3.86625\n",
      "[epoch 24, batch    27] loss: 3.67234\n",
      "[epoch 24, batch    28] loss: 3.25541\n",
      "[epoch 24, batch    29] loss: 3.63214\n",
      "[epoch 24, batch    30] loss: 2.63324\n",
      "[epoch 24, batch    31] loss: 2.90687\n",
      "[epoch 24, batch    32] loss: 2.20912\n",
      "[epoch 25, batch     1] loss: 3.18283\n",
      "[epoch 25, batch     2] loss: 2.69670\n",
      "[epoch 25, batch     3] loss: 3.47397\n",
      "[epoch 25, batch     4] loss: 3.74479\n",
      "[epoch 25, batch     5] loss: 2.74429\n",
      "[epoch 25, batch     6] loss: 3.29277\n",
      "[epoch 25, batch     7] loss: 3.31699\n",
      "[epoch 25, batch     8] loss: 3.84639\n",
      "[epoch 25, batch     9] loss: 3.29522\n",
      "[epoch 25, batch    10] loss: 3.52009\n",
      "[epoch 25, batch    11] loss: 4.39624\n",
      "[epoch 25, batch    12] loss: 3.55771\n",
      "[epoch 25, batch    13] loss: 3.36190\n",
      "[epoch 25, batch    14] loss: 3.27490\n",
      "[epoch 25, batch    15] loss: 3.27880\n",
      "[epoch 25, batch    16] loss: 4.20683\n",
      "[epoch 25, batch    17] loss: 3.33102\n",
      "[epoch 25, batch    18] loss: 3.14378\n",
      "[epoch 25, batch    19] loss: 3.61283\n",
      "[epoch 25, batch    20] loss: 3.99513\n",
      "[epoch 25, batch    21] loss: 3.70356\n",
      "[epoch 25, batch    22] loss: 2.82023\n",
      "[epoch 25, batch    23] loss: 3.12206\n",
      "[epoch 25, batch    24] loss: 3.13216\n",
      "[epoch 25, batch    25] loss: 3.35935\n",
      "[epoch 25, batch    26] loss: 3.19295\n",
      "[epoch 25, batch    27] loss: 4.36145\n",
      "[epoch 25, batch    28] loss: 3.32055\n",
      "[epoch 25, batch    29] loss: 3.67042\n",
      "[epoch 25, batch    30] loss: 2.65674\n",
      "[epoch 25, batch    31] loss: 2.69943\n",
      "[epoch 25, batch    32] loss: 2.51208\n",
      "[epoch 26, batch     1] loss: 4.10938\n",
      "[epoch 26, batch     2] loss: 3.44853\n",
      "[epoch 26, batch     3] loss: 3.28382\n",
      "[epoch 26, batch     4] loss: 3.00067\n",
      "[epoch 26, batch     5] loss: 4.06770\n",
      "[epoch 26, batch     6] loss: 3.38549\n",
      "[epoch 26, batch     7] loss: 3.72962\n",
      "[epoch 26, batch     8] loss: 3.36093\n",
      "[epoch 26, batch     9] loss: 2.27111\n",
      "[epoch 26, batch    10] loss: 3.94514\n",
      "[epoch 26, batch    11] loss: 3.74343\n",
      "[epoch 26, batch    12] loss: 3.26803\n",
      "[epoch 26, batch    13] loss: 3.68124\n",
      "[epoch 26, batch    14] loss: 3.92769\n",
      "[epoch 26, batch    15] loss: 4.15209\n",
      "[epoch 26, batch    16] loss: 3.92671\n",
      "[epoch 26, batch    17] loss: 2.59593\n",
      "[epoch 26, batch    18] loss: 3.49638\n",
      "[epoch 26, batch    19] loss: 4.05685\n",
      "[epoch 26, batch    20] loss: 3.21057\n",
      "[epoch 26, batch    21] loss: 3.03397\n",
      "[epoch 26, batch    22] loss: 3.62241\n",
      "[epoch 26, batch    23] loss: 3.65895\n",
      "[epoch 26, batch    24] loss: 3.01361\n",
      "[epoch 26, batch    25] loss: 3.21233\n",
      "[epoch 26, batch    26] loss: 3.04941\n",
      "[epoch 26, batch    27] loss: 3.09015\n",
      "[epoch 26, batch    28] loss: 3.01525\n",
      "[epoch 26, batch    29] loss: 2.64317\n",
      "[epoch 26, batch    30] loss: 2.78039\n",
      "[epoch 26, batch    31] loss: 3.07748\n",
      "[epoch 26, batch    32] loss: 3.93446\n",
      "[epoch 27, batch     1] loss: 2.71037\n",
      "[epoch 27, batch     2] loss: 3.80832\n",
      "[epoch 27, batch     3] loss: 3.96834\n",
      "[epoch 27, batch     4] loss: 3.13365\n",
      "[epoch 27, batch     5] loss: 3.14293\n",
      "[epoch 27, batch     6] loss: 2.75671\n",
      "[epoch 27, batch     7] loss: 3.75087\n",
      "[epoch 27, batch     8] loss: 3.52033\n",
      "[epoch 27, batch     9] loss: 4.27981\n",
      "[epoch 27, batch    10] loss: 2.26444\n",
      "[epoch 27, batch    11] loss: 3.58976\n",
      "[epoch 27, batch    12] loss: 3.01194\n",
      "[epoch 27, batch    13] loss: 4.12551\n",
      "[epoch 27, batch    14] loss: 2.63654\n",
      "[epoch 27, batch    15] loss: 2.91830\n",
      "[epoch 27, batch    16] loss: 3.36316\n",
      "[epoch 27, batch    17] loss: 3.41787\n",
      "[epoch 27, batch    18] loss: 3.45135\n",
      "[epoch 27, batch    19] loss: 3.27151\n",
      "[epoch 27, batch    20] loss: 3.42234\n",
      "[epoch 27, batch    21] loss: 4.28624\n",
      "[epoch 27, batch    22] loss: 2.93986\n",
      "[epoch 27, batch    23] loss: 3.06298\n",
      "[epoch 27, batch    24] loss: 3.05760\n",
      "[epoch 27, batch    25] loss: 3.69392\n",
      "[epoch 27, batch    26] loss: 4.09267\n",
      "[epoch 27, batch    27] loss: 3.44646\n",
      "[epoch 27, batch    28] loss: 3.30344\n",
      "[epoch 27, batch    29] loss: 4.15459\n",
      "[epoch 27, batch    30] loss: 3.18637\n",
      "[epoch 27, batch    31] loss: 3.22362\n",
      "[epoch 27, batch    32] loss: 2.43745\n",
      "[epoch 28, batch     1] loss: 3.05858\n",
      "[epoch 28, batch     2] loss: 3.54449\n",
      "[epoch 28, batch     3] loss: 4.04426\n",
      "[epoch 28, batch     4] loss: 3.05384\n",
      "[epoch 28, batch     5] loss: 2.93891\n",
      "[epoch 28, batch     6] loss: 4.02351\n",
      "[epoch 28, batch     7] loss: 3.89599\n",
      "[epoch 28, batch     8] loss: 3.76034\n",
      "[epoch 28, batch     9] loss: 3.21922\n",
      "[epoch 28, batch    10] loss: 3.65912\n",
      "[epoch 28, batch    11] loss: 2.39908\n",
      "[epoch 28, batch    12] loss: 3.09827\n",
      "[epoch 28, batch    13] loss: 3.08559\n",
      "[epoch 28, batch    14] loss: 3.97739\n",
      "[epoch 28, batch    15] loss: 3.20223\n",
      "[epoch 28, batch    16] loss: 3.94769\n",
      "[epoch 28, batch    17] loss: 3.64671\n",
      "[epoch 28, batch    18] loss: 3.53501\n",
      "[epoch 28, batch    19] loss: 3.16171\n",
      "[epoch 28, batch    20] loss: 3.82518\n",
      "[epoch 28, batch    21] loss: 3.11918\n",
      "[epoch 28, batch    22] loss: 3.20790\n",
      "[epoch 28, batch    23] loss: 2.84364\n",
      "[epoch 28, batch    24] loss: 3.15230\n",
      "[epoch 28, batch    25] loss: 3.37255\n",
      "[epoch 28, batch    26] loss: 3.14651\n",
      "[epoch 28, batch    27] loss: 3.29348\n",
      "[epoch 28, batch    28] loss: 3.45226\n",
      "[epoch 28, batch    29] loss: 3.08111\n",
      "[epoch 28, batch    30] loss: 3.95580\n",
      "[epoch 28, batch    31] loss: 3.05053\n",
      "[epoch 28, batch    32] loss: 3.03024\n",
      "[epoch 29, batch     1] loss: 2.84658\n",
      "[epoch 29, batch     2] loss: 4.22246\n",
      "[epoch 29, batch     3] loss: 3.95081\n",
      "[epoch 29, batch     4] loss: 3.43850\n",
      "[epoch 29, batch     5] loss: 4.06609\n",
      "[epoch 29, batch     6] loss: 3.49145\n",
      "[epoch 29, batch     7] loss: 3.02003\n",
      "[epoch 29, batch     8] loss: 3.03046\n",
      "[epoch 29, batch     9] loss: 3.81897\n",
      "[epoch 29, batch    10] loss: 3.53918\n",
      "[epoch 29, batch    11] loss: 3.37932\n",
      "[epoch 29, batch    12] loss: 3.61202\n",
      "[epoch 29, batch    13] loss: 3.30614\n",
      "[epoch 29, batch    14] loss: 3.56341\n",
      "[epoch 29, batch    15] loss: 2.44998\n",
      "[epoch 29, batch    16] loss: 3.49136\n",
      "[epoch 29, batch    17] loss: 2.16056\n",
      "[epoch 29, batch    18] loss: 3.69818\n",
      "[epoch 29, batch    19] loss: 4.20459\n",
      "[epoch 29, batch    20] loss: 3.92436\n",
      "[epoch 29, batch    21] loss: 2.75706\n",
      "[epoch 29, batch    22] loss: 2.67981\n",
      "[epoch 29, batch    23] loss: 4.65786\n",
      "[epoch 29, batch    24] loss: 2.90283\n",
      "[epoch 29, batch    25] loss: 3.37103\n",
      "[epoch 29, batch    26] loss: 3.17027\n",
      "[epoch 29, batch    27] loss: 3.57404\n",
      "[epoch 29, batch    28] loss: 3.60653\n",
      "[epoch 29, batch    29] loss: 3.05225\n",
      "[epoch 29, batch    30] loss: 3.42071\n",
      "[epoch 29, batch    31] loss: 2.20320\n",
      "[epoch 29, batch    32] loss: 3.08826\n",
      "[epoch 30, batch     1] loss: 3.85874\n",
      "[epoch 30, batch     2] loss: 3.24738\n",
      "[epoch 30, batch     3] loss: 3.35951\n",
      "[epoch 30, batch     4] loss: 3.60343\n",
      "[epoch 30, batch     5] loss: 2.58587\n",
      "[epoch 30, batch     6] loss: 3.80260\n",
      "[epoch 30, batch     7] loss: 3.48133\n",
      "[epoch 30, batch     8] loss: 3.57797\n",
      "[epoch 30, batch     9] loss: 3.77857\n",
      "[epoch 30, batch    10] loss: 3.26903\n",
      "[epoch 30, batch    11] loss: 3.69147\n",
      "[epoch 30, batch    12] loss: 3.72659\n",
      "[epoch 30, batch    13] loss: 4.31769\n",
      "[epoch 30, batch    14] loss: 3.14601\n",
      "[epoch 30, batch    15] loss: 4.38670\n",
      "[epoch 30, batch    16] loss: 3.09567\n",
      "[epoch 30, batch    17] loss: 3.45688\n",
      "[epoch 30, batch    18] loss: 2.72799\n",
      "[epoch 30, batch    19] loss: 2.83691\n",
      "[epoch 30, batch    20] loss: 3.20913\n",
      "[epoch 30, batch    21] loss: 3.43819\n",
      "[epoch 30, batch    22] loss: 3.18603\n",
      "[epoch 30, batch    23] loss: 3.21239\n",
      "[epoch 30, batch    24] loss: 3.16935\n",
      "[epoch 30, batch    25] loss: 2.56785\n",
      "[epoch 30, batch    26] loss: 2.97907\n",
      "[epoch 30, batch    27] loss: 3.37990\n",
      "[epoch 30, batch    28] loss: 3.66885\n",
      "[epoch 30, batch    29] loss: 3.43107\n",
      "[epoch 30, batch    30] loss: 2.82379\n",
      "[epoch 30, batch    31] loss: 3.46740\n",
      "[epoch 30, batch    32] loss: 2.60485\n",
      "[epoch 31, batch     1] loss: 2.65924\n",
      "[epoch 31, batch     2] loss: 3.17120\n",
      "[epoch 31, batch     3] loss: 3.50113\n",
      "[epoch 31, batch     4] loss: 3.33014\n",
      "[epoch 31, batch     5] loss: 2.91200\n",
      "[epoch 31, batch     6] loss: 3.65314\n",
      "[epoch 31, batch     7] loss: 2.79568\n",
      "[epoch 31, batch     8] loss: 2.99609\n",
      "[epoch 31, batch     9] loss: 3.44418\n",
      "[epoch 31, batch    10] loss: 3.64085\n",
      "[epoch 31, batch    11] loss: 3.39654\n",
      "[epoch 31, batch    12] loss: 3.79190\n",
      "[epoch 31, batch    13] loss: 2.91565\n",
      "[epoch 31, batch    14] loss: 3.60207\n",
      "[epoch 31, batch    15] loss: 2.59418\n",
      "[epoch 31, batch    16] loss: 4.03866\n",
      "[epoch 31, batch    17] loss: 3.25133\n",
      "[epoch 31, batch    18] loss: 3.56634\n",
      "[epoch 31, batch    19] loss: 3.32863\n",
      "[epoch 31, batch    20] loss: 3.16440\n",
      "[epoch 31, batch    21] loss: 3.37973\n",
      "[epoch 31, batch    22] loss: 4.39936\n",
      "[epoch 31, batch    23] loss: 2.98954\n",
      "[epoch 31, batch    24] loss: 2.57038\n",
      "[epoch 31, batch    25] loss: 3.64097\n",
      "[epoch 31, batch    26] loss: 3.56561\n",
      "[epoch 31, batch    27] loss: 2.57128\n",
      "[epoch 31, batch    28] loss: 4.03935\n",
      "[epoch 31, batch    29] loss: 4.16728\n",
      "[epoch 31, batch    30] loss: 3.83180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 31, batch    31] loss: 3.12258\n",
      "[epoch 31, batch    32] loss: 3.82614\n",
      "[epoch 32, batch     1] loss: 4.26701\n",
      "[epoch 32, batch     2] loss: 3.48805\n",
      "[epoch 32, batch     3] loss: 3.43302\n",
      "[epoch 32, batch     4] loss: 3.42388\n",
      "[epoch 32, batch     5] loss: 3.09778\n",
      "[epoch 32, batch     6] loss: 4.13429\n",
      "[epoch 32, batch     7] loss: 2.89932\n",
      "[epoch 32, batch     8] loss: 2.79807\n",
      "[epoch 32, batch     9] loss: 3.70676\n",
      "[epoch 32, batch    10] loss: 3.50078\n",
      "[epoch 32, batch    11] loss: 4.29234\n",
      "[epoch 32, batch    12] loss: 3.72655\n",
      "[epoch 32, batch    13] loss: 2.85703\n",
      "[epoch 32, batch    14] loss: 2.40131\n",
      "[epoch 32, batch    15] loss: 3.00844\n",
      "[epoch 32, batch    16] loss: 3.35896\n",
      "[epoch 32, batch    17] loss: 4.23416\n",
      "[epoch 32, batch    18] loss: 2.74208\n",
      "[epoch 32, batch    19] loss: 3.43402\n",
      "[epoch 32, batch    20] loss: 3.82413\n",
      "[epoch 32, batch    21] loss: 3.87625\n",
      "[epoch 32, batch    22] loss: 3.56868\n",
      "[epoch 32, batch    23] loss: 2.38344\n",
      "[epoch 32, batch    24] loss: 3.29948\n",
      "[epoch 32, batch    25] loss: 2.28230\n",
      "[epoch 32, batch    26] loss: 2.57391\n",
      "[epoch 32, batch    27] loss: 2.67828\n",
      "[epoch 32, batch    28] loss: 3.64162\n",
      "[epoch 32, batch    29] loss: 3.92715\n",
      "[epoch 32, batch    30] loss: 4.16117\n",
      "[epoch 32, batch    31] loss: 2.81948\n",
      "[epoch 32, batch    32] loss: 3.93695\n",
      "[epoch 33, batch     1] loss: 2.69254\n",
      "[epoch 33, batch     2] loss: 4.41982\n",
      "[epoch 33, batch     3] loss: 4.39587\n",
      "[epoch 33, batch     4] loss: 2.78526\n",
      "[epoch 33, batch     5] loss: 3.86501\n",
      "[epoch 33, batch     6] loss: 2.67864\n",
      "[epoch 33, batch     7] loss: 2.86667\n",
      "[epoch 33, batch     8] loss: 2.94926\n",
      "[epoch 33, batch     9] loss: 3.17654\n",
      "[epoch 33, batch    10] loss: 2.45623\n",
      "[epoch 33, batch    11] loss: 3.57398\n",
      "[epoch 33, batch    12] loss: 2.88416\n",
      "[epoch 33, batch    13] loss: 3.13706\n",
      "[epoch 33, batch    14] loss: 3.64991\n",
      "[epoch 33, batch    15] loss: 2.74693\n",
      "[epoch 33, batch    16] loss: 2.78474\n",
      "[epoch 33, batch    17] loss: 3.72318\n",
      "[epoch 33, batch    18] loss: 4.80491\n",
      "[epoch 33, batch    19] loss: 3.29922\n",
      "[epoch 33, batch    20] loss: 4.40116\n",
      "[epoch 33, batch    21] loss: 2.73304\n",
      "[epoch 33, batch    22] loss: 3.65855\n",
      "[epoch 33, batch    23] loss: 3.30320\n",
      "[epoch 33, batch    24] loss: 4.11267\n",
      "[epoch 33, batch    25] loss: 3.23201\n",
      "[epoch 33, batch    26] loss: 2.69072\n",
      "[epoch 33, batch    27] loss: 3.14089\n",
      "[epoch 33, batch    28] loss: 3.13129\n",
      "[epoch 33, batch    29] loss: 3.48796\n",
      "[epoch 33, batch    30] loss: 3.49895\n",
      "[epoch 33, batch    31] loss: 4.01195\n",
      "[epoch 33, batch    32] loss: 1.38456\n",
      "[epoch 34, batch     1] loss: 3.69600\n",
      "[epoch 34, batch     2] loss: 3.23379\n",
      "[epoch 34, batch     3] loss: 3.00247\n",
      "[epoch 34, batch     4] loss: 3.66427\n",
      "[epoch 34, batch     5] loss: 3.42905\n",
      "[epoch 34, batch     6] loss: 3.47896\n",
      "[epoch 34, batch     7] loss: 3.06458\n",
      "[epoch 34, batch     8] loss: 4.32969\n",
      "[epoch 34, batch     9] loss: 3.43615\n",
      "[epoch 34, batch    10] loss: 3.37343\n",
      "[epoch 34, batch    11] loss: 2.63120\n",
      "[epoch 34, batch    12] loss: 3.26303\n",
      "[epoch 34, batch    13] loss: 3.47360\n",
      "[epoch 34, batch    14] loss: 3.12493\n",
      "[epoch 34, batch    15] loss: 3.85610\n",
      "[epoch 34, batch    16] loss: 3.24251\n",
      "[epoch 34, batch    17] loss: 2.63484\n",
      "[epoch 34, batch    18] loss: 3.59923\n",
      "[epoch 34, batch    19] loss: 3.43208\n",
      "[epoch 34, batch    20] loss: 2.75998\n",
      "[epoch 34, batch    21] loss: 3.17194\n",
      "[epoch 34, batch    22] loss: 3.50473\n",
      "[epoch 34, batch    23] loss: 3.71532\n",
      "[epoch 34, batch    24] loss: 2.67906\n",
      "[epoch 34, batch    25] loss: 4.26097\n",
      "[epoch 34, batch    26] loss: 3.00922\n",
      "[epoch 34, batch    27] loss: 2.77001\n",
      "[epoch 34, batch    28] loss: 3.55948\n",
      "[epoch 34, batch    29] loss: 3.73824\n",
      "[epoch 34, batch    30] loss: 3.23235\n",
      "[epoch 34, batch    31] loss: 3.26613\n",
      "[epoch 34, batch    32] loss: 3.13556\n",
      "[epoch 35, batch     1] loss: 3.81433\n",
      "[epoch 35, batch     2] loss: 3.54068\n",
      "[epoch 35, batch     3] loss: 3.06224\n",
      "[epoch 35, batch     4] loss: 3.06164\n",
      "[epoch 35, batch     5] loss: 2.92717\n",
      "[epoch 35, batch     6] loss: 3.11655\n",
      "[epoch 35, batch     7] loss: 3.31672\n",
      "[epoch 35, batch     8] loss: 3.23981\n",
      "[epoch 35, batch     9] loss: 3.50094\n",
      "[epoch 35, batch    10] loss: 3.30772\n",
      "[epoch 35, batch    11] loss: 3.73692\n",
      "[epoch 35, batch    12] loss: 2.83137\n",
      "[epoch 35, batch    13] loss: 3.13489\n",
      "[epoch 35, batch    14] loss: 2.80217\n",
      "[epoch 35, batch    15] loss: 3.98876\n",
      "[epoch 35, batch    16] loss: 3.99244\n",
      "[epoch 35, batch    17] loss: 4.11807\n",
      "[epoch 35, batch    18] loss: 3.37258\n",
      "[epoch 35, batch    19] loss: 3.78284\n",
      "[epoch 35, batch    20] loss: 3.90512\n",
      "[epoch 35, batch    21] loss: 3.04197\n",
      "[epoch 35, batch    22] loss: 2.78981\n",
      "[epoch 35, batch    23] loss: 3.57321\n",
      "[epoch 35, batch    24] loss: 3.43988\n",
      "[epoch 35, batch    25] loss: 2.65460\n",
      "[epoch 35, batch    26] loss: 3.16274\n",
      "[epoch 35, batch    27] loss: 2.90875\n",
      "[epoch 35, batch    28] loss: 3.19419\n",
      "[epoch 35, batch    29] loss: 3.21303\n",
      "[epoch 35, batch    30] loss: 4.14112\n",
      "[epoch 35, batch    31] loss: 2.79947\n",
      "[epoch 35, batch    32] loss: 2.95486\n",
      "[epoch 36, batch     1] loss: 3.34596\n",
      "[epoch 36, batch     2] loss: 3.78569\n",
      "[epoch 36, batch     3] loss: 2.62826\n",
      "[epoch 36, batch     4] loss: 2.81192\n",
      "[epoch 36, batch     5] loss: 3.25429\n",
      "[epoch 36, batch     6] loss: 4.10761\n",
      "[epoch 36, batch     7] loss: 3.11531\n",
      "[epoch 36, batch     8] loss: 2.81339\n",
      "[epoch 36, batch     9] loss: 2.90744\n",
      "[epoch 36, batch    10] loss: 3.38569\n",
      "[epoch 36, batch    11] loss: 3.00740\n",
      "[epoch 36, batch    12] loss: 4.55662\n",
      "[epoch 36, batch    13] loss: 3.81133\n",
      "[epoch 36, batch    14] loss: 4.14474\n",
      "[epoch 36, batch    15] loss: 3.03354\n",
      "[epoch 36, batch    16] loss: 2.58108\n",
      "[epoch 36, batch    17] loss: 3.33898\n",
      "[epoch 36, batch    18] loss: 2.90462\n",
      "[epoch 36, batch    19] loss: 3.38050\n",
      "[epoch 36, batch    20] loss: 3.24710\n",
      "[epoch 36, batch    21] loss: 3.53690\n",
      "[epoch 36, batch    22] loss: 4.16464\n",
      "[epoch 36, batch    23] loss: 2.70393\n",
      "[epoch 36, batch    24] loss: 3.90797\n",
      "[epoch 36, batch    25] loss: 2.96560\n",
      "[epoch 36, batch    26] loss: 3.56960\n",
      "[epoch 36, batch    27] loss: 3.50081\n",
      "[epoch 36, batch    28] loss: 2.55826\n",
      "[epoch 36, batch    29] loss: 3.44866\n",
      "[epoch 36, batch    30] loss: 3.37263\n",
      "[epoch 36, batch    31] loss: 3.52034\n",
      "[epoch 36, batch    32] loss: 3.00248\n",
      "[epoch 37, batch     1] loss: 3.00625\n",
      "[epoch 37, batch     2] loss: 3.61899\n",
      "[epoch 37, batch     3] loss: 2.86862\n",
      "[epoch 37, batch     4] loss: 2.29895\n",
      "[epoch 37, batch     5] loss: 3.57584\n",
      "[epoch 37, batch     6] loss: 3.30172\n",
      "[epoch 37, batch     7] loss: 3.44981\n",
      "[epoch 37, batch     8] loss: 3.47576\n",
      "[epoch 37, batch     9] loss: 3.79045\n",
      "[epoch 37, batch    10] loss: 2.82123\n",
      "[epoch 37, batch    11] loss: 3.28893\n",
      "[epoch 37, batch    12] loss: 2.57412\n",
      "[epoch 37, batch    13] loss: 3.68964\n",
      "[epoch 37, batch    14] loss: 3.71700\n",
      "[epoch 37, batch    15] loss: 2.74405\n",
      "[epoch 37, batch    16] loss: 2.77938\n",
      "[epoch 37, batch    17] loss: 3.92544\n",
      "[epoch 37, batch    18] loss: 3.40827\n",
      "[epoch 37, batch    19] loss: 3.67345\n",
      "[epoch 37, batch    20] loss: 3.38653\n",
      "[epoch 37, batch    21] loss: 3.97567\n",
      "[epoch 37, batch    22] loss: 3.61905\n",
      "[epoch 37, batch    23] loss: 3.69686\n",
      "[epoch 37, batch    24] loss: 3.56613\n",
      "[epoch 37, batch    25] loss: 3.30773\n",
      "[epoch 37, batch    26] loss: 3.47339\n",
      "[epoch 37, batch    27] loss: 3.03178\n",
      "[epoch 37, batch    28] loss: 2.94735\n",
      "[epoch 37, batch    29] loss: 3.53455\n",
      "[epoch 37, batch    30] loss: 3.55830\n",
      "[epoch 37, batch    31] loss: 3.38635\n",
      "[epoch 37, batch    32] loss: 1.89165\n",
      "[epoch 38, batch     1] loss: 3.07294\n",
      "[epoch 38, batch     2] loss: 3.27875\n",
      "[epoch 38, batch     3] loss: 2.92984\n",
      "[epoch 38, batch     4] loss: 2.19302\n",
      "[epoch 38, batch     5] loss: 3.36252\n",
      "[epoch 38, batch     6] loss: 2.79846\n",
      "[epoch 38, batch     7] loss: 3.54924\n",
      "[epoch 38, batch     8] loss: 3.41033\n",
      "[epoch 38, batch     9] loss: 3.70489\n",
      "[epoch 38, batch    10] loss: 3.63642\n",
      "[epoch 38, batch    11] loss: 4.34071\n",
      "[epoch 38, batch    12] loss: 3.02279\n",
      "[epoch 38, batch    13] loss: 3.03418\n",
      "[epoch 38, batch    14] loss: 3.15917\n",
      "[epoch 38, batch    15] loss: 3.60515\n",
      "[epoch 38, batch    16] loss: 3.65368\n",
      "[epoch 38, batch    17] loss: 3.64616\n",
      "[epoch 38, batch    18] loss: 2.82136\n",
      "[epoch 38, batch    19] loss: 3.43203\n",
      "[epoch 38, batch    20] loss: 3.97517\n",
      "[epoch 38, batch    21] loss: 3.93545\n",
      "[epoch 38, batch    22] loss: 3.05818\n",
      "[epoch 38, batch    23] loss: 3.80519\n",
      "[epoch 38, batch    24] loss: 3.51358\n",
      "[epoch 38, batch    25] loss: 3.20077\n",
      "[epoch 38, batch    26] loss: 3.03551\n",
      "[epoch 38, batch    27] loss: 3.44277\n",
      "[epoch 38, batch    28] loss: 3.84698\n",
      "[epoch 38, batch    29] loss: 2.84108\n",
      "[epoch 38, batch    30] loss: 3.01085\n",
      "[epoch 38, batch    31] loss: 2.73281\n",
      "[epoch 38, batch    32] loss: 3.03229\n",
      "[epoch 39, batch     1] loss: 2.70993\n",
      "[epoch 39, batch     2] loss: 3.93044\n",
      "[epoch 39, batch     3] loss: 3.54566\n",
      "[epoch 39, batch     4] loss: 3.25760\n",
      "[epoch 39, batch     5] loss: 3.86647\n",
      "[epoch 39, batch     6] loss: 3.03123\n",
      "[epoch 39, batch     7] loss: 2.95877\n",
      "[epoch 39, batch     8] loss: 4.16926\n",
      "[epoch 39, batch     9] loss: 4.23599\n",
      "[epoch 39, batch    10] loss: 3.84325\n",
      "[epoch 39, batch    11] loss: 2.75544\n",
      "[epoch 39, batch    12] loss: 4.81684\n",
      "[epoch 39, batch    13] loss: 3.80111\n",
      "[epoch 39, batch    14] loss: 2.56690\n",
      "[epoch 39, batch    15] loss: 3.17576\n",
      "[epoch 39, batch    16] loss: 3.46635\n",
      "[epoch 39, batch    17] loss: 3.18237\n",
      "[epoch 39, batch    18] loss: 4.36138\n",
      "[epoch 39, batch    19] loss: 3.54313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 39, batch    20] loss: 2.72403\n",
      "[epoch 39, batch    21] loss: 2.26268\n",
      "[epoch 39, batch    22] loss: 2.60834\n",
      "[epoch 39, batch    23] loss: 3.12927\n",
      "[epoch 39, batch    24] loss: 2.74638\n",
      "[epoch 39, batch    25] loss: 3.56541\n",
      "[epoch 39, batch    26] loss: 3.88229\n",
      "[epoch 39, batch    27] loss: 3.44863\n",
      "[epoch 39, batch    28] loss: 3.59385\n",
      "[epoch 39, batch    29] loss: 2.26116\n",
      "[epoch 39, batch    30] loss: 3.04461\n",
      "[epoch 39, batch    31] loss: 2.46435\n",
      "[epoch 39, batch    32] loss: 2.70336\n",
      "[epoch 40, batch     1] loss: 3.37545\n",
      "[epoch 40, batch     2] loss: 3.08029\n",
      "[epoch 40, batch     3] loss: 3.16273\n",
      "[epoch 40, batch     4] loss: 3.82066\n",
      "[epoch 40, batch     5] loss: 3.99042\n",
      "[epoch 40, batch     6] loss: 4.08899\n",
      "[epoch 40, batch     7] loss: 3.34101\n",
      "[epoch 40, batch     8] loss: 2.89965\n",
      "[epoch 40, batch     9] loss: 2.25181\n",
      "[epoch 40, batch    10] loss: 3.23279\n",
      "[epoch 40, batch    11] loss: 3.28629\n",
      "[epoch 40, batch    12] loss: 3.43191\n",
      "[epoch 40, batch    13] loss: 3.72036\n",
      "[epoch 40, batch    14] loss: 3.30970\n",
      "[epoch 40, batch    15] loss: 3.42177\n",
      "[epoch 40, batch    16] loss: 3.62969\n",
      "[epoch 40, batch    17] loss: 3.02976\n",
      "[epoch 40, batch    18] loss: 3.66914\n",
      "[epoch 40, batch    19] loss: 2.97522\n",
      "[epoch 40, batch    20] loss: 3.75310\n",
      "[epoch 40, batch    21] loss: 2.78688\n",
      "[epoch 40, batch    22] loss: 3.07445\n",
      "[epoch 40, batch    23] loss: 3.08000\n",
      "[epoch 40, batch    24] loss: 2.59951\n",
      "[epoch 40, batch    25] loss: 3.41646\n",
      "[epoch 40, batch    26] loss: 2.65765\n",
      "[epoch 40, batch    27] loss: 3.94049\n",
      "[epoch 40, batch    28] loss: 2.99843\n",
      "[epoch 40, batch    29] loss: 3.84629\n",
      "[epoch 40, batch    30] loss: 3.27566\n",
      "[epoch 40, batch    31] loss: 3.30591\n",
      "[epoch 40, batch    32] loss: 4.18149\n",
      "[epoch 41, batch     1] loss: 3.51067\n",
      "[epoch 41, batch     2] loss: 3.27727\n",
      "[epoch 41, batch     3] loss: 2.70436\n",
      "[epoch 41, batch     4] loss: 3.54080\n",
      "[epoch 41, batch     5] loss: 2.68479\n",
      "[epoch 41, batch     6] loss: 2.32623\n",
      "[epoch 41, batch     7] loss: 3.65984\n",
      "[epoch 41, batch     8] loss: 2.80432\n",
      "[epoch 41, batch     9] loss: 4.07654\n",
      "[epoch 41, batch    10] loss: 2.92225\n",
      "[epoch 41, batch    11] loss: 3.26038\n",
      "[epoch 41, batch    12] loss: 3.45770\n",
      "[epoch 41, batch    13] loss: 3.10399\n",
      "[epoch 41, batch    14] loss: 2.81353\n",
      "[epoch 41, batch    15] loss: 3.70545\n",
      "[epoch 41, batch    16] loss: 3.85073\n",
      "[epoch 41, batch    17] loss: 3.72054\n",
      "[epoch 41, batch    18] loss: 3.21471\n",
      "[epoch 41, batch    19] loss: 4.12371\n",
      "[epoch 41, batch    20] loss: 2.67159\n",
      "[epoch 41, batch    21] loss: 3.57166\n",
      "[epoch 41, batch    22] loss: 2.41433\n",
      "[epoch 41, batch    23] loss: 3.99901\n",
      "[epoch 41, batch    24] loss: 2.59757\n",
      "[epoch 41, batch    25] loss: 3.84772\n",
      "[epoch 41, batch    26] loss: 3.60546\n",
      "[epoch 41, batch    27] loss: 3.08017\n",
      "[epoch 41, batch    28] loss: 3.75717\n",
      "[epoch 41, batch    29] loss: 3.26765\n",
      "[epoch 41, batch    30] loss: 2.98333\n",
      "[epoch 41, batch    31] loss: 3.84064\n",
      "[epoch 41, batch    32] loss: 3.09960\n",
      "[epoch 42, batch     1] loss: 2.92439\n",
      "[epoch 42, batch     2] loss: 3.57779\n",
      "[epoch 42, batch     3] loss: 2.87921\n",
      "[epoch 42, batch     4] loss: 3.65065\n",
      "[epoch 42, batch     5] loss: 3.49693\n",
      "[epoch 42, batch     6] loss: 4.07476\n",
      "[epoch 42, batch     7] loss: 4.10772\n",
      "[epoch 42, batch     8] loss: 3.53707\n",
      "[epoch 42, batch     9] loss: 2.96356\n",
      "[epoch 42, batch    10] loss: 3.06297\n",
      "[epoch 42, batch    11] loss: 3.45835\n",
      "[epoch 42, batch    12] loss: 3.04385\n",
      "[epoch 42, batch    13] loss: 3.48632\n",
      "[epoch 42, batch    14] loss: 3.38906\n",
      "[epoch 42, batch    15] loss: 2.66735\n",
      "[epoch 42, batch    16] loss: 2.91206\n",
      "[epoch 42, batch    17] loss: 3.71438\n",
      "[epoch 42, batch    18] loss: 3.10840\n",
      "[epoch 42, batch    19] loss: 3.66066\n",
      "[epoch 42, batch    20] loss: 3.24018\n",
      "[epoch 42, batch    21] loss: 2.83766\n",
      "[epoch 42, batch    22] loss: 3.33188\n",
      "[epoch 42, batch    23] loss: 3.62957\n",
      "[epoch 42, batch    24] loss: 3.27906\n",
      "[epoch 42, batch    25] loss: 3.62048\n",
      "[epoch 42, batch    26] loss: 2.86044\n",
      "[epoch 42, batch    27] loss: 3.28628\n",
      "[epoch 42, batch    28] loss: 2.59319\n",
      "[epoch 42, batch    29] loss: 3.14541\n",
      "[epoch 42, batch    30] loss: 3.71024\n",
      "[epoch 42, batch    31] loss: 2.71001\n",
      "[epoch 42, batch    32] loss: 4.28200\n",
      "[epoch 43, batch     1] loss: 4.01634\n",
      "[epoch 43, batch     2] loss: 3.08414\n",
      "[epoch 43, batch     3] loss: 2.75999\n",
      "[epoch 43, batch     4] loss: 3.78759\n",
      "[epoch 43, batch     5] loss: 4.36596\n",
      "[epoch 43, batch     6] loss: 3.97823\n",
      "[epoch 43, batch     7] loss: 2.22332\n",
      "[epoch 43, batch     8] loss: 3.79282\n",
      "[epoch 43, batch     9] loss: 3.82729\n",
      "[epoch 43, batch    10] loss: 3.12349\n",
      "[epoch 43, batch    11] loss: 2.58397\n",
      "[epoch 43, batch    12] loss: 3.30554\n",
      "[epoch 43, batch    13] loss: 2.58265\n",
      "[epoch 43, batch    14] loss: 3.94982\n",
      "[epoch 43, batch    15] loss: 3.05792\n",
      "[epoch 43, batch    16] loss: 2.60387\n",
      "[epoch 43, batch    17] loss: 3.54195\n",
      "[epoch 43, batch    18] loss: 3.72826\n",
      "[epoch 43, batch    19] loss: 3.40265\n",
      "[epoch 43, batch    20] loss: 3.59530\n",
      "[epoch 43, batch    21] loss: 3.44713\n",
      "[epoch 43, batch    22] loss: 3.75864\n",
      "[epoch 43, batch    23] loss: 3.56108\n",
      "[epoch 43, batch    24] loss: 3.15044\n",
      "[epoch 43, batch    25] loss: 3.30393\n",
      "[epoch 43, batch    26] loss: 2.68444\n",
      "[epoch 43, batch    27] loss: 3.57649\n",
      "[epoch 43, batch    28] loss: 3.31095\n",
      "[epoch 43, batch    29] loss: 2.91630\n",
      "[epoch 43, batch    30] loss: 3.14223\n",
      "[epoch 43, batch    31] loss: 2.36129\n",
      "[epoch 43, batch    32] loss: 1.55701\n",
      "[epoch 44, batch     1] loss: 3.32907\n",
      "[epoch 44, batch     2] loss: 4.09627\n",
      "[epoch 44, batch     3] loss: 2.94748\n",
      "[epoch 44, batch     4] loss: 3.74561\n",
      "[epoch 44, batch     5] loss: 2.83949\n",
      "[epoch 44, batch     6] loss: 3.18830\n",
      "[epoch 44, batch     7] loss: 3.38033\n",
      "[epoch 44, batch     8] loss: 3.82580\n",
      "[epoch 44, batch     9] loss: 3.09969\n",
      "[epoch 44, batch    10] loss: 3.04152\n",
      "[epoch 44, batch    11] loss: 4.24081\n",
      "[epoch 44, batch    12] loss: 3.40159\n",
      "[epoch 44, batch    13] loss: 3.67571\n",
      "[epoch 44, batch    14] loss: 3.84758\n",
      "[epoch 44, batch    15] loss: 2.99676\n",
      "[epoch 44, batch    16] loss: 3.51685\n",
      "[epoch 44, batch    17] loss: 2.44991\n",
      "[epoch 44, batch    18] loss: 2.88268\n",
      "[epoch 44, batch    19] loss: 3.09098\n",
      "[epoch 44, batch    20] loss: 3.17702\n",
      "[epoch 44, batch    21] loss: 3.53224\n",
      "[epoch 44, batch    22] loss: 2.72546\n",
      "[epoch 44, batch    23] loss: 3.53472\n",
      "[epoch 44, batch    24] loss: 3.81454\n",
      "[epoch 44, batch    25] loss: 3.10725\n",
      "[epoch 44, batch    26] loss: 3.47777\n",
      "[epoch 44, batch    27] loss: 3.06621\n",
      "[epoch 44, batch    28] loss: 2.43617\n",
      "[epoch 44, batch    29] loss: 3.63316\n",
      "[epoch 44, batch    30] loss: 3.28407\n",
      "[epoch 44, batch    31] loss: 2.59933\n",
      "[epoch 44, batch    32] loss: 2.47136\n",
      "[epoch 45, batch     1] loss: 4.17955\n",
      "[epoch 45, batch     2] loss: 3.06698\n",
      "[epoch 45, batch     3] loss: 3.61737\n",
      "[epoch 45, batch     4] loss: 3.39161\n",
      "[epoch 45, batch     5] loss: 3.12435\n",
      "[epoch 45, batch     6] loss: 2.60905\n",
      "[epoch 45, batch     7] loss: 3.49896\n",
      "[epoch 45, batch     8] loss: 4.06324\n",
      "[epoch 45, batch     9] loss: 4.00883\n",
      "[epoch 45, batch    10] loss: 2.97248\n",
      "[epoch 45, batch    11] loss: 3.79450\n",
      "[epoch 45, batch    12] loss: 2.81020\n",
      "[epoch 45, batch    13] loss: 3.53943\n",
      "[epoch 45, batch    14] loss: 3.23209\n",
      "[epoch 45, batch    15] loss: 3.44603\n",
      "[epoch 45, batch    16] loss: 3.75552\n",
      "[epoch 45, batch    17] loss: 3.71505\n",
      "[epoch 45, batch    18] loss: 2.70188\n",
      "[epoch 45, batch    19] loss: 2.45176\n",
      "[epoch 45, batch    20] loss: 3.19553\n",
      "[epoch 45, batch    21] loss: 3.77230\n",
      "[epoch 45, batch    22] loss: 2.76726\n",
      "[epoch 45, batch    23] loss: 2.81340\n",
      "[epoch 45, batch    24] loss: 2.76280\n",
      "[epoch 45, batch    25] loss: 2.59244\n",
      "[epoch 45, batch    26] loss: 3.07712\n",
      "[epoch 45, batch    27] loss: 3.09843\n",
      "[epoch 45, batch    28] loss: 2.14590\n",
      "[epoch 45, batch    29] loss: 3.75596\n",
      "[epoch 45, batch    30] loss: 3.94024\n",
      "[epoch 45, batch    31] loss: 3.76591\n",
      "[epoch 45, batch    32] loss: 2.71665\n",
      "[epoch 46, batch     1] loss: 3.42385\n",
      "[epoch 46, batch     2] loss: 2.42852\n",
      "[epoch 46, batch     3] loss: 3.39145\n",
      "[epoch 46, batch     4] loss: 3.30522\n",
      "[epoch 46, batch     5] loss: 4.00119\n",
      "[epoch 46, batch     6] loss: 2.89876\n",
      "[epoch 46, batch     7] loss: 3.41014\n",
      "[epoch 46, batch     8] loss: 3.60999\n",
      "[epoch 46, batch     9] loss: 3.38535\n",
      "[epoch 46, batch    10] loss: 2.94582\n",
      "[epoch 46, batch    11] loss: 3.13875\n",
      "[epoch 46, batch    12] loss: 3.40813\n",
      "[epoch 46, batch    13] loss: 3.92552\n",
      "[epoch 46, batch    14] loss: 3.25682\n",
      "[epoch 46, batch    15] loss: 2.96590\n",
      "[epoch 46, batch    16] loss: 3.47304\n",
      "[epoch 46, batch    17] loss: 2.98644\n",
      "[epoch 46, batch    18] loss: 2.73302\n",
      "[epoch 46, batch    19] loss: 3.69632\n",
      "[epoch 46, batch    20] loss: 3.05524\n",
      "[epoch 46, batch    21] loss: 3.06001\n",
      "[epoch 46, batch    22] loss: 3.53407\n",
      "[epoch 46, batch    23] loss: 2.27335\n",
      "[epoch 46, batch    24] loss: 3.46305\n",
      "[epoch 46, batch    25] loss: 2.95989\n",
      "[epoch 46, batch    26] loss: 4.03678\n",
      "[epoch 46, batch    27] loss: 4.55213\n",
      "[epoch 46, batch    28] loss: 3.56730\n",
      "[epoch 46, batch    29] loss: 2.88432\n",
      "[epoch 46, batch    30] loss: 2.85386\n",
      "[epoch 46, batch    31] loss: 3.11279\n",
      "[epoch 46, batch    32] loss: 2.90466\n",
      "[epoch 47, batch     1] loss: 3.69272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 47, batch     2] loss: 3.39262\n",
      "[epoch 47, batch     3] loss: 2.59656\n",
      "[epoch 47, batch     4] loss: 2.85692\n",
      "[epoch 47, batch     5] loss: 4.16413\n",
      "[epoch 47, batch     6] loss: 2.98453\n",
      "[epoch 47, batch     7] loss: 3.09495\n",
      "[epoch 47, batch     8] loss: 3.75303\n",
      "[epoch 47, batch     9] loss: 2.75098\n",
      "[epoch 47, batch    10] loss: 4.00562\n",
      "[epoch 47, batch    11] loss: 3.35807\n",
      "[epoch 47, batch    12] loss: 2.80403\n",
      "[epoch 47, batch    13] loss: 2.54794\n",
      "[epoch 47, batch    14] loss: 3.70436\n",
      "[epoch 47, batch    15] loss: 3.44502\n",
      "[epoch 47, batch    16] loss: 4.16306\n",
      "[epoch 47, batch    17] loss: 3.11093\n",
      "[epoch 47, batch    18] loss: 3.52081\n",
      "[epoch 47, batch    19] loss: 3.62874\n",
      "[epoch 47, batch    20] loss: 2.64211\n",
      "[epoch 47, batch    21] loss: 3.35226\n",
      "[epoch 47, batch    22] loss: 2.86677\n",
      "[epoch 47, batch    23] loss: 3.86651\n",
      "[epoch 47, batch    24] loss: 2.40416\n",
      "[epoch 47, batch    25] loss: 3.23015\n",
      "[epoch 47, batch    26] loss: 4.04322\n",
      "[epoch 47, batch    27] loss: 4.00477\n",
      "[epoch 47, batch    28] loss: 2.40120\n",
      "[epoch 47, batch    29] loss: 3.37667\n",
      "[epoch 47, batch    30] loss: 3.01484\n",
      "[epoch 47, batch    31] loss: 2.62597\n",
      "[epoch 47, batch    32] loss: 2.71438\n",
      "[epoch 48, batch     1] loss: 3.55537\n",
      "[epoch 48, batch     2] loss: 2.74728\n",
      "[epoch 48, batch     3] loss: 3.78357\n",
      "[epoch 48, batch     4] loss: 3.49027\n",
      "[epoch 48, batch     5] loss: 3.22179\n",
      "[epoch 48, batch     6] loss: 3.31526\n",
      "[epoch 48, batch     7] loss: 3.55366\n",
      "[epoch 48, batch     8] loss: 3.77714\n",
      "[epoch 48, batch     9] loss: 3.86342\n",
      "[epoch 48, batch    10] loss: 3.09552\n",
      "[epoch 48, batch    11] loss: 2.75697\n",
      "[epoch 48, batch    12] loss: 3.72690\n",
      "[epoch 48, batch    13] loss: 2.76907\n",
      "[epoch 48, batch    14] loss: 2.19575\n",
      "[epoch 48, batch    15] loss: 2.92111\n",
      "[epoch 48, batch    16] loss: 2.74668\n",
      "[epoch 48, batch    17] loss: 4.27640\n",
      "[epoch 48, batch    18] loss: 3.38049\n",
      "[epoch 48, batch    19] loss: 2.85289\n",
      "[epoch 48, batch    20] loss: 3.47888\n",
      "[epoch 48, batch    21] loss: 3.13403\n",
      "[epoch 48, batch    22] loss: 4.66294\n",
      "[epoch 48, batch    23] loss: 3.55943\n",
      "[epoch 48, batch    24] loss: 3.48921\n",
      "[epoch 48, batch    25] loss: 4.08674\n",
      "[epoch 48, batch    26] loss: 2.91664\n",
      "[epoch 48, batch    27] loss: 3.26412\n",
      "[epoch 48, batch    28] loss: 2.63432\n",
      "[epoch 48, batch    29] loss: 2.48167\n",
      "[epoch 48, batch    30] loss: 3.33987\n",
      "[epoch 48, batch    31] loss: 2.51200\n",
      "[epoch 48, batch    32] loss: 2.04375\n",
      "[epoch 49, batch     1] loss: 3.05906\n",
      "[epoch 49, batch     2] loss: 3.39659\n",
      "[epoch 49, batch     3] loss: 3.20110\n",
      "[epoch 49, batch     4] loss: 3.71040\n",
      "[epoch 49, batch     5] loss: 3.13997\n",
      "[epoch 49, batch     6] loss: 3.21559\n",
      "[epoch 49, batch     7] loss: 3.73166\n",
      "[epoch 49, batch     8] loss: 4.11031\n",
      "[epoch 49, batch     9] loss: 2.98639\n",
      "[epoch 49, batch    10] loss: 3.22203\n",
      "[epoch 49, batch    11] loss: 3.33278\n",
      "[epoch 49, batch    12] loss: 3.26314\n",
      "[epoch 49, batch    13] loss: 3.21136\n",
      "[epoch 49, batch    14] loss: 3.20037\n",
      "[epoch 49, batch    15] loss: 2.57358\n",
      "[epoch 49, batch    16] loss: 3.13381\n",
      "[epoch 49, batch    17] loss: 3.21139\n",
      "[epoch 49, batch    18] loss: 3.31890\n",
      "[epoch 49, batch    19] loss: 2.72841\n",
      "[epoch 49, batch    20] loss: 3.31861\n",
      "[epoch 49, batch    21] loss: 3.57905\n",
      "[epoch 49, batch    22] loss: 2.54267\n",
      "[epoch 49, batch    23] loss: 3.75857\n",
      "[epoch 49, batch    24] loss: 3.39879\n",
      "[epoch 49, batch    25] loss: 2.71362\n",
      "[epoch 49, batch    26] loss: 3.40905\n",
      "[epoch 49, batch    27] loss: 3.96825\n",
      "[epoch 49, batch    28] loss: 3.37527\n",
      "[epoch 49, batch    29] loss: 2.80392\n",
      "[epoch 49, batch    30] loss: 3.05964\n",
      "[epoch 49, batch    31] loss: 2.61613\n",
      "[epoch 49, batch    32] loss: 5.01695\n",
      "[epoch 50, batch     1] loss: 3.77056\n",
      "[epoch 50, batch     2] loss: 3.79011\n",
      "[epoch 50, batch     3] loss: 2.58601\n",
      "[epoch 50, batch     4] loss: 2.53200\n",
      "[epoch 50, batch     5] loss: 3.12659\n",
      "[epoch 50, batch     6] loss: 2.48360\n",
      "[epoch 50, batch     7] loss: 3.01604\n",
      "[epoch 50, batch     8] loss: 3.49414\n",
      "[epoch 50, batch     9] loss: 3.30304\n",
      "[epoch 50, batch    10] loss: 2.73513\n",
      "[epoch 50, batch    11] loss: 2.62055\n",
      "[epoch 50, batch    12] loss: 3.94535\n",
      "[epoch 50, batch    13] loss: 2.78564\n",
      "[epoch 50, batch    14] loss: 4.02403\n",
      "[epoch 50, batch    15] loss: 3.21696\n",
      "[epoch 50, batch    16] loss: 3.10392\n",
      "[epoch 50, batch    17] loss: 3.21098\n",
      "[epoch 50, batch    18] loss: 4.55966\n",
      "[epoch 50, batch    19] loss: 3.34714\n",
      "[epoch 50, batch    20] loss: 3.08475\n",
      "[epoch 50, batch    21] loss: 4.15628\n",
      "[epoch 50, batch    22] loss: 3.68042\n",
      "[epoch 50, batch    23] loss: 2.99721\n",
      "[epoch 50, batch    24] loss: 2.61390\n",
      "[epoch 50, batch    25] loss: 3.13416\n",
      "[epoch 50, batch    26] loss: 3.34552\n",
      "[epoch 50, batch    27] loss: 3.01041\n",
      "[epoch 50, batch    28] loss: 3.02515\n",
      "[epoch 50, batch    29] loss: 3.62094\n",
      "[epoch 50, batch    30] loss: 3.21096\n",
      "[epoch 50, batch    31] loss: 3.22068\n",
      "[epoch 50, batch    32] loss: 3.33372\n",
      "[epoch 51, batch     1] loss: 2.27340\n",
      "[epoch 51, batch     2] loss: 3.01507\n",
      "[epoch 51, batch     3] loss: 3.24807\n",
      "[epoch 51, batch     4] loss: 2.07242\n",
      "[epoch 51, batch     5] loss: 2.52192\n",
      "[epoch 51, batch     6] loss: 3.11128\n",
      "[epoch 51, batch     7] loss: 3.29926\n",
      "[epoch 51, batch     8] loss: 3.53596\n",
      "[epoch 51, batch     9] loss: 3.31166\n",
      "[epoch 51, batch    10] loss: 3.51462\n",
      "[epoch 51, batch    11] loss: 3.18835\n",
      "[epoch 51, batch    12] loss: 3.62651\n",
      "[epoch 51, batch    13] loss: 2.91962\n",
      "[epoch 51, batch    14] loss: 2.96884\n",
      "[epoch 51, batch    15] loss: 3.91123\n",
      "[epoch 51, batch    16] loss: 3.79591\n",
      "[epoch 51, batch    17] loss: 3.88017\n",
      "[epoch 51, batch    18] loss: 3.30916\n",
      "[epoch 51, batch    19] loss: 3.00600\n",
      "[epoch 51, batch    20] loss: 3.79910\n",
      "[epoch 51, batch    21] loss: 2.97529\n",
      "[epoch 51, batch    22] loss: 4.03804\n",
      "[epoch 51, batch    23] loss: 3.08747\n",
      "[epoch 51, batch    24] loss: 3.85917\n",
      "[epoch 51, batch    25] loss: 2.52725\n",
      "[epoch 51, batch    26] loss: 3.13461\n",
      "[epoch 51, batch    27] loss: 3.55227\n",
      "[epoch 51, batch    28] loss: 3.74970\n",
      "[epoch 51, batch    29] loss: 3.04629\n",
      "[epoch 51, batch    30] loss: 3.80560\n",
      "[epoch 51, batch    31] loss: 2.46257\n",
      "[epoch 51, batch    32] loss: 3.14900\n",
      "[epoch 52, batch     1] loss: 2.90485\n",
      "[epoch 52, batch     2] loss: 2.57436\n",
      "[epoch 52, batch     3] loss: 3.88641\n",
      "[epoch 52, batch     4] loss: 3.81194\n",
      "[epoch 52, batch     5] loss: 3.71955\n",
      "[epoch 52, batch     6] loss: 3.65743\n",
      "[epoch 52, batch     7] loss: 3.11274\n",
      "[epoch 52, batch     8] loss: 3.38837\n",
      "[epoch 52, batch     9] loss: 2.92019\n",
      "[epoch 52, batch    10] loss: 3.18417\n",
      "[epoch 52, batch    11] loss: 4.23124\n",
      "[epoch 52, batch    12] loss: 2.53236\n",
      "[epoch 52, batch    13] loss: 2.72743\n",
      "[epoch 52, batch    14] loss: 3.17325\n",
      "[epoch 52, batch    15] loss: 2.60515\n",
      "[epoch 52, batch    16] loss: 2.89033\n",
      "[epoch 52, batch    17] loss: 4.00810\n",
      "[epoch 52, batch    18] loss: 2.21272\n",
      "[epoch 52, batch    19] loss: 3.38320\n",
      "[epoch 52, batch    20] loss: 2.84214\n",
      "[epoch 52, batch    21] loss: 3.25481\n",
      "[epoch 52, batch    22] loss: 4.07762\n",
      "[epoch 52, batch    23] loss: 2.70009\n",
      "[epoch 52, batch    24] loss: 3.01418\n",
      "[epoch 52, batch    25] loss: 4.04233\n",
      "[epoch 52, batch    26] loss: 3.64808\n",
      "[epoch 52, batch    27] loss: 2.67695\n",
      "[epoch 52, batch    28] loss: 3.01314\n",
      "[epoch 52, batch    29] loss: 3.98772\n",
      "[epoch 52, batch    30] loss: 3.44816\n",
      "[epoch 52, batch    31] loss: 2.72645\n",
      "[epoch 52, batch    32] loss: 3.25461\n",
      "[epoch 53, batch     1] loss: 3.68970\n",
      "[epoch 53, batch     2] loss: 3.38339\n",
      "[epoch 53, batch     3] loss: 3.43777\n",
      "[epoch 53, batch     4] loss: 2.36533\n",
      "[epoch 53, batch     5] loss: 3.54227\n",
      "[epoch 53, batch     6] loss: 3.13012\n",
      "[epoch 53, batch     7] loss: 3.05484\n",
      "[epoch 53, batch     8] loss: 3.59018\n",
      "[epoch 53, batch     9] loss: 3.52183\n",
      "[epoch 53, batch    10] loss: 3.08187\n",
      "[epoch 53, batch    11] loss: 3.01931\n",
      "[epoch 53, batch    12] loss: 3.04532\n",
      "[epoch 53, batch    13] loss: 2.75536\n",
      "[epoch 53, batch    14] loss: 2.52565\n",
      "[epoch 53, batch    15] loss: 3.10865\n",
      "[epoch 53, batch    16] loss: 3.16174\n",
      "[epoch 53, batch    17] loss: 3.60776\n",
      "[epoch 53, batch    18] loss: 3.49728\n",
      "[epoch 53, batch    19] loss: 3.22832\n",
      "[epoch 53, batch    20] loss: 2.80780\n",
      "[epoch 53, batch    21] loss: 3.08997\n",
      "[epoch 53, batch    22] loss: 3.17409\n",
      "[epoch 53, batch    23] loss: 3.12505\n",
      "[epoch 53, batch    24] loss: 4.40764\n",
      "[epoch 53, batch    25] loss: 2.85712\n",
      "[epoch 53, batch    26] loss: 2.58646\n",
      "[epoch 53, batch    27] loss: 3.69142\n",
      "[epoch 53, batch    28] loss: 3.83485\n",
      "[epoch 53, batch    29] loss: 3.24268\n",
      "[epoch 53, batch    30] loss: 3.21712\n",
      "[epoch 53, batch    31] loss: 3.70172\n",
      "[epoch 53, batch    32] loss: 1.77386\n",
      "[epoch 54, batch     1] loss: 3.30991\n",
      "[epoch 54, batch     2] loss: 3.73857\n",
      "[epoch 54, batch     3] loss: 2.64982\n",
      "[epoch 54, batch     4] loss: 3.42371\n",
      "[epoch 54, batch     5] loss: 2.97324\n",
      "[epoch 54, batch     6] loss: 3.16187\n",
      "[epoch 54, batch     7] loss: 3.43731\n",
      "[epoch 54, batch     8] loss: 4.29370\n",
      "[epoch 54, batch     9] loss: 3.46747\n",
      "[epoch 54, batch    10] loss: 2.86645\n",
      "[epoch 54, batch    11] loss: 3.14591\n",
      "[epoch 54, batch    12] loss: 3.28438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 54, batch    13] loss: 2.81527\n",
      "[epoch 54, batch    14] loss: 3.46398\n",
      "[epoch 54, batch    15] loss: 3.45621\n",
      "[epoch 54, batch    16] loss: 2.80416\n",
      "[epoch 54, batch    17] loss: 3.30221\n",
      "[epoch 54, batch    18] loss: 3.39723\n",
      "[epoch 54, batch    19] loss: 2.78377\n",
      "[epoch 54, batch    20] loss: 3.33728\n",
      "[epoch 54, batch    21] loss: 3.06749\n",
      "[epoch 54, batch    22] loss: 2.78418\n",
      "[epoch 54, batch    23] loss: 2.85794\n",
      "[epoch 54, batch    24] loss: 2.24120\n",
      "[epoch 54, batch    25] loss: 4.24558\n",
      "[epoch 54, batch    26] loss: 3.32800\n",
      "[epoch 54, batch    27] loss: 4.14101\n",
      "[epoch 54, batch    28] loss: 3.07037\n",
      "[epoch 54, batch    29] loss: 2.56802\n",
      "[epoch 54, batch    30] loss: 2.64098\n",
      "[epoch 54, batch    31] loss: 3.57128\n",
      "[epoch 54, batch    32] loss: 4.09488\n",
      "[epoch 55, batch     1] loss: 2.95490\n",
      "[epoch 55, batch     2] loss: 3.85259\n",
      "[epoch 55, batch     3] loss: 3.97400\n",
      "[epoch 55, batch     4] loss: 3.15321\n",
      "[epoch 55, batch     5] loss: 3.65083\n",
      "[epoch 55, batch     6] loss: 3.09165\n",
      "[epoch 55, batch     7] loss: 3.36304\n",
      "[epoch 55, batch     8] loss: 2.93726\n",
      "[epoch 55, batch     9] loss: 3.37692\n",
      "[epoch 55, batch    10] loss: 2.91399\n",
      "[epoch 55, batch    11] loss: 3.40999\n",
      "[epoch 55, batch    12] loss: 3.73837\n",
      "[epoch 55, batch    13] loss: 2.85269\n",
      "[epoch 55, batch    14] loss: 2.60244\n",
      "[epoch 55, batch    15] loss: 3.09790\n",
      "[epoch 55, batch    16] loss: 2.49925\n",
      "[epoch 55, batch    17] loss: 2.73806\n",
      "[epoch 55, batch    18] loss: 3.12971\n",
      "[epoch 55, batch    19] loss: 3.20758\n",
      "[epoch 55, batch    20] loss: 3.49591\n",
      "[epoch 55, batch    21] loss: 2.80190\n",
      "[epoch 55, batch    22] loss: 2.81038\n",
      "[epoch 55, batch    23] loss: 2.31115\n",
      "[epoch 55, batch    24] loss: 2.37797\n",
      "[epoch 55, batch    25] loss: 2.63866\n",
      "[epoch 55, batch    26] loss: 3.97300\n",
      "[epoch 55, batch    27] loss: 3.41979\n",
      "[epoch 55, batch    28] loss: 4.48362\n",
      "[epoch 55, batch    29] loss: 3.67312\n",
      "[epoch 55, batch    30] loss: 3.29485\n",
      "[epoch 55, batch    31] loss: 3.75105\n",
      "[epoch 55, batch    32] loss: 2.47042\n",
      "[epoch 56, batch     1] loss: 2.30146\n",
      "[epoch 56, batch     2] loss: 3.05542\n",
      "[epoch 56, batch     3] loss: 2.96917\n",
      "[epoch 56, batch     4] loss: 2.95081\n",
      "[epoch 56, batch     5] loss: 3.35221\n",
      "[epoch 56, batch     6] loss: 3.46233\n",
      "[epoch 56, batch     7] loss: 3.52065\n",
      "[epoch 56, batch     8] loss: 2.95240\n",
      "[epoch 56, batch     9] loss: 3.35480\n",
      "[epoch 56, batch    10] loss: 3.88065\n",
      "[epoch 56, batch    11] loss: 3.12608\n",
      "[epoch 56, batch    12] loss: 3.26243\n",
      "[epoch 56, batch    13] loss: 3.45976\n",
      "[epoch 56, batch    14] loss: 2.84721\n",
      "[epoch 56, batch    15] loss: 3.03155\n",
      "[epoch 56, batch    16] loss: 2.52039\n",
      "[epoch 56, batch    17] loss: 2.61644\n",
      "[epoch 56, batch    18] loss: 3.77350\n",
      "[epoch 56, batch    19] loss: 3.22808\n",
      "[epoch 56, batch    20] loss: 3.69873\n",
      "[epoch 56, batch    21] loss: 4.08333\n",
      "[epoch 56, batch    22] loss: 3.78486\n",
      "[epoch 56, batch    23] loss: 3.59063\n",
      "[epoch 56, batch    24] loss: 2.85282\n",
      "[epoch 56, batch    25] loss: 2.88600\n",
      "[epoch 56, batch    26] loss: 2.21733\n",
      "[epoch 56, batch    27] loss: 2.82048\n",
      "[epoch 56, batch    28] loss: 3.31561\n",
      "[epoch 56, batch    29] loss: 3.51079\n",
      "[epoch 56, batch    30] loss: 3.88616\n",
      "[epoch 56, batch    31] loss: 3.35749\n",
      "[epoch 56, batch    32] loss: 2.50338\n",
      "[epoch 57, batch     1] loss: 2.91924\n",
      "[epoch 57, batch     2] loss: 3.43051\n",
      "[epoch 57, batch     3] loss: 3.31985\n",
      "[epoch 57, batch     4] loss: 3.99001\n",
      "[epoch 57, batch     5] loss: 3.04197\n",
      "[epoch 57, batch     6] loss: 3.79781\n",
      "[epoch 57, batch     7] loss: 2.69030\n",
      "[epoch 57, batch     8] loss: 2.71353\n",
      "[epoch 57, batch     9] loss: 3.54381\n",
      "[epoch 57, batch    10] loss: 2.97782\n",
      "[epoch 57, batch    11] loss: 3.53067\n",
      "[epoch 57, batch    12] loss: 3.05225\n",
      "[epoch 57, batch    13] loss: 3.15179\n",
      "[epoch 57, batch    14] loss: 2.90953\n",
      "[epoch 57, batch    15] loss: 3.37097\n",
      "[epoch 57, batch    16] loss: 3.22101\n",
      "[epoch 57, batch    17] loss: 2.87720\n",
      "[epoch 57, batch    18] loss: 3.31661\n",
      "[epoch 57, batch    19] loss: 2.95267\n",
      "[epoch 57, batch    20] loss: 4.28374\n",
      "[epoch 57, batch    21] loss: 3.51356\n",
      "[epoch 57, batch    22] loss: 3.00961\n",
      "[epoch 57, batch    23] loss: 2.68859\n",
      "[epoch 57, batch    24] loss: 2.48395\n",
      "[epoch 57, batch    25] loss: 3.21962\n",
      "[epoch 57, batch    26] loss: 2.26577\n",
      "[epoch 57, batch    27] loss: 3.63789\n",
      "[epoch 57, batch    28] loss: 3.45815\n",
      "[epoch 57, batch    29] loss: 3.26887\n",
      "[epoch 57, batch    30] loss: 3.04700\n",
      "[epoch 57, batch    31] loss: 3.71283\n",
      "[epoch 57, batch    32] loss: 2.72412\n",
      "[epoch 58, batch     1] loss: 3.18900\n",
      "[epoch 58, batch     2] loss: 3.30904\n",
      "[epoch 58, batch     3] loss: 3.29236\n",
      "[epoch 58, batch     4] loss: 3.53159\n",
      "[epoch 58, batch     5] loss: 2.92656\n",
      "[epoch 58, batch     6] loss: 3.36835\n",
      "[epoch 58, batch     7] loss: 2.94171\n",
      "[epoch 58, batch     8] loss: 2.89124\n",
      "[epoch 58, batch     9] loss: 3.45708\n",
      "[epoch 58, batch    10] loss: 2.93644\n",
      "[epoch 58, batch    11] loss: 3.62827\n",
      "[epoch 58, batch    12] loss: 3.35192\n",
      "[epoch 58, batch    13] loss: 3.20167\n",
      "[epoch 58, batch    14] loss: 2.99024\n",
      "[epoch 58, batch    15] loss: 2.72826\n",
      "[epoch 58, batch    16] loss: 3.78796\n",
      "[epoch 58, batch    17] loss: 3.11459\n",
      "[epoch 58, batch    18] loss: 2.30829\n",
      "[epoch 58, batch    19] loss: 3.16423\n",
      "[epoch 58, batch    20] loss: 2.48539\n",
      "[epoch 58, batch    21] loss: 4.37616\n",
      "[epoch 58, batch    22] loss: 3.25775\n",
      "[epoch 58, batch    23] loss: 2.87860\n",
      "[epoch 58, batch    24] loss: 2.65793\n",
      "[epoch 58, batch    25] loss: 3.66477\n",
      "[epoch 58, batch    26] loss: 2.91741\n",
      "[epoch 58, batch    27] loss: 3.40577\n",
      "[epoch 58, batch    28] loss: 4.09746\n",
      "[epoch 58, batch    29] loss: 2.71326\n",
      "[epoch 58, batch    30] loss: 2.80776\n",
      "[epoch 58, batch    31] loss: 3.17734\n",
      "[epoch 58, batch    32] loss: 4.31164\n",
      "[epoch 59, batch     1] loss: 2.73715\n",
      "[epoch 59, batch     2] loss: 3.56321\n",
      "[epoch 59, batch     3] loss: 2.74672\n",
      "[epoch 59, batch     4] loss: 3.32504\n",
      "[epoch 59, batch     5] loss: 3.15038\n",
      "[epoch 59, batch     6] loss: 4.17192\n",
      "[epoch 59, batch     7] loss: 3.22296\n",
      "[epoch 59, batch     8] loss: 3.83681\n",
      "[epoch 59, batch     9] loss: 2.89442\n",
      "[epoch 59, batch    10] loss: 2.41368\n",
      "[epoch 59, batch    11] loss: 2.82680\n",
      "[epoch 59, batch    12] loss: 3.33223\n",
      "[epoch 59, batch    13] loss: 3.49435\n",
      "[epoch 59, batch    14] loss: 2.98256\n",
      "[epoch 59, batch    15] loss: 3.07696\n",
      "[epoch 59, batch    16] loss: 3.00707\n",
      "[epoch 59, batch    17] loss: 3.82277\n",
      "[epoch 59, batch    18] loss: 3.32615\n",
      "[epoch 59, batch    19] loss: 3.59515\n",
      "[epoch 59, batch    20] loss: 3.30160\n",
      "[epoch 59, batch    21] loss: 3.89498\n",
      "[epoch 59, batch    22] loss: 3.52100\n",
      "[epoch 59, batch    23] loss: 2.62746\n",
      "[epoch 59, batch    24] loss: 2.93773\n",
      "[epoch 59, batch    25] loss: 2.52809\n",
      "[epoch 59, batch    26] loss: 3.17262\n",
      "[epoch 59, batch    27] loss: 3.02907\n",
      "[epoch 59, batch    28] loss: 3.69358\n",
      "[epoch 59, batch    29] loss: 2.35553\n",
      "[epoch 59, batch    30] loss: 2.61212\n",
      "[epoch 59, batch    31] loss: 3.52912\n",
      "[epoch 59, batch    32] loss: 2.50730\n",
      "[epoch 60, batch     1] loss: 3.19315\n",
      "[epoch 60, batch     2] loss: 2.57221\n",
      "[epoch 60, batch     3] loss: 3.79130\n",
      "[epoch 60, batch     4] loss: 3.84600\n",
      "[epoch 60, batch     5] loss: 2.92508\n",
      "[epoch 60, batch     6] loss: 3.99277\n",
      "[epoch 60, batch     7] loss: 3.77484\n",
      "[epoch 60, batch     8] loss: 3.04306\n",
      "[epoch 60, batch     9] loss: 3.50893\n",
      "[epoch 60, batch    10] loss: 3.02627\n",
      "[epoch 60, batch    11] loss: 2.84019\n",
      "[epoch 60, batch    12] loss: 3.29598\n",
      "[epoch 60, batch    13] loss: 3.20851\n",
      "[epoch 60, batch    14] loss: 2.78419\n",
      "[epoch 60, batch    15] loss: 2.62668\n",
      "[epoch 60, batch    16] loss: 3.61230\n",
      "[epoch 60, batch    17] loss: 2.43978\n",
      "[epoch 60, batch    18] loss: 2.74174\n",
      "[epoch 60, batch    19] loss: 3.33827\n",
      "[epoch 60, batch    20] loss: 3.28238\n",
      "[epoch 60, batch    21] loss: 2.95026\n",
      "[epoch 60, batch    22] loss: 3.85099\n",
      "[epoch 60, batch    23] loss: 2.53730\n",
      "[epoch 60, batch    24] loss: 3.18144\n",
      "[epoch 60, batch    25] loss: 2.58851\n",
      "[epoch 60, batch    26] loss: 2.96700\n",
      "[epoch 60, batch    27] loss: 3.11748\n",
      "[epoch 60, batch    28] loss: 3.39010\n",
      "[epoch 60, batch    29] loss: 3.04555\n",
      "[epoch 60, batch    30] loss: 3.40133\n",
      "[epoch 60, batch    31] loss: 3.32825\n",
      "[epoch 60, batch    32] loss: 4.24662\n",
      "[epoch 61, batch     1] loss: 3.36755\n",
      "[epoch 61, batch     2] loss: 3.77389\n",
      "[epoch 61, batch     3] loss: 3.30358\n",
      "[epoch 61, batch     4] loss: 3.34369\n",
      "[epoch 61, batch     5] loss: 3.31104\n",
      "[epoch 61, batch     6] loss: 2.60373\n",
      "[epoch 61, batch     7] loss: 3.58256\n",
      "[epoch 61, batch     8] loss: 3.02279\n",
      "[epoch 61, batch     9] loss: 2.70953\n",
      "[epoch 61, batch    10] loss: 3.20037\n",
      "[epoch 61, batch    11] loss: 3.50217\n",
      "[epoch 61, batch    12] loss: 2.46128\n",
      "[epoch 61, batch    13] loss: 2.94144\n",
      "[epoch 61, batch    14] loss: 3.62922\n",
      "[epoch 61, batch    15] loss: 2.67612\n",
      "[epoch 61, batch    16] loss: 2.97436\n",
      "[epoch 61, batch    17] loss: 2.89337\n",
      "[epoch 61, batch    18] loss: 3.34055\n",
      "[epoch 61, batch    19] loss: 3.34195\n",
      "[epoch 61, batch    20] loss: 3.17680\n",
      "[epoch 61, batch    21] loss: 3.43412\n",
      "[epoch 61, batch    22] loss: 2.86211\n",
      "[epoch 61, batch    23] loss: 2.60902\n",
      "[epoch 61, batch    24] loss: 4.09184\n",
      "[epoch 61, batch    25] loss: 2.89886\n",
      "[epoch 61, batch    26] loss: 2.65652\n",
      "[epoch 61, batch    27] loss: 3.06804\n",
      "[epoch 61, batch    28] loss: 3.08067\n",
      "[epoch 61, batch    29] loss: 3.19876\n",
      "[epoch 61, batch    30] loss: 3.65793\n",
      "[epoch 61, batch    31] loss: 3.51089\n",
      "[epoch 61, batch    32] loss: 3.26896\n",
      "[epoch 62, batch     1] loss: 2.16597\n",
      "[epoch 62, batch     2] loss: 3.07496\n",
      "[epoch 62, batch     3] loss: 3.26604\n",
      "[epoch 62, batch     4] loss: 2.97963\n",
      "[epoch 62, batch     5] loss: 3.66341\n",
      "[epoch 62, batch     6] loss: 3.27441\n",
      "[epoch 62, batch     7] loss: 2.58594\n",
      "[epoch 62, batch     8] loss: 3.06797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 62, batch     9] loss: 2.54671\n",
      "[epoch 62, batch    10] loss: 3.32422\n",
      "[epoch 62, batch    11] loss: 3.27804\n",
      "[epoch 62, batch    12] loss: 2.98049\n",
      "[epoch 62, batch    13] loss: 3.47727\n",
      "[epoch 62, batch    14] loss: 2.93558\n",
      "[epoch 62, batch    15] loss: 3.22139\n",
      "[epoch 62, batch    16] loss: 2.80262\n",
      "[epoch 62, batch    17] loss: 3.30879\n",
      "[epoch 62, batch    18] loss: 3.04197\n",
      "[epoch 62, batch    19] loss: 3.94011\n",
      "[epoch 62, batch    20] loss: 3.97087\n",
      "[epoch 62, batch    21] loss: 2.87528\n",
      "[epoch 62, batch    22] loss: 3.81786\n",
      "[epoch 62, batch    23] loss: 3.22958\n",
      "[epoch 62, batch    24] loss: 3.13784\n",
      "[epoch 62, batch    25] loss: 3.02810\n",
      "[epoch 62, batch    26] loss: 3.11801\n",
      "[epoch 62, batch    27] loss: 3.57681\n",
      "[epoch 62, batch    28] loss: 3.06700\n",
      "[epoch 62, batch    29] loss: 3.65621\n",
      "[epoch 62, batch    30] loss: 2.74714\n",
      "[epoch 62, batch    31] loss: 2.73620\n",
      "[epoch 62, batch    32] loss: 3.40420\n",
      "[epoch 63, batch     1] loss: 3.13985\n",
      "[epoch 63, batch     2] loss: 3.95188\n",
      "[epoch 63, batch     3] loss: 2.86445\n",
      "[epoch 63, batch     4] loss: 2.93968\n",
      "[epoch 63, batch     5] loss: 3.26219\n",
      "[epoch 63, batch     6] loss: 3.58261\n",
      "[epoch 63, batch     7] loss: 3.19622\n",
      "[epoch 63, batch     8] loss: 3.72149\n",
      "[epoch 63, batch     9] loss: 2.44618\n",
      "[epoch 63, batch    10] loss: 3.23170\n",
      "[epoch 63, batch    11] loss: 3.35818\n",
      "[epoch 63, batch    12] loss: 2.98974\n",
      "[epoch 63, batch    13] loss: 2.42736\n",
      "[epoch 63, batch    14] loss: 3.49925\n",
      "[epoch 63, batch    15] loss: 2.85668\n",
      "[epoch 63, batch    16] loss: 2.66412\n",
      "[epoch 63, batch    17] loss: 3.77323\n",
      "[epoch 63, batch    18] loss: 3.93533\n",
      "[epoch 63, batch    19] loss: 2.49153\n",
      "[epoch 63, batch    20] loss: 3.61613\n",
      "[epoch 63, batch    21] loss: 2.29752\n",
      "[epoch 63, batch    22] loss: 3.90600\n",
      "[epoch 63, batch    23] loss: 3.60365\n",
      "[epoch 63, batch    24] loss: 3.27533\n",
      "[epoch 63, batch    25] loss: 2.86123\n",
      "[epoch 63, batch    26] loss: 2.66533\n",
      "[epoch 63, batch    27] loss: 2.72996\n",
      "[epoch 63, batch    28] loss: 2.92502\n",
      "[epoch 63, batch    29] loss: 3.16311\n",
      "[epoch 63, batch    30] loss: 3.25550\n",
      "[epoch 63, batch    31] loss: 2.45966\n",
      "[epoch 63, batch    32] loss: 5.92955\n",
      "[epoch 64, batch     1] loss: 3.57502\n",
      "[epoch 64, batch     2] loss: 2.66111\n",
      "[epoch 64, batch     3] loss: 2.85082\n",
      "[epoch 64, batch     4] loss: 3.08535\n",
      "[epoch 64, batch     5] loss: 3.16329\n",
      "[epoch 64, batch     6] loss: 3.77417\n",
      "[epoch 64, batch     7] loss: 3.59864\n",
      "[epoch 64, batch     8] loss: 2.55776\n",
      "[epoch 64, batch     9] loss: 3.45192\n",
      "[epoch 64, batch    10] loss: 2.86698\n",
      "[epoch 64, batch    11] loss: 2.72235\n",
      "[epoch 64, batch    12] loss: 3.41079\n",
      "[epoch 64, batch    13] loss: 2.67442\n",
      "[epoch 64, batch    14] loss: 2.63489\n",
      "[epoch 64, batch    15] loss: 3.01728\n",
      "[epoch 64, batch    16] loss: 2.84984\n",
      "[epoch 64, batch    17] loss: 3.82318\n",
      "[epoch 64, batch    18] loss: 3.66887\n",
      "[epoch 64, batch    19] loss: 3.63320\n",
      "[epoch 64, batch    20] loss: 2.74515\n",
      "[epoch 64, batch    21] loss: 2.94765\n",
      "[epoch 64, batch    22] loss: 3.01631\n",
      "[epoch 64, batch    23] loss: 3.23816\n",
      "[epoch 64, batch    24] loss: 2.55079\n",
      "[epoch 64, batch    25] loss: 3.87297\n",
      "[epoch 64, batch    26] loss: 3.65812\n",
      "[epoch 64, batch    27] loss: 3.47353\n",
      "[epoch 64, batch    28] loss: 2.74293\n",
      "[epoch 64, batch    29] loss: 3.37495\n",
      "[epoch 64, batch    30] loss: 2.79056\n",
      "[epoch 64, batch    31] loss: 3.33996\n",
      "[epoch 64, batch    32] loss: 2.49136\n",
      "[epoch 65, batch     1] loss: 3.54013\n",
      "[epoch 65, batch     2] loss: 2.73797\n",
      "[epoch 65, batch     3] loss: 4.25964\n",
      "[epoch 65, batch     4] loss: 2.70727\n",
      "[epoch 65, batch     5] loss: 2.91739\n",
      "[epoch 65, batch     6] loss: 2.57334\n",
      "[epoch 65, batch     7] loss: 3.85659\n",
      "[epoch 65, batch     8] loss: 3.57592\n",
      "[epoch 65, batch     9] loss: 2.79107\n",
      "[epoch 65, batch    10] loss: 4.08698\n",
      "[epoch 65, batch    11] loss: 2.65633\n",
      "[epoch 65, batch    12] loss: 2.90368\n",
      "[epoch 65, batch    13] loss: 2.43251\n",
      "[epoch 65, batch    14] loss: 3.61919\n",
      "[epoch 65, batch    15] loss: 2.77372\n",
      "[epoch 65, batch    16] loss: 2.95660\n",
      "[epoch 65, batch    17] loss: 3.06723\n",
      "[epoch 65, batch    18] loss: 2.95462\n",
      "[epoch 65, batch    19] loss: 3.51100\n",
      "[epoch 65, batch    20] loss: 3.45347\n",
      "[epoch 65, batch    21] loss: 2.87055\n",
      "[epoch 65, batch    22] loss: 3.75834\n",
      "[epoch 65, batch    23] loss: 3.21637\n",
      "[epoch 65, batch    24] loss: 3.94499\n",
      "[epoch 65, batch    25] loss: 2.54449\n",
      "[epoch 65, batch    26] loss: 3.27707\n",
      "[epoch 65, batch    27] loss: 3.23268\n",
      "[epoch 65, batch    28] loss: 2.59261\n",
      "[epoch 65, batch    29] loss: 3.55364\n",
      "[epoch 65, batch    30] loss: 2.84176\n",
      "[epoch 65, batch    31] loss: 2.61021\n",
      "[epoch 65, batch    32] loss: 1.65816\n",
      "[epoch 66, batch     1] loss: 3.44238\n",
      "[epoch 66, batch     2] loss: 2.84690\n",
      "[epoch 66, batch     3] loss: 2.71837\n",
      "[epoch 66, batch     4] loss: 3.19820\n",
      "[epoch 66, batch     5] loss: 2.97676\n",
      "[epoch 66, batch     6] loss: 2.44764\n",
      "[epoch 66, batch     7] loss: 3.30421\n",
      "[epoch 66, batch     8] loss: 3.16019\n",
      "[epoch 66, batch     9] loss: 3.19455\n",
      "[epoch 66, batch    10] loss: 3.25700\n",
      "[epoch 66, batch    11] loss: 2.95942\n",
      "[epoch 66, batch    12] loss: 3.01912\n",
      "[epoch 66, batch    13] loss: 3.23237\n",
      "[epoch 66, batch    14] loss: 3.24384\n",
      "[epoch 66, batch    15] loss: 3.18020\n",
      "[epoch 66, batch    16] loss: 3.35173\n",
      "[epoch 66, batch    17] loss: 3.37879\n",
      "[epoch 66, batch    18] loss: 3.62086\n",
      "[epoch 66, batch    19] loss: 2.44085\n",
      "[epoch 66, batch    20] loss: 3.59833\n",
      "[epoch 66, batch    21] loss: 2.58398\n",
      "[epoch 66, batch    22] loss: 3.43287\n",
      "[epoch 66, batch    23] loss: 3.41794\n",
      "[epoch 66, batch    24] loss: 3.75466\n",
      "[epoch 66, batch    25] loss: 2.38840\n",
      "[epoch 66, batch    26] loss: 2.94326\n",
      "[epoch 66, batch    27] loss: 3.64624\n",
      "[epoch 66, batch    28] loss: 2.89692\n",
      "[epoch 66, batch    29] loss: 2.51710\n",
      "[epoch 66, batch    30] loss: 3.70885\n",
      "[epoch 66, batch    31] loss: 3.38280\n",
      "[epoch 66, batch    32] loss: 2.25280\n",
      "[epoch 67, batch     1] loss: 3.04351\n",
      "[epoch 67, batch     2] loss: 3.56945\n",
      "[epoch 67, batch     3] loss: 3.24081\n",
      "[epoch 67, batch     4] loss: 3.91890\n",
      "[epoch 67, batch     5] loss: 3.06091\n",
      "[epoch 67, batch     6] loss: 3.57235\n",
      "[epoch 67, batch     7] loss: 2.96295\n",
      "[epoch 67, batch     8] loss: 2.74866\n",
      "[epoch 67, batch     9] loss: 4.12359\n",
      "[epoch 67, batch    10] loss: 3.63209\n",
      "[epoch 67, batch    11] loss: 2.60359\n",
      "[epoch 67, batch    12] loss: 3.07018\n",
      "[epoch 67, batch    13] loss: 3.82332\n",
      "[epoch 67, batch    14] loss: 2.25668\n",
      "[epoch 67, batch    15] loss: 3.30892\n",
      "[epoch 67, batch    16] loss: 2.34554\n",
      "[epoch 67, batch    17] loss: 2.54128\n",
      "[epoch 67, batch    18] loss: 3.30043\n",
      "[epoch 67, batch    19] loss: 2.87547\n",
      "[epoch 67, batch    20] loss: 3.95516\n",
      "[epoch 67, batch    21] loss: 2.82991\n",
      "[epoch 67, batch    22] loss: 2.66596\n",
      "[epoch 67, batch    23] loss: 2.79127\n",
      "[epoch 67, batch    24] loss: 2.65077\n",
      "[epoch 67, batch    25] loss: 2.62511\n",
      "[epoch 67, batch    26] loss: 4.43221\n",
      "[epoch 67, batch    27] loss: 2.86426\n",
      "[epoch 67, batch    28] loss: 2.89754\n",
      "[epoch 67, batch    29] loss: 3.20786\n",
      "[epoch 67, batch    30] loss: 3.34688\n",
      "[epoch 67, batch    31] loss: 2.66144\n",
      "[epoch 67, batch    32] loss: 3.10727\n",
      "[epoch 68, batch     1] loss: 3.01206\n",
      "[epoch 68, batch     2] loss: 2.90215\n",
      "[epoch 68, batch     3] loss: 2.25250\n",
      "[epoch 68, batch     4] loss: 4.19247\n",
      "[epoch 68, batch     5] loss: 2.91622\n",
      "[epoch 68, batch     6] loss: 3.58465\n",
      "[epoch 68, batch     7] loss: 2.04795\n",
      "[epoch 68, batch     8] loss: 3.00041\n",
      "[epoch 68, batch     9] loss: 2.66119\n",
      "[epoch 68, batch    10] loss: 3.57200\n",
      "[epoch 68, batch    11] loss: 3.40590\n",
      "[epoch 68, batch    12] loss: 3.20202\n",
      "[epoch 68, batch    13] loss: 3.53033\n",
      "[epoch 68, batch    14] loss: 2.48397\n",
      "[epoch 68, batch    15] loss: 2.52551\n",
      "[epoch 68, batch    16] loss: 3.71329\n",
      "[epoch 68, batch    17] loss: 2.52496\n",
      "[epoch 68, batch    18] loss: 3.32273\n",
      "[epoch 68, batch    19] loss: 3.33530\n",
      "[epoch 68, batch    20] loss: 2.96237\n",
      "[epoch 68, batch    21] loss: 2.80002\n",
      "[epoch 68, batch    22] loss: 2.51680\n",
      "[epoch 68, batch    23] loss: 3.77767\n",
      "[epoch 68, batch    24] loss: 3.41062\n",
      "[epoch 68, batch    25] loss: 3.77389\n",
      "[epoch 68, batch    26] loss: 2.54159\n",
      "[epoch 68, batch    27] loss: 2.74099\n",
      "[epoch 68, batch    28] loss: 4.37948\n",
      "[epoch 68, batch    29] loss: 2.50775\n",
      "[epoch 68, batch    30] loss: 3.75191\n",
      "[epoch 68, batch    31] loss: 2.68957\n",
      "[epoch 68, batch    32] loss: 5.69963\n",
      "[epoch 69, batch     1] loss: 2.52611\n",
      "[epoch 69, batch     2] loss: 2.95726\n",
      "[epoch 69, batch     3] loss: 2.70633\n",
      "[epoch 69, batch     4] loss: 2.67528\n",
      "[epoch 69, batch     5] loss: 3.65817\n",
      "[epoch 69, batch     6] loss: 4.02138\n",
      "[epoch 69, batch     7] loss: 3.08460\n",
      "[epoch 69, batch     8] loss: 3.38450\n",
      "[epoch 69, batch     9] loss: 2.77186\n",
      "[epoch 69, batch    10] loss: 3.75480\n",
      "[epoch 69, batch    11] loss: 3.72546\n",
      "[epoch 69, batch    12] loss: 2.10000\n",
      "[epoch 69, batch    13] loss: 3.14409\n",
      "[epoch 69, batch    14] loss: 2.08036\n",
      "[epoch 69, batch    15] loss: 2.66727\n",
      "[epoch 69, batch    16] loss: 3.11600\n",
      "[epoch 69, batch    17] loss: 3.96754\n",
      "[epoch 69, batch    18] loss: 3.54375\n",
      "[epoch 69, batch    19] loss: 2.68533\n",
      "[epoch 69, batch    20] loss: 2.30819\n",
      "[epoch 69, batch    21] loss: 4.22732\n",
      "[epoch 69, batch    22] loss: 2.70316\n",
      "[epoch 69, batch    23] loss: 3.21562\n",
      "[epoch 69, batch    24] loss: 3.41794\n",
      "[epoch 69, batch    25] loss: 3.28396\n",
      "[epoch 69, batch    26] loss: 2.37991\n",
      "[epoch 69, batch    27] loss: 3.44439\n",
      "[epoch 69, batch    28] loss: 2.88839\n",
      "[epoch 69, batch    29] loss: 3.35703\n",
      "[epoch 69, batch    30] loss: 3.13906\n",
      "[epoch 69, batch    31] loss: 2.99391\n",
      "[epoch 69, batch    32] loss: 5.35835\n",
      "[epoch 70, batch     1] loss: 3.19307\n",
      "[epoch 70, batch     2] loss: 3.15007\n",
      "[epoch 70, batch     3] loss: 3.29248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 70, batch     4] loss: 3.42529\n",
      "[epoch 70, batch     5] loss: 3.47910\n",
      "[epoch 70, batch     6] loss: 3.59737\n",
      "[epoch 70, batch     7] loss: 2.84597\n",
      "[epoch 70, batch     8] loss: 4.18621\n",
      "[epoch 70, batch     9] loss: 2.74076\n",
      "[epoch 70, batch    10] loss: 2.84043\n",
      "[epoch 70, batch    11] loss: 2.81765\n",
      "[epoch 70, batch    12] loss: 3.04618\n",
      "[epoch 70, batch    13] loss: 2.74444\n",
      "[epoch 70, batch    14] loss: 2.36571\n",
      "[epoch 70, batch    15] loss: 3.40123\n",
      "[epoch 70, batch    16] loss: 2.57016\n",
      "[epoch 70, batch    17] loss: 3.18394\n",
      "[epoch 70, batch    18] loss: 2.62070\n",
      "[epoch 70, batch    19] loss: 2.71928\n",
      "[epoch 70, batch    20] loss: 2.98768\n",
      "[epoch 70, batch    21] loss: 3.09383\n",
      "[epoch 70, batch    22] loss: 3.03731\n",
      "[epoch 70, batch    23] loss: 3.37008\n",
      "[epoch 70, batch    24] loss: 3.00543\n",
      "[epoch 70, batch    25] loss: 3.14338\n",
      "[epoch 70, batch    26] loss: 2.73464\n",
      "[epoch 70, batch    27] loss: 2.74446\n",
      "[epoch 70, batch    28] loss: 3.17096\n",
      "[epoch 70, batch    29] loss: 3.43387\n",
      "[epoch 70, batch    30] loss: 3.56027\n",
      "[epoch 70, batch    31] loss: 3.66484\n",
      "[epoch 70, batch    32] loss: 2.76715\n",
      "[epoch 71, batch     1] loss: 3.14513\n",
      "[epoch 71, batch     2] loss: 2.83162\n",
      "[epoch 71, batch     3] loss: 3.23160\n",
      "[epoch 71, batch     4] loss: 3.45886\n",
      "[epoch 71, batch     5] loss: 3.19063\n",
      "[epoch 71, batch     6] loss: 2.72168\n",
      "[epoch 71, batch     7] loss: 2.58915\n",
      "[epoch 71, batch     8] loss: 3.59835\n",
      "[epoch 71, batch     9] loss: 3.59971\n",
      "[epoch 71, batch    10] loss: 3.56596\n",
      "[epoch 71, batch    11] loss: 2.37663\n",
      "[epoch 71, batch    12] loss: 3.14384\n",
      "[epoch 71, batch    13] loss: 2.61869\n",
      "[epoch 71, batch    14] loss: 3.32096\n",
      "[epoch 71, batch    15] loss: 3.19760\n",
      "[epoch 71, batch    16] loss: 2.23583\n",
      "[epoch 71, batch    17] loss: 3.33475\n",
      "[epoch 71, batch    18] loss: 2.58327\n",
      "[epoch 71, batch    19] loss: 3.15729\n",
      "[epoch 71, batch    20] loss: 3.38515\n",
      "[epoch 71, batch    21] loss: 3.07405\n",
      "[epoch 71, batch    22] loss: 3.28605\n",
      "[epoch 71, batch    23] loss: 2.50224\n",
      "[epoch 71, batch    24] loss: 3.64130\n",
      "[epoch 71, batch    25] loss: 2.54433\n",
      "[epoch 71, batch    26] loss: 3.17624\n",
      "[epoch 71, batch    27] loss: 3.30981\n",
      "[epoch 71, batch    28] loss: 3.91157\n",
      "[epoch 71, batch    29] loss: 2.88971\n",
      "[epoch 71, batch    30] loss: 3.54333\n",
      "[epoch 71, batch    31] loss: 2.63468\n",
      "[epoch 71, batch    32] loss: 4.81309\n",
      "[epoch 72, batch     1] loss: 2.55416\n",
      "[epoch 72, batch     2] loss: 3.07123\n",
      "[epoch 72, batch     3] loss: 2.77659\n",
      "[epoch 72, batch     4] loss: 3.47321\n",
      "[epoch 72, batch     5] loss: 3.77433\n",
      "[epoch 72, batch     6] loss: 3.27807\n",
      "[epoch 72, batch     7] loss: 2.77676\n",
      "[epoch 72, batch     8] loss: 2.81705\n",
      "[epoch 72, batch     9] loss: 3.36512\n",
      "[epoch 72, batch    10] loss: 2.66280\n",
      "[epoch 72, batch    11] loss: 1.71702\n",
      "[epoch 72, batch    12] loss: 2.84566\n",
      "[epoch 72, batch    13] loss: 3.09339\n",
      "[epoch 72, batch    14] loss: 3.00607\n",
      "[epoch 72, batch    15] loss: 3.35709\n",
      "[epoch 72, batch    16] loss: 3.61878\n",
      "[epoch 72, batch    17] loss: 3.30624\n",
      "[epoch 72, batch    18] loss: 2.64551\n",
      "[epoch 72, batch    19] loss: 3.48051\n",
      "[epoch 72, batch    20] loss: 3.43105\n",
      "[epoch 72, batch    21] loss: 2.38961\n",
      "[epoch 72, batch    22] loss: 2.84803\n",
      "[epoch 72, batch    23] loss: 2.66452\n",
      "[epoch 72, batch    24] loss: 4.03722\n",
      "[epoch 72, batch    25] loss: 3.54942\n",
      "[epoch 72, batch    26] loss: 3.71693\n",
      "[epoch 72, batch    27] loss: 3.08197\n",
      "[epoch 72, batch    28] loss: 3.53196\n",
      "[epoch 72, batch    29] loss: 3.07234\n",
      "[epoch 72, batch    30] loss: 3.05853\n",
      "[epoch 72, batch    31] loss: 2.94907\n",
      "[epoch 72, batch    32] loss: 2.32428\n",
      "[epoch 73, batch     1] loss: 3.72406\n",
      "[epoch 73, batch     2] loss: 3.48243\n",
      "[epoch 73, batch     3] loss: 3.38827\n",
      "[epoch 73, batch     4] loss: 2.46847\n",
      "[epoch 73, batch     5] loss: 2.66268\n",
      "[epoch 73, batch     6] loss: 2.65109\n",
      "[epoch 73, batch     7] loss: 2.84436\n",
      "[epoch 73, batch     8] loss: 2.83228\n",
      "[epoch 73, batch     9] loss: 3.14632\n",
      "[epoch 73, batch    10] loss: 3.81499\n",
      "[epoch 73, batch    11] loss: 3.64224\n",
      "[epoch 73, batch    12] loss: 2.08636\n",
      "[epoch 73, batch    13] loss: 2.45335\n",
      "[epoch 73, batch    14] loss: 2.94845\n",
      "[epoch 73, batch    15] loss: 2.30510\n",
      "[epoch 73, batch    16] loss: 3.49902\n",
      "[epoch 73, batch    17] loss: 2.34319\n",
      "[epoch 73, batch    18] loss: 3.26697\n",
      "[epoch 73, batch    19] loss: 3.98958\n",
      "[epoch 73, batch    20] loss: 2.80318\n",
      "[epoch 73, batch    21] loss: 2.73646\n",
      "[epoch 73, batch    22] loss: 3.19400\n",
      "[epoch 73, batch    23] loss: 3.73591\n",
      "[epoch 73, batch    24] loss: 3.35018\n",
      "[epoch 73, batch    25] loss: 3.21233\n",
      "[epoch 73, batch    26] loss: 3.31702\n",
      "[epoch 73, batch    27] loss: 3.15975\n",
      "[epoch 73, batch    28] loss: 3.06185\n",
      "[epoch 73, batch    29] loss: 3.42315\n",
      "[epoch 73, batch    30] loss: 2.71412\n",
      "[epoch 73, batch    31] loss: 3.78854\n",
      "[epoch 73, batch    32] loss: 2.99080\n",
      "[epoch 74, batch     1] loss: 2.71621\n",
      "[epoch 74, batch     2] loss: 2.82752\n",
      "[epoch 74, batch     3] loss: 2.60587\n",
      "[epoch 74, batch     4] loss: 2.54888\n",
      "[epoch 74, batch     5] loss: 3.19754\n",
      "[epoch 74, batch     6] loss: 4.04549\n",
      "[epoch 74, batch     7] loss: 3.18874\n",
      "[epoch 74, batch     8] loss: 3.10205\n",
      "[epoch 74, batch     9] loss: 3.90548\n",
      "[epoch 74, batch    10] loss: 2.93722\n",
      "[epoch 74, batch    11] loss: 2.39734\n",
      "[epoch 74, batch    12] loss: 3.37879\n",
      "[epoch 74, batch    13] loss: 2.86283\n",
      "[epoch 74, batch    14] loss: 3.56656\n",
      "[epoch 74, batch    15] loss: 4.01872\n",
      "[epoch 74, batch    16] loss: 3.01774\n",
      "[epoch 74, batch    17] loss: 3.67953\n",
      "[epoch 74, batch    18] loss: 3.04045\n",
      "[epoch 74, batch    19] loss: 2.77788\n",
      "[epoch 74, batch    20] loss: 4.28573\n",
      "[epoch 74, batch    21] loss: 3.06453\n",
      "[epoch 74, batch    22] loss: 3.01946\n",
      "[epoch 74, batch    23] loss: 2.90981\n",
      "[epoch 74, batch    24] loss: 2.98541\n",
      "[epoch 74, batch    25] loss: 2.74792\n",
      "[epoch 74, batch    26] loss: 3.03260\n",
      "[epoch 74, batch    27] loss: 2.88576\n",
      "[epoch 74, batch    28] loss: 2.91809\n",
      "[epoch 74, batch    29] loss: 2.97887\n",
      "[epoch 74, batch    30] loss: 2.79117\n",
      "[epoch 74, batch    31] loss: 2.72001\n",
      "[epoch 74, batch    32] loss: 2.44794\n",
      "[epoch 75, batch     1] loss: 3.03120\n",
      "[epoch 75, batch     2] loss: 2.53600\n",
      "[epoch 75, batch     3] loss: 3.09738\n",
      "[epoch 75, batch     4] loss: 2.73101\n",
      "[epoch 75, batch     5] loss: 3.16807\n",
      "[epoch 75, batch     6] loss: 2.51205\n",
      "[epoch 75, batch     7] loss: 2.78072\n",
      "[epoch 75, batch     8] loss: 2.91593\n",
      "[epoch 75, batch     9] loss: 3.07661\n",
      "[epoch 75, batch    10] loss: 3.55138\n",
      "[epoch 75, batch    11] loss: 3.20888\n",
      "[epoch 75, batch    12] loss: 3.24962\n",
      "[epoch 75, batch    13] loss: 3.83315\n",
      "[epoch 75, batch    14] loss: 2.78837\n",
      "[epoch 75, batch    15] loss: 3.45426\n",
      "[epoch 75, batch    16] loss: 3.04358\n",
      "[epoch 75, batch    17] loss: 2.51725\n",
      "[epoch 75, batch    18] loss: 2.94635\n",
      "[epoch 75, batch    19] loss: 3.08365\n",
      "[epoch 75, batch    20] loss: 2.91100\n",
      "[epoch 75, batch    21] loss: 3.25522\n",
      "[epoch 75, batch    22] loss: 2.96867\n",
      "[epoch 75, batch    23] loss: 3.15806\n",
      "[epoch 75, batch    24] loss: 3.60775\n",
      "[epoch 75, batch    25] loss: 3.22728\n",
      "[epoch 75, batch    26] loss: 3.17933\n",
      "[epoch 75, batch    27] loss: 2.95235\n",
      "[epoch 75, batch    28] loss: 2.94542\n",
      "[epoch 75, batch    29] loss: 3.39680\n",
      "[epoch 75, batch    30] loss: 3.06700\n",
      "[epoch 75, batch    31] loss: 3.13955\n",
      "[epoch 75, batch    32] loss: 4.68293\n",
      "[epoch 76, batch     1] loss: 3.52699\n",
      "[epoch 76, batch     2] loss: 2.95209\n",
      "[epoch 76, batch     3] loss: 3.56083\n",
      "[epoch 76, batch     4] loss: 2.76419\n",
      "[epoch 76, batch     5] loss: 2.97104\n",
      "[epoch 76, batch     6] loss: 3.12652\n",
      "[epoch 76, batch     7] loss: 2.80473\n",
      "[epoch 76, batch     8] loss: 3.19188\n",
      "[epoch 76, batch     9] loss: 2.51202\n",
      "[epoch 76, batch    10] loss: 3.17353\n",
      "[epoch 76, batch    11] loss: 2.33350\n",
      "[epoch 76, batch    12] loss: 2.97000\n",
      "[epoch 76, batch    13] loss: 2.92441\n",
      "[epoch 76, batch    14] loss: 3.65617\n",
      "[epoch 76, batch    15] loss: 2.56740\n",
      "[epoch 76, batch    16] loss: 2.43033\n",
      "[epoch 76, batch    17] loss: 2.84080\n",
      "[epoch 76, batch    18] loss: 3.10499\n",
      "[epoch 76, batch    19] loss: 4.32125\n",
      "[epoch 76, batch    20] loss: 2.67291\n",
      "[epoch 76, batch    21] loss: 3.54229\n",
      "[epoch 76, batch    22] loss: 3.23446\n",
      "[epoch 76, batch    23] loss: 2.93455\n",
      "[epoch 76, batch    24] loss: 3.01347\n",
      "[epoch 76, batch    25] loss: 2.98546\n",
      "[epoch 76, batch    26] loss: 3.22034\n",
      "[epoch 76, batch    27] loss: 3.40716\n",
      "[epoch 76, batch    28] loss: 2.71164\n",
      "[epoch 76, batch    29] loss: 3.35895\n",
      "[epoch 76, batch    30] loss: 3.34907\n",
      "[epoch 76, batch    31] loss: 3.26571\n",
      "[epoch 76, batch    32] loss: 3.33709\n",
      "[epoch 77, batch     1] loss: 2.92245\n",
      "[epoch 77, batch     2] loss: 2.83099\n",
      "[epoch 77, batch     3] loss: 3.21846\n",
      "[epoch 77, batch     4] loss: 3.15194\n",
      "[epoch 77, batch     5] loss: 3.44908\n",
      "[epoch 77, batch     6] loss: 3.10771\n",
      "[epoch 77, batch     7] loss: 2.67323\n",
      "[epoch 77, batch     8] loss: 3.40384\n",
      "[epoch 77, batch     9] loss: 2.63531\n",
      "[epoch 77, batch    10] loss: 3.48078\n",
      "[epoch 77, batch    11] loss: 2.63843\n",
      "[epoch 77, batch    12] loss: 2.39665\n",
      "[epoch 77, batch    13] loss: 3.40703\n",
      "[epoch 77, batch    14] loss: 2.72258\n",
      "[epoch 77, batch    15] loss: 2.37742\n",
      "[epoch 77, batch    16] loss: 2.79172\n",
      "[epoch 77, batch    17] loss: 3.59692\n",
      "[epoch 77, batch    18] loss: 3.54668\n",
      "[epoch 77, batch    19] loss: 2.84850\n",
      "[epoch 77, batch    20] loss: 3.36605\n",
      "[epoch 77, batch    21] loss: 4.37592\n",
      "[epoch 77, batch    22] loss: 1.99669\n",
      "[epoch 77, batch    23] loss: 3.37969\n",
      "[epoch 77, batch    24] loss: 2.95292\n",
      "[epoch 77, batch    25] loss: 3.31746\n",
      "[epoch 77, batch    26] loss: 3.88454\n",
      "[epoch 77, batch    27] loss: 2.75390\n",
      "[epoch 77, batch    28] loss: 2.03291\n",
      "[epoch 77, batch    29] loss: 3.41834\n",
      "[epoch 77, batch    30] loss: 3.43861\n",
      "[epoch 77, batch    31] loss: 3.56335\n",
      "[epoch 77, batch    32] loss: 2.55412\n",
      "[epoch 78, batch     1] loss: 2.37776\n",
      "[epoch 78, batch     2] loss: 3.45492\n",
      "[epoch 78, batch     3] loss: 2.26280\n",
      "[epoch 78, batch     4] loss: 2.58584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 78, batch     5] loss: 3.18091\n",
      "[epoch 78, batch     6] loss: 3.53021\n",
      "[epoch 78, batch     7] loss: 2.79035\n",
      "[epoch 78, batch     8] loss: 3.30193\n",
      "[epoch 78, batch     9] loss: 3.00800\n",
      "[epoch 78, batch    10] loss: 3.63835\n",
      "[epoch 78, batch    11] loss: 3.76067\n",
      "[epoch 78, batch    12] loss: 3.42652\n",
      "[epoch 78, batch    13] loss: 3.18707\n",
      "[epoch 78, batch    14] loss: 3.47529\n",
      "[epoch 78, batch    15] loss: 3.76636\n",
      "[epoch 78, batch    16] loss: 2.23286\n",
      "[epoch 78, batch    17] loss: 3.18308\n",
      "[epoch 78, batch    18] loss: 3.14396\n",
      "[epoch 78, batch    19] loss: 2.76314\n",
      "[epoch 78, batch    20] loss: 4.10018\n",
      "[epoch 78, batch    21] loss: 3.40393\n",
      "[epoch 78, batch    22] loss: 2.54386\n",
      "[epoch 78, batch    23] loss: 2.58302\n",
      "[epoch 78, batch    24] loss: 2.50321\n",
      "[epoch 78, batch    25] loss: 3.03963\n",
      "[epoch 78, batch    26] loss: 2.86815\n",
      "[epoch 78, batch    27] loss: 3.66912\n",
      "[epoch 78, batch    28] loss: 2.14844\n",
      "[epoch 78, batch    29] loss: 2.05065\n",
      "[epoch 78, batch    30] loss: 3.30849\n",
      "[epoch 78, batch    31] loss: 3.39028\n",
      "[epoch 78, batch    32] loss: 4.16317\n",
      "[epoch 79, batch     1] loss: 2.85332\n",
      "[epoch 79, batch     2] loss: 2.40998\n",
      "[epoch 79, batch     3] loss: 3.35237\n",
      "[epoch 79, batch     4] loss: 3.63629\n",
      "[epoch 79, batch     5] loss: 2.43683\n",
      "[epoch 79, batch     6] loss: 3.00735\n",
      "[epoch 79, batch     7] loss: 2.98797\n",
      "[epoch 79, batch     8] loss: 3.06899\n",
      "[epoch 79, batch     9] loss: 3.47677\n",
      "[epoch 79, batch    10] loss: 3.10638\n",
      "[epoch 79, batch    11] loss: 2.45805\n",
      "[epoch 79, batch    12] loss: 3.54790\n",
      "[epoch 79, batch    13] loss: 3.58640\n",
      "[epoch 79, batch    14] loss: 3.23871\n",
      "[epoch 79, batch    15] loss: 3.66639\n",
      "[epoch 79, batch    16] loss: 3.14407\n",
      "[epoch 79, batch    17] loss: 2.87333\n",
      "[epoch 79, batch    18] loss: 3.18264\n",
      "[epoch 79, batch    19] loss: 2.48661\n",
      "[epoch 79, batch    20] loss: 3.22514\n",
      "[epoch 79, batch    21] loss: 3.39243\n",
      "[epoch 79, batch    22] loss: 2.88042\n",
      "[epoch 79, batch    23] loss: 3.07979\n",
      "[epoch 79, batch    24] loss: 2.58746\n",
      "[epoch 79, batch    25] loss: 3.61293\n",
      "[epoch 79, batch    26] loss: 2.01570\n",
      "[epoch 79, batch    27] loss: 3.67056\n",
      "[epoch 79, batch    28] loss: 2.90752\n",
      "[epoch 79, batch    29] loss: 3.77403\n",
      "[epoch 79, batch    30] loss: 2.31510\n",
      "[epoch 79, batch    31] loss: 3.60033\n",
      "[epoch 79, batch    32] loss: 2.06285\n",
      "[epoch 80, batch     1] loss: 2.96851\n",
      "[epoch 80, batch     2] loss: 2.88464\n",
      "[epoch 80, batch     3] loss: 2.91159\n",
      "[epoch 80, batch     4] loss: 3.40325\n",
      "[epoch 80, batch     5] loss: 3.62311\n",
      "[epoch 80, batch     6] loss: 2.91328\n",
      "[epoch 80, batch     7] loss: 3.13963\n",
      "[epoch 80, batch     8] loss: 3.10034\n",
      "[epoch 80, batch     9] loss: 2.66176\n",
      "[epoch 80, batch    10] loss: 3.81958\n",
      "[epoch 80, batch    11] loss: 2.98689\n",
      "[epoch 80, batch    12] loss: 2.44994\n",
      "[epoch 80, batch    13] loss: 3.34598\n",
      "[epoch 80, batch    14] loss: 2.74258\n",
      "[epoch 80, batch    15] loss: 2.53654\n",
      "[epoch 80, batch    16] loss: 3.71359\n",
      "[epoch 80, batch    17] loss: 2.63574\n",
      "[epoch 80, batch    18] loss: 2.22804\n",
      "[epoch 80, batch    19] loss: 2.88680\n",
      "[epoch 80, batch    20] loss: 3.68147\n",
      "[epoch 80, batch    21] loss: 3.93235\n",
      "[epoch 80, batch    22] loss: 3.52274\n",
      "[epoch 80, batch    23] loss: 2.85661\n",
      "[epoch 80, batch    24] loss: 2.74386\n",
      "[epoch 80, batch    25] loss: 2.50948\n",
      "[epoch 80, batch    26] loss: 3.08259\n",
      "[epoch 80, batch    27] loss: 3.29063\n",
      "[epoch 80, batch    28] loss: 2.37310\n",
      "[epoch 80, batch    29] loss: 2.69822\n",
      "[epoch 80, batch    30] loss: 3.63785\n",
      "[epoch 80, batch    31] loss: 3.34197\n",
      "[epoch 80, batch    32] loss: 4.94495\n",
      "[epoch 81, batch     1] loss: 3.19170\n",
      "[epoch 81, batch     2] loss: 2.69491\n",
      "[epoch 81, batch     3] loss: 2.65786\n",
      "[epoch 81, batch     4] loss: 2.43670\n",
      "[epoch 81, batch     5] loss: 2.89704\n",
      "[epoch 81, batch     6] loss: 3.04964\n",
      "[epoch 81, batch     7] loss: 2.61822\n",
      "[epoch 81, batch     8] loss: 2.41784\n",
      "[epoch 81, batch     9] loss: 3.37803\n",
      "[epoch 81, batch    10] loss: 2.61488\n",
      "[epoch 81, batch    11] loss: 4.40129\n",
      "[epoch 81, batch    12] loss: 2.44192\n",
      "[epoch 81, batch    13] loss: 2.97192\n",
      "[epoch 81, batch    14] loss: 2.87071\n",
      "[epoch 81, batch    15] loss: 2.97676\n",
      "[epoch 81, batch    16] loss: 3.02393\n",
      "[epoch 81, batch    17] loss: 2.81993\n",
      "[epoch 81, batch    18] loss: 2.58583\n",
      "[epoch 81, batch    19] loss: 2.73165\n",
      "[epoch 81, batch    20] loss: 3.90244\n",
      "[epoch 81, batch    21] loss: 3.34249\n",
      "[epoch 81, batch    22] loss: 3.46281\n",
      "[epoch 81, batch    23] loss: 4.42148\n",
      "[epoch 81, batch    24] loss: 2.96879\n",
      "[epoch 81, batch    25] loss: 3.66785\n",
      "[epoch 81, batch    26] loss: 3.30142\n",
      "[epoch 81, batch    27] loss: 2.99805\n",
      "[epoch 81, batch    28] loss: 3.42040\n",
      "[epoch 81, batch    29] loss: 2.40915\n",
      "[epoch 81, batch    30] loss: 3.17012\n",
      "[epoch 81, batch    31] loss: 3.29430\n",
      "[epoch 81, batch    32] loss: 3.74982\n",
      "[epoch 82, batch     1] loss: 3.30762\n",
      "[epoch 82, batch     2] loss: 3.34679\n",
      "[epoch 82, batch     3] loss: 2.58854\n",
      "[epoch 82, batch     4] loss: 3.03130\n",
      "[epoch 82, batch     5] loss: 3.96388\n",
      "[epoch 82, batch     6] loss: 3.23839\n",
      "[epoch 82, batch     7] loss: 4.35911\n",
      "[epoch 82, batch     8] loss: 2.77150\n",
      "[epoch 82, batch     9] loss: 2.51180\n",
      "[epoch 82, batch    10] loss: 2.71452\n",
      "[epoch 82, batch    11] loss: 3.23476\n",
      "[epoch 82, batch    12] loss: 2.65376\n",
      "[epoch 82, batch    13] loss: 2.21322\n",
      "[epoch 82, batch    14] loss: 2.33897\n",
      "[epoch 82, batch    15] loss: 3.76536\n",
      "[epoch 82, batch    16] loss: 3.52315\n",
      "[epoch 82, batch    17] loss: 3.01746\n",
      "[epoch 82, batch    18] loss: 3.11425\n",
      "[epoch 82, batch    19] loss: 2.27679\n",
      "[epoch 82, batch    20] loss: 2.82653\n",
      "[epoch 82, batch    21] loss: 3.07263\n",
      "[epoch 82, batch    22] loss: 3.85246\n",
      "[epoch 82, batch    23] loss: 3.62262\n",
      "[epoch 82, batch    24] loss: 2.61479\n",
      "[epoch 82, batch    25] loss: 2.93407\n",
      "[epoch 82, batch    26] loss: 3.14046\n",
      "[epoch 82, batch    27] loss: 2.99641\n",
      "[epoch 82, batch    28] loss: 3.08837\n",
      "[epoch 82, batch    29] loss: 3.59403\n",
      "[epoch 82, batch    30] loss: 1.76388\n",
      "[epoch 82, batch    31] loss: 2.87541\n",
      "[epoch 82, batch    32] loss: 4.01469\n",
      "[epoch 83, batch     1] loss: 3.11033\n",
      "[epoch 83, batch     2] loss: 3.36088\n",
      "[epoch 83, batch     3] loss: 3.28659\n",
      "[epoch 83, batch     4] loss: 3.17503\n",
      "[epoch 83, batch     5] loss: 2.79514\n",
      "[epoch 83, batch     6] loss: 3.40119\n",
      "[epoch 83, batch     7] loss: 3.03660\n",
      "[epoch 83, batch     8] loss: 2.54862\n",
      "[epoch 83, batch     9] loss: 3.13389\n",
      "[epoch 83, batch    10] loss: 2.18373\n",
      "[epoch 83, batch    11] loss: 3.08582\n",
      "[epoch 83, batch    12] loss: 2.89047\n",
      "[epoch 83, batch    13] loss: 3.44294\n",
      "[epoch 83, batch    14] loss: 2.94102\n",
      "[epoch 83, batch    15] loss: 3.01562\n",
      "[epoch 83, batch    16] loss: 3.77906\n",
      "[epoch 83, batch    17] loss: 2.72530\n",
      "[epoch 83, batch    18] loss: 2.60001\n",
      "[epoch 83, batch    19] loss: 2.91019\n",
      "[epoch 83, batch    20] loss: 3.57576\n",
      "[epoch 83, batch    21] loss: 2.75015\n",
      "[epoch 83, batch    22] loss: 3.96771\n",
      "[epoch 83, batch    23] loss: 2.49732\n",
      "[epoch 83, batch    24] loss: 2.31471\n",
      "[epoch 83, batch    25] loss: 3.06755\n",
      "[epoch 83, batch    26] loss: 3.90750\n",
      "[epoch 83, batch    27] loss: 2.97912\n",
      "[epoch 83, batch    28] loss: 2.78155\n",
      "[epoch 83, batch    29] loss: 2.91680\n",
      "[epoch 83, batch    30] loss: 3.56914\n",
      "[epoch 83, batch    31] loss: 3.04433\n",
      "[epoch 83, batch    32] loss: 3.61630\n",
      "[epoch 84, batch     1] loss: 4.20629\n",
      "[epoch 84, batch     2] loss: 4.21544\n",
      "[epoch 84, batch     3] loss: 2.70680\n",
      "[epoch 84, batch     4] loss: 2.64456\n",
      "[epoch 84, batch     5] loss: 3.15412\n",
      "[epoch 84, batch     6] loss: 3.08195\n",
      "[epoch 84, batch     7] loss: 3.30391\n",
      "[epoch 84, batch     8] loss: 2.77012\n",
      "[epoch 84, batch     9] loss: 3.44514\n",
      "[epoch 84, batch    10] loss: 1.99156\n",
      "[epoch 84, batch    11] loss: 2.98745\n",
      "[epoch 84, batch    12] loss: 3.04690\n",
      "[epoch 84, batch    13] loss: 2.61463\n",
      "[epoch 84, batch    14] loss: 3.05131\n",
      "[epoch 84, batch    15] loss: 3.29955\n",
      "[epoch 84, batch    16] loss: 3.05755\n",
      "[epoch 84, batch    17] loss: 3.27738\n",
      "[epoch 84, batch    18] loss: 2.83551\n",
      "[epoch 84, batch    19] loss: 2.96243\n",
      "[epoch 84, batch    20] loss: 2.44777\n",
      "[epoch 84, batch    21] loss: 2.37369\n",
      "[epoch 84, batch    22] loss: 2.96539\n",
      "[epoch 84, batch    23] loss: 2.77543\n",
      "[epoch 84, batch    24] loss: 2.50733\n",
      "[epoch 84, batch    25] loss: 3.68659\n",
      "[epoch 84, batch    26] loss: 2.67212\n",
      "[epoch 84, batch    27] loss: 3.60770\n",
      "[epoch 84, batch    28] loss: 2.80324\n",
      "[epoch 84, batch    29] loss: 3.71730\n",
      "[epoch 84, batch    30] loss: 3.19161\n",
      "[epoch 84, batch    31] loss: 3.33226\n",
      "[epoch 84, batch    32] loss: 3.49133\n",
      "[epoch 85, batch     1] loss: 3.41469\n",
      "[epoch 85, batch     2] loss: 2.85592\n",
      "[epoch 85, batch     3] loss: 3.02644\n",
      "[epoch 85, batch     4] loss: 2.71643\n",
      "[epoch 85, batch     5] loss: 3.25426\n",
      "[epoch 85, batch     6] loss: 2.79819\n",
      "[epoch 85, batch     7] loss: 2.56299\n",
      "[epoch 85, batch     8] loss: 3.22488\n",
      "[epoch 85, batch     9] loss: 3.21667\n",
      "[epoch 85, batch    10] loss: 4.23226\n",
      "[epoch 85, batch    11] loss: 3.34736\n",
      "[epoch 85, batch    12] loss: 3.46461\n",
      "[epoch 85, batch    13] loss: 3.59371\n",
      "[epoch 85, batch    14] loss: 3.00801\n",
      "[epoch 85, batch    15] loss: 2.40016\n",
      "[epoch 85, batch    16] loss: 3.12657\n",
      "[epoch 85, batch    17] loss: 2.93722\n",
      "[epoch 85, batch    18] loss: 3.95538\n",
      "[epoch 85, batch    19] loss: 2.78992\n",
      "[epoch 85, batch    20] loss: 1.81921\n",
      "[epoch 85, batch    21] loss: 3.21802\n",
      "[epoch 85, batch    22] loss: 2.90533\n",
      "[epoch 85, batch    23] loss: 2.78127\n",
      "[epoch 85, batch    24] loss: 1.85939\n",
      "[epoch 85, batch    25] loss: 3.68961\n",
      "[epoch 85, batch    26] loss: 2.41854\n",
      "[epoch 85, batch    27] loss: 3.62361\n",
      "[epoch 85, batch    28] loss: 2.57027\n",
      "[epoch 85, batch    29] loss: 3.21128\n",
      "[epoch 85, batch    30] loss: 3.40533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 85, batch    31] loss: 3.59048\n",
      "[epoch 85, batch    32] loss: 2.77548\n",
      "[epoch 86, batch     1] loss: 3.10732\n",
      "[epoch 86, batch     2] loss: 2.48542\n",
      "[epoch 86, batch     3] loss: 3.52420\n",
      "[epoch 86, batch     4] loss: 2.90724\n",
      "[epoch 86, batch     5] loss: 3.14038\n",
      "[epoch 86, batch     6] loss: 2.48565\n",
      "[epoch 86, batch     7] loss: 2.65489\n",
      "[epoch 86, batch     8] loss: 3.80762\n",
      "[epoch 86, batch     9] loss: 2.21224\n",
      "[epoch 86, batch    10] loss: 2.44829\n",
      "[epoch 86, batch    11] loss: 3.04457\n",
      "[epoch 86, batch    12] loss: 2.69031\n",
      "[epoch 86, batch    13] loss: 3.64107\n",
      "[epoch 86, batch    14] loss: 2.78033\n",
      "[epoch 86, batch    15] loss: 2.96953\n",
      "[epoch 86, batch    16] loss: 2.61128\n",
      "[epoch 86, batch    17] loss: 3.37716\n",
      "[epoch 86, batch    18] loss: 3.04068\n",
      "[epoch 86, batch    19] loss: 3.32418\n",
      "[epoch 86, batch    20] loss: 3.34118\n",
      "[epoch 86, batch    21] loss: 2.79638\n",
      "[epoch 86, batch    22] loss: 4.40834\n",
      "[epoch 86, batch    23] loss: 3.42285\n",
      "[epoch 86, batch    24] loss: 2.72598\n",
      "[epoch 86, batch    25] loss: 2.63937\n",
      "[epoch 86, batch    26] loss: 3.16919\n",
      "[epoch 86, batch    27] loss: 2.99003\n",
      "[epoch 86, batch    28] loss: 3.52737\n",
      "[epoch 86, batch    29] loss: 2.90355\n",
      "[epoch 86, batch    30] loss: 3.80630\n",
      "[epoch 86, batch    31] loss: 3.14943\n",
      "[epoch 86, batch    32] loss: 1.69481\n",
      "[epoch 87, batch     1] loss: 2.64943\n",
      "[epoch 87, batch     2] loss: 3.00626\n",
      "[epoch 87, batch     3] loss: 2.78128\n",
      "[epoch 87, batch     4] loss: 3.05920\n",
      "[epoch 87, batch     5] loss: 3.46448\n",
      "[epoch 87, batch     6] loss: 2.62503\n",
      "[epoch 87, batch     7] loss: 3.12620\n",
      "[epoch 87, batch     8] loss: 4.05630\n",
      "[epoch 87, batch     9] loss: 3.20982\n",
      "[epoch 87, batch    10] loss: 2.82701\n",
      "[epoch 87, batch    11] loss: 3.17516\n",
      "[epoch 87, batch    12] loss: 3.75519\n",
      "[epoch 87, batch    13] loss: 2.13487\n",
      "[epoch 87, batch    14] loss: 4.23743\n",
      "[epoch 87, batch    15] loss: 2.83073\n",
      "[epoch 87, batch    16] loss: 3.72152\n",
      "[epoch 87, batch    17] loss: 3.79718\n",
      "[epoch 87, batch    18] loss: 2.75726\n",
      "[epoch 87, batch    19] loss: 2.65564\n",
      "[epoch 87, batch    20] loss: 2.40976\n",
      "[epoch 87, batch    21] loss: 2.76345\n",
      "[epoch 87, batch    22] loss: 2.61970\n",
      "[epoch 87, batch    23] loss: 3.08400\n",
      "[epoch 87, batch    24] loss: 3.25906\n",
      "[epoch 87, batch    25] loss: 3.57137\n",
      "[epoch 87, batch    26] loss: 3.23802\n",
      "[epoch 87, batch    27] loss: 2.79926\n",
      "[epoch 87, batch    28] loss: 3.12903\n",
      "[epoch 87, batch    29] loss: 2.04249\n",
      "[epoch 87, batch    30] loss: 3.52793\n",
      "[epoch 87, batch    31] loss: 2.47311\n",
      "[epoch 87, batch    32] loss: 2.90403\n",
      "[epoch 88, batch     1] loss: 2.78655\n",
      "[epoch 88, batch     2] loss: 2.82408\n",
      "[epoch 88, batch     3] loss: 3.69905\n",
      "[epoch 88, batch     4] loss: 3.64699\n",
      "[epoch 88, batch     5] loss: 3.16224\n",
      "[epoch 88, batch     6] loss: 3.22771\n",
      "[epoch 88, batch     7] loss: 2.95728\n",
      "[epoch 88, batch     8] loss: 2.74135\n",
      "[epoch 88, batch     9] loss: 2.64713\n",
      "[epoch 88, batch    10] loss: 2.91601\n",
      "[epoch 88, batch    11] loss: 2.27192\n",
      "[epoch 88, batch    12] loss: 2.71523\n",
      "[epoch 88, batch    13] loss: 3.12857\n",
      "[epoch 88, batch    14] loss: 3.32615\n",
      "[epoch 88, batch    15] loss: 2.52125\n",
      "[epoch 88, batch    16] loss: 3.31512\n",
      "[epoch 88, batch    17] loss: 3.17794\n",
      "[epoch 88, batch    18] loss: 3.67569\n",
      "[epoch 88, batch    19] loss: 3.26035\n",
      "[epoch 88, batch    20] loss: 2.98493\n",
      "[epoch 88, batch    21] loss: 3.26349\n",
      "[epoch 88, batch    22] loss: 2.67499\n",
      "[epoch 88, batch    23] loss: 3.24954\n",
      "[epoch 88, batch    24] loss: 2.78897\n",
      "[epoch 88, batch    25] loss: 2.89793\n",
      "[epoch 88, batch    26] loss: 2.78284\n",
      "[epoch 88, batch    27] loss: 3.50750\n",
      "[epoch 88, batch    28] loss: 3.45440\n",
      "[epoch 88, batch    29] loss: 3.48110\n",
      "[epoch 88, batch    30] loss: 2.84269\n",
      "[epoch 88, batch    31] loss: 2.70235\n",
      "[epoch 88, batch    32] loss: 3.32068\n",
      "[epoch 89, batch     1] loss: 2.99353\n",
      "[epoch 89, batch     2] loss: 3.22417\n",
      "[epoch 89, batch     3] loss: 2.75125\n",
      "[epoch 89, batch     4] loss: 3.42401\n",
      "[epoch 89, batch     5] loss: 2.92486\n",
      "[epoch 89, batch     6] loss: 2.90087\n",
      "[epoch 89, batch     7] loss: 3.75404\n",
      "[epoch 89, batch     8] loss: 2.83239\n",
      "[epoch 89, batch     9] loss: 3.33018\n",
      "[epoch 89, batch    10] loss: 2.38503\n",
      "[epoch 89, batch    11] loss: 3.30427\n",
      "[epoch 89, batch    12] loss: 2.68079\n",
      "[epoch 89, batch    13] loss: 3.19306\n",
      "[epoch 89, batch    14] loss: 3.33864\n",
      "[epoch 89, batch    15] loss: 3.65492\n",
      "[epoch 89, batch    16] loss: 3.19704\n",
      "[epoch 89, batch    17] loss: 2.62050\n",
      "[epoch 89, batch    18] loss: 2.67086\n",
      "[epoch 89, batch    19] loss: 2.35303\n",
      "[epoch 89, batch    20] loss: 3.17840\n",
      "[epoch 89, batch    21] loss: 2.60817\n",
      "[epoch 89, batch    22] loss: 3.21992\n",
      "[epoch 89, batch    23] loss: 2.95970\n",
      "[epoch 89, batch    24] loss: 3.15479\n",
      "[epoch 89, batch    25] loss: 3.38771\n",
      "[epoch 89, batch    26] loss: 3.48912\n",
      "[epoch 89, batch    27] loss: 3.11475\n",
      "[epoch 89, batch    28] loss: 3.13019\n",
      "[epoch 89, batch    29] loss: 2.93719\n",
      "[epoch 89, batch    30] loss: 2.77605\n",
      "[epoch 89, batch    31] loss: 2.42116\n",
      "[epoch 89, batch    32] loss: 5.86939\n",
      "[epoch 90, batch     1] loss: 3.36401\n",
      "[epoch 90, batch     2] loss: 3.75871\n",
      "[epoch 90, batch     3] loss: 4.00362\n",
      "[epoch 90, batch     4] loss: 2.90108\n",
      "[epoch 90, batch     5] loss: 2.76356\n",
      "[epoch 90, batch     6] loss: 3.21884\n",
      "[epoch 90, batch     7] loss: 3.20232\n",
      "[epoch 90, batch     8] loss: 3.50689\n",
      "[epoch 90, batch     9] loss: 2.56662\n",
      "[epoch 90, batch    10] loss: 2.69957\n",
      "[epoch 90, batch    11] loss: 3.18906\n",
      "[epoch 90, batch    12] loss: 2.93739\n",
      "[epoch 90, batch    13] loss: 2.41458\n",
      "[epoch 90, batch    14] loss: 2.28790\n",
      "[epoch 90, batch    15] loss: 2.63878\n",
      "[epoch 90, batch    16] loss: 2.09652\n",
      "[epoch 90, batch    17] loss: 2.28344\n",
      "[epoch 90, batch    18] loss: 3.52151\n",
      "[epoch 90, batch    19] loss: 3.32581\n",
      "[epoch 90, batch    20] loss: 3.21798\n",
      "[epoch 90, batch    21] loss: 2.28003\n",
      "[epoch 90, batch    22] loss: 3.52428\n",
      "[epoch 90, batch    23] loss: 3.45097\n",
      "[epoch 90, batch    24] loss: 2.92216\n",
      "[epoch 90, batch    25] loss: 3.39572\n",
      "[epoch 90, batch    26] loss: 3.42097\n",
      "[epoch 90, batch    27] loss: 3.51078\n",
      "[epoch 90, batch    28] loss: 3.94829\n",
      "[epoch 90, batch    29] loss: 2.79388\n",
      "[epoch 90, batch    30] loss: 2.61699\n",
      "[epoch 90, batch    31] loss: 2.59201\n",
      "[epoch 90, batch    32] loss: 3.40472\n",
      "[epoch 91, batch     1] loss: 3.00653\n",
      "[epoch 91, batch     2] loss: 3.26526\n",
      "[epoch 91, batch     3] loss: 2.68340\n",
      "[epoch 91, batch     4] loss: 3.09230\n",
      "[epoch 91, batch     5] loss: 2.54014\n",
      "[epoch 91, batch     6] loss: 3.80176\n",
      "[epoch 91, batch     7] loss: 2.92350\n",
      "[epoch 91, batch     8] loss: 2.62138\n",
      "[epoch 91, batch     9] loss: 3.56806\n",
      "[epoch 91, batch    10] loss: 3.26159\n",
      "[epoch 91, batch    11] loss: 3.14074\n",
      "[epoch 91, batch    12] loss: 3.80325\n",
      "[epoch 91, batch    13] loss: 3.11223\n",
      "[epoch 91, batch    14] loss: 2.44385\n",
      "[epoch 91, batch    15] loss: 2.31440\n",
      "[epoch 91, batch    16] loss: 3.89804\n",
      "[epoch 91, batch    17] loss: 3.14607\n",
      "[epoch 91, batch    18] loss: 2.41993\n",
      "[epoch 91, batch    19] loss: 3.24431\n",
      "[epoch 91, batch    20] loss: 2.97827\n",
      "[epoch 91, batch    21] loss: 3.05946\n",
      "[epoch 91, batch    22] loss: 3.67596\n",
      "[epoch 91, batch    23] loss: 3.22234\n",
      "[epoch 91, batch    24] loss: 3.07130\n",
      "[epoch 91, batch    25] loss: 2.58972\n",
      "[epoch 91, batch    26] loss: 3.02871\n",
      "[epoch 91, batch    27] loss: 3.26702\n",
      "[epoch 91, batch    28] loss: 2.49877\n",
      "[epoch 91, batch    29] loss: 3.44626\n",
      "[epoch 91, batch    30] loss: 2.57286\n",
      "[epoch 91, batch    31] loss: 2.88005\n",
      "[epoch 91, batch    32] loss: 3.06763\n",
      "[epoch 92, batch     1] loss: 3.10299\n",
      "[epoch 92, batch     2] loss: 3.79994\n",
      "[epoch 92, batch     3] loss: 3.34193\n",
      "[epoch 92, batch     4] loss: 2.62460\n",
      "[epoch 92, batch     5] loss: 3.33833\n",
      "[epoch 92, batch     6] loss: 3.41101\n",
      "[epoch 92, batch     7] loss: 2.45079\n",
      "[epoch 92, batch     8] loss: 3.66761\n",
      "[epoch 92, batch     9] loss: 3.16639\n",
      "[epoch 92, batch    10] loss: 3.10331\n",
      "[epoch 92, batch    11] loss: 3.19761\n",
      "[epoch 92, batch    12] loss: 3.83707\n",
      "[epoch 92, batch    13] loss: 2.56317\n",
      "[epoch 92, batch    14] loss: 2.55625\n",
      "[epoch 92, batch    15] loss: 2.75755\n",
      "[epoch 92, batch    16] loss: 3.13513\n",
      "[epoch 92, batch    17] loss: 2.98865\n",
      "[epoch 92, batch    18] loss: 2.60252\n",
      "[epoch 92, batch    19] loss: 3.40297\n",
      "[epoch 92, batch    20] loss: 3.63445\n",
      "[epoch 92, batch    21] loss: 2.57645\n",
      "[epoch 92, batch    22] loss: 2.95589\n",
      "[epoch 92, batch    23] loss: 2.92043\n",
      "[epoch 92, batch    24] loss: 3.11078\n",
      "[epoch 92, batch    25] loss: 3.18317\n",
      "[epoch 92, batch    26] loss: 1.82447\n",
      "[epoch 92, batch    27] loss: 3.09421\n",
      "[epoch 92, batch    28] loss: 2.70045\n",
      "[epoch 92, batch    29] loss: 3.83889\n",
      "[epoch 92, batch    30] loss: 3.18775\n",
      "[epoch 92, batch    31] loss: 2.11561\n",
      "[epoch 92, batch    32] loss: 2.84001\n",
      "[epoch 93, batch     1] loss: 2.78981\n",
      "[epoch 93, batch     2] loss: 2.91369\n",
      "[epoch 93, batch     3] loss: 3.70871\n",
      "[epoch 93, batch     4] loss: 3.09012\n",
      "[epoch 93, batch     5] loss: 2.65470\n",
      "[epoch 93, batch     6] loss: 2.88392\n",
      "[epoch 93, batch     7] loss: 3.33889\n",
      "[epoch 93, batch     8] loss: 2.58297\n",
      "[epoch 93, batch     9] loss: 2.81088\n",
      "[epoch 93, batch    10] loss: 3.18521\n",
      "[epoch 93, batch    11] loss: 3.68517\n",
      "[epoch 93, batch    12] loss: 3.94345\n",
      "[epoch 93, batch    13] loss: 3.40356\n",
      "[epoch 93, batch    14] loss: 2.75928\n",
      "[epoch 93, batch    15] loss: 2.45227\n",
      "[epoch 93, batch    16] loss: 2.54490\n",
      "[epoch 93, batch    17] loss: 3.62358\n",
      "[epoch 93, batch    18] loss: 3.07604\n",
      "[epoch 93, batch    19] loss: 3.88378\n",
      "[epoch 93, batch    20] loss: 3.04989\n",
      "[epoch 93, batch    21] loss: 3.78181\n",
      "[epoch 93, batch    22] loss: 3.05249\n",
      "[epoch 93, batch    23] loss: 2.97276\n",
      "[epoch 93, batch    24] loss: 2.25813\n",
      "[epoch 93, batch    25] loss: 3.06966\n",
      "[epoch 93, batch    26] loss: 2.68403\n",
      "[epoch 93, batch    27] loss: 2.64671\n",
      "[epoch 93, batch    28] loss: 2.83154\n",
      "[epoch 93, batch    29] loss: 2.55977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 93, batch    30] loss: 3.53273\n",
      "[epoch 93, batch    31] loss: 2.30235\n",
      "[epoch 93, batch    32] loss: 2.99582\n",
      "[epoch 94, batch     1] loss: 2.62528\n",
      "[epoch 94, batch     2] loss: 2.94618\n",
      "[epoch 94, batch     3] loss: 3.80954\n",
      "[epoch 94, batch     4] loss: 2.89483\n",
      "[epoch 94, batch     5] loss: 4.56486\n",
      "[epoch 94, batch     6] loss: 2.97659\n",
      "[epoch 94, batch     7] loss: 4.22380\n",
      "[epoch 94, batch     8] loss: 2.70081\n",
      "[epoch 94, batch     9] loss: 4.18574\n",
      "[epoch 94, batch    10] loss: 3.27167\n",
      "[epoch 94, batch    11] loss: 2.40438\n",
      "[epoch 94, batch    12] loss: 2.75410\n",
      "[epoch 94, batch    13] loss: 2.68312\n",
      "[epoch 94, batch    14] loss: 2.12018\n",
      "[epoch 94, batch    15] loss: 3.02695\n",
      "[epoch 94, batch    16] loss: 2.79408\n",
      "[epoch 94, batch    17] loss: 2.92042\n",
      "[epoch 94, batch    18] loss: 3.24338\n",
      "[epoch 94, batch    19] loss: 2.61156\n",
      "[epoch 94, batch    20] loss: 3.10546\n",
      "[epoch 94, batch    21] loss: 2.23358\n",
      "[epoch 94, batch    22] loss: 3.64623\n",
      "[epoch 94, batch    23] loss: 3.22093\n",
      "[epoch 94, batch    24] loss: 3.07471\n",
      "[epoch 94, batch    25] loss: 2.56719\n",
      "[epoch 94, batch    26] loss: 3.22803\n",
      "[epoch 94, batch    27] loss: 3.13520\n",
      "[epoch 94, batch    28] loss: 3.77808\n",
      "[epoch 94, batch    29] loss: 2.97851\n",
      "[epoch 94, batch    30] loss: 2.15518\n",
      "[epoch 94, batch    31] loss: 2.51562\n",
      "[epoch 94, batch    32] loss: 2.61512\n",
      "[epoch 95, batch     1] loss: 2.62182\n",
      "[epoch 95, batch     2] loss: 3.46432\n",
      "[epoch 95, batch     3] loss: 2.50153\n",
      "[epoch 95, batch     4] loss: 3.05549\n",
      "[epoch 95, batch     5] loss: 2.45230\n",
      "[epoch 95, batch     6] loss: 3.09758\n",
      "[epoch 95, batch     7] loss: 2.95532\n",
      "[epoch 95, batch     8] loss: 3.34643\n",
      "[epoch 95, batch     9] loss: 2.72731\n",
      "[epoch 95, batch    10] loss: 2.91362\n",
      "[epoch 95, batch    11] loss: 3.41734\n",
      "[epoch 95, batch    12] loss: 2.91498\n",
      "[epoch 95, batch    13] loss: 3.36019\n",
      "[epoch 95, batch    14] loss: 3.92745\n",
      "[epoch 95, batch    15] loss: 2.75250\n",
      "[epoch 95, batch    16] loss: 3.26529\n",
      "[epoch 95, batch    17] loss: 3.00114\n",
      "[epoch 95, batch    18] loss: 2.83530\n",
      "[epoch 95, batch    19] loss: 3.05254\n",
      "[epoch 95, batch    20] loss: 3.14212\n",
      "[epoch 95, batch    21] loss: 2.21222\n",
      "[epoch 95, batch    22] loss: 2.81139\n",
      "[epoch 95, batch    23] loss: 2.84780\n",
      "[epoch 95, batch    24] loss: 2.71039\n",
      "[epoch 95, batch    25] loss: 3.44042\n",
      "[epoch 95, batch    26] loss: 3.39654\n",
      "[epoch 95, batch    27] loss: 3.01109\n",
      "[epoch 95, batch    28] loss: 3.38202\n",
      "[epoch 95, batch    29] loss: 3.66113\n",
      "[epoch 95, batch    30] loss: 2.85258\n",
      "[epoch 95, batch    31] loss: 3.30978\n",
      "[epoch 95, batch    32] loss: 2.98468\n",
      "[epoch 96, batch     1] loss: 3.70745\n",
      "[epoch 96, batch     2] loss: 2.75936\n",
      "[epoch 96, batch     3] loss: 3.12354\n",
      "[epoch 96, batch     4] loss: 3.15526\n",
      "[epoch 96, batch     5] loss: 2.89236\n",
      "[epoch 96, batch     6] loss: 3.27427\n",
      "[epoch 96, batch     7] loss: 2.65393\n",
      "[epoch 96, batch     8] loss: 2.84540\n",
      "[epoch 96, batch     9] loss: 3.13395\n",
      "[epoch 96, batch    10] loss: 3.60638\n",
      "[epoch 96, batch    11] loss: 3.22060\n",
      "[epoch 96, batch    12] loss: 2.57665\n",
      "[epoch 96, batch    13] loss: 2.20932\n",
      "[epoch 96, batch    14] loss: 2.53013\n",
      "[epoch 96, batch    15] loss: 4.31449\n",
      "[epoch 96, batch    16] loss: 2.83586\n",
      "[epoch 96, batch    17] loss: 2.34305\n",
      "[epoch 96, batch    18] loss: 2.46851\n",
      "[epoch 96, batch    19] loss: 3.43984\n",
      "[epoch 96, batch    20] loss: 2.38669\n",
      "[epoch 96, batch    21] loss: 3.18405\n",
      "[epoch 96, batch    22] loss: 3.86797\n",
      "[epoch 96, batch    23] loss: 3.52719\n",
      "[epoch 96, batch    24] loss: 3.62476\n",
      "[epoch 96, batch    25] loss: 2.85919\n",
      "[epoch 96, batch    26] loss: 3.10369\n",
      "[epoch 96, batch    27] loss: 2.99915\n",
      "[epoch 96, batch    28] loss: 2.98047\n",
      "[epoch 96, batch    29] loss: 2.54744\n",
      "[epoch 96, batch    30] loss: 2.77695\n",
      "[epoch 96, batch    31] loss: 3.49758\n",
      "[epoch 96, batch    32] loss: 2.96492\n",
      "[epoch 97, batch     1] loss: 3.55020\n",
      "[epoch 97, batch     2] loss: 3.09389\n",
      "[epoch 97, batch     3] loss: 3.03781\n",
      "[epoch 97, batch     4] loss: 3.06552\n",
      "[epoch 97, batch     5] loss: 3.58028\n",
      "[epoch 97, batch     6] loss: 2.85974\n",
      "[epoch 97, batch     7] loss: 2.76463\n",
      "[epoch 97, batch     8] loss: 3.24734\n",
      "[epoch 97, batch     9] loss: 2.96103\n",
      "[epoch 97, batch    10] loss: 3.35807\n",
      "[epoch 97, batch    11] loss: 3.40292\n",
      "[epoch 97, batch    12] loss: 4.00503\n",
      "[epoch 97, batch    13] loss: 2.54129\n",
      "[epoch 97, batch    14] loss: 2.87064\n",
      "[epoch 97, batch    15] loss: 1.76995\n",
      "[epoch 97, batch    16] loss: 3.83073\n",
      "[epoch 97, batch    17] loss: 2.96648\n",
      "[epoch 97, batch    18] loss: 3.07112\n",
      "[epoch 97, batch    19] loss: 3.46054\n",
      "[epoch 97, batch    20] loss: 3.14309\n",
      "[epoch 97, batch    21] loss: 2.92487\n",
      "[epoch 97, batch    22] loss: 3.25962\n",
      "[epoch 97, batch    23] loss: 2.37052\n",
      "[epoch 97, batch    24] loss: 2.71360\n",
      "[epoch 97, batch    25] loss: 2.57681\n",
      "[epoch 97, batch    26] loss: 2.96019\n",
      "[epoch 97, batch    27] loss: 2.79394\n",
      "[epoch 97, batch    28] loss: 2.40456\n",
      "[epoch 97, batch    29] loss: 2.50133\n",
      "[epoch 97, batch    30] loss: 3.80290\n",
      "[epoch 97, batch    31] loss: 3.61905\n",
      "[epoch 97, batch    32] loss: 3.38640\n",
      "[epoch 98, batch     1] loss: 3.00904\n",
      "[epoch 98, batch     2] loss: 2.17700\n",
      "[epoch 98, batch     3] loss: 2.89901\n",
      "[epoch 98, batch     4] loss: 3.10425\n",
      "[epoch 98, batch     5] loss: 2.61530\n",
      "[epoch 98, batch     6] loss: 3.42251\n",
      "[epoch 98, batch     7] loss: 2.74776\n",
      "[epoch 98, batch     8] loss: 3.72944\n",
      "[epoch 98, batch     9] loss: 2.75639\n",
      "[epoch 98, batch    10] loss: 2.03907\n",
      "[epoch 98, batch    11] loss: 3.32846\n",
      "[epoch 98, batch    12] loss: 3.58916\n",
      "[epoch 98, batch    13] loss: 3.13321\n",
      "[epoch 98, batch    14] loss: 2.75517\n",
      "[epoch 98, batch    15] loss: 3.07088\n",
      "[epoch 98, batch    16] loss: 2.78255\n",
      "[epoch 98, batch    17] loss: 2.63551\n",
      "[epoch 98, batch    18] loss: 2.40521\n",
      "[epoch 98, batch    19] loss: 2.45466\n",
      "[epoch 98, batch    20] loss: 3.66677\n",
      "[epoch 98, batch    21] loss: 2.33668\n",
      "[epoch 98, batch    22] loss: 2.79490\n",
      "[epoch 98, batch    23] loss: 3.07822\n",
      "[epoch 98, batch    24] loss: 3.90256\n",
      "[epoch 98, batch    25] loss: 3.42329\n",
      "[epoch 98, batch    26] loss: 3.55369\n",
      "[epoch 98, batch    27] loss: 4.89185\n",
      "[epoch 98, batch    28] loss: 3.47731\n",
      "[epoch 98, batch    29] loss: 2.80465\n",
      "[epoch 98, batch    30] loss: 2.97833\n",
      "[epoch 98, batch    31] loss: 2.31919\n",
      "[epoch 98, batch    32] loss: 3.07400\n",
      "[epoch 99, batch     1] loss: 2.76144\n",
      "[epoch 99, batch     2] loss: 3.20409\n",
      "[epoch 99, batch     3] loss: 3.59360\n",
      "[epoch 99, batch     4] loss: 2.87251\n",
      "[epoch 99, batch     5] loss: 3.11071\n",
      "[epoch 99, batch     6] loss: 2.51052\n",
      "[epoch 99, batch     7] loss: 2.22379\n",
      "[epoch 99, batch     8] loss: 3.06170\n",
      "[epoch 99, batch     9] loss: 2.36952\n",
      "[epoch 99, batch    10] loss: 3.29289\n",
      "[epoch 99, batch    11] loss: 3.63707\n",
      "[epoch 99, batch    12] loss: 3.66098\n",
      "[epoch 99, batch    13] loss: 3.60892\n",
      "[epoch 99, batch    14] loss: 2.58258\n",
      "[epoch 99, batch    15] loss: 2.52176\n",
      "[epoch 99, batch    16] loss: 2.21600\n",
      "[epoch 99, batch    17] loss: 2.35327\n",
      "[epoch 99, batch    18] loss: 2.54301\n",
      "[epoch 99, batch    19] loss: 3.48567\n",
      "[epoch 99, batch    20] loss: 2.72427\n",
      "[epoch 99, batch    21] loss: 2.60375\n",
      "[epoch 99, batch    22] loss: 3.13105\n",
      "[epoch 99, batch    23] loss: 3.32407\n",
      "[epoch 99, batch    24] loss: 3.48517\n",
      "[epoch 99, batch    25] loss: 3.91349\n",
      "[epoch 99, batch    26] loss: 3.65946\n",
      "[epoch 99, batch    27] loss: 2.30856\n",
      "[epoch 99, batch    28] loss: 3.16076\n",
      "[epoch 99, batch    29] loss: 3.08068\n",
      "[epoch 99, batch    30] loss: 3.86594\n",
      "[epoch 99, batch    31] loss: 3.11006\n",
      "[epoch 99, batch    32] loss: 3.56435\n",
      "[epoch 100, batch     1] loss: 2.48532\n",
      "[epoch 100, batch     2] loss: 2.90484\n",
      "[epoch 100, batch     3] loss: 2.44355\n",
      "[epoch 100, batch     4] loss: 2.96747\n",
      "[epoch 100, batch     5] loss: 3.51788\n",
      "[epoch 100, batch     6] loss: 2.54497\n",
      "[epoch 100, batch     7] loss: 2.72343\n",
      "[epoch 100, batch     8] loss: 3.02413\n",
      "[epoch 100, batch     9] loss: 3.46841\n",
      "[epoch 100, batch    10] loss: 3.72376\n",
      "[epoch 100, batch    11] loss: 3.52377\n",
      "[epoch 100, batch    12] loss: 3.63411\n",
      "[epoch 100, batch    13] loss: 3.29475\n",
      "[epoch 100, batch    14] loss: 2.90828\n",
      "[epoch 100, batch    15] loss: 3.19131\n",
      "[epoch 100, batch    16] loss: 2.85807\n",
      "[epoch 100, batch    17] loss: 2.76733\n",
      "[epoch 100, batch    18] loss: 2.50837\n",
      "[epoch 100, batch    19] loss: 2.52523\n",
      "[epoch 100, batch    20] loss: 3.40869\n",
      "[epoch 100, batch    21] loss: 2.90305\n",
      "[epoch 100, batch    22] loss: 3.28920\n",
      "[epoch 100, batch    23] loss: 3.03993\n",
      "[epoch 100, batch    24] loss: 2.71159\n",
      "[epoch 100, batch    25] loss: 3.11847\n",
      "[epoch 100, batch    26] loss: 3.13791\n",
      "[epoch 100, batch    27] loss: 3.28209\n",
      "[epoch 100, batch    28] loss: 2.95681\n",
      "[epoch 100, batch    29] loss: 3.13946\n",
      "[epoch 100, batch    30] loss: 3.06912\n",
      "[epoch 100, batch    31] loss: 3.20977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 100, batch    32] loss: 1.14778\n",
      "[epoch 101, batch     1] loss: 2.59128\n",
      "[epoch 101, batch     2] loss: 3.38758\n",
      "[epoch 101, batch     3] loss: 2.31945\n",
      "[epoch 101, batch     4] loss: 3.16506\n",
      "[epoch 101, batch     5] loss: 3.33671\n",
      "[epoch 101, batch     6] loss: 3.06339\n",
      "[epoch 101, batch     7] loss: 3.62381\n",
      "[epoch 101, batch     8] loss: 2.56324\n",
      "[epoch 101, batch     9] loss: 2.33179\n",
      "[epoch 101, batch    10] loss: 3.00375\n",
      "[epoch 101, batch    11] loss: 2.92588\n",
      "[epoch 101, batch    12] loss: 3.07051\n",
      "[epoch 101, batch    13] loss: 3.32090\n",
      "[epoch 101, batch    14] loss: 3.26807\n",
      "[epoch 101, batch    15] loss: 2.73368\n",
      "[epoch 101, batch    16] loss: 2.91424\n",
      "[epoch 101, batch    17] loss: 3.08307\n",
      "[epoch 101, batch    18] loss: 4.26169\n",
      "[epoch 101, batch    19] loss: 2.79116\n",
      "[epoch 101, batch    20] loss: 3.24975\n",
      "[epoch 101, batch    21] loss: 3.10492\n",
      "[epoch 101, batch    22] loss: 4.06329\n",
      "[epoch 101, batch    23] loss: 3.71109\n",
      "[epoch 101, batch    24] loss: 2.96199\n",
      "[epoch 101, batch    25] loss: 3.60387\n",
      "[epoch 101, batch    26] loss: 2.74437\n",
      "[epoch 101, batch    27] loss: 2.87698\n",
      "[epoch 101, batch    28] loss: 3.21393\n",
      "[epoch 101, batch    29] loss: 2.80254\n",
      "[epoch 101, batch    30] loss: 2.40152\n",
      "[epoch 101, batch    31] loss: 2.46134\n",
      "[epoch 101, batch    32] loss: 2.39002\n",
      "[epoch 102, batch     1] loss: 3.69158\n",
      "[epoch 102, batch     2] loss: 3.09110\n",
      "[epoch 102, batch     3] loss: 2.66031\n",
      "[epoch 102, batch     4] loss: 2.62935\n",
      "[epoch 102, batch     5] loss: 3.30958\n",
      "[epoch 102, batch     6] loss: 3.54178\n",
      "[epoch 102, batch     7] loss: 2.64971\n",
      "[epoch 102, batch     8] loss: 2.84312\n",
      "[epoch 102, batch     9] loss: 2.91899\n",
      "[epoch 102, batch    10] loss: 3.51915\n",
      "[epoch 102, batch    11] loss: 2.86251\n",
      "[epoch 102, batch    12] loss: 3.32141\n",
      "[epoch 102, batch    13] loss: 2.30021\n",
      "[epoch 102, batch    14] loss: 2.87335\n",
      "[epoch 102, batch    15] loss: 3.11399\n",
      "[epoch 102, batch    16] loss: 3.39107\n",
      "[epoch 102, batch    17] loss: 3.08502\n",
      "[epoch 102, batch    18] loss: 2.95087\n",
      "[epoch 102, batch    19] loss: 4.00708\n",
      "[epoch 102, batch    20] loss: 2.23494\n",
      "[epoch 102, batch    21] loss: 3.72315\n",
      "[epoch 102, batch    22] loss: 3.80167\n",
      "[epoch 102, batch    23] loss: 2.75249\n",
      "[epoch 102, batch    24] loss: 2.79336\n",
      "[epoch 102, batch    25] loss: 3.05082\n",
      "[epoch 102, batch    26] loss: 3.44275\n",
      "[epoch 102, batch    27] loss: 2.96877\n",
      "[epoch 102, batch    28] loss: 2.26626\n",
      "[epoch 102, batch    29] loss: 2.81676\n",
      "[epoch 102, batch    30] loss: 2.66947\n",
      "[epoch 102, batch    31] loss: 3.44128\n",
      "[epoch 102, batch    32] loss: 2.06615\n",
      "[epoch 103, batch     1] loss: 3.07485\n",
      "[epoch 103, batch     2] loss: 3.02908\n",
      "[epoch 103, batch     3] loss: 3.17327\n",
      "[epoch 103, batch     4] loss: 3.27336\n",
      "[epoch 103, batch     5] loss: 3.66542\n",
      "[epoch 103, batch     6] loss: 3.07393\n",
      "[epoch 103, batch     7] loss: 3.21229\n",
      "[epoch 103, batch     8] loss: 3.04853\n",
      "[epoch 103, batch     9] loss: 2.61829\n",
      "[epoch 103, batch    10] loss: 3.29362\n",
      "[epoch 103, batch    11] loss: 2.92971\n",
      "[epoch 103, batch    12] loss: 2.70977\n",
      "[epoch 103, batch    13] loss: 3.00019\n",
      "[epoch 103, batch    14] loss: 2.93895\n",
      "[epoch 103, batch    15] loss: 2.53092\n",
      "[epoch 103, batch    16] loss: 2.62860\n",
      "[epoch 103, batch    17] loss: 2.51947\n",
      "[epoch 103, batch    18] loss: 4.02139\n",
      "[epoch 103, batch    19] loss: 2.42919\n",
      "[epoch 103, batch    20] loss: 2.85553\n",
      "[epoch 103, batch    21] loss: 3.26436\n",
      "[epoch 103, batch    22] loss: 2.92894\n",
      "[epoch 103, batch    23] loss: 3.13246\n",
      "[epoch 103, batch    24] loss: 2.50636\n",
      "[epoch 103, batch    25] loss: 3.50767\n",
      "[epoch 103, batch    26] loss: 2.90869\n",
      "[epoch 103, batch    27] loss: 2.94629\n",
      "[epoch 103, batch    28] loss: 2.07972\n",
      "[epoch 103, batch    29] loss: 3.50970\n",
      "[epoch 103, batch    30] loss: 3.73311\n",
      "[epoch 103, batch    31] loss: 3.85580\n",
      "[epoch 103, batch    32] loss: 3.00757\n",
      "[epoch 104, batch     1] loss: 3.13710\n",
      "[epoch 104, batch     2] loss: 3.07937\n",
      "[epoch 104, batch     3] loss: 2.85952\n",
      "[epoch 104, batch     4] loss: 2.91908\n",
      "[epoch 104, batch     5] loss: 4.11663\n",
      "[epoch 104, batch     6] loss: 3.38958\n",
      "[epoch 104, batch     7] loss: 4.21609\n",
      "[epoch 104, batch     8] loss: 2.85116\n",
      "[epoch 104, batch     9] loss: 3.37208\n",
      "[epoch 104, batch    10] loss: 3.65487\n",
      "[epoch 104, batch    11] loss: 2.66997\n",
      "[epoch 104, batch    12] loss: 3.25149\n",
      "[epoch 104, batch    13] loss: 3.30229\n",
      "[epoch 104, batch    14] loss: 3.64247\n",
      "[epoch 104, batch    15] loss: 2.91463\n",
      "[epoch 104, batch    16] loss: 2.76707\n",
      "[epoch 104, batch    17] loss: 2.52505\n",
      "[epoch 104, batch    18] loss: 2.66396\n",
      "[epoch 104, batch    19] loss: 2.68553\n",
      "[epoch 104, batch    20] loss: 1.65957\n",
      "[epoch 104, batch    21] loss: 2.85537\n",
      "[epoch 104, batch    22] loss: 3.33942\n",
      "[epoch 104, batch    23] loss: 2.65063\n",
      "[epoch 104, batch    24] loss: 2.80020\n",
      "[epoch 104, batch    25] loss: 3.29986\n",
      "[epoch 104, batch    26] loss: 3.04099\n",
      "[epoch 104, batch    27] loss: 3.18248\n",
      "[epoch 104, batch    28] loss: 3.09919\n",
      "[epoch 104, batch    29] loss: 2.36565\n",
      "[epoch 104, batch    30] loss: 3.05088\n",
      "[epoch 104, batch    31] loss: 2.58129\n",
      "[epoch 104, batch    32] loss: 3.80986\n",
      "[epoch 105, batch     1] loss: 3.67033\n",
      "[epoch 105, batch     2] loss: 2.52228\n",
      "[epoch 105, batch     3] loss: 3.43643\n",
      "[epoch 105, batch     4] loss: 2.71860\n",
      "[epoch 105, batch     5] loss: 3.13178\n",
      "[epoch 105, batch     6] loss: 3.11417\n",
      "[epoch 105, batch     7] loss: 2.64368\n",
      "[epoch 105, batch     8] loss: 3.05975\n",
      "[epoch 105, batch     9] loss: 2.85163\n",
      "[epoch 105, batch    10] loss: 4.30334\n",
      "[epoch 105, batch    11] loss: 3.17275\n",
      "[epoch 105, batch    12] loss: 2.85216\n",
      "[epoch 105, batch    13] loss: 3.29488\n",
      "[epoch 105, batch    14] loss: 2.81606\n",
      "[epoch 105, batch    15] loss: 3.26112\n",
      "[epoch 105, batch    16] loss: 4.42438\n",
      "[epoch 105, batch    17] loss: 2.91298\n",
      "[epoch 105, batch    18] loss: 3.25544\n",
      "[epoch 105, batch    19] loss: 2.48876\n",
      "[epoch 105, batch    20] loss: 2.64810\n",
      "[epoch 105, batch    21] loss: 3.16487\n",
      "[epoch 105, batch    22] loss: 2.65861\n",
      "[epoch 105, batch    23] loss: 2.14424\n",
      "[epoch 105, batch    24] loss: 3.36500\n",
      "[epoch 105, batch    25] loss: 2.75111\n",
      "[epoch 105, batch    26] loss: 3.31695\n",
      "[epoch 105, batch    27] loss: 2.49215\n",
      "[epoch 105, batch    28] loss: 2.65142\n",
      "[epoch 105, batch    29] loss: 2.75870\n",
      "[epoch 105, batch    30] loss: 2.95944\n",
      "[epoch 105, batch    31] loss: 2.93643\n",
      "[epoch 105, batch    32] loss: 4.78211\n",
      "[epoch 106, batch     1] loss: 2.74468\n",
      "[epoch 106, batch     2] loss: 2.86829\n",
      "[epoch 106, batch     3] loss: 2.91265\n",
      "[epoch 106, batch     4] loss: 3.00488\n",
      "[epoch 106, batch     5] loss: 2.33834\n",
      "[epoch 106, batch     6] loss: 3.04449\n",
      "[epoch 106, batch     7] loss: 2.80155\n",
      "[epoch 106, batch     8] loss: 3.31760\n",
      "[epoch 106, batch     9] loss: 3.42872\n",
      "[epoch 106, batch    10] loss: 2.38314\n",
      "[epoch 106, batch    11] loss: 3.05967\n",
      "[epoch 106, batch    12] loss: 2.94210\n",
      "[epoch 106, batch    13] loss: 2.76688\n",
      "[epoch 106, batch    14] loss: 2.41412\n",
      "[epoch 106, batch    15] loss: 3.54399\n",
      "[epoch 106, batch    16] loss: 2.58138\n",
      "[epoch 106, batch    17] loss: 2.64694\n",
      "[epoch 106, batch    18] loss: 3.14485\n",
      "[epoch 106, batch    19] loss: 2.86359\n",
      "[epoch 106, batch    20] loss: 3.25734\n",
      "[epoch 106, batch    21] loss: 3.64181\n",
      "[epoch 106, batch    22] loss: 4.28365\n",
      "[epoch 106, batch    23] loss: 2.78031\n",
      "[epoch 106, batch    24] loss: 2.94237\n",
      "[epoch 106, batch    25] loss: 3.06610\n",
      "[epoch 106, batch    26] loss: 4.00269\n",
      "[epoch 106, batch    27] loss: 3.36788\n",
      "[epoch 106, batch    28] loss: 2.76408\n",
      "[epoch 106, batch    29] loss: 2.19490\n",
      "[epoch 106, batch    30] loss: 4.31998\n",
      "[epoch 106, batch    31] loss: 3.13878\n",
      "[epoch 106, batch    32] loss: 2.67655\n",
      "[epoch 107, batch     1] loss: 3.19640\n",
      "[epoch 107, batch     2] loss: 2.22969\n",
      "[epoch 107, batch     3] loss: 3.26734\n",
      "[epoch 107, batch     4] loss: 2.87478\n",
      "[epoch 107, batch     5] loss: 2.96638\n",
      "[epoch 107, batch     6] loss: 4.03797\n",
      "[epoch 107, batch     7] loss: 3.07666\n",
      "[epoch 107, batch     8] loss: 3.27042\n",
      "[epoch 107, batch     9] loss: 3.85012\n",
      "[epoch 107, batch    10] loss: 2.87277\n",
      "[epoch 107, batch    11] loss: 2.67464\n",
      "[epoch 107, batch    12] loss: 2.56426\n",
      "[epoch 107, batch    13] loss: 2.47264\n",
      "[epoch 107, batch    14] loss: 2.89546\n",
      "[epoch 107, batch    15] loss: 2.93019\n",
      "[epoch 107, batch    16] loss: 2.54673\n",
      "[epoch 107, batch    17] loss: 2.72316\n",
      "[epoch 107, batch    18] loss: 2.19238\n",
      "[epoch 107, batch    19] loss: 2.98169\n",
      "[epoch 107, batch    20] loss: 2.33714\n",
      "[epoch 107, batch    21] loss: 3.31151\n",
      "[epoch 107, batch    22] loss: 3.18205\n",
      "[epoch 107, batch    23] loss: 3.79408\n",
      "[epoch 107, batch    24] loss: 2.87459\n",
      "[epoch 107, batch    25] loss: 3.36673\n",
      "[epoch 107, batch    26] loss: 4.06066\n",
      "[epoch 107, batch    27] loss: 2.82909\n",
      "[epoch 107, batch    28] loss: 4.03863\n",
      "[epoch 107, batch    29] loss: 2.81568\n",
      "[epoch 107, batch    30] loss: 2.94592\n",
      "[epoch 107, batch    31] loss: 3.04526\n",
      "[epoch 107, batch    32] loss: 2.56391\n",
      "[epoch 108, batch     1] loss: 3.09656\n",
      "[epoch 108, batch     2] loss: 3.34814\n",
      "[epoch 108, batch     3] loss: 2.37555\n",
      "[epoch 108, batch     4] loss: 2.28241\n",
      "[epoch 108, batch     5] loss: 3.25420\n",
      "[epoch 108, batch     6] loss: 2.87800\n",
      "[epoch 108, batch     7] loss: 2.86950\n",
      "[epoch 108, batch     8] loss: 3.58799\n",
      "[epoch 108, batch     9] loss: 2.98567\n",
      "[epoch 108, batch    10] loss: 2.55178\n",
      "[epoch 108, batch    11] loss: 3.10243\n",
      "[epoch 108, batch    12] loss: 2.89045\n",
      "[epoch 108, batch    13] loss: 2.91206\n",
      "[epoch 108, batch    14] loss: 3.58254\n",
      "[epoch 108, batch    15] loss: 3.14044\n",
      "[epoch 108, batch    16] loss: 3.08192\n",
      "[epoch 108, batch    17] loss: 3.43475\n",
      "[epoch 108, batch    18] loss: 2.34866\n",
      "[epoch 108, batch    19] loss: 3.01040\n",
      "[epoch 108, batch    20] loss: 3.25666\n",
      "[epoch 108, batch    21] loss: 2.52359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 108, batch    22] loss: 2.71005\n",
      "[epoch 108, batch    23] loss: 2.84536\n",
      "[epoch 108, batch    24] loss: 2.38548\n",
      "[epoch 108, batch    25] loss: 3.26684\n",
      "[epoch 108, batch    26] loss: 4.04108\n",
      "[epoch 108, batch    27] loss: 3.55163\n",
      "[epoch 108, batch    28] loss: 2.63724\n",
      "[epoch 108, batch    29] loss: 3.55345\n",
      "[epoch 108, batch    30] loss: 3.04908\n",
      "[epoch 108, batch    31] loss: 3.39714\n",
      "[epoch 108, batch    32] loss: 3.08988\n",
      "[epoch 109, batch     1] loss: 2.82776\n",
      "[epoch 109, batch     2] loss: 2.90204\n",
      "[epoch 109, batch     3] loss: 2.71137\n",
      "[epoch 109, batch     4] loss: 3.97983\n",
      "[epoch 109, batch     5] loss: 3.47119\n",
      "[epoch 109, batch     6] loss: 2.97484\n",
      "[epoch 109, batch     7] loss: 3.26781\n",
      "[epoch 109, batch     8] loss: 2.43140\n",
      "[epoch 109, batch     9] loss: 2.95837\n",
      "[epoch 109, batch    10] loss: 2.51743\n",
      "[epoch 109, batch    11] loss: 3.11910\n",
      "[epoch 109, batch    12] loss: 2.36551\n",
      "[epoch 109, batch    13] loss: 2.45216\n",
      "[epoch 109, batch    14] loss: 3.71156\n",
      "[epoch 109, batch    15] loss: 2.76161\n",
      "[epoch 109, batch    16] loss: 3.15443\n",
      "[epoch 109, batch    17] loss: 2.48149\n",
      "[epoch 109, batch    18] loss: 2.26068\n",
      "[epoch 109, batch    19] loss: 3.03065\n",
      "[epoch 109, batch    20] loss: 3.20127\n",
      "[epoch 109, batch    21] loss: 3.33127\n",
      "[epoch 109, batch    22] loss: 2.97112\n",
      "[epoch 109, batch    23] loss: 2.64968\n",
      "[epoch 109, batch    24] loss: 3.35040\n",
      "[epoch 109, batch    25] loss: 3.93473\n",
      "[epoch 109, batch    26] loss: 2.92668\n",
      "[epoch 109, batch    27] loss: 4.22559\n",
      "[epoch 109, batch    28] loss: 2.89467\n",
      "[epoch 109, batch    29] loss: 2.93128\n",
      "[epoch 109, batch    30] loss: 2.86776\n",
      "[epoch 109, batch    31] loss: 3.21137\n",
      "[epoch 109, batch    32] loss: 3.64180\n",
      "[epoch 110, batch     1] loss: 3.52661\n",
      "[epoch 110, batch     2] loss: 3.57477\n",
      "[epoch 110, batch     3] loss: 2.75220\n",
      "[epoch 110, batch     4] loss: 2.68645\n",
      "[epoch 110, batch     5] loss: 2.56619\n",
      "[epoch 110, batch     6] loss: 3.20581\n",
      "[epoch 110, batch     7] loss: 3.57901\n",
      "[epoch 110, batch     8] loss: 2.93774\n",
      "[epoch 110, batch     9] loss: 3.46496\n",
      "[epoch 110, batch    10] loss: 3.20841\n",
      "[epoch 110, batch    11] loss: 3.56845\n",
      "[epoch 110, batch    12] loss: 2.87452\n",
      "[epoch 110, batch    13] loss: 3.28786\n",
      "[epoch 110, batch    14] loss: 3.80993\n",
      "[epoch 110, batch    15] loss: 2.77325\n",
      "[epoch 110, batch    16] loss: 3.14903\n",
      "[epoch 110, batch    17] loss: 2.51075\n",
      "[epoch 110, batch    18] loss: 2.67468\n",
      "[epoch 110, batch    19] loss: 2.59397\n",
      "[epoch 110, batch    20] loss: 3.09143\n",
      "[epoch 110, batch    21] loss: 3.28691\n",
      "[epoch 110, batch    22] loss: 3.00599\n",
      "[epoch 110, batch    23] loss: 2.82083\n",
      "[epoch 110, batch    24] loss: 2.18108\n",
      "[epoch 110, batch    25] loss: 3.19609\n",
      "[epoch 110, batch    26] loss: 2.87511\n",
      "[epoch 110, batch    27] loss: 4.09627\n",
      "[epoch 110, batch    28] loss: 2.87696\n",
      "[epoch 110, batch    29] loss: 2.39784\n",
      "[epoch 110, batch    30] loss: 2.53289\n",
      "[epoch 110, batch    31] loss: 3.49731\n",
      "[epoch 110, batch    32] loss: 3.29299\n",
      "[epoch 111, batch     1] loss: 3.10778\n",
      "[epoch 111, batch     2] loss: 3.27968\n",
      "[epoch 111, batch     3] loss: 3.42868\n",
      "[epoch 111, batch     4] loss: 2.76608\n",
      "[epoch 111, batch     5] loss: 2.43383\n",
      "[epoch 111, batch     6] loss: 3.70862\n",
      "[epoch 111, batch     7] loss: 3.08197\n",
      "[epoch 111, batch     8] loss: 3.57583\n",
      "[epoch 111, batch     9] loss: 2.67249\n",
      "[epoch 111, batch    10] loss: 3.44921\n",
      "[epoch 111, batch    11] loss: 3.79319\n",
      "[epoch 111, batch    12] loss: 3.23638\n",
      "[epoch 111, batch    13] loss: 4.17328\n",
      "[epoch 111, batch    14] loss: 2.49846\n",
      "[epoch 111, batch    15] loss: 3.60117\n",
      "[epoch 111, batch    16] loss: 2.70453\n",
      "[epoch 111, batch    17] loss: 2.95047\n",
      "[epoch 111, batch    18] loss: 2.41415\n",
      "[epoch 111, batch    19] loss: 2.71829\n",
      "[epoch 111, batch    20] loss: 2.59367\n",
      "[epoch 111, batch    21] loss: 3.08758\n",
      "[epoch 111, batch    22] loss: 2.73241\n",
      "[epoch 111, batch    23] loss: 2.70557\n",
      "[epoch 111, batch    24] loss: 2.52601\n",
      "[epoch 111, batch    25] loss: 2.56973\n",
      "[epoch 111, batch    26] loss: 2.69391\n",
      "[epoch 111, batch    27] loss: 3.02525\n",
      "[epoch 111, batch    28] loss: 3.18545\n",
      "[epoch 111, batch    29] loss: 3.17718\n",
      "[epoch 111, batch    30] loss: 2.89776\n",
      "[epoch 111, batch    31] loss: 2.89286\n",
      "[epoch 111, batch    32] loss: 3.42363\n",
      "[epoch 112, batch     1] loss: 3.06584\n",
      "[epoch 112, batch     2] loss: 2.35167\n",
      "[epoch 112, batch     3] loss: 3.02562\n",
      "[epoch 112, batch     4] loss: 2.63715\n",
      "[epoch 112, batch     5] loss: 3.11961\n",
      "[epoch 112, batch     6] loss: 3.66185\n",
      "[epoch 112, batch     7] loss: 2.98865\n",
      "[epoch 112, batch     8] loss: 3.15808\n",
      "[epoch 112, batch     9] loss: 3.67765\n",
      "[epoch 112, batch    10] loss: 2.91232\n",
      "[epoch 112, batch    11] loss: 3.11958\n",
      "[epoch 112, batch    12] loss: 2.93547\n",
      "[epoch 112, batch    13] loss: 3.48995\n",
      "[epoch 112, batch    14] loss: 3.15186\n",
      "[epoch 112, batch    15] loss: 3.32815\n",
      "[epoch 112, batch    16] loss: 2.91515\n",
      "[epoch 112, batch    17] loss: 3.03976\n",
      "[epoch 112, batch    18] loss: 2.78092\n",
      "[epoch 112, batch    19] loss: 2.64016\n",
      "[epoch 112, batch    20] loss: 2.75065\n",
      "[epoch 112, batch    21] loss: 3.16286\n",
      "[epoch 112, batch    22] loss: 2.79965\n",
      "[epoch 112, batch    23] loss: 3.60401\n",
      "[epoch 112, batch    24] loss: 2.69038\n",
      "[epoch 112, batch    25] loss: 2.81979\n",
      "[epoch 112, batch    26] loss: 2.32851\n",
      "[epoch 112, batch    27] loss: 3.14747\n",
      "[epoch 112, batch    28] loss: 2.96668\n",
      "[epoch 112, batch    29] loss: 3.72032\n",
      "[epoch 112, batch    30] loss: 2.81803\n",
      "[epoch 112, batch    31] loss: 3.10337\n",
      "[epoch 112, batch    32] loss: 3.10859\n",
      "[epoch 113, batch     1] loss: 2.17099\n",
      "[epoch 113, batch     2] loss: 3.76821\n",
      "[epoch 113, batch     3] loss: 2.67574\n",
      "[epoch 113, batch     4] loss: 3.33650\n",
      "[epoch 113, batch     5] loss: 2.68500\n",
      "[epoch 113, batch     6] loss: 3.76383\n",
      "[epoch 113, batch     7] loss: 2.13141\n",
      "[epoch 113, batch     8] loss: 3.40158\n",
      "[epoch 113, batch     9] loss: 3.15516\n",
      "[epoch 113, batch    10] loss: 3.22283\n",
      "[epoch 113, batch    11] loss: 2.79779\n",
      "[epoch 113, batch    12] loss: 3.26054\n",
      "[epoch 113, batch    13] loss: 1.99810\n",
      "[epoch 113, batch    14] loss: 3.52742\n",
      "[epoch 113, batch    15] loss: 3.30823\n",
      "[epoch 113, batch    16] loss: 2.86549\n",
      "[epoch 113, batch    17] loss: 2.46008\n",
      "[epoch 113, batch    18] loss: 3.32342\n",
      "[epoch 113, batch    19] loss: 2.90865\n",
      "[epoch 113, batch    20] loss: 3.55869\n",
      "[epoch 113, batch    21] loss: 2.58770\n",
      "[epoch 113, batch    22] loss: 3.72720\n",
      "[epoch 113, batch    23] loss: 2.40527\n",
      "[epoch 113, batch    24] loss: 2.32185\n",
      "[epoch 113, batch    25] loss: 3.20192\n",
      "[epoch 113, batch    26] loss: 2.54022\n",
      "[epoch 113, batch    27] loss: 3.17019\n",
      "[epoch 113, batch    28] loss: 2.39511\n",
      "[epoch 113, batch    29] loss: 3.85760\n",
      "[epoch 113, batch    30] loss: 4.05379\n",
      "[epoch 113, batch    31] loss: 3.78794\n",
      "[epoch 113, batch    32] loss: 1.62659\n",
      "[epoch 114, batch     1] loss: 2.50777\n",
      "[epoch 114, batch     2] loss: 2.48063\n",
      "[epoch 114, batch     3] loss: 2.66163\n",
      "[epoch 114, batch     4] loss: 2.80183\n",
      "[epoch 114, batch     5] loss: 4.03605\n",
      "[epoch 114, batch     6] loss: 2.95383\n",
      "[epoch 114, batch     7] loss: 4.23706\n",
      "[epoch 114, batch     8] loss: 2.63575\n",
      "[epoch 114, batch     9] loss: 3.09128\n",
      "[epoch 114, batch    10] loss: 2.43980\n",
      "[epoch 114, batch    11] loss: 2.58202\n",
      "[epoch 114, batch    12] loss: 2.55341\n",
      "[epoch 114, batch    13] loss: 2.97433\n",
      "[epoch 114, batch    14] loss: 3.01987\n",
      "[epoch 114, batch    15] loss: 2.66060\n",
      "[epoch 114, batch    16] loss: 3.30838\n",
      "[epoch 114, batch    17] loss: 3.18522\n",
      "[epoch 114, batch    18] loss: 3.92845\n",
      "[epoch 114, batch    19] loss: 2.51712\n",
      "[epoch 114, batch    20] loss: 3.05422\n",
      "[epoch 114, batch    21] loss: 3.45169\n",
      "[epoch 114, batch    22] loss: 3.56286\n",
      "[epoch 114, batch    23] loss: 3.68081\n",
      "[epoch 114, batch    24] loss: 3.30317\n",
      "[epoch 114, batch    25] loss: 2.11274\n",
      "[epoch 114, batch    26] loss: 2.78330\n",
      "[epoch 114, batch    27] loss: 3.96373\n",
      "[epoch 114, batch    28] loss: 3.29530\n",
      "[epoch 114, batch    29] loss: 3.04051\n",
      "[epoch 114, batch    30] loss: 2.97688\n",
      "[epoch 114, batch    31] loss: 2.37130\n",
      "[epoch 114, batch    32] loss: 2.67104\n",
      "[epoch 115, batch     1] loss: 3.38411\n",
      "[epoch 115, batch     2] loss: 3.13663\n",
      "[epoch 115, batch     3] loss: 3.75505\n",
      "[epoch 115, batch     4] loss: 2.48406\n",
      "[epoch 115, batch     5] loss: 2.93045\n",
      "[epoch 115, batch     6] loss: 3.51520\n",
      "[epoch 115, batch     7] loss: 2.44597\n",
      "[epoch 115, batch     8] loss: 2.30899\n",
      "[epoch 115, batch     9] loss: 2.64208\n",
      "[epoch 115, batch    10] loss: 3.12024\n",
      "[epoch 115, batch    11] loss: 2.69709\n",
      "[epoch 115, batch    12] loss: 2.84438\n",
      "[epoch 115, batch    13] loss: 2.77129\n",
      "[epoch 115, batch    14] loss: 3.51006\n",
      "[epoch 115, batch    15] loss: 2.20490\n",
      "[epoch 115, batch    16] loss: 3.49099\n",
      "[epoch 115, batch    17] loss: 2.99375\n",
      "[epoch 115, batch    18] loss: 3.50562\n",
      "[epoch 115, batch    19] loss: 3.85116\n",
      "[epoch 115, batch    20] loss: 2.50141\n",
      "[epoch 115, batch    21] loss: 3.67332\n",
      "[epoch 115, batch    22] loss: 2.77405\n",
      "[epoch 115, batch    23] loss: 2.78677\n",
      "[epoch 115, batch    24] loss: 2.41832\n",
      "[epoch 115, batch    25] loss: 3.78425\n",
      "[epoch 115, batch    26] loss: 3.24056\n",
      "[epoch 115, batch    27] loss: 2.95377\n",
      "[epoch 115, batch    28] loss: 3.27113\n",
      "[epoch 115, batch    29] loss: 2.59697\n",
      "[epoch 115, batch    30] loss: 3.38964\n",
      "[epoch 115, batch    31] loss: 2.76675\n",
      "[epoch 115, batch    32] loss: 5.06575\n",
      "[epoch 116, batch     1] loss: 2.51799\n",
      "[epoch 116, batch     2] loss: 2.76264\n",
      "[epoch 116, batch     3] loss: 3.36530\n",
      "[epoch 116, batch     4] loss: 3.56041\n",
      "[epoch 116, batch     5] loss: 2.09823\n",
      "[epoch 116, batch     6] loss: 3.41299\n",
      "[epoch 116, batch     7] loss: 3.40795\n",
      "[epoch 116, batch     8] loss: 2.83114\n",
      "[epoch 116, batch     9] loss: 2.43339\n",
      "[epoch 116, batch    10] loss: 3.49570\n",
      "[epoch 116, batch    11] loss: 3.04053\n",
      "[epoch 116, batch    12] loss: 2.70197\n",
      "[epoch 116, batch    13] loss: 3.23588\n",
      "[epoch 116, batch    14] loss: 3.47032\n",
      "[epoch 116, batch    15] loss: 3.13408\n",
      "[epoch 116, batch    16] loss: 2.78088\n",
      "[epoch 116, batch    17] loss: 2.92947\n",
      "[epoch 116, batch    18] loss: 3.72604\n",
      "[epoch 116, batch    19] loss: 3.86555\n",
      "[epoch 116, batch    20] loss: 3.88291\n",
      "[epoch 116, batch    21] loss: 2.30502\n",
      "[epoch 116, batch    22] loss: 2.26255\n",
      "[epoch 116, batch    23] loss: 2.73163\n",
      "[epoch 116, batch    24] loss: 3.77573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 116, batch    25] loss: 2.97073\n",
      "[epoch 116, batch    26] loss: 3.45465\n",
      "[epoch 116, batch    27] loss: 2.18869\n",
      "[epoch 116, batch    28] loss: 2.42012\n",
      "[epoch 116, batch    29] loss: 3.15865\n",
      "[epoch 116, batch    30] loss: 3.20283\n",
      "[epoch 116, batch    31] loss: 2.41363\n",
      "[epoch 116, batch    32] loss: 3.75969\n",
      "[epoch 117, batch     1] loss: 2.65765\n",
      "[epoch 117, batch     2] loss: 3.11341\n",
      "[epoch 117, batch     3] loss: 2.84600\n",
      "[epoch 117, batch     4] loss: 3.21108\n",
      "[epoch 117, batch     5] loss: 2.86704\n",
      "[epoch 117, batch     6] loss: 2.70716\n",
      "[epoch 117, batch     7] loss: 3.32594\n",
      "[epoch 117, batch     8] loss: 3.91890\n",
      "[epoch 117, batch     9] loss: 3.26769\n",
      "[epoch 117, batch    10] loss: 3.52001\n",
      "[epoch 117, batch    11] loss: 2.78523\n",
      "[epoch 117, batch    12] loss: 2.86429\n",
      "[epoch 117, batch    13] loss: 2.55220\n",
      "[epoch 117, batch    14] loss: 3.58569\n",
      "[epoch 117, batch    15] loss: 3.02873\n",
      "[epoch 117, batch    16] loss: 2.55783\n",
      "[epoch 117, batch    17] loss: 2.88136\n",
      "[epoch 117, batch    18] loss: 3.60073\n",
      "[epoch 117, batch    19] loss: 2.80463\n",
      "[epoch 117, batch    20] loss: 2.73496\n",
      "[epoch 117, batch    21] loss: 2.58030\n",
      "[epoch 117, batch    22] loss: 2.86249\n",
      "[epoch 117, batch    23] loss: 2.84695\n",
      "[epoch 117, batch    24] loss: 2.40413\n",
      "[epoch 117, batch    25] loss: 3.42510\n",
      "[epoch 117, batch    26] loss: 3.41845\n",
      "[epoch 117, batch    27] loss: 2.58899\n",
      "[epoch 117, batch    28] loss: 2.95869\n",
      "[epoch 117, batch    29] loss: 4.15759\n",
      "[epoch 117, batch    30] loss: 3.51841\n",
      "[epoch 117, batch    31] loss: 2.80974\n",
      "[epoch 117, batch    32] loss: 2.24664\n",
      "[epoch 118, batch     1] loss: 2.96080\n",
      "[epoch 118, batch     2] loss: 3.21800\n",
      "[epoch 118, batch     3] loss: 2.58105\n",
      "[epoch 118, batch     4] loss: 2.91137\n",
      "[epoch 118, batch     5] loss: 3.31228\n",
      "[epoch 118, batch     6] loss: 3.73222\n",
      "[epoch 118, batch     7] loss: 2.79825\n",
      "[epoch 118, batch     8] loss: 3.10349\n",
      "[epoch 118, batch     9] loss: 3.30787\n",
      "[epoch 118, batch    10] loss: 2.86287\n",
      "[epoch 118, batch    11] loss: 3.20614\n",
      "[epoch 118, batch    12] loss: 2.74243\n",
      "[epoch 118, batch    13] loss: 2.93570\n",
      "[epoch 118, batch    14] loss: 2.47750\n",
      "[epoch 118, batch    15] loss: 3.15718\n",
      "[epoch 118, batch    16] loss: 2.74726\n",
      "[epoch 118, batch    17] loss: 2.65640\n",
      "[epoch 118, batch    18] loss: 2.50516\n",
      "[epoch 118, batch    19] loss: 3.75063\n",
      "[epoch 118, batch    20] loss: 3.54378\n",
      "[epoch 118, batch    21] loss: 2.58727\n",
      "[epoch 118, batch    22] loss: 3.06781\n",
      "[epoch 118, batch    23] loss: 3.83057\n",
      "[epoch 118, batch    24] loss: 2.82431\n",
      "[epoch 118, batch    25] loss: 2.92224\n",
      "[epoch 118, batch    26] loss: 3.31315\n",
      "[epoch 118, batch    27] loss: 2.58100\n",
      "[epoch 118, batch    28] loss: 3.09913\n",
      "[epoch 118, batch    29] loss: 3.35674\n",
      "[epoch 118, batch    30] loss: 3.46621\n",
      "[epoch 118, batch    31] loss: 2.67757\n",
      "[epoch 118, batch    32] loss: 3.50412\n",
      "[epoch 119, batch     1] loss: 2.85982\n",
      "[epoch 119, batch     2] loss: 2.91300\n",
      "[epoch 119, batch     3] loss: 3.08005\n",
      "[epoch 119, batch     4] loss: 2.44777\n",
      "[epoch 119, batch     5] loss: 3.91577\n",
      "[epoch 119, batch     6] loss: 2.37893\n",
      "[epoch 119, batch     7] loss: 3.21635\n",
      "[epoch 119, batch     8] loss: 2.60139\n",
      "[epoch 119, batch     9] loss: 2.62626\n",
      "[epoch 119, batch    10] loss: 3.79027\n",
      "[epoch 119, batch    11] loss: 2.57066\n",
      "[epoch 119, batch    12] loss: 3.39941\n",
      "[epoch 119, batch    13] loss: 3.34251\n",
      "[epoch 119, batch    14] loss: 3.13384\n",
      "[epoch 119, batch    15] loss: 2.37443\n",
      "[epoch 119, batch    16] loss: 3.27738\n",
      "[epoch 119, batch    17] loss: 1.96181\n",
      "[epoch 119, batch    18] loss: 3.61081\n",
      "[epoch 119, batch    19] loss: 3.63443\n",
      "[epoch 119, batch    20] loss: 3.00599\n",
      "[epoch 119, batch    21] loss: 2.69228\n",
      "[epoch 119, batch    22] loss: 3.59648\n",
      "[epoch 119, batch    23] loss: 3.39571\n",
      "[epoch 119, batch    24] loss: 2.98892\n",
      "[epoch 119, batch    25] loss: 2.55484\n",
      "[epoch 119, batch    26] loss: 3.92783\n",
      "[epoch 119, batch    27] loss: 3.47707\n",
      "[epoch 119, batch    28] loss: 3.09519\n",
      "[epoch 119, batch    29] loss: 2.70623\n",
      "[epoch 119, batch    30] loss: 2.50483\n",
      "[epoch 119, batch    31] loss: 2.82380\n",
      "[epoch 119, batch    32] loss: 3.08960\n",
      "[epoch 120, batch     1] loss: 2.26426\n",
      "[epoch 120, batch     2] loss: 2.93710\n",
      "[epoch 120, batch     3] loss: 2.61884\n",
      "[epoch 120, batch     4] loss: 3.04807\n",
      "[epoch 120, batch     5] loss: 3.07865\n",
      "[epoch 120, batch     6] loss: 2.51333\n",
      "[epoch 120, batch     7] loss: 2.88271\n",
      "[epoch 120, batch     8] loss: 3.25901\n",
      "[epoch 120, batch     9] loss: 4.18759\n",
      "[epoch 120, batch    10] loss: 2.73922\n",
      "[epoch 120, batch    11] loss: 3.54414\n",
      "[epoch 120, batch    12] loss: 3.04045\n",
      "[epoch 120, batch    13] loss: 2.55874\n",
      "[epoch 120, batch    14] loss: 3.52165\n",
      "[epoch 120, batch    15] loss: 3.01910\n",
      "[epoch 120, batch    16] loss: 3.13122\n",
      "[epoch 120, batch    17] loss: 3.20715\n",
      "[epoch 120, batch    18] loss: 3.17570\n",
      "[epoch 120, batch    19] loss: 2.99036\n",
      "[epoch 120, batch    20] loss: 3.18353\n",
      "[epoch 120, batch    21] loss: 3.90792\n",
      "[epoch 120, batch    22] loss: 3.30366\n",
      "[epoch 120, batch    23] loss: 2.33506\n",
      "[epoch 120, batch    24] loss: 3.74900\n",
      "[epoch 120, batch    25] loss: 2.25360\n",
      "[epoch 120, batch    26] loss: 2.49981\n",
      "[epoch 120, batch    27] loss: 2.78228\n",
      "[epoch 120, batch    28] loss: 2.62343\n",
      "[epoch 120, batch    29] loss: 3.89208\n",
      "[epoch 120, batch    30] loss: 2.59331\n",
      "[epoch 120, batch    31] loss: 3.56327\n",
      "[epoch 120, batch    32] loss: 3.31164\n",
      "[epoch 121, batch     1] loss: 2.83375\n",
      "[epoch 121, batch     2] loss: 2.35024\n",
      "[epoch 121, batch     3] loss: 2.95886\n",
      "[epoch 121, batch     4] loss: 2.96843\n",
      "[epoch 121, batch     5] loss: 2.20279\n",
      "[epoch 121, batch     6] loss: 3.19571\n",
      "[epoch 121, batch     7] loss: 3.46408\n",
      "[epoch 121, batch     8] loss: 2.10279\n",
      "[epoch 121, batch     9] loss: 2.86247\n",
      "[epoch 121, batch    10] loss: 3.23974\n",
      "[epoch 121, batch    11] loss: 3.70465\n",
      "[epoch 121, batch    12] loss: 3.11677\n",
      "[epoch 121, batch    13] loss: 2.89909\n",
      "[epoch 121, batch    14] loss: 2.66718\n",
      "[epoch 121, batch    15] loss: 2.66290\n",
      "[epoch 121, batch    16] loss: 3.10403\n",
      "[epoch 121, batch    17] loss: 3.68334\n",
      "[epoch 121, batch    18] loss: 3.30020\n",
      "[epoch 121, batch    19] loss: 2.77073\n",
      "[epoch 121, batch    20] loss: 2.41266\n",
      "[epoch 121, batch    21] loss: 3.70337\n",
      "[epoch 121, batch    22] loss: 3.00396\n",
      "[epoch 121, batch    23] loss: 3.43138\n",
      "[epoch 121, batch    24] loss: 3.13436\n",
      "[epoch 121, batch    25] loss: 3.97703\n",
      "[epoch 121, batch    26] loss: 2.72672\n",
      "[epoch 121, batch    27] loss: 3.76087\n",
      "[epoch 121, batch    28] loss: 3.05594\n",
      "[epoch 121, batch    29] loss: 2.73154\n",
      "[epoch 121, batch    30] loss: 3.44769\n",
      "[epoch 121, batch    31] loss: 3.09549\n",
      "[epoch 121, batch    32] loss: 1.95035\n",
      "[epoch 122, batch     1] loss: 2.73348\n",
      "[epoch 122, batch     2] loss: 4.16967\n",
      "[epoch 122, batch     3] loss: 2.58264\n",
      "[epoch 122, batch     4] loss: 2.84889\n",
      "[epoch 122, batch     5] loss: 3.65184\n",
      "[epoch 122, batch     6] loss: 3.28804\n",
      "[epoch 122, batch     7] loss: 3.33049\n",
      "[epoch 122, batch     8] loss: 3.25214\n",
      "[epoch 122, batch     9] loss: 2.82809\n",
      "[epoch 122, batch    10] loss: 1.98101\n",
      "[epoch 122, batch    11] loss: 3.88850\n",
      "[epoch 122, batch    12] loss: 3.27599\n",
      "[epoch 122, batch    13] loss: 2.90784\n",
      "[epoch 122, batch    14] loss: 2.58936\n",
      "[epoch 122, batch    15] loss: 2.38972\n",
      "[epoch 122, batch    16] loss: 3.76937\n",
      "[epoch 122, batch    17] loss: 3.47149\n",
      "[epoch 122, batch    18] loss: 3.06069\n",
      "[epoch 122, batch    19] loss: 2.79375\n",
      "[epoch 122, batch    20] loss: 2.94451\n",
      "[epoch 122, batch    21] loss: 2.59824\n",
      "[epoch 122, batch    22] loss: 3.22773\n",
      "[epoch 122, batch    23] loss: 2.46836\n",
      "[epoch 122, batch    24] loss: 3.53499\n",
      "[epoch 122, batch    25] loss: 2.92286\n",
      "[epoch 122, batch    26] loss: 3.11040\n",
      "[epoch 122, batch    27] loss: 2.65907\n",
      "[epoch 122, batch    28] loss: 3.47535\n",
      "[epoch 122, batch    29] loss: 3.02312\n",
      "[epoch 122, batch    30] loss: 2.73191\n",
      "[epoch 122, batch    31] loss: 2.39310\n",
      "[epoch 122, batch    32] loss: 3.32199\n",
      "[epoch 123, batch     1] loss: 2.81877\n",
      "[epoch 123, batch     2] loss: 2.48107\n",
      "[epoch 123, batch     3] loss: 3.06144\n",
      "[epoch 123, batch     4] loss: 2.88821\n",
      "[epoch 123, batch     5] loss: 3.21479\n",
      "[epoch 123, batch     6] loss: 3.47114\n",
      "[epoch 123, batch     7] loss: 2.77606\n",
      "[epoch 123, batch     8] loss: 3.58596\n",
      "[epoch 123, batch     9] loss: 2.35087\n",
      "[epoch 123, batch    10] loss: 2.64834\n",
      "[epoch 123, batch    11] loss: 3.01106\n",
      "[epoch 123, batch    12] loss: 3.24749\n",
      "[epoch 123, batch    13] loss: 3.38166\n",
      "[epoch 123, batch    14] loss: 2.67652\n",
      "[epoch 123, batch    15] loss: 3.16804\n",
      "[epoch 123, batch    16] loss: 2.80200\n",
      "[epoch 123, batch    17] loss: 2.86312\n",
      "[epoch 123, batch    18] loss: 3.47106\n",
      "[epoch 123, batch    19] loss: 3.32947\n",
      "[epoch 123, batch    20] loss: 2.35183\n",
      "[epoch 123, batch    21] loss: 2.72899\n",
      "[epoch 123, batch    22] loss: 2.57867\n",
      "[epoch 123, batch    23] loss: 3.13063\n",
      "[epoch 123, batch    24] loss: 3.66419\n",
      "[epoch 123, batch    25] loss: 3.38305\n",
      "[epoch 123, batch    26] loss: 3.29367\n",
      "[epoch 123, batch    27] loss: 3.66285\n",
      "[epoch 123, batch    28] loss: 3.01124\n",
      "[epoch 123, batch    29] loss: 3.18454\n",
      "[epoch 123, batch    30] loss: 2.57523\n",
      "[epoch 123, batch    31] loss: 3.95132\n",
      "[epoch 123, batch    32] loss: 2.58525\n",
      "[epoch 124, batch     1] loss: 3.80389\n",
      "[epoch 124, batch     2] loss: 2.49641\n",
      "[epoch 124, batch     3] loss: 2.58235\n",
      "[epoch 124, batch     4] loss: 2.90271\n",
      "[epoch 124, batch     5] loss: 3.67087\n",
      "[epoch 124, batch     6] loss: 2.72030\n",
      "[epoch 124, batch     7] loss: 3.15563\n",
      "[epoch 124, batch     8] loss: 2.48546\n",
      "[epoch 124, batch     9] loss: 4.06217\n",
      "[epoch 124, batch    10] loss: 3.54410\n",
      "[epoch 124, batch    11] loss: 2.51428\n",
      "[epoch 124, batch    12] loss: 2.90692\n",
      "[epoch 124, batch    13] loss: 2.38965\n",
      "[epoch 124, batch    14] loss: 4.37903\n",
      "[epoch 124, batch    15] loss: 2.72087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 124, batch    16] loss: 2.78269\n",
      "[epoch 124, batch    17] loss: 3.44449\n",
      "[epoch 124, batch    18] loss: 2.90840\n",
      "[epoch 124, batch    19] loss: 3.36723\n",
      "[epoch 124, batch    20] loss: 2.79074\n",
      "[epoch 124, batch    21] loss: 2.80469\n",
      "[epoch 124, batch    22] loss: 2.75733\n",
      "[epoch 124, batch    23] loss: 2.94175\n",
      "[epoch 124, batch    24] loss: 2.74164\n",
      "[epoch 124, batch    25] loss: 2.42999\n",
      "[epoch 124, batch    26] loss: 3.48708\n",
      "[epoch 124, batch    27] loss: 3.29059\n",
      "[epoch 124, batch    28] loss: 2.47944\n",
      "[epoch 124, batch    29] loss: 2.37132\n",
      "[epoch 124, batch    30] loss: 3.25579\n",
      "[epoch 124, batch    31] loss: 3.58063\n",
      "[epoch 124, batch    32] loss: 4.44008\n",
      "[epoch 125, batch     1] loss: 2.95135\n",
      "[epoch 125, batch     2] loss: 2.92503\n",
      "[epoch 125, batch     3] loss: 2.46430\n",
      "[epoch 125, batch     4] loss: 2.47817\n",
      "[epoch 125, batch     5] loss: 3.18726\n",
      "[epoch 125, batch     6] loss: 2.93700\n",
      "[epoch 125, batch     7] loss: 2.93452\n",
      "[epoch 125, batch     8] loss: 3.92029\n",
      "[epoch 125, batch     9] loss: 2.85040\n",
      "[epoch 125, batch    10] loss: 2.95598\n",
      "[epoch 125, batch    11] loss: 3.81563\n",
      "[epoch 125, batch    12] loss: 3.60173\n",
      "[epoch 125, batch    13] loss: 2.91298\n",
      "[epoch 125, batch    14] loss: 2.40313\n",
      "[epoch 125, batch    15] loss: 2.92321\n",
      "[epoch 125, batch    16] loss: 3.47790\n",
      "[epoch 125, batch    17] loss: 2.97575\n",
      "[epoch 125, batch    18] loss: 3.27216\n",
      "[epoch 125, batch    19] loss: 2.94045\n",
      "[epoch 125, batch    20] loss: 3.69694\n",
      "[epoch 125, batch    21] loss: 3.79446\n",
      "[epoch 125, batch    22] loss: 2.57712\n",
      "[epoch 125, batch    23] loss: 3.41897\n",
      "[epoch 125, batch    24] loss: 3.02972\n",
      "[epoch 125, batch    25] loss: 2.97803\n",
      "[epoch 125, batch    26] loss: 3.26120\n",
      "[epoch 125, batch    27] loss: 3.16397\n",
      "[epoch 125, batch    28] loss: 2.83849\n",
      "[epoch 125, batch    29] loss: 3.09094\n",
      "[epoch 125, batch    30] loss: 2.51395\n",
      "[epoch 125, batch    31] loss: 2.34341\n",
      "[epoch 125, batch    32] loss: 3.09210\n",
      "[epoch 126, batch     1] loss: 3.50986\n",
      "[epoch 126, batch     2] loss: 2.77281\n",
      "[epoch 126, batch     3] loss: 3.71064\n",
      "[epoch 126, batch     4] loss: 2.54497\n",
      "[epoch 126, batch     5] loss: 3.17867\n",
      "[epoch 126, batch     6] loss: 2.98971\n",
      "[epoch 126, batch     7] loss: 3.59085\n",
      "[epoch 126, batch     8] loss: 2.83412\n",
      "[epoch 126, batch     9] loss: 2.66824\n",
      "[epoch 126, batch    10] loss: 2.69403\n",
      "[epoch 126, batch    11] loss: 2.39404\n",
      "[epoch 126, batch    12] loss: 2.88229\n",
      "[epoch 126, batch    13] loss: 3.92068\n",
      "[epoch 126, batch    14] loss: 2.53400\n",
      "[epoch 126, batch    15] loss: 3.38886\n",
      "[epoch 126, batch    16] loss: 3.31648\n",
      "[epoch 126, batch    17] loss: 3.69601\n",
      "[epoch 126, batch    18] loss: 2.84315\n",
      "[epoch 126, batch    19] loss: 2.69259\n",
      "[epoch 126, batch    20] loss: 3.35031\n",
      "[epoch 126, batch    21] loss: 3.19331\n",
      "[epoch 126, batch    22] loss: 2.91140\n",
      "[epoch 126, batch    23] loss: 3.59954\n",
      "[epoch 126, batch    24] loss: 2.97624\n",
      "[epoch 126, batch    25] loss: 2.32974\n",
      "[epoch 126, batch    26] loss: 2.99584\n",
      "[epoch 126, batch    27] loss: 3.15885\n",
      "[epoch 126, batch    28] loss: 4.01122\n",
      "[epoch 126, batch    29] loss: 2.06253\n",
      "[epoch 126, batch    30] loss: 2.68170\n",
      "[epoch 126, batch    31] loss: 3.08375\n",
      "[epoch 126, batch    32] loss: 2.37051\n",
      "[epoch 127, batch     1] loss: 2.52025\n",
      "[epoch 127, batch     2] loss: 2.26159\n",
      "[epoch 127, batch     3] loss: 3.11871\n",
      "[epoch 127, batch     4] loss: 2.18013\n",
      "[epoch 127, batch     5] loss: 3.38118\n",
      "[epoch 127, batch     6] loss: 3.39011\n",
      "[epoch 127, batch     7] loss: 3.84335\n",
      "[epoch 127, batch     8] loss: 2.93292\n",
      "[epoch 127, batch     9] loss: 2.95521\n",
      "[epoch 127, batch    10] loss: 2.27298\n",
      "[epoch 127, batch    11] loss: 2.89737\n",
      "[epoch 127, batch    12] loss: 3.50159\n",
      "[epoch 127, batch    13] loss: 3.40052\n",
      "[epoch 127, batch    14] loss: 3.23683\n",
      "[epoch 127, batch    15] loss: 2.57616\n",
      "[epoch 127, batch    16] loss: 4.28056\n",
      "[epoch 127, batch    17] loss: 2.33769\n",
      "[epoch 127, batch    18] loss: 2.72858\n",
      "[epoch 127, batch    19] loss: 3.87938\n",
      "[epoch 127, batch    20] loss: 2.93867\n",
      "[epoch 127, batch    21] loss: 3.24328\n",
      "[epoch 127, batch    22] loss: 2.46499\n",
      "[epoch 127, batch    23] loss: 3.14487\n",
      "[epoch 127, batch    24] loss: 3.37156\n",
      "[epoch 127, batch    25] loss: 2.68105\n",
      "[epoch 127, batch    26] loss: 3.21451\n",
      "[epoch 127, batch    27] loss: 3.20435\n",
      "[epoch 127, batch    28] loss: 3.03977\n",
      "[epoch 127, batch    29] loss: 2.93680\n",
      "[epoch 127, batch    30] loss: 3.13289\n",
      "[epoch 127, batch    31] loss: 2.83289\n",
      "[epoch 127, batch    32] loss: 5.29887\n",
      "[epoch 128, batch     1] loss: 3.54626\n",
      "[epoch 128, batch     2] loss: 2.60598\n",
      "[epoch 128, batch     3] loss: 4.24086\n",
      "[epoch 128, batch     4] loss: 3.65616\n",
      "[epoch 128, batch     5] loss: 2.72632\n",
      "[epoch 128, batch     6] loss: 3.22814\n",
      "[epoch 128, batch     7] loss: 3.99463\n",
      "[epoch 128, batch     8] loss: 2.63032\n",
      "[epoch 128, batch     9] loss: 3.15306\n",
      "[epoch 128, batch    10] loss: 2.98738\n",
      "[epoch 128, batch    11] loss: 2.40475\n",
      "[epoch 128, batch    12] loss: 2.66915\n",
      "[epoch 128, batch    13] loss: 2.69622\n",
      "[epoch 128, batch    14] loss: 2.67863\n",
      "[epoch 128, batch    15] loss: 2.65707\n",
      "[epoch 128, batch    16] loss: 3.01142\n",
      "[epoch 128, batch    17] loss: 2.40733\n",
      "[epoch 128, batch    18] loss: 2.33033\n",
      "[epoch 128, batch    19] loss: 2.45693\n",
      "[epoch 128, batch    20] loss: 3.23667\n",
      "[epoch 128, batch    21] loss: 3.15987\n",
      "[epoch 128, batch    22] loss: 3.96050\n",
      "[epoch 128, batch    23] loss: 3.84963\n",
      "[epoch 128, batch    24] loss: 3.18037\n",
      "[epoch 128, batch    25] loss: 2.67716\n",
      "[epoch 128, batch    26] loss: 3.50211\n",
      "[epoch 128, batch    27] loss: 2.76230\n",
      "[epoch 128, batch    28] loss: 2.53685\n",
      "[epoch 128, batch    29] loss: 3.04894\n",
      "[epoch 128, batch    30] loss: 2.24303\n",
      "[epoch 128, batch    31] loss: 4.12511\n",
      "[epoch 128, batch    32] loss: 1.98017\n",
      "[epoch 129, batch     1] loss: 4.10126\n",
      "[epoch 129, batch     2] loss: 2.97613\n",
      "[epoch 129, batch     3] loss: 3.61365\n",
      "[epoch 129, batch     4] loss: 3.22916\n",
      "[epoch 129, batch     5] loss: 3.89249\n",
      "[epoch 129, batch     6] loss: 2.80737\n",
      "[epoch 129, batch     7] loss: 3.22473\n",
      "[epoch 129, batch     8] loss: 2.96333\n",
      "[epoch 129, batch     9] loss: 3.05861\n",
      "[epoch 129, batch    10] loss: 2.27202\n",
      "[epoch 129, batch    11] loss: 3.04398\n",
      "[epoch 129, batch    12] loss: 2.63061\n",
      "[epoch 129, batch    13] loss: 3.15402\n",
      "[epoch 129, batch    14] loss: 4.00519\n",
      "[epoch 129, batch    15] loss: 2.96651\n",
      "[epoch 129, batch    16] loss: 3.09408\n",
      "[epoch 129, batch    17] loss: 2.56320\n",
      "[epoch 129, batch    18] loss: 3.65763\n",
      "[epoch 129, batch    19] loss: 2.74601\n",
      "[epoch 129, batch    20] loss: 3.71172\n",
      "[epoch 129, batch    21] loss: 2.30061\n",
      "[epoch 129, batch    22] loss: 2.79384\n",
      "[epoch 129, batch    23] loss: 2.59611\n",
      "[epoch 129, batch    24] loss: 3.51912\n",
      "[epoch 129, batch    25] loss: 2.58866\n",
      "[epoch 129, batch    26] loss: 2.55294\n",
      "[epoch 129, batch    27] loss: 2.20918\n",
      "[epoch 129, batch    28] loss: 3.36900\n",
      "[epoch 129, batch    29] loss: 2.71169\n",
      "[epoch 129, batch    30] loss: 2.61915\n",
      "[epoch 129, batch    31] loss: 3.15915\n",
      "[epoch 129, batch    32] loss: 2.91299\n",
      "[epoch 130, batch     1] loss: 2.90580\n",
      "[epoch 130, batch     2] loss: 3.72963\n",
      "[epoch 130, batch     3] loss: 3.44926\n",
      "[epoch 130, batch     4] loss: 3.26181\n",
      "[epoch 130, batch     5] loss: 2.58740\n",
      "[epoch 130, batch     6] loss: 3.54792\n",
      "[epoch 130, batch     7] loss: 3.15555\n",
      "[epoch 130, batch     8] loss: 4.10906\n",
      "[epoch 130, batch     9] loss: 2.74061\n",
      "[epoch 130, batch    10] loss: 2.10050\n",
      "[epoch 130, batch    11] loss: 3.02018\n",
      "[epoch 130, batch    12] loss: 3.26795\n",
      "[epoch 130, batch    13] loss: 3.50302\n",
      "[epoch 130, batch    14] loss: 3.04879\n",
      "[epoch 130, batch    15] loss: 2.69154\n",
      "[epoch 130, batch    16] loss: 2.40929\n",
      "[epoch 130, batch    17] loss: 2.27232\n",
      "[epoch 130, batch    18] loss: 2.95253\n",
      "[epoch 130, batch    19] loss: 3.12638\n",
      "[epoch 130, batch    20] loss: 2.77570\n",
      "[epoch 130, batch    21] loss: 2.82322\n",
      "[epoch 130, batch    22] loss: 2.06359\n",
      "[epoch 130, batch    23] loss: 2.88718\n",
      "[epoch 130, batch    24] loss: 4.83122\n",
      "[epoch 130, batch    25] loss: 2.33227\n",
      "[epoch 130, batch    26] loss: 4.32320\n",
      "[epoch 130, batch    27] loss: 2.59598\n",
      "[epoch 130, batch    28] loss: 3.18023\n",
      "[epoch 130, batch    29] loss: 2.83333\n",
      "[epoch 130, batch    30] loss: 2.70113\n",
      "[epoch 130, batch    31] loss: 3.23191\n",
      "[epoch 130, batch    32] loss: 1.69643\n",
      "[epoch 131, batch     1] loss: 2.00871\n",
      "[epoch 131, batch     2] loss: 3.69928\n",
      "[epoch 131, batch     3] loss: 3.17562\n",
      "[epoch 131, batch     4] loss: 2.13893\n",
      "[epoch 131, batch     5] loss: 2.08471\n",
      "[epoch 131, batch     6] loss: 3.16554\n",
      "[epoch 131, batch     7] loss: 3.03426\n",
      "[epoch 131, batch     8] loss: 3.00745\n",
      "[epoch 131, batch     9] loss: 3.40497\n",
      "[epoch 131, batch    10] loss: 2.62325\n",
      "[epoch 131, batch    11] loss: 3.76440\n",
      "[epoch 131, batch    12] loss: 3.58749\n",
      "[epoch 131, batch    13] loss: 3.07695\n",
      "[epoch 131, batch    14] loss: 2.94489\n",
      "[epoch 131, batch    15] loss: 3.16325\n",
      "[epoch 131, batch    16] loss: 2.70861\n",
      "[epoch 131, batch    17] loss: 3.84000\n",
      "[epoch 131, batch    18] loss: 2.89696\n",
      "[epoch 131, batch    19] loss: 3.92980\n",
      "[epoch 131, batch    20] loss: 3.16209\n",
      "[epoch 131, batch    21] loss: 2.52892\n",
      "[epoch 131, batch    22] loss: 2.24782\n",
      "[epoch 131, batch    23] loss: 3.51500\n",
      "[epoch 131, batch    24] loss: 3.30187\n",
      "[epoch 131, batch    25] loss: 3.02280\n",
      "[epoch 131, batch    26] loss: 2.51550\n",
      "[epoch 131, batch    27] loss: 3.70241\n",
      "[epoch 131, batch    28] loss: 3.12579\n",
      "[epoch 131, batch    29] loss: 2.98955\n",
      "[epoch 131, batch    30] loss: 3.35636\n",
      "[epoch 131, batch    31] loss: 2.16604\n",
      "[epoch 131, batch    32] loss: 3.10117\n",
      "[epoch 132, batch     1] loss: 4.75451\n",
      "[epoch 132, batch     2] loss: 3.68410\n",
      "[epoch 132, batch     3] loss: 3.33768\n",
      "[epoch 132, batch     4] loss: 3.48103\n",
      "[epoch 132, batch     5] loss: 3.80106\n",
      "[epoch 132, batch     6] loss: 2.19861\n",
      "[epoch 132, batch     7] loss: 3.26911\n",
      "[epoch 132, batch     8] loss: 2.90743\n",
      "[epoch 132, batch     9] loss: 2.90741\n",
      "[epoch 132, batch    10] loss: 3.07651\n",
      "[epoch 132, batch    11] loss: 3.45714\n",
      "[epoch 132, batch    12] loss: 2.51319\n",
      "[epoch 132, batch    13] loss: 2.94531\n",
      "[epoch 132, batch    14] loss: 2.47577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 132, batch    15] loss: 2.35627\n",
      "[epoch 132, batch    16] loss: 2.21058\n",
      "[epoch 132, batch    17] loss: 2.93076\n",
      "[epoch 132, batch    18] loss: 3.89946\n",
      "[epoch 132, batch    19] loss: 3.25850\n",
      "[epoch 132, batch    20] loss: 2.56651\n",
      "[epoch 132, batch    21] loss: 3.67711\n",
      "[epoch 132, batch    22] loss: 2.56276\n",
      "[epoch 132, batch    23] loss: 2.82183\n",
      "[epoch 132, batch    24] loss: 2.42806\n",
      "[epoch 132, batch    25] loss: 3.32155\n",
      "[epoch 132, batch    26] loss: 2.42759\n",
      "[epoch 132, batch    27] loss: 2.66283\n",
      "[epoch 132, batch    28] loss: 4.03720\n",
      "[epoch 132, batch    29] loss: 2.36086\n",
      "[epoch 132, batch    30] loss: 3.26139\n",
      "[epoch 132, batch    31] loss: 2.89404\n",
      "[epoch 132, batch    32] loss: 2.69728\n",
      "[epoch 133, batch     1] loss: 3.27840\n",
      "[epoch 133, batch     2] loss: 2.98975\n",
      "[epoch 133, batch     3] loss: 3.27604\n",
      "[epoch 133, batch     4] loss: 2.91782\n",
      "[epoch 133, batch     5] loss: 3.92664\n",
      "[epoch 133, batch     6] loss: 3.03227\n",
      "[epoch 133, batch     7] loss: 3.11310\n",
      "[epoch 133, batch     8] loss: 2.75129\n",
      "[epoch 133, batch     9] loss: 2.34395\n",
      "[epoch 133, batch    10] loss: 3.66648\n",
      "[epoch 133, batch    11] loss: 3.57637\n",
      "[epoch 133, batch    12] loss: 3.33699\n",
      "[epoch 133, batch    13] loss: 3.65881\n",
      "[epoch 133, batch    14] loss: 2.76789\n",
      "[epoch 133, batch    15] loss: 2.95527\n",
      "[epoch 133, batch    16] loss: 3.24292\n",
      "[epoch 133, batch    17] loss: 2.81044\n",
      "[epoch 133, batch    18] loss: 2.89908\n",
      "[epoch 133, batch    19] loss: 2.40298\n",
      "[epoch 133, batch    20] loss: 3.62379\n",
      "[epoch 133, batch    21] loss: 3.16047\n",
      "[epoch 133, batch    22] loss: 3.17818\n",
      "[epoch 133, batch    23] loss: 2.98922\n",
      "[epoch 133, batch    24] loss: 3.08463\n",
      "[epoch 133, batch    25] loss: 3.62062\n",
      "[epoch 133, batch    26] loss: 2.96598\n",
      "[epoch 133, batch    27] loss: 3.14867\n",
      "[epoch 133, batch    28] loss: 2.43087\n",
      "[epoch 133, batch    29] loss: 2.43464\n",
      "[epoch 133, batch    30] loss: 2.24454\n",
      "[epoch 133, batch    31] loss: 2.54513\n",
      "[epoch 133, batch    32] loss: 2.86041\n",
      "[epoch 134, batch     1] loss: 2.80127\n",
      "[epoch 134, batch     2] loss: 4.07782\n",
      "[epoch 134, batch     3] loss: 3.64226\n",
      "[epoch 134, batch     4] loss: 2.35406\n",
      "[epoch 134, batch     5] loss: 3.11529\n",
      "[epoch 134, batch     6] loss: 2.69667\n",
      "[epoch 134, batch     7] loss: 3.74649\n",
      "[epoch 134, batch     8] loss: 3.49345\n",
      "[epoch 134, batch     9] loss: 3.98743\n",
      "[epoch 134, batch    10] loss: 2.75386\n",
      "[epoch 134, batch    11] loss: 2.74457\n",
      "[epoch 134, batch    12] loss: 2.72736\n",
      "[epoch 134, batch    13] loss: 3.41525\n",
      "[epoch 134, batch    14] loss: 2.49400\n",
      "[epoch 134, batch    15] loss: 3.61616\n",
      "[epoch 134, batch    16] loss: 2.53962\n",
      "[epoch 134, batch    17] loss: 2.81067\n",
      "[epoch 134, batch    18] loss: 2.74267\n",
      "[epoch 134, batch    19] loss: 3.00061\n",
      "[epoch 134, batch    20] loss: 3.72337\n",
      "[epoch 134, batch    21] loss: 2.80459\n",
      "[epoch 134, batch    22] loss: 2.51074\n",
      "[epoch 134, batch    23] loss: 2.51592\n",
      "[epoch 134, batch    24] loss: 2.76770\n",
      "[epoch 134, batch    25] loss: 3.02915\n",
      "[epoch 134, batch    26] loss: 3.05584\n",
      "[epoch 134, batch    27] loss: 3.49901\n",
      "[epoch 134, batch    28] loss: 2.94704\n",
      "[epoch 134, batch    29] loss: 2.42694\n",
      "[epoch 134, batch    30] loss: 3.19375\n",
      "[epoch 134, batch    31] loss: 3.65358\n",
      "[epoch 134, batch    32] loss: 2.49897\n",
      "[epoch 135, batch     1] loss: 2.71186\n",
      "[epoch 135, batch     2] loss: 2.87212\n",
      "[epoch 135, batch     3] loss: 3.79540\n",
      "[epoch 135, batch     4] loss: 2.99208\n",
      "[epoch 135, batch     5] loss: 3.05226\n",
      "[epoch 135, batch     6] loss: 3.16394\n",
      "[epoch 135, batch     7] loss: 3.55973\n",
      "[epoch 135, batch     8] loss: 3.09352\n",
      "[epoch 135, batch     9] loss: 2.62548\n",
      "[epoch 135, batch    10] loss: 2.86515\n",
      "[epoch 135, batch    11] loss: 2.41932\n",
      "[epoch 135, batch    12] loss: 3.14287\n",
      "[epoch 135, batch    13] loss: 2.78351\n",
      "[epoch 135, batch    14] loss: 3.83562\n",
      "[epoch 135, batch    15] loss: 3.16429\n",
      "[epoch 135, batch    16] loss: 2.25263\n",
      "[epoch 135, batch    17] loss: 3.18237\n",
      "[epoch 135, batch    18] loss: 3.20978\n",
      "[epoch 135, batch    19] loss: 3.24384\n",
      "[epoch 135, batch    20] loss: 3.18883\n",
      "[epoch 135, batch    21] loss: 2.59308\n",
      "[epoch 135, batch    22] loss: 2.67032\n",
      "[epoch 135, batch    23] loss: 3.16238\n",
      "[epoch 135, batch    24] loss: 4.19589\n",
      "[epoch 135, batch    25] loss: 2.51508\n",
      "[epoch 135, batch    26] loss: 2.63640\n",
      "[epoch 135, batch    27] loss: 3.87811\n",
      "[epoch 135, batch    28] loss: 3.01929\n",
      "[epoch 135, batch    29] loss: 3.23905\n",
      "[epoch 135, batch    30] loss: 2.90151\n",
      "[epoch 135, batch    31] loss: 2.54337\n",
      "[epoch 135, batch    32] loss: 2.51352\n",
      "[epoch 136, batch     1] loss: 3.45870\n",
      "[epoch 136, batch     2] loss: 2.79256\n",
      "[epoch 136, batch     3] loss: 3.63669\n",
      "[epoch 136, batch     4] loss: 3.52709\n",
      "[epoch 136, batch     5] loss: 3.00682\n",
      "[epoch 136, batch     6] loss: 2.54580\n",
      "[epoch 136, batch     7] loss: 2.55926\n",
      "[epoch 136, batch     8] loss: 3.33513\n",
      "[epoch 136, batch     9] loss: 2.94925\n",
      "[epoch 136, batch    10] loss: 2.76154\n",
      "[epoch 136, batch    11] loss: 2.86720\n",
      "[epoch 136, batch    12] loss: 2.89259\n",
      "[epoch 136, batch    13] loss: 2.94198\n",
      "[epoch 136, batch    14] loss: 2.77359\n",
      "[epoch 136, batch    15] loss: 2.56099\n",
      "[epoch 136, batch    16] loss: 3.86760\n",
      "[epoch 136, batch    17] loss: 3.39620\n",
      "[epoch 136, batch    18] loss: 2.81821\n",
      "[epoch 136, batch    19] loss: 3.28592\n",
      "[epoch 136, batch    20] loss: 2.29257\n",
      "[epoch 136, batch    21] loss: 3.33338\n",
      "[epoch 136, batch    22] loss: 2.06946\n",
      "[epoch 136, batch    23] loss: 2.59570\n",
      "[epoch 136, batch    24] loss: 3.14426\n",
      "[epoch 136, batch    25] loss: 3.00767\n",
      "[epoch 136, batch    26] loss: 3.55171\n",
      "[epoch 136, batch    27] loss: 2.56412\n",
      "[epoch 136, batch    28] loss: 3.43772\n",
      "[epoch 136, batch    29] loss: 3.09195\n",
      "[epoch 136, batch    30] loss: 3.01769\n",
      "[epoch 136, batch    31] loss: 3.94653\n",
      "[epoch 136, batch    32] loss: 4.98843\n",
      "[epoch 137, batch     1] loss: 3.26807\n",
      "[epoch 137, batch     2] loss: 3.07609\n",
      "[epoch 137, batch     3] loss: 3.22254\n",
      "[epoch 137, batch     4] loss: 3.16975\n",
      "[epoch 137, batch     5] loss: 2.80838\n",
      "[epoch 137, batch     6] loss: 2.65418\n",
      "[epoch 137, batch     7] loss: 3.31726\n",
      "[epoch 137, batch     8] loss: 2.62567\n",
      "[epoch 137, batch     9] loss: 1.83225\n",
      "[epoch 137, batch    10] loss: 3.18307\n",
      "[epoch 137, batch    11] loss: 3.40388\n",
      "[epoch 137, batch    12] loss: 3.32476\n",
      "[epoch 137, batch    13] loss: 2.67962\n",
      "[epoch 137, batch    14] loss: 3.07044\n",
      "[epoch 137, batch    15] loss: 2.81311\n",
      "[epoch 137, batch    16] loss: 2.60844\n",
      "[epoch 137, batch    17] loss: 2.75596\n",
      "[epoch 137, batch    18] loss: 3.82099\n",
      "[epoch 137, batch    19] loss: 2.46255\n",
      "[epoch 137, batch    20] loss: 3.29781\n",
      "[epoch 137, batch    21] loss: 3.07993\n",
      "[epoch 137, batch    22] loss: 3.16240\n",
      "[epoch 137, batch    23] loss: 3.15879\n",
      "[epoch 137, batch    24] loss: 2.53791\n",
      "[epoch 137, batch    25] loss: 3.45086\n",
      "[epoch 137, batch    26] loss: 3.20081\n",
      "[epoch 137, batch    27] loss: 3.80396\n",
      "[epoch 137, batch    28] loss: 2.42562\n",
      "[epoch 137, batch    29] loss: 2.98255\n",
      "[epoch 137, batch    30] loss: 3.87151\n",
      "[epoch 137, batch    31] loss: 3.80217\n",
      "[epoch 137, batch    32] loss: 2.17044\n",
      "[epoch 138, batch     1] loss: 3.64707\n",
      "[epoch 138, batch     2] loss: 2.76448\n",
      "[epoch 138, batch     3] loss: 2.89321\n",
      "[epoch 138, batch     4] loss: 3.65655\n",
      "[epoch 138, batch     5] loss: 3.13469\n",
      "[epoch 138, batch     6] loss: 2.87716\n",
      "[epoch 138, batch     7] loss: 3.21965\n",
      "[epoch 138, batch     8] loss: 3.33835\n",
      "[epoch 138, batch     9] loss: 3.04229\n",
      "[epoch 138, batch    10] loss: 2.65643\n",
      "[epoch 138, batch    11] loss: 4.02598\n",
      "[epoch 138, batch    12] loss: 2.95735\n",
      "[epoch 138, batch    13] loss: 3.10398\n",
      "[epoch 138, batch    14] loss: 2.22788\n",
      "[epoch 138, batch    15] loss: 3.73937\n",
      "[epoch 138, batch    16] loss: 3.43918\n",
      "[epoch 138, batch    17] loss: 2.41778\n",
      "[epoch 138, batch    18] loss: 2.74144\n",
      "[epoch 138, batch    19] loss: 3.09811\n",
      "[epoch 138, batch    20] loss: 2.72135\n",
      "[epoch 138, batch    21] loss: 3.11408\n",
      "[epoch 138, batch    22] loss: 3.56250\n",
      "[epoch 138, batch    23] loss: 2.37819\n",
      "[epoch 138, batch    24] loss: 2.96530\n",
      "[epoch 138, batch    25] loss: 2.99791\n",
      "[epoch 138, batch    26] loss: 3.68155\n",
      "[epoch 138, batch    27] loss: 2.88720\n",
      "[epoch 138, batch    28] loss: 2.95226\n",
      "[epoch 138, batch    29] loss: 2.85140\n",
      "[epoch 138, batch    30] loss: 2.67497\n",
      "[epoch 138, batch    31] loss: 2.91159\n",
      "[epoch 138, batch    32] loss: 2.49118\n",
      "[epoch 139, batch     1] loss: 2.70891\n",
      "[epoch 139, batch     2] loss: 3.06453\n",
      "[epoch 139, batch     3] loss: 3.03007\n",
      "[epoch 139, batch     4] loss: 3.63569\n",
      "[epoch 139, batch     5] loss: 3.20106\n",
      "[epoch 139, batch     6] loss: 2.89485\n",
      "[epoch 139, batch     7] loss: 2.57524\n",
      "[epoch 139, batch     8] loss: 3.02046\n",
      "[epoch 139, batch     9] loss: 3.93382\n",
      "[epoch 139, batch    10] loss: 2.85242\n",
      "[epoch 139, batch    11] loss: 2.97434\n",
      "[epoch 139, batch    12] loss: 2.85077\n",
      "[epoch 139, batch    13] loss: 4.02534\n",
      "[epoch 139, batch    14] loss: 3.14827\n",
      "[epoch 139, batch    15] loss: 3.61186\n",
      "[epoch 139, batch    16] loss: 3.25043\n",
      "[epoch 139, batch    17] loss: 2.40869\n",
      "[epoch 139, batch    18] loss: 3.47040\n",
      "[epoch 139, batch    19] loss: 3.94506\n",
      "[epoch 139, batch    20] loss: 3.23512\n",
      "[epoch 139, batch    21] loss: 3.21652\n",
      "[epoch 139, batch    22] loss: 2.76829\n",
      "[epoch 139, batch    23] loss: 2.80805\n",
      "[epoch 139, batch    24] loss: 2.03041\n",
      "[epoch 139, batch    25] loss: 2.93184\n",
      "[epoch 139, batch    26] loss: 3.40527\n",
      "[epoch 139, batch    27] loss: 2.27843\n",
      "[epoch 139, batch    28] loss: 2.47266\n",
      "[epoch 139, batch    29] loss: 2.40430\n",
      "[epoch 139, batch    30] loss: 2.77189\n",
      "[epoch 139, batch    31] loss: 2.68380\n",
      "[epoch 139, batch    32] loss: 3.67010\n",
      "[epoch 140, batch     1] loss: 3.76212\n",
      "[epoch 140, batch     2] loss: 3.06614\n",
      "[epoch 140, batch     3] loss: 3.29178\n",
      "[epoch 140, batch     4] loss: 3.11373\n",
      "[epoch 140, batch     5] loss: 3.24765\n",
      "[epoch 140, batch     6] loss: 3.35154\n",
      "[epoch 140, batch     7] loss: 3.38832\n",
      "[epoch 140, batch     8] loss: 2.80007\n",
      "[epoch 140, batch     9] loss: 3.55849\n",
      "[epoch 140, batch    10] loss: 3.50660\n",
      "[epoch 140, batch    11] loss: 2.24950\n",
      "[epoch 140, batch    12] loss: 3.19203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 140, batch    13] loss: 2.34706\n",
      "[epoch 140, batch    14] loss: 3.84146\n",
      "[epoch 140, batch    15] loss: 3.06682\n",
      "[epoch 140, batch    16] loss: 2.74294\n",
      "[epoch 140, batch    17] loss: 3.19232\n",
      "[epoch 140, batch    18] loss: 2.75254\n",
      "[epoch 140, batch    19] loss: 2.32067\n",
      "[epoch 140, batch    20] loss: 3.44829\n",
      "[epoch 140, batch    21] loss: 2.85871\n",
      "[epoch 140, batch    22] loss: 3.22303\n",
      "[epoch 140, batch    23] loss: 3.16656\n",
      "[epoch 140, batch    24] loss: 3.31494\n",
      "[epoch 140, batch    25] loss: 2.98941\n",
      "[epoch 140, batch    26] loss: 2.11972\n",
      "[epoch 140, batch    27] loss: 3.04590\n",
      "[epoch 140, batch    28] loss: 2.71691\n",
      "[epoch 140, batch    29] loss: 2.62105\n",
      "[epoch 140, batch    30] loss: 2.61768\n",
      "[epoch 140, batch    31] loss: 2.86592\n",
      "[epoch 140, batch    32] loss: 3.29156\n",
      "[epoch 141, batch     1] loss: 3.44471\n",
      "[epoch 141, batch     2] loss: 2.87037\n",
      "[epoch 141, batch     3] loss: 2.04582\n",
      "[epoch 141, batch     4] loss: 2.70717\n",
      "[epoch 141, batch     5] loss: 3.05949\n",
      "[epoch 141, batch     6] loss: 2.82860\n",
      "[epoch 141, batch     7] loss: 3.09153\n",
      "[epoch 141, batch     8] loss: 2.45923\n",
      "[epoch 141, batch     9] loss: 3.31440\n",
      "[epoch 141, batch    10] loss: 2.75831\n",
      "[epoch 141, batch    11] loss: 2.60118\n",
      "[epoch 141, batch    12] loss: 3.42529\n",
      "[epoch 141, batch    13] loss: 2.44351\n",
      "[epoch 141, batch    14] loss: 2.60786\n",
      "[epoch 141, batch    15] loss: 3.94574\n",
      "[epoch 141, batch    16] loss: 3.19255\n",
      "[epoch 141, batch    17] loss: 3.08417\n",
      "[epoch 141, batch    18] loss: 4.03384\n",
      "[epoch 141, batch    19] loss: 4.36857\n",
      "[epoch 141, batch    20] loss: 3.25500\n",
      "[epoch 141, batch    21] loss: 3.42672\n",
      "[epoch 141, batch    22] loss: 2.52349\n",
      "[epoch 141, batch    23] loss: 3.25599\n",
      "[epoch 141, batch    24] loss: 3.23874\n",
      "[epoch 141, batch    25] loss: 2.91007\n",
      "[epoch 141, batch    26] loss: 3.35518\n",
      "[epoch 141, batch    27] loss: 2.38910\n",
      "[epoch 141, batch    28] loss: 2.50106\n",
      "[epoch 141, batch    29] loss: 2.91200\n",
      "[epoch 141, batch    30] loss: 2.30563\n",
      "[epoch 141, batch    31] loss: 4.04648\n",
      "[epoch 141, batch    32] loss: 2.98191\n",
      "[epoch 142, batch     1] loss: 3.15502\n",
      "[epoch 142, batch     2] loss: 3.10805\n",
      "[epoch 142, batch     3] loss: 3.28371\n",
      "[epoch 142, batch     4] loss: 3.09321\n",
      "[epoch 142, batch     5] loss: 2.27425\n",
      "[epoch 142, batch     6] loss: 2.97204\n",
      "[epoch 142, batch     7] loss: 2.54522\n",
      "[epoch 142, batch     8] loss: 3.51316\n",
      "[epoch 142, batch     9] loss: 3.19330\n",
      "[epoch 142, batch    10] loss: 2.88355\n",
      "[epoch 142, batch    11] loss: 3.11156\n",
      "[epoch 142, batch    12] loss: 3.10642\n",
      "[epoch 142, batch    13] loss: 3.29265\n",
      "[epoch 142, batch    14] loss: 2.96536\n",
      "[epoch 142, batch    15] loss: 2.94777\n",
      "[epoch 142, batch    16] loss: 2.66347\n",
      "[epoch 142, batch    17] loss: 3.13126\n",
      "[epoch 142, batch    18] loss: 3.65380\n",
      "[epoch 142, batch    19] loss: 3.44066\n",
      "[epoch 142, batch    20] loss: 3.58593\n",
      "[epoch 142, batch    21] loss: 2.07529\n",
      "[epoch 142, batch    22] loss: 2.16840\n",
      "[epoch 142, batch    23] loss: 4.42945\n",
      "[epoch 142, batch    24] loss: 2.49619\n",
      "[epoch 142, batch    25] loss: 2.53678\n",
      "[epoch 142, batch    26] loss: 3.54128\n",
      "[epoch 142, batch    27] loss: 2.93278\n",
      "[epoch 142, batch    28] loss: 2.31216\n",
      "[epoch 142, batch    29] loss: 3.43588\n",
      "[epoch 142, batch    30] loss: 3.37908\n",
      "[epoch 142, batch    31] loss: 2.58644\n",
      "[epoch 142, batch    32] loss: 4.22140\n",
      "[epoch 143, batch     1] loss: 2.80110\n",
      "[epoch 143, batch     2] loss: 3.07856\n",
      "[epoch 143, batch     3] loss: 2.69777\n",
      "[epoch 143, batch     4] loss: 2.29400\n",
      "[epoch 143, batch     5] loss: 3.76951\n",
      "[epoch 143, batch     6] loss: 2.31894\n",
      "[epoch 143, batch     7] loss: 2.65902\n",
      "[epoch 143, batch     8] loss: 2.48676\n",
      "[epoch 143, batch     9] loss: 3.39003\n",
      "[epoch 143, batch    10] loss: 3.15195\n",
      "[epoch 143, batch    11] loss: 3.21060\n",
      "[epoch 143, batch    12] loss: 2.69620\n",
      "[epoch 143, batch    13] loss: 3.63413\n",
      "[epoch 143, batch    14] loss: 2.71980\n",
      "[epoch 143, batch    15] loss: 2.56925\n",
      "[epoch 143, batch    16] loss: 2.24845\n",
      "[epoch 143, batch    17] loss: 2.88895\n",
      "[epoch 143, batch    18] loss: 3.04358\n",
      "[epoch 143, batch    19] loss: 2.65072\n",
      "[epoch 143, batch    20] loss: 3.43863\n",
      "[epoch 143, batch    21] loss: 4.03873\n",
      "[epoch 143, batch    22] loss: 2.70161\n",
      "[epoch 143, batch    23] loss: 2.63720\n",
      "[epoch 143, batch    24] loss: 3.86294\n",
      "[epoch 143, batch    25] loss: 4.30826\n",
      "[epoch 143, batch    26] loss: 2.67808\n",
      "[epoch 143, batch    27] loss: 3.43995\n",
      "[epoch 143, batch    28] loss: 3.44395\n",
      "[epoch 143, batch    29] loss: 2.90119\n",
      "[epoch 143, batch    30] loss: 3.03321\n",
      "[epoch 143, batch    31] loss: 3.57725\n",
      "[epoch 143, batch    32] loss: 2.59275\n",
      "[epoch 144, batch     1] loss: 3.18424\n",
      "[epoch 144, batch     2] loss: 3.20200\n",
      "[epoch 144, batch     3] loss: 3.53443\n",
      "[epoch 144, batch     4] loss: 3.31677\n",
      "[epoch 144, batch     5] loss: 2.45050\n",
      "[epoch 144, batch     6] loss: 3.58420\n",
      "[epoch 144, batch     7] loss: 2.70458\n",
      "[epoch 144, batch     8] loss: 2.88102\n",
      "[epoch 144, batch     9] loss: 2.90558\n",
      "[epoch 144, batch    10] loss: 2.71730\n",
      "[epoch 144, batch    11] loss: 3.10085\n",
      "[epoch 144, batch    12] loss: 3.61354\n",
      "[epoch 144, batch    13] loss: 2.81217\n",
      "[epoch 144, batch    14] loss: 3.31575\n",
      "[epoch 144, batch    15] loss: 2.00677\n",
      "[epoch 144, batch    16] loss: 3.43245\n",
      "[epoch 144, batch    17] loss: 2.87103\n",
      "[epoch 144, batch    18] loss: 2.97941\n",
      "[epoch 144, batch    19] loss: 3.04379\n",
      "[epoch 144, batch    20] loss: 2.50014\n",
      "[epoch 144, batch    21] loss: 3.51613\n",
      "[epoch 144, batch    22] loss: 2.85834\n",
      "[epoch 144, batch    23] loss: 2.79899\n",
      "[epoch 144, batch    24] loss: 3.48802\n",
      "[epoch 144, batch    25] loss: 2.88045\n",
      "[epoch 144, batch    26] loss: 3.00476\n",
      "[epoch 144, batch    27] loss: 3.87446\n",
      "[epoch 144, batch    28] loss: 3.21182\n",
      "[epoch 144, batch    29] loss: 2.76545\n",
      "[epoch 144, batch    30] loss: 2.68613\n",
      "[epoch 144, batch    31] loss: 2.94916\n",
      "[epoch 144, batch    32] loss: 3.75607\n",
      "[epoch 145, batch     1] loss: 3.47070\n",
      "[epoch 145, batch     2] loss: 3.80461\n",
      "[epoch 145, batch     3] loss: 3.55474\n",
      "[epoch 145, batch     4] loss: 3.29842\n",
      "[epoch 145, batch     5] loss: 2.79604\n",
      "[epoch 145, batch     6] loss: 3.44285\n",
      "[epoch 145, batch     7] loss: 2.67460\n",
      "[epoch 145, batch     8] loss: 3.21006\n",
      "[epoch 145, batch     9] loss: 3.07858\n",
      "[epoch 145, batch    10] loss: 3.70497\n",
      "[epoch 145, batch    11] loss: 3.12771\n",
      "[epoch 145, batch    12] loss: 2.93781\n",
      "[epoch 145, batch    13] loss: 2.77580\n",
      "[epoch 145, batch    14] loss: 3.08510\n",
      "[epoch 145, batch    15] loss: 2.20488\n",
      "[epoch 145, batch    16] loss: 2.68887\n",
      "[epoch 145, batch    17] loss: 2.63812\n",
      "[epoch 145, batch    18] loss: 2.93392\n",
      "[epoch 145, batch    19] loss: 3.33843\n",
      "[epoch 145, batch    20] loss: 2.99108\n",
      "[epoch 145, batch    21] loss: 3.00594\n",
      "[epoch 145, batch    22] loss: 2.53752\n",
      "[epoch 145, batch    23] loss: 4.02265\n",
      "[epoch 145, batch    24] loss: 3.49366\n",
      "[epoch 145, batch    25] loss: 2.67628\n",
      "[epoch 145, batch    26] loss: 2.37871\n",
      "[epoch 145, batch    27] loss: 3.13454\n",
      "[epoch 145, batch    28] loss: 2.77931\n",
      "[epoch 145, batch    29] loss: 3.32861\n",
      "[epoch 145, batch    30] loss: 2.56832\n",
      "[epoch 145, batch    31] loss: 2.83911\n",
      "[epoch 145, batch    32] loss: 2.97531\n",
      "[epoch 146, batch     1] loss: 3.04658\n",
      "[epoch 146, batch     2] loss: 2.51994\n",
      "[epoch 146, batch     3] loss: 2.23641\n",
      "[epoch 146, batch     4] loss: 2.91103\n",
      "[epoch 146, batch     5] loss: 3.58292\n",
      "[epoch 146, batch     6] loss: 2.34247\n",
      "[epoch 146, batch     7] loss: 3.33015\n",
      "[epoch 146, batch     8] loss: 3.58958\n",
      "[epoch 146, batch     9] loss: 2.63703\n",
      "[epoch 146, batch    10] loss: 3.20021\n",
      "[epoch 146, batch    11] loss: 3.16358\n",
      "[epoch 146, batch    12] loss: 2.99205\n",
      "[epoch 146, batch    13] loss: 3.27166\n",
      "[epoch 146, batch    14] loss: 3.48261\n",
      "[epoch 146, batch    15] loss: 2.92939\n",
      "[epoch 146, batch    16] loss: 3.25989\n",
      "[epoch 146, batch    17] loss: 2.46891\n",
      "[epoch 146, batch    18] loss: 2.96749\n",
      "[epoch 146, batch    19] loss: 2.50313\n",
      "[epoch 146, batch    20] loss: 2.34607\n",
      "[epoch 146, batch    21] loss: 3.22474\n",
      "[epoch 146, batch    22] loss: 2.59313\n",
      "[epoch 146, batch    23] loss: 2.67836\n",
      "[epoch 146, batch    24] loss: 2.80705\n",
      "[epoch 146, batch    25] loss: 4.59019\n",
      "[epoch 146, batch    26] loss: 3.39100\n",
      "[epoch 146, batch    27] loss: 3.64224\n",
      "[epoch 146, batch    28] loss: 3.24312\n",
      "[epoch 146, batch    29] loss: 3.12889\n",
      "[epoch 146, batch    30] loss: 2.79010\n",
      "[epoch 146, batch    31] loss: 3.24771\n",
      "[epoch 146, batch    32] loss: 2.58160\n",
      "[epoch 147, batch     1] loss: 3.63911\n",
      "[epoch 147, batch     2] loss: 2.86420\n",
      "[epoch 147, batch     3] loss: 2.90309\n",
      "[epoch 147, batch     4] loss: 2.26091\n",
      "[epoch 147, batch     5] loss: 3.16123\n",
      "[epoch 147, batch     6] loss: 2.90239\n",
      "[epoch 147, batch     7] loss: 2.61820\n",
      "[epoch 147, batch     8] loss: 2.74581\n",
      "[epoch 147, batch     9] loss: 3.28135\n",
      "[epoch 147, batch    10] loss: 3.11397\n",
      "[epoch 147, batch    11] loss: 2.71474\n",
      "[epoch 147, batch    12] loss: 3.51989\n",
      "[epoch 147, batch    13] loss: 3.34546\n",
      "[epoch 147, batch    14] loss: 3.40135\n",
      "[epoch 147, batch    15] loss: 2.57912\n",
      "[epoch 147, batch    16] loss: 3.41507\n",
      "[epoch 147, batch    17] loss: 3.13181\n",
      "[epoch 147, batch    18] loss: 3.01661\n",
      "[epoch 147, batch    19] loss: 2.68851\n",
      "[epoch 147, batch    20] loss: 3.29229\n",
      "[epoch 147, batch    21] loss: 3.62156\n",
      "[epoch 147, batch    22] loss: 2.72034\n",
      "[epoch 147, batch    23] loss: 2.53660\n",
      "[epoch 147, batch    24] loss: 2.82284\n",
      "[epoch 147, batch    25] loss: 3.08232\n",
      "[epoch 147, batch    26] loss: 3.07367\n",
      "[epoch 147, batch    27] loss: 3.44735\n",
      "[epoch 147, batch    28] loss: 3.18055\n",
      "[epoch 147, batch    29] loss: 2.90017\n",
      "[epoch 147, batch    30] loss: 3.35846\n",
      "[epoch 147, batch    31] loss: 2.83505\n",
      "[epoch 147, batch    32] loss: 2.14238\n",
      "[epoch 148, batch     1] loss: 3.19102\n",
      "[epoch 148, batch     2] loss: 2.54650\n",
      "[epoch 148, batch     3] loss: 2.87868\n",
      "[epoch 148, batch     4] loss: 3.82107\n",
      "[epoch 148, batch     5] loss: 3.79612\n",
      "[epoch 148, batch     6] loss: 3.25933\n",
      "[epoch 148, batch     7] loss: 2.39993\n",
      "[epoch 148, batch     8] loss: 3.35954\n",
      "[epoch 148, batch     9] loss: 2.69789\n",
      "[epoch 148, batch    10] loss: 2.71684\n",
      "[epoch 148, batch    11] loss: 3.26509\n",
      "[epoch 148, batch    12] loss: 2.93185\n",
      "[epoch 148, batch    13] loss: 2.76866\n",
      "[epoch 148, batch    14] loss: 2.57358\n",
      "[epoch 148, batch    15] loss: 2.89477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 148, batch    16] loss: 1.90337\n",
      "[epoch 148, batch    17] loss: 2.78760\n",
      "[epoch 148, batch    18] loss: 3.60218\n",
      "[epoch 148, batch    19] loss: 3.39950\n",
      "[epoch 148, batch    20] loss: 3.15132\n",
      "[epoch 148, batch    21] loss: 3.44439\n",
      "[epoch 148, batch    22] loss: 3.06504\n",
      "[epoch 148, batch    23] loss: 3.36178\n",
      "[epoch 148, batch    24] loss: 3.83685\n",
      "[epoch 148, batch    25] loss: 2.36663\n",
      "[epoch 148, batch    26] loss: 3.16367\n",
      "[epoch 148, batch    27] loss: 2.60073\n",
      "[epoch 148, batch    28] loss: 3.65875\n",
      "[epoch 148, batch    29] loss: 2.84372\n",
      "[epoch 148, batch    30] loss: 3.09031\n",
      "[epoch 148, batch    31] loss: 2.98766\n",
      "[epoch 148, batch    32] loss: 2.51259\n",
      "[epoch 149, batch     1] loss: 2.89871\n",
      "[epoch 149, batch     2] loss: 3.54791\n",
      "[epoch 149, batch     3] loss: 3.46200\n",
      "[epoch 149, batch     4] loss: 2.76080\n",
      "[epoch 149, batch     5] loss: 2.35841\n",
      "[epoch 149, batch     6] loss: 2.30874\n",
      "[epoch 149, batch     7] loss: 3.19023\n",
      "[epoch 149, batch     8] loss: 3.02346\n",
      "[epoch 149, batch     9] loss: 2.39677\n",
      "[epoch 149, batch    10] loss: 3.20888\n",
      "[epoch 149, batch    11] loss: 2.36700\n",
      "[epoch 149, batch    12] loss: 2.54614\n",
      "[epoch 149, batch    13] loss: 2.46541\n",
      "[epoch 149, batch    14] loss: 3.27135\n",
      "[epoch 149, batch    15] loss: 2.92456\n",
      "[epoch 149, batch    16] loss: 3.24985\n",
      "[epoch 149, batch    17] loss: 3.76196\n",
      "[epoch 149, batch    18] loss: 3.01713\n",
      "[epoch 149, batch    19] loss: 3.50570\n",
      "[epoch 149, batch    20] loss: 3.37149\n",
      "[epoch 149, batch    21] loss: 3.30924\n",
      "[epoch 149, batch    22] loss: 3.19841\n",
      "[epoch 149, batch    23] loss: 2.89492\n",
      "[epoch 149, batch    24] loss: 2.54608\n",
      "[epoch 149, batch    25] loss: 3.18449\n",
      "[epoch 149, batch    26] loss: 3.12367\n",
      "[epoch 149, batch    27] loss: 4.17722\n",
      "[epoch 149, batch    28] loss: 2.52025\n",
      "[epoch 149, batch    29] loss: 3.21054\n",
      "[epoch 149, batch    30] loss: 3.72159\n",
      "[epoch 149, batch    31] loss: 2.54413\n",
      "[epoch 149, batch    32] loss: 3.31379\n",
      "[epoch 150, batch     1] loss: 2.84226\n",
      "[epoch 150, batch     2] loss: 2.73433\n",
      "[epoch 150, batch     3] loss: 2.78493\n",
      "[epoch 150, batch     4] loss: 2.81001\n",
      "[epoch 150, batch     5] loss: 3.25155\n",
      "[epoch 150, batch     6] loss: 3.71027\n",
      "[epoch 150, batch     7] loss: 2.72136\n",
      "[epoch 150, batch     8] loss: 2.45773\n",
      "[epoch 150, batch     9] loss: 3.54702\n",
      "[epoch 150, batch    10] loss: 3.49771\n",
      "[epoch 150, batch    11] loss: 3.08799\n",
      "[epoch 150, batch    12] loss: 3.53941\n",
      "[epoch 150, batch    13] loss: 2.55709\n",
      "[epoch 150, batch    14] loss: 3.07740\n",
      "[epoch 150, batch    15] loss: 3.35698\n",
      "[epoch 150, batch    16] loss: 3.56541\n",
      "[epoch 150, batch    17] loss: 3.57187\n",
      "[epoch 150, batch    18] loss: 3.22613\n",
      "[epoch 150, batch    19] loss: 2.17190\n",
      "[epoch 150, batch    20] loss: 3.32775\n",
      "[epoch 150, batch    21] loss: 3.00634\n",
      "[epoch 150, batch    22] loss: 2.42409\n",
      "[epoch 150, batch    23] loss: 2.62927\n",
      "[epoch 150, batch    24] loss: 2.96858\n",
      "[epoch 150, batch    25] loss: 3.27718\n",
      "[epoch 150, batch    26] loss: 3.40292\n",
      "[epoch 150, batch    27] loss: 3.25090\n",
      "[epoch 150, batch    28] loss: 2.24879\n",
      "[epoch 150, batch    29] loss: 2.47334\n",
      "[epoch 150, batch    30] loss: 3.58264\n",
      "[epoch 150, batch    31] loss: 2.96857\n",
      "[epoch 150, batch    32] loss: 3.26950\n",
      "[epoch 151, batch     1] loss: 2.36765\n",
      "[epoch 151, batch     2] loss: 4.72606\n",
      "[epoch 151, batch     3] loss: 3.09332\n",
      "[epoch 151, batch     4] loss: 2.53180\n",
      "[epoch 151, batch     5] loss: 2.16288\n",
      "[epoch 151, batch     6] loss: 2.73605\n",
      "[epoch 151, batch     7] loss: 2.63208\n",
      "[epoch 151, batch     8] loss: 2.99742\n",
      "[epoch 151, batch     9] loss: 3.00180\n",
      "[epoch 151, batch    10] loss: 2.25793\n",
      "[epoch 151, batch    11] loss: 3.31012\n",
      "[epoch 151, batch    12] loss: 2.48231\n",
      "[epoch 151, batch    13] loss: 3.17107\n",
      "[epoch 151, batch    14] loss: 3.24651\n",
      "[epoch 151, batch    15] loss: 3.12774\n",
      "[epoch 151, batch    16] loss: 3.35352\n",
      "[epoch 151, batch    17] loss: 3.24439\n",
      "[epoch 151, batch    18] loss: 2.59574\n",
      "[epoch 151, batch    19] loss: 3.34068\n",
      "[epoch 151, batch    20] loss: 2.90179\n",
      "[epoch 151, batch    21] loss: 4.09251\n",
      "[epoch 151, batch    22] loss: 2.65063\n",
      "[epoch 151, batch    23] loss: 3.36831\n",
      "[epoch 151, batch    24] loss: 3.04200\n",
      "[epoch 151, batch    25] loss: 3.04775\n",
      "[epoch 151, batch    26] loss: 3.59861\n",
      "[epoch 151, batch    27] loss: 3.21785\n",
      "[epoch 151, batch    28] loss: 3.62812\n",
      "[epoch 151, batch    29] loss: 2.93325\n",
      "[epoch 151, batch    30] loss: 3.27398\n",
      "[epoch 151, batch    31] loss: 2.43595\n",
      "[epoch 151, batch    32] loss: 3.10390\n",
      "[epoch 152, batch     1] loss: 2.87217\n",
      "[epoch 152, batch     2] loss: 2.85721\n",
      "[epoch 152, batch     3] loss: 2.58502\n",
      "[epoch 152, batch     4] loss: 2.85453\n",
      "[epoch 152, batch     5] loss: 2.80664\n",
      "[epoch 152, batch     6] loss: 4.17080\n",
      "[epoch 152, batch     7] loss: 2.62832\n",
      "[epoch 152, batch     8] loss: 2.50654\n",
      "[epoch 152, batch     9] loss: 3.47175\n",
      "[epoch 152, batch    10] loss: 4.34208\n",
      "[epoch 152, batch    11] loss: 2.79651\n",
      "[epoch 152, batch    12] loss: 2.79576\n",
      "[epoch 152, batch    13] loss: 3.10423\n",
      "[epoch 152, batch    14] loss: 3.68105\n",
      "[epoch 152, batch    15] loss: 3.53224\n",
      "[epoch 152, batch    16] loss: 2.55505\n",
      "[epoch 152, batch    17] loss: 3.21899\n",
      "[epoch 152, batch    18] loss: 2.02587\n",
      "[epoch 152, batch    19] loss: 2.63526\n",
      "[epoch 152, batch    20] loss: 3.18944\n",
      "[epoch 152, batch    21] loss: 3.20637\n",
      "[epoch 152, batch    22] loss: 3.09558\n",
      "[epoch 152, batch    23] loss: 2.68921\n",
      "[epoch 152, batch    24] loss: 2.91395\n",
      "[epoch 152, batch    25] loss: 2.82152\n",
      "[epoch 152, batch    26] loss: 2.78097\n",
      "[epoch 152, batch    27] loss: 3.27387\n",
      "[epoch 152, batch    28] loss: 3.28880\n",
      "[epoch 152, batch    29] loss: 3.47219\n",
      "[epoch 152, batch    30] loss: 2.54216\n",
      "[epoch 152, batch    31] loss: 3.23795\n",
      "[epoch 152, batch    32] loss: 3.86409\n",
      "[epoch 153, batch     1] loss: 3.61499\n",
      "[epoch 153, batch     2] loss: 3.41387\n",
      "[epoch 153, batch     3] loss: 2.91841\n",
      "[epoch 153, batch     4] loss: 3.15288\n",
      "[epoch 153, batch     5] loss: 3.22048\n",
      "[epoch 153, batch     6] loss: 3.95154\n",
      "[epoch 153, batch     7] loss: 3.03059\n",
      "[epoch 153, batch     8] loss: 2.65991\n",
      "[epoch 153, batch     9] loss: 2.94326\n",
      "[epoch 153, batch    10] loss: 3.39003\n",
      "[epoch 153, batch    11] loss: 2.42594\n",
      "[epoch 153, batch    12] loss: 2.85547\n",
      "[epoch 153, batch    13] loss: 3.64414\n",
      "[epoch 153, batch    14] loss: 3.73919\n",
      "[epoch 153, batch    15] loss: 3.32101\n",
      "[epoch 153, batch    16] loss: 2.77539\n",
      "[epoch 153, batch    17] loss: 2.24253\n",
      "[epoch 153, batch    18] loss: 2.87664\n",
      "[epoch 153, batch    19] loss: 2.20130\n",
      "[epoch 153, batch    20] loss: 3.36079\n",
      "[epoch 153, batch    21] loss: 3.19405\n",
      "[epoch 153, batch    22] loss: 3.10763\n",
      "[epoch 153, batch    23] loss: 2.26715\n",
      "[epoch 153, batch    24] loss: 2.66957\n",
      "[epoch 153, batch    25] loss: 2.93104\n",
      "[epoch 153, batch    26] loss: 3.05156\n",
      "[epoch 153, batch    27] loss: 3.19700\n",
      "[epoch 153, batch    28] loss: 3.12907\n",
      "[epoch 153, batch    29] loss: 2.20998\n",
      "[epoch 153, batch    30] loss: 2.48108\n",
      "[epoch 153, batch    31] loss: 3.55436\n",
      "[epoch 153, batch    32] loss: 4.25695\n",
      "[epoch 154, batch     1] loss: 3.34018\n",
      "[epoch 154, batch     2] loss: 2.01640\n",
      "[epoch 154, batch     3] loss: 3.00466\n",
      "[epoch 154, batch     4] loss: 2.10393\n",
      "[epoch 154, batch     5] loss: 3.19561\n",
      "[epoch 154, batch     6] loss: 4.77729\n",
      "[epoch 154, batch     7] loss: 3.20489\n",
      "[epoch 154, batch     8] loss: 2.54063\n",
      "[epoch 154, batch     9] loss: 2.78302\n",
      "[epoch 154, batch    10] loss: 2.95947\n",
      "[epoch 154, batch    11] loss: 2.88385\n",
      "[epoch 154, batch    12] loss: 2.55406\n",
      "[epoch 154, batch    13] loss: 3.63691\n",
      "[epoch 154, batch    14] loss: 2.71115\n",
      "[epoch 154, batch    15] loss: 3.07291\n",
      "[epoch 154, batch    16] loss: 3.07849\n",
      "[epoch 154, batch    17] loss: 4.41732\n",
      "[epoch 154, batch    18] loss: 3.05540\n",
      "[epoch 154, batch    19] loss: 3.26453\n",
      "[epoch 154, batch    20] loss: 2.46856\n",
      "[epoch 154, batch    21] loss: 3.21606\n",
      "[epoch 154, batch    22] loss: 3.06920\n",
      "[epoch 154, batch    23] loss: 3.22852\n",
      "[epoch 154, batch    24] loss: 2.33162\n",
      "[epoch 154, batch    25] loss: 2.84572\n",
      "[epoch 154, batch    26] loss: 2.19890\n",
      "[epoch 154, batch    27] loss: 3.14360\n",
      "[epoch 154, batch    28] loss: 3.03465\n",
      "[epoch 154, batch    29] loss: 3.53355\n",
      "[epoch 154, batch    30] loss: 3.57218\n",
      "[epoch 154, batch    31] loss: 2.98027\n",
      "[epoch 154, batch    32] loss: 2.00382\n",
      "[epoch 155, batch     1] loss: 2.39090\n",
      "[epoch 155, batch     2] loss: 3.47590\n",
      "[epoch 155, batch     3] loss: 3.21179\n",
      "[epoch 155, batch     4] loss: 3.04623\n",
      "[epoch 155, batch     5] loss: 2.77103\n",
      "[epoch 155, batch     6] loss: 4.52849\n",
      "[epoch 155, batch     7] loss: 2.64155\n",
      "[epoch 155, batch     8] loss: 3.47647\n",
      "[epoch 155, batch     9] loss: 3.21686\n",
      "[epoch 155, batch    10] loss: 2.68694\n",
      "[epoch 155, batch    11] loss: 2.76550\n",
      "[epoch 155, batch    12] loss: 2.73542\n",
      "[epoch 155, batch    13] loss: 2.61771\n",
      "[epoch 155, batch    14] loss: 2.52703\n",
      "[epoch 155, batch    15] loss: 4.44345\n",
      "[epoch 155, batch    16] loss: 2.60546\n",
      "[epoch 155, batch    17] loss: 3.44798\n",
      "[epoch 155, batch    18] loss: 2.72167\n",
      "[epoch 155, batch    19] loss: 2.85446\n",
      "[epoch 155, batch    20] loss: 2.56031\n",
      "[epoch 155, batch    21] loss: 3.63325\n",
      "[epoch 155, batch    22] loss: 3.14225\n",
      "[epoch 155, batch    23] loss: 2.68545\n",
      "[epoch 155, batch    24] loss: 3.11763\n",
      "[epoch 155, batch    25] loss: 2.89043\n",
      "[epoch 155, batch    26] loss: 3.43022\n",
      "[epoch 155, batch    27] loss: 2.33552\n",
      "[epoch 155, batch    28] loss: 3.19759\n",
      "[epoch 155, batch    29] loss: 3.29124\n",
      "[epoch 155, batch    30] loss: 2.99958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 155, batch    31] loss: 3.10364\n",
      "[epoch 155, batch    32] loss: 1.91458\n",
      "[epoch 156, batch     1] loss: 2.63366\n",
      "[epoch 156, batch     2] loss: 3.53571\n",
      "[epoch 156, batch     3] loss: 3.03641\n",
      "[epoch 156, batch     4] loss: 3.10313\n",
      "[epoch 156, batch     5] loss: 2.72294\n",
      "[epoch 156, batch     6] loss: 3.21430\n",
      "[epoch 156, batch     7] loss: 3.48036\n",
      "[epoch 156, batch     8] loss: 2.97857\n",
      "[epoch 156, batch     9] loss: 3.19823\n",
      "[epoch 156, batch    10] loss: 3.70116\n",
      "[epoch 156, batch    11] loss: 1.99840\n",
      "[epoch 156, batch    12] loss: 3.10666\n",
      "[epoch 156, batch    13] loss: 3.47889\n",
      "[epoch 156, batch    14] loss: 3.29072\n",
      "[epoch 156, batch    15] loss: 3.34108\n",
      "[epoch 156, batch    16] loss: 2.54087\n",
      "[epoch 156, batch    17] loss: 2.31818\n",
      "[epoch 156, batch    18] loss: 4.93855\n",
      "[epoch 156, batch    19] loss: 3.01126\n",
      "[epoch 156, batch    20] loss: 2.74491\n",
      "[epoch 156, batch    21] loss: 2.60416\n",
      "[epoch 156, batch    22] loss: 3.41437\n",
      "[epoch 156, batch    23] loss: 3.26111\n",
      "[epoch 156, batch    24] loss: 2.69187\n",
      "[epoch 156, batch    25] loss: 3.37177\n",
      "[epoch 156, batch    26] loss: 4.00029\n",
      "[epoch 156, batch    27] loss: 3.23094\n",
      "[epoch 156, batch    28] loss: 1.92848\n",
      "[epoch 156, batch    29] loss: 2.66567\n",
      "[epoch 156, batch    30] loss: 3.09931\n",
      "[epoch 156, batch    31] loss: 2.45561\n",
      "[epoch 156, batch    32] loss: 2.04173\n",
      "[epoch 157, batch     1] loss: 2.94704\n",
      "[epoch 157, batch     2] loss: 2.67729\n",
      "[epoch 157, batch     3] loss: 2.67277\n",
      "[epoch 157, batch     4] loss: 3.67620\n",
      "[epoch 157, batch     5] loss: 3.14168\n",
      "[epoch 157, batch     6] loss: 3.22555\n",
      "[epoch 157, batch     7] loss: 2.93403\n",
      "[epoch 157, batch     8] loss: 2.79037\n",
      "[epoch 157, batch     9] loss: 4.03945\n",
      "[epoch 157, batch    10] loss: 3.72052\n",
      "[epoch 157, batch    11] loss: 2.90329\n",
      "[epoch 157, batch    12] loss: 3.24515\n",
      "[epoch 157, batch    13] loss: 2.93436\n",
      "[epoch 157, batch    14] loss: 2.94213\n",
      "[epoch 157, batch    15] loss: 2.62838\n",
      "[epoch 157, batch    16] loss: 3.98701\n",
      "[epoch 157, batch    17] loss: 3.17224\n",
      "[epoch 157, batch    18] loss: 3.03075\n",
      "[epoch 157, batch    19] loss: 3.23779\n",
      "[epoch 157, batch    20] loss: 2.98825\n",
      "[epoch 157, batch    21] loss: 2.40971\n",
      "[epoch 157, batch    22] loss: 2.32990\n",
      "[epoch 157, batch    23] loss: 3.03201\n",
      "[epoch 157, batch    24] loss: 3.41695\n",
      "[epoch 157, batch    25] loss: 2.63386\n",
      "[epoch 157, batch    26] loss: 2.95229\n",
      "[epoch 157, batch    27] loss: 2.58091\n",
      "[epoch 157, batch    28] loss: 2.29541\n",
      "[epoch 157, batch    29] loss: 2.81340\n",
      "[epoch 157, batch    30] loss: 3.83591\n",
      "[epoch 157, batch    31] loss: 2.81947\n",
      "[epoch 157, batch    32] loss: 4.37366\n",
      "[epoch 158, batch     1] loss: 3.04966\n",
      "[epoch 158, batch     2] loss: 2.67885\n",
      "[epoch 158, batch     3] loss: 2.94389\n",
      "[epoch 158, batch     4] loss: 2.58483\n",
      "[epoch 158, batch     5] loss: 3.04874\n",
      "[epoch 158, batch     6] loss: 2.22072\n",
      "[epoch 158, batch     7] loss: 3.23451\n",
      "[epoch 158, batch     8] loss: 2.76211\n",
      "[epoch 158, batch     9] loss: 4.24728\n",
      "[epoch 158, batch    10] loss: 3.47835\n",
      "[epoch 158, batch    11] loss: 4.27431\n",
      "[epoch 158, batch    12] loss: 3.32814\n",
      "[epoch 158, batch    13] loss: 2.94959\n",
      "[epoch 158, batch    14] loss: 2.64852\n",
      "[epoch 158, batch    15] loss: 2.77947\n",
      "[epoch 158, batch    16] loss: 3.10460\n",
      "[epoch 158, batch    17] loss: 3.14486\n",
      "[epoch 158, batch    18] loss: 2.42716\n",
      "[epoch 158, batch    19] loss: 2.55010\n",
      "[epoch 158, batch    20] loss: 3.70613\n",
      "[epoch 158, batch    21] loss: 2.87500\n",
      "[epoch 158, batch    22] loss: 2.30677\n",
      "[epoch 158, batch    23] loss: 3.23654\n",
      "[epoch 158, batch    24] loss: 2.75501\n",
      "[epoch 158, batch    25] loss: 2.79090\n",
      "[epoch 158, batch    26] loss: 3.31167\n",
      "[epoch 158, batch    27] loss: 3.04787\n",
      "[epoch 158, batch    28] loss: 3.05919\n",
      "[epoch 158, batch    29] loss: 3.59188\n",
      "[epoch 158, batch    30] loss: 3.38872\n",
      "[epoch 158, batch    31] loss: 2.57385\n",
      "[epoch 158, batch    32] loss: 2.58050\n",
      "[epoch 159, batch     1] loss: 3.59055\n",
      "[epoch 159, batch     2] loss: 4.46771\n",
      "[epoch 159, batch     3] loss: 2.71946\n",
      "[epoch 159, batch     4] loss: 3.41172\n",
      "[epoch 159, batch     5] loss: 2.53612\n",
      "[epoch 159, batch     6] loss: 2.42246\n",
      "[epoch 159, batch     7] loss: 2.51920\n",
      "[epoch 159, batch     8] loss: 3.57728\n",
      "[epoch 159, batch     9] loss: 2.87004\n",
      "[epoch 159, batch    10] loss: 2.79024\n",
      "[epoch 159, batch    11] loss: 3.28012\n",
      "[epoch 159, batch    12] loss: 2.71826\n",
      "[epoch 159, batch    13] loss: 2.50962\n",
      "[epoch 159, batch    14] loss: 3.12321\n",
      "[epoch 159, batch    15] loss: 3.36227\n",
      "[epoch 159, batch    16] loss: 3.14009\n",
      "[epoch 159, batch    17] loss: 2.71836\n",
      "[epoch 159, batch    18] loss: 3.10240\n",
      "[epoch 159, batch    19] loss: 3.15682\n",
      "[epoch 159, batch    20] loss: 2.85865\n",
      "[epoch 159, batch    21] loss: 3.24948\n",
      "[epoch 159, batch    22] loss: 2.97487\n",
      "[epoch 159, batch    23] loss: 3.62658\n",
      "[epoch 159, batch    24] loss: 2.56222\n",
      "[epoch 159, batch    25] loss: 3.09302\n",
      "[epoch 159, batch    26] loss: 3.07891\n",
      "[epoch 159, batch    27] loss: 3.09490\n",
      "[epoch 159, batch    28] loss: 2.55802\n",
      "[epoch 159, batch    29] loss: 2.92244\n",
      "[epoch 159, batch    30] loss: 2.91999\n",
      "[epoch 159, batch    31] loss: 3.19096\n",
      "[epoch 159, batch    32] loss: 2.96084\n",
      "[epoch 160, batch     1] loss: 2.89827\n",
      "[epoch 160, batch     2] loss: 2.90761\n",
      "[epoch 160, batch     3] loss: 3.43566\n",
      "[epoch 160, batch     4] loss: 3.35731\n",
      "[epoch 160, batch     5] loss: 3.98231\n",
      "[epoch 160, batch     6] loss: 3.72175\n",
      "[epoch 160, batch     7] loss: 2.67437\n",
      "[epoch 160, batch     8] loss: 2.37703\n",
      "[epoch 160, batch     9] loss: 2.86122\n",
      "[epoch 160, batch    10] loss: 2.49313\n",
      "[epoch 160, batch    11] loss: 3.68333\n",
      "[epoch 160, batch    12] loss: 2.70243\n",
      "[epoch 160, batch    13] loss: 2.72151\n",
      "[epoch 160, batch    14] loss: 3.34671\n",
      "[epoch 160, batch    15] loss: 3.30948\n",
      "[epoch 160, batch    16] loss: 2.91562\n",
      "[epoch 160, batch    17] loss: 2.43140\n",
      "[epoch 160, batch    18] loss: 3.42013\n",
      "[epoch 160, batch    19] loss: 2.86916\n",
      "[epoch 160, batch    20] loss: 3.27823\n",
      "[epoch 160, batch    21] loss: 3.14184\n",
      "[epoch 160, batch    22] loss: 2.77605\n",
      "[epoch 160, batch    23] loss: 2.54806\n",
      "[epoch 160, batch    24] loss: 2.44179\n",
      "[epoch 160, batch    25] loss: 3.32000\n",
      "[epoch 160, batch    26] loss: 3.37583\n",
      "[epoch 160, batch    27] loss: 2.97544\n",
      "[epoch 160, batch    28] loss: 2.96520\n",
      "[epoch 160, batch    29] loss: 3.19382\n",
      "[epoch 160, batch    30] loss: 3.82464\n",
      "[epoch 160, batch    31] loss: 2.54294\n",
      "[epoch 160, batch    32] loss: 2.38749\n",
      "[epoch 161, batch     1] loss: 2.60441\n",
      "[epoch 161, batch     2] loss: 2.93959\n",
      "[epoch 161, batch     3] loss: 2.70284\n",
      "[epoch 161, batch     4] loss: 2.68311\n",
      "[epoch 161, batch     5] loss: 2.78304\n",
      "[epoch 161, batch     6] loss: 3.99799\n",
      "[epoch 161, batch     7] loss: 2.37596\n",
      "[epoch 161, batch     8] loss: 3.26684\n",
      "[epoch 161, batch     9] loss: 2.59777\n",
      "[epoch 161, batch    10] loss: 2.92205\n",
      "[epoch 161, batch    11] loss: 3.21931\n",
      "[epoch 161, batch    12] loss: 2.98858\n",
      "[epoch 161, batch    13] loss: 2.01147\n",
      "[epoch 161, batch    14] loss: 2.58695\n",
      "[epoch 161, batch    15] loss: 3.01208\n",
      "[epoch 161, batch    16] loss: 3.04968\n",
      "[epoch 161, batch    17] loss: 3.45584\n",
      "[epoch 161, batch    18] loss: 2.76131\n",
      "[epoch 161, batch    19] loss: 3.17119\n",
      "[epoch 161, batch    20] loss: 2.39865\n",
      "[epoch 161, batch    21] loss: 3.44192\n",
      "[epoch 161, batch    22] loss: 2.93566\n",
      "[epoch 161, batch    23] loss: 2.88809\n",
      "[epoch 161, batch    24] loss: 3.80347\n",
      "[epoch 161, batch    25] loss: 3.20307\n",
      "[epoch 161, batch    26] loss: 3.02842\n",
      "[epoch 161, batch    27] loss: 2.74636\n",
      "[epoch 161, batch    28] loss: 3.73137\n",
      "[epoch 161, batch    29] loss: 3.39874\n",
      "[epoch 161, batch    30] loss: 4.01852\n",
      "[epoch 161, batch    31] loss: 3.61382\n",
      "[epoch 161, batch    32] loss: 3.45233\n",
      "[epoch 162, batch     1] loss: 3.04590\n",
      "[epoch 162, batch     2] loss: 4.07251\n",
      "[epoch 162, batch     3] loss: 3.20950\n",
      "[epoch 162, batch     4] loss: 3.12769\n",
      "[epoch 162, batch     5] loss: 2.72887\n",
      "[epoch 162, batch     6] loss: 3.75349\n",
      "[epoch 162, batch     7] loss: 2.76370\n",
      "[epoch 162, batch     8] loss: 2.58771\n",
      "[epoch 162, batch     9] loss: 3.09969\n",
      "[epoch 162, batch    10] loss: 3.07032\n",
      "[epoch 162, batch    11] loss: 3.52365\n",
      "[epoch 162, batch    12] loss: 2.82544\n",
      "[epoch 162, batch    13] loss: 3.07367\n",
      "[epoch 162, batch    14] loss: 3.11019\n",
      "[epoch 162, batch    15] loss: 2.38710\n",
      "[epoch 162, batch    16] loss: 2.43925\n",
      "[epoch 162, batch    17] loss: 2.93114\n",
      "[epoch 162, batch    18] loss: 2.71347\n",
      "[epoch 162, batch    19] loss: 2.95498\n",
      "[epoch 162, batch    20] loss: 3.86703\n",
      "[epoch 162, batch    21] loss: 3.59123\n",
      "[epoch 162, batch    22] loss: 2.55540\n",
      "[epoch 162, batch    23] loss: 3.04730\n",
      "[epoch 162, batch    24] loss: 2.85289\n",
      "[epoch 162, batch    25] loss: 2.93475\n",
      "[epoch 162, batch    26] loss: 2.90150\n",
      "[epoch 162, batch    27] loss: 3.51712\n",
      "[epoch 162, batch    28] loss: 2.46539\n",
      "[epoch 162, batch    29] loss: 3.01759\n",
      "[epoch 162, batch    30] loss: 3.12931\n",
      "[epoch 162, batch    31] loss: 2.86777\n",
      "[epoch 162, batch    32] loss: 3.64422\n",
      "[epoch 163, batch     1] loss: 2.25008\n",
      "[epoch 163, batch     2] loss: 3.08641\n",
      "[epoch 163, batch     3] loss: 3.43059\n",
      "[epoch 163, batch     4] loss: 3.26195\n",
      "[epoch 163, batch     5] loss: 2.61572\n",
      "[epoch 163, batch     6] loss: 2.91130\n",
      "[epoch 163, batch     7] loss: 3.28213\n",
      "[epoch 163, batch     8] loss: 2.96949\n",
      "[epoch 163, batch     9] loss: 1.97025\n",
      "[epoch 163, batch    10] loss: 2.78465\n",
      "[epoch 163, batch    11] loss: 2.77009\n",
      "[epoch 163, batch    12] loss: 2.67100\n",
      "[epoch 163, batch    13] loss: 3.48626\n",
      "[epoch 163, batch    14] loss: 3.01229\n",
      "[epoch 163, batch    15] loss: 3.25770\n",
      "[epoch 163, batch    16] loss: 2.18562\n",
      "[epoch 163, batch    17] loss: 2.21034\n",
      "[epoch 163, batch    18] loss: 2.94241\n",
      "[epoch 163, batch    19] loss: 3.43372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 163, batch    20] loss: 3.39295\n",
      "[epoch 163, batch    21] loss: 3.03986\n",
      "[epoch 163, batch    22] loss: 3.64687\n",
      "[epoch 163, batch    23] loss: 3.78820\n",
      "[epoch 163, batch    24] loss: 3.69213\n",
      "[epoch 163, batch    25] loss: 3.35763\n",
      "[epoch 163, batch    26] loss: 3.01100\n",
      "[epoch 163, batch    27] loss: 3.61413\n",
      "[epoch 163, batch    28] loss: 2.61764\n",
      "[epoch 163, batch    29] loss: 3.94879\n",
      "[epoch 163, batch    30] loss: 2.28845\n",
      "[epoch 163, batch    31] loss: 2.55646\n",
      "[epoch 163, batch    32] loss: 4.66397\n",
      "[epoch 164, batch     1] loss: 3.44447\n",
      "[epoch 164, batch     2] loss: 3.01842\n",
      "[epoch 164, batch     3] loss: 3.24983\n",
      "[epoch 164, batch     4] loss: 2.86462\n",
      "[epoch 164, batch     5] loss: 3.85306\n",
      "[epoch 164, batch     6] loss: 3.80791\n",
      "[epoch 164, batch     7] loss: 2.38413\n",
      "[epoch 164, batch     8] loss: 2.68655\n",
      "[epoch 164, batch     9] loss: 2.34974\n",
      "[epoch 164, batch    10] loss: 2.98443\n",
      "[epoch 164, batch    11] loss: 3.22205\n",
      "[epoch 164, batch    12] loss: 3.71507\n",
      "[epoch 164, batch    13] loss: 2.93064\n",
      "[epoch 164, batch    14] loss: 3.35328\n",
      "[epoch 164, batch    15] loss: 2.07788\n",
      "[epoch 164, batch    16] loss: 2.73675\n",
      "[epoch 164, batch    17] loss: 3.85576\n",
      "[epoch 164, batch    18] loss: 3.05513\n",
      "[epoch 164, batch    19] loss: 3.32417\n",
      "[epoch 164, batch    20] loss: 3.39137\n",
      "[epoch 164, batch    21] loss: 2.90552\n",
      "[epoch 164, batch    22] loss: 2.79534\n",
      "[epoch 164, batch    23] loss: 3.36941\n",
      "[epoch 164, batch    24] loss: 2.70574\n",
      "[epoch 164, batch    25] loss: 2.08598\n",
      "[epoch 164, batch    26] loss: 3.11665\n",
      "[epoch 164, batch    27] loss: 2.34138\n",
      "[epoch 164, batch    28] loss: 3.24057\n",
      "[epoch 164, batch    29] loss: 3.30723\n",
      "[epoch 164, batch    30] loss: 2.77006\n",
      "[epoch 164, batch    31] loss: 3.04067\n",
      "[epoch 164, batch    32] loss: 3.86982\n",
      "[epoch 165, batch     1] loss: 2.75859\n",
      "[epoch 165, batch     2] loss: 2.49723\n",
      "[epoch 165, batch     3] loss: 3.13017\n",
      "[epoch 165, batch     4] loss: 2.81028\n",
      "[epoch 165, batch     5] loss: 3.17984\n",
      "[epoch 165, batch     6] loss: 2.27935\n",
      "[epoch 165, batch     7] loss: 4.57667\n",
      "[epoch 165, batch     8] loss: 3.42127\n",
      "[epoch 165, batch     9] loss: 2.57608\n",
      "[epoch 165, batch    10] loss: 2.22865\n",
      "[epoch 165, batch    11] loss: 2.61543\n",
      "[epoch 165, batch    12] loss: 2.60671\n",
      "[epoch 165, batch    13] loss: 2.44325\n",
      "[epoch 165, batch    14] loss: 4.32590\n",
      "[epoch 165, batch    15] loss: 3.11332\n",
      "[epoch 165, batch    16] loss: 3.01692\n",
      "[epoch 165, batch    17] loss: 3.24341\n",
      "[epoch 165, batch    18] loss: 2.75860\n",
      "[epoch 165, batch    19] loss: 3.27357\n",
      "[epoch 165, batch    20] loss: 2.89722\n",
      "[epoch 165, batch    21] loss: 3.63080\n",
      "[epoch 165, batch    22] loss: 2.66058\n",
      "[epoch 165, batch    23] loss: 3.06136\n",
      "[epoch 165, batch    24] loss: 2.89728\n",
      "[epoch 165, batch    25] loss: 2.42656\n",
      "[epoch 165, batch    26] loss: 2.62212\n",
      "[epoch 165, batch    27] loss: 3.41409\n",
      "[epoch 165, batch    28] loss: 3.27402\n",
      "[epoch 165, batch    29] loss: 2.97958\n",
      "[epoch 165, batch    30] loss: 4.43942\n",
      "[epoch 165, batch    31] loss: 2.59227\n",
      "[epoch 165, batch    32] loss: 3.60940\n",
      "[epoch 166, batch     1] loss: 2.86240\n",
      "[epoch 166, batch     2] loss: 2.73260\n",
      "[epoch 166, batch     3] loss: 4.63474\n",
      "[epoch 166, batch     4] loss: 2.71738\n",
      "[epoch 166, batch     5] loss: 2.82194\n",
      "[epoch 166, batch     6] loss: 3.03602\n",
      "[epoch 166, batch     7] loss: 3.44223\n",
      "[epoch 166, batch     8] loss: 2.49776\n",
      "[epoch 166, batch     9] loss: 2.68412\n",
      "[epoch 166, batch    10] loss: 3.12996\n",
      "[epoch 166, batch    11] loss: 2.84199\n",
      "[epoch 166, batch    12] loss: 3.21417\n",
      "[epoch 166, batch    13] loss: 3.20237\n",
      "[epoch 166, batch    14] loss: 2.92641\n",
      "[epoch 166, batch    15] loss: 3.16051\n",
      "[epoch 166, batch    16] loss: 3.07961\n",
      "[epoch 166, batch    17] loss: 4.33336\n",
      "[epoch 166, batch    18] loss: 3.58203\n",
      "[epoch 166, batch    19] loss: 1.96816\n",
      "[epoch 166, batch    20] loss: 2.87044\n",
      "[epoch 166, batch    21] loss: 2.94076\n",
      "[epoch 166, batch    22] loss: 3.26835\n",
      "[epoch 166, batch    23] loss: 3.25058\n",
      "[epoch 166, batch    24] loss: 2.53701\n",
      "[epoch 166, batch    25] loss: 2.50265\n",
      "[epoch 166, batch    26] loss: 3.88860\n",
      "[epoch 166, batch    27] loss: 2.23004\n",
      "[epoch 166, batch    28] loss: 3.31291\n",
      "[epoch 166, batch    29] loss: 2.61282\n",
      "[epoch 166, batch    30] loss: 3.14106\n",
      "[epoch 166, batch    31] loss: 2.61416\n",
      "[epoch 166, batch    32] loss: 4.86214\n",
      "[epoch 167, batch     1] loss: 3.24632\n",
      "[epoch 167, batch     2] loss: 2.86153\n",
      "[epoch 167, batch     3] loss: 2.88703\n",
      "[epoch 167, batch     4] loss: 3.25082\n",
      "[epoch 167, batch     5] loss: 3.11359\n",
      "[epoch 167, batch     6] loss: 3.47002\n",
      "[epoch 167, batch     7] loss: 3.34620\n",
      "[epoch 167, batch     8] loss: 2.61055\n",
      "[epoch 167, batch     9] loss: 3.71633\n",
      "[epoch 167, batch    10] loss: 3.30713\n",
      "[epoch 167, batch    11] loss: 2.75781\n",
      "[epoch 167, batch    12] loss: 2.77653\n",
      "[epoch 167, batch    13] loss: 3.21539\n",
      "[epoch 167, batch    14] loss: 2.55029\n",
      "[epoch 167, batch    15] loss: 2.44507\n",
      "[epoch 167, batch    16] loss: 2.83560\n",
      "[epoch 167, batch    17] loss: 3.11171\n",
      "[epoch 167, batch    18] loss: 3.48640\n",
      "[epoch 167, batch    19] loss: 2.82410\n",
      "[epoch 167, batch    20] loss: 3.04289\n",
      "[epoch 167, batch    21] loss: 3.84011\n",
      "[epoch 167, batch    22] loss: 2.66189\n",
      "[epoch 167, batch    23] loss: 3.25220\n",
      "[epoch 167, batch    24] loss: 2.04716\n",
      "[epoch 167, batch    25] loss: 2.29493\n",
      "[epoch 167, batch    26] loss: 2.99309\n",
      "[epoch 167, batch    27] loss: 2.83734\n",
      "[epoch 167, batch    28] loss: 3.49610\n",
      "[epoch 167, batch    29] loss: 2.96627\n",
      "[epoch 167, batch    30] loss: 3.12542\n",
      "[epoch 167, batch    31] loss: 3.64524\n",
      "[epoch 167, batch    32] loss: 2.55103\n",
      "[epoch 168, batch     1] loss: 2.11750\n",
      "[epoch 168, batch     2] loss: 2.81442\n",
      "[epoch 168, batch     3] loss: 3.72543\n",
      "[epoch 168, batch     4] loss: 2.59005\n",
      "[epoch 168, batch     5] loss: 4.09537\n",
      "[epoch 168, batch     6] loss: 3.32166\n",
      "[epoch 168, batch     7] loss: 4.10225\n",
      "[epoch 168, batch     8] loss: 2.50965\n",
      "[epoch 168, batch     9] loss: 2.86096\n",
      "[epoch 168, batch    10] loss: 3.02125\n",
      "[epoch 168, batch    11] loss: 3.31898\n",
      "[epoch 168, batch    12] loss: 2.86283\n",
      "[epoch 168, batch    13] loss: 3.02015\n",
      "[epoch 168, batch    14] loss: 3.36766\n",
      "[epoch 168, batch    15] loss: 2.94400\n",
      "[epoch 168, batch    16] loss: 2.93340\n",
      "[epoch 168, batch    17] loss: 2.59734\n",
      "[epoch 168, batch    18] loss: 2.70187\n",
      "[epoch 168, batch    19] loss: 2.95578\n",
      "[epoch 168, batch    20] loss: 3.28797\n",
      "[epoch 168, batch    21] loss: 3.40733\n",
      "[epoch 168, batch    22] loss: 3.55763\n",
      "[epoch 168, batch    23] loss: 2.74511\n",
      "[epoch 168, batch    24] loss: 3.42830\n",
      "[epoch 168, batch    25] loss: 3.52840\n",
      "[epoch 168, batch    26] loss: 2.40728\n",
      "[epoch 168, batch    27] loss: 3.19112\n",
      "[epoch 168, batch    28] loss: 2.73327\n",
      "[epoch 168, batch    29] loss: 2.63876\n",
      "[epoch 168, batch    30] loss: 2.49537\n",
      "[epoch 168, batch    31] loss: 2.85644\n",
      "[epoch 168, batch    32] loss: 3.24763\n",
      "[epoch 169, batch     1] loss: 3.83053\n",
      "[epoch 169, batch     2] loss: 2.31806\n",
      "[epoch 169, batch     3] loss: 3.17815\n",
      "[epoch 169, batch     4] loss: 2.89324\n",
      "[epoch 169, batch     5] loss: 2.98840\n",
      "[epoch 169, batch     6] loss: 2.89377\n",
      "[epoch 169, batch     7] loss: 3.19210\n",
      "[epoch 169, batch     8] loss: 2.52845\n",
      "[epoch 169, batch     9] loss: 3.93957\n",
      "[epoch 169, batch    10] loss: 3.49503\n",
      "[epoch 169, batch    11] loss: 3.24873\n",
      "[epoch 169, batch    12] loss: 3.59759\n",
      "[epoch 169, batch    13] loss: 2.03816\n",
      "[epoch 169, batch    14] loss: 2.87708\n",
      "[epoch 169, batch    15] loss: 2.92111\n",
      "[epoch 169, batch    16] loss: 3.11659\n",
      "[epoch 169, batch    17] loss: 2.13688\n",
      "[epoch 169, batch    18] loss: 3.19231\n",
      "[epoch 169, batch    19] loss: 3.39695\n",
      "[epoch 169, batch    20] loss: 4.12151\n",
      "[epoch 169, batch    21] loss: 2.71197\n",
      "[epoch 169, batch    22] loss: 2.85700\n",
      "[epoch 169, batch    23] loss: 3.63118\n",
      "[epoch 169, batch    24] loss: 3.27281\n",
      "[epoch 169, batch    25] loss: 3.28299\n",
      "[epoch 169, batch    26] loss: 2.82267\n",
      "[epoch 169, batch    27] loss: 2.00238\n",
      "[epoch 169, batch    28] loss: 2.50084\n",
      "[epoch 169, batch    29] loss: 2.80285\n",
      "[epoch 169, batch    30] loss: 3.05277\n",
      "[epoch 169, batch    31] loss: 3.04283\n",
      "[epoch 169, batch    32] loss: 3.88757\n",
      "[epoch 170, batch     1] loss: 2.56976\n",
      "[epoch 170, batch     2] loss: 3.92301\n",
      "[epoch 170, batch     3] loss: 2.58036\n",
      "[epoch 170, batch     4] loss: 3.07570\n",
      "[epoch 170, batch     5] loss: 3.31900\n",
      "[epoch 170, batch     6] loss: 2.70218\n",
      "[epoch 170, batch     7] loss: 2.50986\n",
      "[epoch 170, batch     8] loss: 3.85835\n",
      "[epoch 170, batch     9] loss: 3.77643\n",
      "[epoch 170, batch    10] loss: 3.13965\n",
      "[epoch 170, batch    11] loss: 3.70007\n",
      "[epoch 170, batch    12] loss: 2.40895\n",
      "[epoch 170, batch    13] loss: 3.42851\n",
      "[epoch 170, batch    14] loss: 3.08103\n",
      "[epoch 170, batch    15] loss: 3.58120\n",
      "[epoch 170, batch    16] loss: 2.23222\n",
      "[epoch 170, batch    17] loss: 2.88150\n",
      "[epoch 170, batch    18] loss: 2.93160\n",
      "[epoch 170, batch    19] loss: 2.16301\n",
      "[epoch 170, batch    20] loss: 2.74641\n",
      "[epoch 170, batch    21] loss: 2.53474\n",
      "[epoch 170, batch    22] loss: 3.68150\n",
      "[epoch 170, batch    23] loss: 3.22618\n",
      "[epoch 170, batch    24] loss: 2.34266\n",
      "[epoch 170, batch    25] loss: 3.19844\n",
      "[epoch 170, batch    26] loss: 3.54816\n",
      "[epoch 170, batch    27] loss: 2.65975\n",
      "[epoch 170, batch    28] loss: 3.41067\n",
      "[epoch 170, batch    29] loss: 2.64180\n",
      "[epoch 170, batch    30] loss: 3.00438\n",
      "[epoch 170, batch    31] loss: 3.34139\n",
      "[epoch 170, batch    32] loss: 2.15540\n",
      "[epoch 171, batch     1] loss: 2.88233\n",
      "[epoch 171, batch     2] loss: 2.98516\n",
      "[epoch 171, batch     3] loss: 2.59451\n",
      "[epoch 171, batch     4] loss: 3.62110\n",
      "[epoch 171, batch     5] loss: 3.12188\n",
      "[epoch 171, batch     6] loss: 3.21234\n",
      "[epoch 171, batch     7] loss: 2.67600\n",
      "[epoch 171, batch     8] loss: 3.05918\n",
      "[epoch 171, batch     9] loss: 3.29283\n",
      "[epoch 171, batch    10] loss: 3.13584\n",
      "[epoch 171, batch    11] loss: 2.86599\n",
      "[epoch 171, batch    12] loss: 2.23453\n",
      "[epoch 171, batch    13] loss: 3.10667\n",
      "[epoch 171, batch    14] loss: 3.94245\n",
      "[epoch 171, batch    15] loss: 2.21142\n",
      "[epoch 171, batch    16] loss: 3.43669\n",
      "[epoch 171, batch    17] loss: 3.06473\n",
      "[epoch 171, batch    18] loss: 3.33695\n",
      "[epoch 171, batch    19] loss: 3.25785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 171, batch    20] loss: 3.55580\n",
      "[epoch 171, batch    21] loss: 3.03224\n",
      "[epoch 171, batch    22] loss: 2.86509\n",
      "[epoch 171, batch    23] loss: 2.58110\n",
      "[epoch 171, batch    24] loss: 3.19661\n",
      "[epoch 171, batch    25] loss: 3.27724\n",
      "[epoch 171, batch    26] loss: 2.99932\n",
      "[epoch 171, batch    27] loss: 2.56123\n",
      "[epoch 171, batch    28] loss: 2.83508\n",
      "[epoch 171, batch    29] loss: 3.22386\n",
      "[epoch 171, batch    30] loss: 2.75951\n",
      "[epoch 171, batch    31] loss: 3.15416\n",
      "[epoch 171, batch    32] loss: 2.52256\n",
      "[epoch 172, batch     1] loss: 2.90311\n",
      "[epoch 172, batch     2] loss: 3.63683\n",
      "[epoch 172, batch     3] loss: 2.40879\n",
      "[epoch 172, batch     4] loss: 3.58707\n",
      "[epoch 172, batch     5] loss: 3.13941\n",
      "[epoch 172, batch     6] loss: 3.33602\n",
      "[epoch 172, batch     7] loss: 4.00795\n",
      "[epoch 172, batch     8] loss: 3.18152\n",
      "[epoch 172, batch     9] loss: 2.83457\n",
      "[epoch 172, batch    10] loss: 2.81533\n",
      "[epoch 172, batch    11] loss: 2.22768\n",
      "[epoch 172, batch    12] loss: 3.26112\n",
      "[epoch 172, batch    13] loss: 2.45044\n",
      "[epoch 172, batch    14] loss: 2.81299\n",
      "[epoch 172, batch    15] loss: 3.30475\n",
      "[epoch 172, batch    16] loss: 2.80443\n",
      "[epoch 172, batch    17] loss: 2.97454\n",
      "[epoch 172, batch    18] loss: 3.68184\n",
      "[epoch 172, batch    19] loss: 2.36598\n",
      "[epoch 172, batch    20] loss: 3.57705\n",
      "[epoch 172, batch    21] loss: 3.48274\n",
      "[epoch 172, batch    22] loss: 3.51449\n",
      "[epoch 172, batch    23] loss: 2.87944\n",
      "[epoch 172, batch    24] loss: 3.44032\n",
      "[epoch 172, batch    25] loss: 3.22602\n",
      "[epoch 172, batch    26] loss: 2.29770\n",
      "[epoch 172, batch    27] loss: 3.65026\n",
      "[epoch 172, batch    28] loss: 1.93830\n",
      "[epoch 172, batch    29] loss: 3.22309\n",
      "[epoch 172, batch    30] loss: 2.88455\n",
      "[epoch 172, batch    31] loss: 2.10814\n",
      "[epoch 172, batch    32] loss: 2.85963\n",
      "[epoch 173, batch     1] loss: 3.60299\n",
      "[epoch 173, batch     2] loss: 2.85879\n",
      "[epoch 173, batch     3] loss: 3.47583\n",
      "[epoch 173, batch     4] loss: 4.10534\n",
      "[epoch 173, batch     5] loss: 2.34971\n",
      "[epoch 173, batch     6] loss: 2.92825\n",
      "[epoch 173, batch     7] loss: 3.84231\n",
      "[epoch 173, batch     8] loss: 2.38135\n",
      "[epoch 173, batch     9] loss: 2.37065\n",
      "[epoch 173, batch    10] loss: 3.37144\n",
      "[epoch 173, batch    11] loss: 2.87437\n",
      "[epoch 173, batch    12] loss: 3.04187\n",
      "[epoch 173, batch    13] loss: 2.11857\n",
      "[epoch 173, batch    14] loss: 3.45040\n",
      "[epoch 173, batch    15] loss: 3.27381\n",
      "[epoch 173, batch    16] loss: 3.37529\n",
      "[epoch 173, batch    17] loss: 3.82378\n",
      "[epoch 173, batch    18] loss: 2.29785\n",
      "[epoch 173, batch    19] loss: 3.12547\n",
      "[epoch 173, batch    20] loss: 2.42500\n",
      "[epoch 173, batch    21] loss: 3.16521\n",
      "[epoch 173, batch    22] loss: 2.61501\n",
      "[epoch 173, batch    23] loss: 2.32526\n",
      "[epoch 173, batch    24] loss: 3.31237\n",
      "[epoch 173, batch    25] loss: 2.95465\n",
      "[epoch 173, batch    26] loss: 2.70379\n",
      "[epoch 173, batch    27] loss: 2.85351\n",
      "[epoch 173, batch    28] loss: 3.34538\n",
      "[epoch 173, batch    29] loss: 2.97057\n",
      "[epoch 173, batch    30] loss: 3.38156\n",
      "[epoch 173, batch    31] loss: 3.38685\n",
      "[epoch 173, batch    32] loss: 3.06410\n",
      "[epoch 174, batch     1] loss: 2.70246\n",
      "[epoch 174, batch     2] loss: 3.06026\n",
      "[epoch 174, batch     3] loss: 2.27348\n",
      "[epoch 174, batch     4] loss: 2.37874\n",
      "[epoch 174, batch     5] loss: 2.98883\n",
      "[epoch 174, batch     6] loss: 2.62841\n",
      "[epoch 174, batch     7] loss: 3.00144\n",
      "[epoch 174, batch     8] loss: 3.04812\n",
      "[epoch 174, batch     9] loss: 3.17697\n",
      "[epoch 174, batch    10] loss: 3.15427\n",
      "[epoch 174, batch    11] loss: 3.21889\n",
      "[epoch 174, batch    12] loss: 2.84715\n",
      "[epoch 174, batch    13] loss: 2.82268\n",
      "[epoch 174, batch    14] loss: 3.71164\n",
      "[epoch 174, batch    15] loss: 3.43104\n",
      "[epoch 174, batch    16] loss: 3.09751\n",
      "[epoch 174, batch    17] loss: 3.59132\n",
      "[epoch 174, batch    18] loss: 2.60572\n",
      "[epoch 174, batch    19] loss: 2.84060\n",
      "[epoch 174, batch    20] loss: 2.53448\n",
      "[epoch 174, batch    21] loss: 2.65952\n",
      "[epoch 174, batch    22] loss: 2.68149\n",
      "[epoch 174, batch    23] loss: 4.05164\n",
      "[epoch 174, batch    24] loss: 3.10261\n",
      "[epoch 174, batch    25] loss: 3.16699\n",
      "[epoch 174, batch    26] loss: 3.59370\n",
      "[epoch 174, batch    27] loss: 3.13658\n",
      "[epoch 174, batch    28] loss: 2.86261\n",
      "[epoch 174, batch    29] loss: 3.82399\n",
      "[epoch 174, batch    30] loss: 2.77431\n",
      "[epoch 174, batch    31] loss: 3.45205\n",
      "[epoch 174, batch    32] loss: 2.88500\n",
      "[epoch 175, batch     1] loss: 2.80925\n",
      "[epoch 175, batch     2] loss: 3.08152\n",
      "[epoch 175, batch     3] loss: 4.01032\n",
      "[epoch 175, batch     4] loss: 2.77593\n",
      "[epoch 175, batch     5] loss: 2.61440\n",
      "[epoch 175, batch     6] loss: 3.65550\n",
      "[epoch 175, batch     7] loss: 1.90452\n",
      "[epoch 175, batch     8] loss: 3.73553\n",
      "[epoch 175, batch     9] loss: 3.26696\n",
      "[epoch 175, batch    10] loss: 2.68935\n",
      "[epoch 175, batch    11] loss: 2.86339\n",
      "[epoch 175, batch    12] loss: 2.79867\n",
      "[epoch 175, batch    13] loss: 2.85225\n",
      "[epoch 175, batch    14] loss: 4.68377\n",
      "[epoch 175, batch    15] loss: 3.31021\n",
      "[epoch 175, batch    16] loss: 2.39941\n",
      "[epoch 175, batch    17] loss: 2.83926\n",
      "[epoch 175, batch    18] loss: 3.47987\n",
      "[epoch 175, batch    19] loss: 3.13195\n",
      "[epoch 175, batch    20] loss: 2.44878\n",
      "[epoch 175, batch    21] loss: 3.59678\n",
      "[epoch 175, batch    22] loss: 3.26475\n",
      "[epoch 175, batch    23] loss: 3.68201\n",
      "[epoch 175, batch    24] loss: 2.85294\n",
      "[epoch 175, batch    25] loss: 2.55267\n",
      "[epoch 175, batch    26] loss: 3.16646\n",
      "[epoch 175, batch    27] loss: 2.39003\n",
      "[epoch 175, batch    28] loss: 2.80959\n",
      "[epoch 175, batch    29] loss: 2.57910\n",
      "[epoch 175, batch    30] loss: 3.08799\n",
      "[epoch 175, batch    31] loss: 2.41495\n",
      "[epoch 175, batch    32] loss: 3.70984\n",
      "[epoch 176, batch     1] loss: 3.41957\n",
      "[epoch 176, batch     2] loss: 3.15635\n",
      "[epoch 176, batch     3] loss: 3.12725\n",
      "[epoch 176, batch     4] loss: 3.35285\n",
      "[epoch 176, batch     5] loss: 3.44587\n",
      "[epoch 176, batch     6] loss: 3.40420\n",
      "[epoch 176, batch     7] loss: 2.71937\n",
      "[epoch 176, batch     8] loss: 2.42265\n",
      "[epoch 176, batch     9] loss: 2.11346\n",
      "[epoch 176, batch    10] loss: 2.60935\n",
      "[epoch 176, batch    11] loss: 3.49431\n",
      "[epoch 176, batch    12] loss: 3.11491\n",
      "[epoch 176, batch    13] loss: 3.01469\n",
      "[epoch 176, batch    14] loss: 2.39560\n",
      "[epoch 176, batch    15] loss: 2.39199\n",
      "[epoch 176, batch    16] loss: 2.99900\n",
      "[epoch 176, batch    17] loss: 3.82485\n",
      "[epoch 176, batch    18] loss: 4.05544\n",
      "[epoch 176, batch    19] loss: 3.00444\n",
      "[epoch 176, batch    20] loss: 2.25056\n",
      "[epoch 176, batch    21] loss: 2.85087\n",
      "[epoch 176, batch    22] loss: 2.89880\n",
      "[epoch 176, batch    23] loss: 2.73443\n",
      "[epoch 176, batch    24] loss: 3.23348\n",
      "[epoch 176, batch    25] loss: 2.80422\n",
      "[epoch 176, batch    26] loss: 3.18194\n",
      "[epoch 176, batch    27] loss: 3.22118\n",
      "[epoch 176, batch    28] loss: 3.71379\n",
      "[epoch 176, batch    29] loss: 3.97645\n",
      "[epoch 176, batch    30] loss: 2.85706\n",
      "[epoch 176, batch    31] loss: 2.96436\n",
      "[epoch 176, batch    32] loss: 1.85608\n",
      "[epoch 177, batch     1] loss: 2.54350\n",
      "[epoch 177, batch     2] loss: 2.35404\n",
      "[epoch 177, batch     3] loss: 2.97740\n",
      "[epoch 177, batch     4] loss: 3.11678\n",
      "[epoch 177, batch     5] loss: 2.74519\n",
      "[epoch 177, batch     6] loss: 2.62535\n",
      "[epoch 177, batch     7] loss: 2.91572\n",
      "[epoch 177, batch     8] loss: 3.55422\n",
      "[epoch 177, batch     9] loss: 3.20774\n",
      "[epoch 177, batch    10] loss: 2.87942\n",
      "[epoch 177, batch    11] loss: 3.25093\n",
      "[epoch 177, batch    12] loss: 3.66923\n",
      "[epoch 177, batch    13] loss: 3.94798\n",
      "[epoch 177, batch    14] loss: 3.30003\n",
      "[epoch 177, batch    15] loss: 3.00535\n",
      "[epoch 177, batch    16] loss: 2.95376\n",
      "[epoch 177, batch    17] loss: 2.75607\n",
      "[epoch 177, batch    18] loss: 3.39801\n",
      "[epoch 177, batch    19] loss: 2.35231\n",
      "[epoch 177, batch    20] loss: 2.59856\n",
      "[epoch 177, batch    21] loss: 4.37991\n",
      "[epoch 177, batch    22] loss: 3.11179\n",
      "[epoch 177, batch    23] loss: 2.88423\n",
      "[epoch 177, batch    24] loss: 3.24622\n",
      "[epoch 177, batch    25] loss: 2.67276\n",
      "[epoch 177, batch    26] loss: 3.10844\n",
      "[epoch 177, batch    27] loss: 3.44331\n",
      "[epoch 177, batch    28] loss: 2.43498\n",
      "[epoch 177, batch    29] loss: 3.33252\n",
      "[epoch 177, batch    30] loss: 3.21802\n",
      "[epoch 177, batch    31] loss: 2.60971\n",
      "[epoch 177, batch    32] loss: 2.59521\n",
      "[epoch 178, batch     1] loss: 3.52864\n",
      "[epoch 178, batch     2] loss: 3.11902\n",
      "[epoch 178, batch     3] loss: 2.86600\n",
      "[epoch 178, batch     4] loss: 2.86830\n",
      "[epoch 178, batch     5] loss: 2.91513\n",
      "[epoch 178, batch     6] loss: 3.02394\n",
      "[epoch 178, batch     7] loss: 3.35517\n",
      "[epoch 178, batch     8] loss: 2.63296\n",
      "[epoch 178, batch     9] loss: 3.07006\n",
      "[epoch 178, batch    10] loss: 2.61141\n",
      "[epoch 178, batch    11] loss: 3.38933\n",
      "[epoch 178, batch    12] loss: 3.00469\n",
      "[epoch 178, batch    13] loss: 2.87836\n",
      "[epoch 178, batch    14] loss: 2.86981\n",
      "[epoch 178, batch    15] loss: 3.11950\n",
      "[epoch 178, batch    16] loss: 3.71524\n",
      "[epoch 178, batch    17] loss: 2.67219\n",
      "[epoch 178, batch    18] loss: 2.43642\n",
      "[epoch 178, batch    19] loss: 3.12237\n",
      "[epoch 178, batch    20] loss: 4.88902\n",
      "[epoch 178, batch    21] loss: 2.28166\n",
      "[epoch 178, batch    22] loss: 2.34974\n",
      "[epoch 178, batch    23] loss: 3.42251\n",
      "[epoch 178, batch    24] loss: 3.12178\n",
      "[epoch 178, batch    25] loss: 2.10545\n",
      "[epoch 178, batch    26] loss: 2.43525\n",
      "[epoch 178, batch    27] loss: 3.06262\n",
      "[epoch 178, batch    28] loss: 3.50131\n",
      "[epoch 178, batch    29] loss: 2.64592\n",
      "[epoch 178, batch    30] loss: 3.84648\n",
      "[epoch 178, batch    31] loss: 3.97681\n",
      "[epoch 178, batch    32] loss: 2.43018\n",
      "[epoch 179, batch     1] loss: 3.05715\n",
      "[epoch 179, batch     2] loss: 2.89240\n",
      "[epoch 179, batch     3] loss: 3.21053\n",
      "[epoch 179, batch     4] loss: 3.39298\n",
      "[epoch 179, batch     5] loss: 3.32676\n",
      "[epoch 179, batch     6] loss: 3.41955\n",
      "[epoch 179, batch     7] loss: 2.79546\n",
      "[epoch 179, batch     8] loss: 3.54628\n",
      "[epoch 179, batch     9] loss: 2.88771\n",
      "[epoch 179, batch    10] loss: 3.21584\n",
      "[epoch 179, batch    11] loss: 2.74350\n",
      "[epoch 179, batch    12] loss: 3.49762\n",
      "[epoch 179, batch    13] loss: 2.66367\n",
      "[epoch 179, batch    14] loss: 2.42660\n",
      "[epoch 179, batch    15] loss: 3.13606\n",
      "[epoch 179, batch    16] loss: 3.24215\n",
      "[epoch 179, batch    17] loss: 3.72101\n",
      "[epoch 179, batch    18] loss: 3.03422\n",
      "[epoch 179, batch    19] loss: 2.62243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 179, batch    20] loss: 3.07800\n",
      "[epoch 179, batch    21] loss: 3.08607\n",
      "[epoch 179, batch    22] loss: 2.73674\n",
      "[epoch 179, batch    23] loss: 3.36824\n",
      "[epoch 179, batch    24] loss: 3.05077\n",
      "[epoch 179, batch    25] loss: 2.73680\n",
      "[epoch 179, batch    26] loss: 2.00902\n",
      "[epoch 179, batch    27] loss: 3.28746\n",
      "[epoch 179, batch    28] loss: 3.31156\n",
      "[epoch 179, batch    29] loss: 2.53216\n",
      "[epoch 179, batch    30] loss: 2.91682\n",
      "[epoch 179, batch    31] loss: 3.09782\n",
      "[epoch 179, batch    32] loss: 4.20078\n",
      "[epoch 180, batch     1] loss: 3.03031\n",
      "[epoch 180, batch     2] loss: 3.30976\n",
      "[epoch 180, batch     3] loss: 2.47718\n",
      "[epoch 180, batch     4] loss: 3.63915\n",
      "[epoch 180, batch     5] loss: 2.11171\n",
      "[epoch 180, batch     6] loss: 3.06571\n",
      "[epoch 180, batch     7] loss: 3.01227\n",
      "[epoch 180, batch     8] loss: 3.83655\n",
      "[epoch 180, batch     9] loss: 3.10901\n",
      "[epoch 180, batch    10] loss: 2.22910\n",
      "[epoch 180, batch    11] loss: 2.99608\n",
      "[epoch 180, batch    12] loss: 2.83343\n",
      "[epoch 180, batch    13] loss: 2.98573\n",
      "[epoch 180, batch    14] loss: 3.09970\n",
      "[epoch 180, batch    15] loss: 2.63404\n",
      "[epoch 180, batch    16] loss: 3.44998\n",
      "[epoch 180, batch    17] loss: 3.42026\n",
      "[epoch 180, batch    18] loss: 2.80898\n",
      "[epoch 180, batch    19] loss: 3.43365\n",
      "[epoch 180, batch    20] loss: 3.61130\n",
      "[epoch 180, batch    21] loss: 2.88882\n",
      "[epoch 180, batch    22] loss: 2.91908\n",
      "[epoch 180, batch    23] loss: 2.64832\n",
      "[epoch 180, batch    24] loss: 2.63897\n",
      "[epoch 180, batch    25] loss: 2.77590\n",
      "[epoch 180, batch    26] loss: 4.11544\n",
      "[epoch 180, batch    27] loss: 2.23730\n",
      "[epoch 180, batch    28] loss: 3.17303\n",
      "[epoch 180, batch    29] loss: 2.92316\n",
      "[epoch 180, batch    30] loss: 2.98069\n",
      "[epoch 180, batch    31] loss: 3.78151\n",
      "[epoch 180, batch    32] loss: 1.94096\n",
      "[epoch 181, batch     1] loss: 2.90043\n",
      "[epoch 181, batch     2] loss: 3.11161\n",
      "[epoch 181, batch     3] loss: 2.83658\n",
      "[epoch 181, batch     4] loss: 2.69659\n",
      "[epoch 181, batch     5] loss: 2.60140\n",
      "[epoch 181, batch     6] loss: 3.68697\n",
      "[epoch 181, batch     7] loss: 2.40084\n",
      "[epoch 181, batch     8] loss: 2.73716\n",
      "[epoch 181, batch     9] loss: 3.30880\n",
      "[epoch 181, batch    10] loss: 2.45348\n",
      "[epoch 181, batch    11] loss: 2.77159\n",
      "[epoch 181, batch    12] loss: 3.06451\n",
      "[epoch 181, batch    13] loss: 3.57818\n",
      "[epoch 181, batch    14] loss: 3.28185\n",
      "[epoch 181, batch    15] loss: 2.54153\n",
      "[epoch 181, batch    16] loss: 2.70450\n",
      "[epoch 181, batch    17] loss: 1.86881\n",
      "[epoch 181, batch    18] loss: 2.78985\n",
      "[epoch 181, batch    19] loss: 2.92362\n",
      "[epoch 181, batch    20] loss: 3.56026\n",
      "[epoch 181, batch    21] loss: 2.23201\n",
      "[epoch 181, batch    22] loss: 3.31989\n",
      "[epoch 181, batch    23] loss: 3.79754\n",
      "[epoch 181, batch    24] loss: 3.77381\n",
      "[epoch 181, batch    25] loss: 2.91868\n",
      "[epoch 181, batch    26] loss: 3.37548\n",
      "[epoch 181, batch    27] loss: 3.37167\n",
      "[epoch 181, batch    28] loss: 3.15602\n",
      "[epoch 181, batch    29] loss: 3.08066\n",
      "[epoch 181, batch    30] loss: 4.05445\n",
      "[epoch 181, batch    31] loss: 3.31284\n",
      "[epoch 181, batch    32] loss: 2.07709\n",
      "[epoch 182, batch     1] loss: 3.05535\n",
      "[epoch 182, batch     2] loss: 3.27726\n",
      "[epoch 182, batch     3] loss: 3.70137\n",
      "[epoch 182, batch     4] loss: 3.44278\n",
      "[epoch 182, batch     5] loss: 3.25638\n",
      "[epoch 182, batch     6] loss: 3.02050\n",
      "[epoch 182, batch     7] loss: 2.62977\n",
      "[epoch 182, batch     8] loss: 3.13146\n",
      "[epoch 182, batch     9] loss: 2.84632\n",
      "[epoch 182, batch    10] loss: 3.29250\n",
      "[epoch 182, batch    11] loss: 3.31050\n",
      "[epoch 182, batch    12] loss: 2.79866\n",
      "[epoch 182, batch    13] loss: 2.71897\n",
      "[epoch 182, batch    14] loss: 3.35515\n",
      "[epoch 182, batch    15] loss: 3.13287\n",
      "[epoch 182, batch    16] loss: 3.00213\n",
      "[epoch 182, batch    17] loss: 3.47003\n",
      "[epoch 182, batch    18] loss: 2.68601\n",
      "[epoch 182, batch    19] loss: 2.41971\n",
      "[epoch 182, batch    20] loss: 2.59028\n",
      "[epoch 182, batch    21] loss: 3.34856\n",
      "[epoch 182, batch    22] loss: 2.67000\n",
      "[epoch 182, batch    23] loss: 2.43986\n",
      "[epoch 182, batch    24] loss: 2.92740\n",
      "[epoch 182, batch    25] loss: 3.37722\n",
      "[epoch 182, batch    26] loss: 3.13497\n",
      "[epoch 182, batch    27] loss: 3.21417\n",
      "[epoch 182, batch    28] loss: 2.58262\n",
      "[epoch 182, batch    29] loss: 3.11397\n",
      "[epoch 182, batch    30] loss: 2.96282\n",
      "[epoch 182, batch    31] loss: 3.09849\n",
      "[epoch 182, batch    32] loss: 2.36779\n",
      "[epoch 183, batch     1] loss: 2.59517\n",
      "[epoch 183, batch     2] loss: 3.03541\n",
      "[epoch 183, batch     3] loss: 3.19048\n",
      "[epoch 183, batch     4] loss: 2.42469\n",
      "[epoch 183, batch     5] loss: 2.67558\n",
      "[epoch 183, batch     6] loss: 3.09837\n",
      "[epoch 183, batch     7] loss: 2.85481\n",
      "[epoch 183, batch     8] loss: 3.78549\n",
      "[epoch 183, batch     9] loss: 3.45986\n",
      "[epoch 183, batch    10] loss: 3.23143\n",
      "[epoch 183, batch    11] loss: 2.93688\n",
      "[epoch 183, batch    12] loss: 3.06461\n",
      "[epoch 183, batch    13] loss: 3.03970\n",
      "[epoch 183, batch    14] loss: 2.84293\n",
      "[epoch 183, batch    15] loss: 3.17548\n",
      "[epoch 183, batch    16] loss: 2.96705\n",
      "[epoch 183, batch    17] loss: 3.04595\n",
      "[epoch 183, batch    18] loss: 2.55563\n",
      "[epoch 183, batch    19] loss: 3.24025\n",
      "[epoch 183, batch    20] loss: 4.64718\n",
      "[epoch 183, batch    21] loss: 3.78123\n",
      "[epoch 183, batch    22] loss: 2.57583\n",
      "[epoch 183, batch    23] loss: 2.99688\n",
      "[epoch 183, batch    24] loss: 3.66597\n",
      "[epoch 183, batch    25] loss: 3.29732\n",
      "[epoch 183, batch    26] loss: 2.65739\n",
      "[epoch 183, batch    27] loss: 2.36926\n",
      "[epoch 183, batch    28] loss: 2.82077\n",
      "[epoch 183, batch    29] loss: 2.35128\n",
      "[epoch 183, batch    30] loss: 3.16685\n",
      "[epoch 183, batch    31] loss: 2.41002\n",
      "[epoch 183, batch    32] loss: 3.80571\n",
      "[epoch 184, batch     1] loss: 3.04900\n",
      "[epoch 184, batch     2] loss: 2.14234\n",
      "[epoch 184, batch     3] loss: 3.86761\n",
      "[epoch 184, batch     4] loss: 3.04707\n",
      "[epoch 184, batch     5] loss: 3.05792\n",
      "[epoch 184, batch     6] loss: 3.52800\n",
      "[epoch 184, batch     7] loss: 3.47286\n",
      "[epoch 184, batch     8] loss: 2.81107\n",
      "[epoch 184, batch     9] loss: 2.98588\n",
      "[epoch 184, batch    10] loss: 3.03648\n",
      "[epoch 184, batch    11] loss: 2.78938\n",
      "[epoch 184, batch    12] loss: 3.20741\n",
      "[epoch 184, batch    13] loss: 2.71584\n",
      "[epoch 184, batch    14] loss: 3.85507\n",
      "[epoch 184, batch    15] loss: 2.90353\n",
      "[epoch 184, batch    16] loss: 2.95129\n",
      "[epoch 184, batch    17] loss: 3.09559\n",
      "[epoch 184, batch    18] loss: 3.49038\n",
      "[epoch 184, batch    19] loss: 3.10492\n",
      "[epoch 184, batch    20] loss: 2.57248\n",
      "[epoch 184, batch    21] loss: 2.80504\n",
      "[epoch 184, batch    22] loss: 2.48798\n",
      "[epoch 184, batch    23] loss: 3.39752\n",
      "[epoch 184, batch    24] loss: 2.08671\n",
      "[epoch 184, batch    25] loss: 3.83171\n",
      "[epoch 184, batch    26] loss: 2.64691\n",
      "[epoch 184, batch    27] loss: 3.19892\n",
      "[epoch 184, batch    28] loss: 3.48180\n",
      "[epoch 184, batch    29] loss: 2.96842\n",
      "[epoch 184, batch    30] loss: 3.17479\n",
      "[epoch 184, batch    31] loss: 3.26232\n",
      "[epoch 184, batch    32] loss: 1.57885\n",
      "[epoch 185, batch     1] loss: 3.09706\n",
      "[epoch 185, batch     2] loss: 2.03851\n",
      "[epoch 185, batch     3] loss: 3.25679\n",
      "[epoch 185, batch     4] loss: 2.56305\n",
      "[epoch 185, batch     5] loss: 2.51090\n",
      "[epoch 185, batch     6] loss: 2.17163\n",
      "[epoch 185, batch     7] loss: 2.80223\n",
      "[epoch 185, batch     8] loss: 2.63346\n",
      "[epoch 185, batch     9] loss: 3.26242\n",
      "[epoch 185, batch    10] loss: 3.47497\n",
      "[epoch 185, batch    11] loss: 4.11319\n",
      "[epoch 185, batch    12] loss: 2.65294\n",
      "[epoch 185, batch    13] loss: 3.13739\n",
      "[epoch 185, batch    14] loss: 2.85534\n",
      "[epoch 185, batch    15] loss: 1.85098\n",
      "[epoch 185, batch    16] loss: 3.16991\n",
      "[epoch 185, batch    17] loss: 2.83557\n",
      "[epoch 185, batch    18] loss: 2.70532\n",
      "[epoch 185, batch    19] loss: 2.47845\n",
      "[epoch 185, batch    20] loss: 3.13698\n",
      "[epoch 185, batch    21] loss: 2.98241\n",
      "[epoch 185, batch    22] loss: 2.41474\n",
      "[epoch 185, batch    23] loss: 3.94394\n",
      "[epoch 185, batch    24] loss: 3.52385\n",
      "[epoch 185, batch    25] loss: 4.03832\n",
      "[epoch 185, batch    26] loss: 3.01442\n",
      "[epoch 185, batch    27] loss: 4.20277\n",
      "[epoch 185, batch    28] loss: 2.73397\n",
      "[epoch 185, batch    29] loss: 4.13978\n",
      "[epoch 185, batch    30] loss: 3.40795\n",
      "[epoch 185, batch    31] loss: 3.13452\n",
      "[epoch 185, batch    32] loss: 3.99294\n",
      "[epoch 186, batch     1] loss: 2.95355\n",
      "[epoch 186, batch     2] loss: 2.95330\n",
      "[epoch 186, batch     3] loss: 2.72740\n",
      "[epoch 186, batch     4] loss: 2.97552\n",
      "[epoch 186, batch     5] loss: 3.05763\n",
      "[epoch 186, batch     6] loss: 2.73302\n",
      "[epoch 186, batch     7] loss: 2.56855\n",
      "[epoch 186, batch     8] loss: 2.84631\n",
      "[epoch 186, batch     9] loss: 2.74562\n",
      "[epoch 186, batch    10] loss: 3.90427\n",
      "[epoch 186, batch    11] loss: 3.95169\n",
      "[epoch 186, batch    12] loss: 3.53214\n",
      "[epoch 186, batch    13] loss: 2.15770\n",
      "[epoch 186, batch    14] loss: 3.82490\n",
      "[epoch 186, batch    15] loss: 2.58844\n",
      "[epoch 186, batch    16] loss: 2.52585\n",
      "[epoch 186, batch    17] loss: 2.64312\n",
      "[epoch 186, batch    18] loss: 3.08536\n",
      "[epoch 186, batch    19] loss: 2.96257\n",
      "[epoch 186, batch    20] loss: 3.58814\n",
      "[epoch 186, batch    21] loss: 2.65852\n",
      "[epoch 186, batch    22] loss: 3.18635\n",
      "[epoch 186, batch    23] loss: 2.97242\n",
      "[epoch 186, batch    24] loss: 2.77720\n",
      "[epoch 186, batch    25] loss: 3.58531\n",
      "[epoch 186, batch    26] loss: 3.26864\n",
      "[epoch 186, batch    27] loss: 2.57514\n",
      "[epoch 186, batch    28] loss: 2.63937\n",
      "[epoch 186, batch    29] loss: 3.72586\n",
      "[epoch 186, batch    30] loss: 3.41099\n",
      "[epoch 186, batch    31] loss: 3.35168\n",
      "[epoch 186, batch    32] loss: 1.58407\n",
      "[epoch 187, batch     1] loss: 3.40399\n",
      "[epoch 187, batch     2] loss: 3.28529\n",
      "[epoch 187, batch     3] loss: 2.75640\n",
      "[epoch 187, batch     4] loss: 3.19870\n",
      "[epoch 187, batch     5] loss: 3.93296\n",
      "[epoch 187, batch     6] loss: 2.77977\n",
      "[epoch 187, batch     7] loss: 2.64759\n",
      "[epoch 187, batch     8] loss: 3.20039\n",
      "[epoch 187, batch     9] loss: 2.91597\n",
      "[epoch 187, batch    10] loss: 2.09704\n",
      "[epoch 187, batch    11] loss: 3.57252\n",
      "[epoch 187, batch    12] loss: 2.64520\n",
      "[epoch 187, batch    13] loss: 2.70216\n",
      "[epoch 187, batch    14] loss: 2.65231\n",
      "[epoch 187, batch    15] loss: 2.78145\n",
      "[epoch 187, batch    16] loss: 3.08718\n",
      "[epoch 187, batch    17] loss: 2.99904\n",
      "[epoch 187, batch    18] loss: 2.41284\n",
      "[epoch 187, batch    19] loss: 3.73246\n",
      "[epoch 187, batch    20] loss: 4.10016\n",
      "[epoch 187, batch    21] loss: 2.72744\n",
      "[epoch 187, batch    22] loss: 2.92021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 187, batch    23] loss: 3.84055\n",
      "[epoch 187, batch    24] loss: 2.56353\n",
      "[epoch 187, batch    25] loss: 2.28819\n",
      "[epoch 187, batch    26] loss: 3.72046\n",
      "[epoch 187, batch    27] loss: 2.62000\n",
      "[epoch 187, batch    28] loss: 3.19399\n",
      "[epoch 187, batch    29] loss: 3.12285\n",
      "[epoch 187, batch    30] loss: 3.44638\n",
      "[epoch 187, batch    31] loss: 2.84606\n",
      "[epoch 187, batch    32] loss: 2.97609\n",
      "[epoch 188, batch     1] loss: 3.48624\n",
      "[epoch 188, batch     2] loss: 3.14488\n",
      "[epoch 188, batch     3] loss: 3.27718\n",
      "[epoch 188, batch     4] loss: 2.52422\n",
      "[epoch 188, batch     5] loss: 3.48499\n",
      "[epoch 188, batch     6] loss: 2.54266\n",
      "[epoch 188, batch     7] loss: 3.34216\n",
      "[epoch 188, batch     8] loss: 3.24903\n",
      "[epoch 188, batch     9] loss: 3.37712\n",
      "[epoch 188, batch    10] loss: 3.65897\n",
      "[epoch 188, batch    11] loss: 1.91930\n",
      "[epoch 188, batch    12] loss: 3.22456\n",
      "[epoch 188, batch    13] loss: 2.75575\n",
      "[epoch 188, batch    14] loss: 3.27386\n",
      "[epoch 188, batch    15] loss: 2.07873\n",
      "[epoch 188, batch    16] loss: 3.48982\n",
      "[epoch 188, batch    17] loss: 2.76288\n",
      "[epoch 188, batch    18] loss: 3.59420\n",
      "[epoch 188, batch    19] loss: 2.19827\n",
      "[epoch 188, batch    20] loss: 3.19537\n",
      "[epoch 188, batch    21] loss: 3.32162\n",
      "[epoch 188, batch    22] loss: 2.76495\n",
      "[epoch 188, batch    23] loss: 2.80697\n",
      "[epoch 188, batch    24] loss: 2.90619\n",
      "[epoch 188, batch    25] loss: 3.11596\n",
      "[epoch 188, batch    26] loss: 2.77993\n",
      "[epoch 188, batch    27] loss: 3.03751\n",
      "[epoch 188, batch    28] loss: 2.90658\n",
      "[epoch 188, batch    29] loss: 3.18567\n",
      "[epoch 188, batch    30] loss: 3.10869\n",
      "[epoch 188, batch    31] loss: 2.97161\n",
      "[epoch 188, batch    32] loss: 6.40029\n",
      "[epoch 189, batch     1] loss: 2.32509\n",
      "[epoch 189, batch     2] loss: 3.28942\n",
      "[epoch 189, batch     3] loss: 2.64534\n",
      "[epoch 189, batch     4] loss: 2.64942\n",
      "[epoch 189, batch     5] loss: 3.10766\n",
      "[epoch 189, batch     6] loss: 3.18960\n",
      "[epoch 189, batch     7] loss: 3.11041\n",
      "[epoch 189, batch     8] loss: 3.23680\n",
      "[epoch 189, batch     9] loss: 2.29718\n",
      "[epoch 189, batch    10] loss: 2.69585\n",
      "[epoch 189, batch    11] loss: 3.95239\n",
      "[epoch 189, batch    12] loss: 3.34179\n",
      "[epoch 189, batch    13] loss: 2.57590\n",
      "[epoch 189, batch    14] loss: 3.29199\n",
      "[epoch 189, batch    15] loss: 3.34362\n",
      "[epoch 189, batch    16] loss: 2.47261\n",
      "[epoch 189, batch    17] loss: 3.87422\n",
      "[epoch 189, batch    18] loss: 2.62506\n",
      "[epoch 189, batch    19] loss: 2.65181\n",
      "[epoch 189, batch    20] loss: 2.78836\n",
      "[epoch 189, batch    21] loss: 2.94272\n",
      "[epoch 189, batch    22] loss: 3.66216\n",
      "[epoch 189, batch    23] loss: 3.14477\n",
      "[epoch 189, batch    24] loss: 3.25794\n",
      "[epoch 189, batch    25] loss: 3.13069\n",
      "[epoch 189, batch    26] loss: 3.04090\n",
      "[epoch 189, batch    27] loss: 3.19165\n",
      "[epoch 189, batch    28] loss: 2.98238\n",
      "[epoch 189, batch    29] loss: 3.13498\n",
      "[epoch 189, batch    30] loss: 2.74093\n",
      "[epoch 189, batch    31] loss: 3.69088\n",
      "[epoch 189, batch    32] loss: 2.85902\n",
      "[epoch 190, batch     1] loss: 3.40516\n",
      "[epoch 190, batch     2] loss: 2.71600\n",
      "[epoch 190, batch     3] loss: 3.37556\n",
      "[epoch 190, batch     4] loss: 3.90596\n",
      "[epoch 190, batch     5] loss: 2.80934\n",
      "[epoch 190, batch     6] loss: 3.00942\n",
      "[epoch 190, batch     7] loss: 3.03272\n",
      "[epoch 190, batch     8] loss: 3.73098\n",
      "[epoch 190, batch     9] loss: 3.20308\n",
      "[epoch 190, batch    10] loss: 3.75412\n",
      "[epoch 190, batch    11] loss: 3.05815\n",
      "[epoch 190, batch    12] loss: 3.05926\n",
      "[epoch 190, batch    13] loss: 2.57456\n",
      "[epoch 190, batch    14] loss: 3.54995\n",
      "[epoch 190, batch    15] loss: 3.40520\n",
      "[epoch 190, batch    16] loss: 2.10081\n",
      "[epoch 190, batch    17] loss: 2.97672\n",
      "[epoch 190, batch    18] loss: 3.22182\n",
      "[epoch 190, batch    19] loss: 2.97584\n",
      "[epoch 190, batch    20] loss: 3.07924\n",
      "[epoch 190, batch    21] loss: 3.59712\n",
      "[epoch 190, batch    22] loss: 3.58547\n",
      "[epoch 190, batch    23] loss: 2.62598\n",
      "[epoch 190, batch    24] loss: 3.18458\n",
      "[epoch 190, batch    25] loss: 2.41697\n",
      "[epoch 190, batch    26] loss: 2.43051\n",
      "[epoch 190, batch    27] loss: 2.09682\n",
      "[epoch 190, batch    28] loss: 2.75064\n",
      "[epoch 190, batch    29] loss: 3.01556\n",
      "[epoch 190, batch    30] loss: 2.38385\n",
      "[epoch 190, batch    31] loss: 3.19069\n",
      "[epoch 190, batch    32] loss: 3.32922\n",
      "[epoch 191, batch     1] loss: 2.98649\n",
      "[epoch 191, batch     2] loss: 3.61839\n",
      "[epoch 191, batch     3] loss: 2.64922\n",
      "[epoch 191, batch     4] loss: 2.44994\n",
      "[epoch 191, batch     5] loss: 2.56723\n",
      "[epoch 191, batch     6] loss: 2.96810\n",
      "[epoch 191, batch     7] loss: 3.78708\n",
      "[epoch 191, batch     8] loss: 3.23198\n",
      "[epoch 191, batch     9] loss: 2.55722\n",
      "[epoch 191, batch    10] loss: 3.33259\n",
      "[epoch 191, batch    11] loss: 2.78054\n",
      "[epoch 191, batch    12] loss: 2.97186\n",
      "[epoch 191, batch    13] loss: 2.71394\n",
      "[epoch 191, batch    14] loss: 3.09028\n",
      "[epoch 191, batch    15] loss: 2.22207\n",
      "[epoch 191, batch    16] loss: 3.01399\n",
      "[epoch 191, batch    17] loss: 3.91961\n",
      "[epoch 191, batch    18] loss: 2.86705\n",
      "[epoch 191, batch    19] loss: 3.45324\n",
      "[epoch 191, batch    20] loss: 2.16971\n",
      "[epoch 191, batch    21] loss: 3.45214\n",
      "[epoch 191, batch    22] loss: 2.78523\n",
      "[epoch 191, batch    23] loss: 3.07018\n",
      "[epoch 191, batch    24] loss: 2.92508\n",
      "[epoch 191, batch    25] loss: 2.43156\n",
      "[epoch 191, batch    26] loss: 4.03302\n",
      "[epoch 191, batch    27] loss: 2.32070\n",
      "[epoch 191, batch    28] loss: 4.19069\n",
      "[epoch 191, batch    29] loss: 3.07300\n",
      "[epoch 191, batch    30] loss: 3.15221\n",
      "[epoch 191, batch    31] loss: 2.84974\n",
      "[epoch 191, batch    32] loss: 3.36593\n",
      "[epoch 192, batch     1] loss: 2.70677\n",
      "[epoch 192, batch     2] loss: 4.06363\n",
      "[epoch 192, batch     3] loss: 3.45202\n",
      "[epoch 192, batch     4] loss: 2.81144\n",
      "[epoch 192, batch     5] loss: 2.71022\n",
      "[epoch 192, batch     6] loss: 2.72899\n",
      "[epoch 192, batch     7] loss: 3.00869\n",
      "[epoch 192, batch     8] loss: 3.25401\n",
      "[epoch 192, batch     9] loss: 3.29877\n",
      "[epoch 192, batch    10] loss: 3.37050\n",
      "[epoch 192, batch    11] loss: 3.15554\n",
      "[epoch 192, batch    12] loss: 2.44541\n",
      "[epoch 192, batch    13] loss: 2.44790\n",
      "[epoch 192, batch    14] loss: 2.57841\n",
      "[epoch 192, batch    15] loss: 3.41078\n",
      "[epoch 192, batch    16] loss: 3.85165\n",
      "[epoch 192, batch    17] loss: 2.46682\n",
      "[epoch 192, batch    18] loss: 2.91628\n",
      "[epoch 192, batch    19] loss: 2.54209\n",
      "[epoch 192, batch    20] loss: 3.02439\n",
      "[epoch 192, batch    21] loss: 3.12394\n",
      "[epoch 192, batch    22] loss: 2.92622\n",
      "[epoch 192, batch    23] loss: 3.52624\n",
      "[epoch 192, batch    24] loss: 2.97841\n",
      "[epoch 192, batch    25] loss: 2.88485\n",
      "[epoch 192, batch    26] loss: 2.95424\n",
      "[epoch 192, batch    27] loss: 2.60114\n",
      "[epoch 192, batch    28] loss: 4.33020\n",
      "[epoch 192, batch    29] loss: 2.23586\n",
      "[epoch 192, batch    30] loss: 2.96052\n",
      "[epoch 192, batch    31] loss: 3.50544\n",
      "[epoch 192, batch    32] loss: 2.52106\n",
      "[epoch 193, batch     1] loss: 2.84468\n",
      "[epoch 193, batch     2] loss: 3.17884\n",
      "[epoch 193, batch     3] loss: 3.17533\n",
      "[epoch 193, batch     4] loss: 2.99761\n",
      "[epoch 193, batch     5] loss: 2.48548\n",
      "[epoch 193, batch     6] loss: 2.49324\n",
      "[epoch 193, batch     7] loss: 3.05042\n",
      "[epoch 193, batch     8] loss: 2.99899\n",
      "[epoch 193, batch     9] loss: 2.97648\n",
      "[epoch 193, batch    10] loss: 2.50027\n",
      "[epoch 193, batch    11] loss: 3.94419\n",
      "[epoch 193, batch    12] loss: 4.32603\n",
      "[epoch 193, batch    13] loss: 2.33142\n",
      "[epoch 193, batch    14] loss: 3.18639\n",
      "[epoch 193, batch    15] loss: 3.13232\n",
      "[epoch 193, batch    16] loss: 3.43880\n",
      "[epoch 193, batch    17] loss: 2.17728\n",
      "[epoch 193, batch    18] loss: 2.90444\n",
      "[epoch 193, batch    19] loss: 4.70080\n",
      "[epoch 193, batch    20] loss: 3.34526\n",
      "[epoch 193, batch    21] loss: 3.27970\n",
      "[epoch 193, batch    22] loss: 2.50962\n",
      "[epoch 193, batch    23] loss: 2.33038\n",
      "[epoch 193, batch    24] loss: 2.99813\n",
      "[epoch 193, batch    25] loss: 2.55326\n",
      "[epoch 193, batch    26] loss: 3.29237\n",
      "[epoch 193, batch    27] loss: 3.63898\n",
      "[epoch 193, batch    28] loss: 2.94422\n",
      "[epoch 193, batch    29] loss: 2.16076\n",
      "[epoch 193, batch    30] loss: 3.34472\n",
      "[epoch 193, batch    31] loss: 3.16056\n",
      "[epoch 193, batch    32] loss: 2.49290\n",
      "[epoch 194, batch     1] loss: 3.20158\n",
      "[epoch 194, batch     2] loss: 3.32809\n",
      "[epoch 194, batch     3] loss: 3.61007\n",
      "[epoch 194, batch     4] loss: 2.98240\n",
      "[epoch 194, batch     5] loss: 2.66048\n",
      "[epoch 194, batch     6] loss: 2.77635\n",
      "[epoch 194, batch     7] loss: 2.99604\n",
      "[epoch 194, batch     8] loss: 3.16547\n",
      "[epoch 194, batch     9] loss: 3.85754\n",
      "[epoch 194, batch    10] loss: 2.58618\n",
      "[epoch 194, batch    11] loss: 3.20819\n",
      "[epoch 194, batch    12] loss: 3.75494\n",
      "[epoch 194, batch    13] loss: 3.44488\n",
      "[epoch 194, batch    14] loss: 3.03638\n",
      "[epoch 194, batch    15] loss: 2.64757\n",
      "[epoch 194, batch    16] loss: 2.22776\n",
      "[epoch 194, batch    17] loss: 2.30757\n",
      "[epoch 194, batch    18] loss: 3.63729\n",
      "[epoch 194, batch    19] loss: 3.24023\n",
      "[epoch 194, batch    20] loss: 2.67814\n",
      "[epoch 194, batch    21] loss: 3.15940\n",
      "[epoch 194, batch    22] loss: 2.52845\n",
      "[epoch 194, batch    23] loss: 2.92731\n",
      "[epoch 194, batch    24] loss: 2.39536\n",
      "[epoch 194, batch    25] loss: 2.85104\n",
      "[epoch 194, batch    26] loss: 2.70332\n",
      "[epoch 194, batch    27] loss: 3.00456\n",
      "[epoch 194, batch    28] loss: 3.21799\n",
      "[epoch 194, batch    29] loss: 3.13083\n",
      "[epoch 194, batch    30] loss: 3.70818\n",
      "[epoch 194, batch    31] loss: 2.99355\n",
      "[epoch 194, batch    32] loss: 2.20398\n",
      "[epoch 195, batch     1] loss: 3.45265\n",
      "[epoch 195, batch     2] loss: 2.13445\n",
      "[epoch 195, batch     3] loss: 3.20383\n",
      "[epoch 195, batch     4] loss: 2.94085\n",
      "[epoch 195, batch     5] loss: 3.75989\n",
      "[epoch 195, batch     6] loss: 2.96165\n",
      "[epoch 195, batch     7] loss: 3.16070\n",
      "[epoch 195, batch     8] loss: 2.84357\n",
      "[epoch 195, batch     9] loss: 2.95962\n",
      "[epoch 195, batch    10] loss: 2.68652\n",
      "[epoch 195, batch    11] loss: 3.52413\n",
      "[epoch 195, batch    12] loss: 3.88415\n",
      "[epoch 195, batch    13] loss: 3.07246\n",
      "[epoch 195, batch    14] loss: 3.39875\n",
      "[epoch 195, batch    15] loss: 2.55589\n",
      "[epoch 195, batch    16] loss: 3.45330\n",
      "[epoch 195, batch    17] loss: 3.22266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 195, batch    18] loss: 2.68979\n",
      "[epoch 195, batch    19] loss: 3.51417\n",
      "[epoch 195, batch    20] loss: 2.50899\n",
      "[epoch 195, batch    21] loss: 2.90526\n",
      "[epoch 195, batch    22] loss: 2.87896\n",
      "[epoch 195, batch    23] loss: 3.12798\n",
      "[epoch 195, batch    24] loss: 3.46179\n",
      "[epoch 195, batch    25] loss: 2.18818\n",
      "[epoch 195, batch    26] loss: 2.64675\n",
      "[epoch 195, batch    27] loss: 3.23728\n",
      "[epoch 195, batch    28] loss: 2.49498\n",
      "[epoch 195, batch    29] loss: 3.01344\n",
      "[epoch 195, batch    30] loss: 2.74670\n",
      "[epoch 195, batch    31] loss: 3.14722\n",
      "[epoch 195, batch    32] loss: 4.19686\n",
      "[epoch 196, batch     1] loss: 2.97187\n",
      "[epoch 196, batch     2] loss: 2.46918\n",
      "[epoch 196, batch     3] loss: 3.37883\n",
      "[epoch 196, batch     4] loss: 3.69281\n",
      "[epoch 196, batch     5] loss: 2.63122\n",
      "[epoch 196, batch     6] loss: 2.82251\n",
      "[epoch 196, batch     7] loss: 3.33243\n",
      "[epoch 196, batch     8] loss: 3.46960\n",
      "[epoch 196, batch     9] loss: 3.65634\n",
      "[epoch 196, batch    10] loss: 3.30099\n",
      "[epoch 196, batch    11] loss: 2.51976\n",
      "[epoch 196, batch    12] loss: 3.39466\n",
      "[epoch 196, batch    13] loss: 2.87409\n",
      "[epoch 196, batch    14] loss: 3.38458\n",
      "[epoch 196, batch    15] loss: 2.99062\n",
      "[epoch 196, batch    16] loss: 3.35178\n",
      "[epoch 196, batch    17] loss: 2.97977\n",
      "[epoch 196, batch    18] loss: 2.62471\n",
      "[epoch 196, batch    19] loss: 3.21128\n",
      "[epoch 196, batch    20] loss: 2.29220\n",
      "[epoch 196, batch    21] loss: 2.97384\n",
      "[epoch 196, batch    22] loss: 2.82517\n",
      "[epoch 196, batch    23] loss: 3.05919\n",
      "[epoch 196, batch    24] loss: 2.64456\n",
      "[epoch 196, batch    25] loss: 2.18475\n",
      "[epoch 196, batch    26] loss: 3.16382\n",
      "[epoch 196, batch    27] loss: 2.90368\n",
      "[epoch 196, batch    28] loss: 3.35060\n",
      "[epoch 196, batch    29] loss: 3.14413\n",
      "[epoch 196, batch    30] loss: 3.17471\n",
      "[epoch 196, batch    31] loss: 3.24914\n",
      "[epoch 196, batch    32] loss: 3.68312\n",
      "[epoch 197, batch     1] loss: 2.65464\n",
      "[epoch 197, batch     2] loss: 2.48448\n",
      "[epoch 197, batch     3] loss: 2.93518\n",
      "[epoch 197, batch     4] loss: 2.67288\n",
      "[epoch 197, batch     5] loss: 3.14988\n",
      "[epoch 197, batch     6] loss: 4.24981\n",
      "[epoch 197, batch     7] loss: 2.43635\n",
      "[epoch 197, batch     8] loss: 3.88611\n",
      "[epoch 197, batch     9] loss: 2.74711\n",
      "[epoch 197, batch    10] loss: 2.28793\n",
      "[epoch 197, batch    11] loss: 3.44773\n",
      "[epoch 197, batch    12] loss: 2.50627\n",
      "[epoch 197, batch    13] loss: 3.76297\n",
      "[epoch 197, batch    14] loss: 3.58499\n",
      "[epoch 197, batch    15] loss: 3.18790\n",
      "[epoch 197, batch    16] loss: 2.14654\n",
      "[epoch 197, batch    17] loss: 3.09241\n",
      "[epoch 197, batch    18] loss: 3.24747\n",
      "[epoch 197, batch    19] loss: 3.05906\n",
      "[epoch 197, batch    20] loss: 3.57074\n",
      "[epoch 197, batch    21] loss: 2.27701\n",
      "[epoch 197, batch    22] loss: 3.54122\n",
      "[epoch 197, batch    23] loss: 2.76986\n",
      "[epoch 197, batch    24] loss: 2.61105\n",
      "[epoch 197, batch    25] loss: 3.25134\n",
      "[epoch 197, batch    26] loss: 3.25443\n",
      "[epoch 197, batch    27] loss: 3.14203\n",
      "[epoch 197, batch    28] loss: 3.17030\n",
      "[epoch 197, batch    29] loss: 4.24588\n",
      "[epoch 197, batch    30] loss: 2.93260\n",
      "[epoch 197, batch    31] loss: 2.28625\n",
      "[epoch 197, batch    32] loss: 1.06593\n",
      "[epoch 198, batch     1] loss: 2.94939\n",
      "[epoch 198, batch     2] loss: 4.37513\n",
      "[epoch 198, batch     3] loss: 3.21535\n",
      "[epoch 198, batch     4] loss: 2.72097\n",
      "[epoch 198, batch     5] loss: 3.38381\n",
      "[epoch 198, batch     6] loss: 3.28217\n",
      "[epoch 198, batch     7] loss: 2.85535\n",
      "[epoch 198, batch     8] loss: 3.82679\n",
      "[epoch 198, batch     9] loss: 3.16316\n",
      "[epoch 198, batch    10] loss: 2.93883\n",
      "[epoch 198, batch    11] loss: 3.05572\n",
      "[epoch 198, batch    12] loss: 2.52246\n",
      "[epoch 198, batch    13] loss: 2.55755\n",
      "[epoch 198, batch    14] loss: 2.59351\n",
      "[epoch 198, batch    15] loss: 3.77963\n",
      "[epoch 198, batch    16] loss: 2.87656\n",
      "[epoch 198, batch    17] loss: 3.09229\n",
      "[epoch 198, batch    18] loss: 3.75421\n",
      "[epoch 198, batch    19] loss: 3.92954\n",
      "[epoch 198, batch    20] loss: 2.39894\n",
      "[epoch 198, batch    21] loss: 3.43355\n",
      "[epoch 198, batch    22] loss: 2.85929\n",
      "[epoch 198, batch    23] loss: 2.60102\n",
      "[epoch 198, batch    24] loss: 2.99875\n",
      "[epoch 198, batch    25] loss: 3.16012\n",
      "[epoch 198, batch    26] loss: 2.25717\n",
      "[epoch 198, batch    27] loss: 2.36249\n",
      "[epoch 198, batch    28] loss: 3.25210\n",
      "[epoch 198, batch    29] loss: 3.52175\n",
      "[epoch 198, batch    30] loss: 2.52581\n",
      "[epoch 198, batch    31] loss: 2.70336\n",
      "[epoch 198, batch    32] loss: 1.99134\n",
      "[epoch 199, batch     1] loss: 2.27593\n",
      "[epoch 199, batch     2] loss: 2.80194\n",
      "[epoch 199, batch     3] loss: 2.85744\n",
      "[epoch 199, batch     4] loss: 3.57527\n",
      "[epoch 199, batch     5] loss: 3.31088\n",
      "[epoch 199, batch     6] loss: 2.98443\n",
      "[epoch 199, batch     7] loss: 4.30522\n",
      "[epoch 199, batch     8] loss: 2.81602\n",
      "[epoch 199, batch     9] loss: 2.71701\n",
      "[epoch 199, batch    10] loss: 2.43306\n",
      "[epoch 199, batch    11] loss: 4.12221\n",
      "[epoch 199, batch    12] loss: 2.63248\n",
      "[epoch 199, batch    13] loss: 2.60319\n",
      "[epoch 199, batch    14] loss: 2.84179\n",
      "[epoch 199, batch    15] loss: 3.30664\n",
      "[epoch 199, batch    16] loss: 3.09604\n",
      "[epoch 199, batch    17] loss: 2.98432\n",
      "[epoch 199, batch    18] loss: 2.35264\n",
      "[epoch 199, batch    19] loss: 2.83656\n",
      "[epoch 199, batch    20] loss: 2.72602\n",
      "[epoch 199, batch    21] loss: 2.48478\n",
      "[epoch 199, batch    22] loss: 2.67613\n",
      "[epoch 199, batch    23] loss: 3.56016\n",
      "[epoch 199, batch    24] loss: 2.60651\n",
      "[epoch 199, batch    25] loss: 4.48936\n",
      "[epoch 199, batch    26] loss: 2.93117\n",
      "[epoch 199, batch    27] loss: 3.48316\n",
      "[epoch 199, batch    28] loss: 3.17620\n",
      "[epoch 199, batch    29] loss: 2.59426\n",
      "[epoch 199, batch    30] loss: 3.05397\n",
      "[epoch 199, batch    31] loss: 3.36590\n",
      "[epoch 199, batch    32] loss: 4.64732\n",
      "[epoch 200, batch     1] loss: 2.56780\n",
      "[epoch 200, batch     2] loss: 2.79885\n",
      "[epoch 200, batch     3] loss: 2.88597\n",
      "[epoch 200, batch     4] loss: 3.01935\n",
      "[epoch 200, batch     5] loss: 2.96175\n",
      "[epoch 200, batch     6] loss: 2.98241\n",
      "[epoch 200, batch     7] loss: 2.45404\n",
      "[epoch 200, batch     8] loss: 2.92526\n",
      "[epoch 200, batch     9] loss: 3.52223\n",
      "[epoch 200, batch    10] loss: 2.91207\n",
      "[epoch 200, batch    11] loss: 3.47856\n",
      "[epoch 200, batch    12] loss: 3.21396\n",
      "[epoch 200, batch    13] loss: 3.73433\n",
      "[epoch 200, batch    14] loss: 2.83309\n",
      "[epoch 200, batch    15] loss: 2.74808\n",
      "[epoch 200, batch    16] loss: 3.40176\n",
      "[epoch 200, batch    17] loss: 2.54593\n",
      "[epoch 200, batch    18] loss: 3.22885\n",
      "[epoch 200, batch    19] loss: 3.09894\n",
      "[epoch 200, batch    20] loss: 2.52625\n",
      "[epoch 200, batch    21] loss: 3.25341\n",
      "[epoch 200, batch    22] loss: 3.27042\n",
      "[epoch 200, batch    23] loss: 3.63748\n",
      "[epoch 200, batch    24] loss: 2.73940\n",
      "[epoch 200, batch    25] loss: 3.15837\n",
      "[epoch 200, batch    26] loss: 2.27390\n",
      "[epoch 200, batch    27] loss: 3.11016\n",
      "[epoch 200, batch    28] loss: 3.38824\n",
      "[epoch 200, batch    29] loss: 3.84665\n",
      "[epoch 200, batch    30] loss: 2.71548\n",
      "[epoch 200, batch    31] loss: 3.15295\n",
      "[epoch 200, batch    32] loss: 4.03199\n",
      "[epoch 201, batch     1] loss: 2.56000\n",
      "[epoch 201, batch     2] loss: 2.93818\n",
      "[epoch 201, batch     3] loss: 2.46156\n",
      "[epoch 201, batch     4] loss: 3.87535\n",
      "[epoch 201, batch     5] loss: 3.27158\n",
      "[epoch 201, batch     6] loss: 4.62199\n",
      "[epoch 201, batch     7] loss: 2.63337\n",
      "[epoch 201, batch     8] loss: 2.52085\n",
      "[epoch 201, batch     9] loss: 3.39050\n",
      "[epoch 201, batch    10] loss: 2.79060\n",
      "[epoch 201, batch    11] loss: 2.42108\n",
      "[epoch 201, batch    12] loss: 1.89200\n",
      "[epoch 201, batch    13] loss: 2.94649\n",
      "[epoch 201, batch    14] loss: 2.95702\n",
      "[epoch 201, batch    15] loss: 2.57051\n",
      "[epoch 201, batch    16] loss: 3.75787\n",
      "[epoch 201, batch    17] loss: 3.11365\n",
      "[epoch 201, batch    18] loss: 2.56247\n",
      "[epoch 201, batch    19] loss: 2.67209\n",
      "[epoch 201, batch    20] loss: 2.92201\n",
      "[epoch 201, batch    21] loss: 3.19365\n",
      "[epoch 201, batch    22] loss: 3.86690\n",
      "[epoch 201, batch    23] loss: 2.81400\n",
      "[epoch 201, batch    24] loss: 3.43005\n",
      "[epoch 201, batch    25] loss: 2.38966\n",
      "[epoch 201, batch    26] loss: 2.92079\n",
      "[epoch 201, batch    27] loss: 3.04000\n",
      "[epoch 201, batch    28] loss: 2.97711\n",
      "[epoch 201, batch    29] loss: 3.48209\n",
      "[epoch 201, batch    30] loss: 3.86370\n",
      "[epoch 201, batch    31] loss: 3.49132\n",
      "[epoch 201, batch    32] loss: 2.60511\n",
      "[epoch 202, batch     1] loss: 2.34874\n",
      "[epoch 202, batch     2] loss: 3.48202\n",
      "[epoch 202, batch     3] loss: 2.94533\n",
      "[epoch 202, batch     4] loss: 2.90694\n",
      "[epoch 202, batch     5] loss: 3.09827\n",
      "[epoch 202, batch     6] loss: 2.91228\n",
      "[epoch 202, batch     7] loss: 3.10856\n",
      "[epoch 202, batch     8] loss: 2.54844\n",
      "[epoch 202, batch     9] loss: 3.11599\n",
      "[epoch 202, batch    10] loss: 3.73399\n",
      "[epoch 202, batch    11] loss: 3.66620\n",
      "[epoch 202, batch    12] loss: 2.48178\n",
      "[epoch 202, batch    13] loss: 2.82857\n",
      "[epoch 202, batch    14] loss: 2.59071\n",
      "[epoch 202, batch    15] loss: 2.56613\n",
      "[epoch 202, batch    16] loss: 3.03278\n",
      "[epoch 202, batch    17] loss: 4.18548\n",
      "[epoch 202, batch    18] loss: 2.46690\n",
      "[epoch 202, batch    19] loss: 2.72669\n",
      "[epoch 202, batch    20] loss: 3.22092\n",
      "[epoch 202, batch    21] loss: 2.70972\n",
      "[epoch 202, batch    22] loss: 3.45499\n",
      "[epoch 202, batch    23] loss: 3.79688\n",
      "[epoch 202, batch    24] loss: 2.78869\n",
      "[epoch 202, batch    25] loss: 2.90390\n",
      "[epoch 202, batch    26] loss: 3.45909\n",
      "[epoch 202, batch    27] loss: 3.45693\n",
      "[epoch 202, batch    28] loss: 2.64036\n",
      "[epoch 202, batch    29] loss: 2.62050\n",
      "[epoch 202, batch    30] loss: 2.88454\n",
      "[epoch 202, batch    31] loss: 3.14805\n",
      "[epoch 202, batch    32] loss: 2.80631\n",
      "[epoch 203, batch     1] loss: 2.60774\n",
      "[epoch 203, batch     2] loss: 3.07727\n",
      "[epoch 203, batch     3] loss: 2.52706\n",
      "[epoch 203, batch     4] loss: 2.79638\n",
      "[epoch 203, batch     5] loss: 2.50623\n",
      "[epoch 203, batch     6] loss: 3.02324\n",
      "[epoch 203, batch     7] loss: 2.78560\n",
      "[epoch 203, batch     8] loss: 2.78329\n",
      "[epoch 203, batch     9] loss: 3.47714\n",
      "[epoch 203, batch    10] loss: 3.40871\n",
      "[epoch 203, batch    11] loss: 2.46120\n",
      "[epoch 203, batch    12] loss: 3.63472\n",
      "[epoch 203, batch    13] loss: 3.12123\n",
      "[epoch 203, batch    14] loss: 3.20765\n",
      "[epoch 203, batch    15] loss: 2.74287\n",
      "[epoch 203, batch    16] loss: 3.57579\n",
      "[epoch 203, batch    17] loss: 2.73129\n",
      "[epoch 203, batch    18] loss: 3.01211\n",
      "[epoch 203, batch    19] loss: 4.02276\n",
      "[epoch 203, batch    20] loss: 2.48897\n",
      "[epoch 203, batch    21] loss: 3.43099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 203, batch    22] loss: 2.91412\n",
      "[epoch 203, batch    23] loss: 3.21989\n",
      "[epoch 203, batch    24] loss: 2.56551\n",
      "[epoch 203, batch    25] loss: 3.52281\n",
      "[epoch 203, batch    26] loss: 3.10007\n",
      "[epoch 203, batch    27] loss: 2.45168\n",
      "[epoch 203, batch    28] loss: 2.84179\n",
      "[epoch 203, batch    29] loss: 3.18123\n",
      "[epoch 203, batch    30] loss: 4.04291\n",
      "[epoch 203, batch    31] loss: 2.48953\n",
      "[epoch 203, batch    32] loss: 4.60840\n",
      "[epoch 204, batch     1] loss: 2.50620\n",
      "[epoch 204, batch     2] loss: 2.51924\n",
      "[epoch 204, batch     3] loss: 3.23695\n",
      "[epoch 204, batch     4] loss: 2.73642\n",
      "[epoch 204, batch     5] loss: 3.29291\n",
      "[epoch 204, batch     6] loss: 2.53228\n",
      "[epoch 204, batch     7] loss: 2.85635\n",
      "[epoch 204, batch     8] loss: 3.33733\n",
      "[epoch 204, batch     9] loss: 2.73654\n",
      "[epoch 204, batch    10] loss: 3.54566\n",
      "[epoch 204, batch    11] loss: 2.93227\n",
      "[epoch 204, batch    12] loss: 2.37136\n",
      "[epoch 204, batch    13] loss: 2.88371\n",
      "[epoch 204, batch    14] loss: 3.29324\n",
      "[epoch 204, batch    15] loss: 2.64482\n",
      "[epoch 204, batch    16] loss: 2.41159\n",
      "[epoch 204, batch    17] loss: 3.45016\n",
      "[epoch 204, batch    18] loss: 3.02381\n",
      "[epoch 204, batch    19] loss: 2.42809\n",
      "[epoch 204, batch    20] loss: 3.80740\n",
      "[epoch 204, batch    21] loss: 3.47264\n",
      "[epoch 204, batch    22] loss: 3.83743\n",
      "[epoch 204, batch    23] loss: 3.00880\n",
      "[epoch 204, batch    24] loss: 3.52454\n",
      "[epoch 204, batch    25] loss: 2.66440\n",
      "[epoch 204, batch    26] loss: 2.92948\n",
      "[epoch 204, batch    27] loss: 3.03933\n",
      "[epoch 204, batch    28] loss: 3.02027\n",
      "[epoch 204, batch    29] loss: 4.37359\n",
      "[epoch 204, batch    30] loss: 2.74431\n",
      "[epoch 204, batch    31] loss: 2.60609\n",
      "[epoch 204, batch    32] loss: 4.00400\n",
      "[epoch 205, batch     1] loss: 2.35734\n",
      "[epoch 205, batch     2] loss: 3.32642\n",
      "[epoch 205, batch     3] loss: 3.46735\n",
      "[epoch 205, batch     4] loss: 2.37401\n",
      "[epoch 205, batch     5] loss: 3.25995\n",
      "[epoch 205, batch     6] loss: 3.36644\n",
      "[epoch 205, batch     7] loss: 2.56481\n",
      "[epoch 205, batch     8] loss: 3.58916\n",
      "[epoch 205, batch     9] loss: 3.66513\n",
      "[epoch 205, batch    10] loss: 2.89275\n",
      "[epoch 205, batch    11] loss: 3.04845\n",
      "[epoch 205, batch    12] loss: 3.44928\n",
      "[epoch 205, batch    13] loss: 2.38344\n",
      "[epoch 205, batch    14] loss: 2.63795\n",
      "[epoch 205, batch    15] loss: 3.33492\n",
      "[epoch 205, batch    16] loss: 3.19379\n",
      "[epoch 205, batch    17] loss: 2.77088\n",
      "[epoch 205, batch    18] loss: 3.18056\n",
      "[epoch 205, batch    19] loss: 2.35958\n",
      "[epoch 205, batch    20] loss: 3.18587\n",
      "[epoch 205, batch    21] loss: 3.07659\n",
      "[epoch 205, batch    22] loss: 2.97488\n",
      "[epoch 205, batch    23] loss: 2.62829\n",
      "[epoch 205, batch    24] loss: 2.62860\n",
      "[epoch 205, batch    25] loss: 3.43710\n",
      "[epoch 205, batch    26] loss: 4.07664\n",
      "[epoch 205, batch    27] loss: 3.79791\n",
      "[epoch 205, batch    28] loss: 3.24815\n",
      "[epoch 205, batch    29] loss: 2.21781\n",
      "[epoch 205, batch    30] loss: 3.41574\n",
      "[epoch 205, batch    31] loss: 2.63952\n",
      "[epoch 205, batch    32] loss: 2.60811\n",
      "[epoch 206, batch     1] loss: 2.94039\n",
      "[epoch 206, batch     2] loss: 3.36682\n",
      "[epoch 206, batch     3] loss: 2.70701\n",
      "[epoch 206, batch     4] loss: 3.02477\n",
      "[epoch 206, batch     5] loss: 3.38172\n",
      "[epoch 206, batch     6] loss: 2.55220\n",
      "[epoch 206, batch     7] loss: 3.30788\n",
      "[epoch 206, batch     8] loss: 3.49527\n",
      "[epoch 206, batch     9] loss: 3.10522\n",
      "[epoch 206, batch    10] loss: 2.09282\n",
      "[epoch 206, batch    11] loss: 2.89243\n",
      "[epoch 206, batch    12] loss: 3.62557\n",
      "[epoch 206, batch    13] loss: 2.31834\n",
      "[epoch 206, batch    14] loss: 3.29035\n",
      "[epoch 206, batch    15] loss: 2.68325\n",
      "[epoch 206, batch    16] loss: 3.12870\n",
      "[epoch 206, batch    17] loss: 3.40137\n",
      "[epoch 206, batch    18] loss: 2.73632\n",
      "[epoch 206, batch    19] loss: 3.56707\n",
      "[epoch 206, batch    20] loss: 2.91966\n",
      "[epoch 206, batch    21] loss: 2.87886\n",
      "[epoch 206, batch    22] loss: 3.41888\n",
      "[epoch 206, batch    23] loss: 3.50300\n",
      "[epoch 206, batch    24] loss: 3.18218\n",
      "[epoch 206, batch    25] loss: 2.45690\n",
      "[epoch 206, batch    26] loss: 2.57595\n",
      "[epoch 206, batch    27] loss: 3.62614\n",
      "[epoch 206, batch    28] loss: 2.70037\n",
      "[epoch 206, batch    29] loss: 3.77578\n",
      "[epoch 206, batch    30] loss: 2.66427\n",
      "[epoch 206, batch    31] loss: 3.28804\n",
      "[epoch 206, batch    32] loss: 2.34872\n",
      "[epoch 207, batch     1] loss: 2.98089\n",
      "[epoch 207, batch     2] loss: 2.13954\n",
      "[epoch 207, batch     3] loss: 2.73119\n",
      "[epoch 207, batch     4] loss: 3.17584\n",
      "[epoch 207, batch     5] loss: 3.87561\n",
      "[epoch 207, batch     6] loss: 2.77377\n",
      "[epoch 207, batch     7] loss: 2.88979\n",
      "[epoch 207, batch     8] loss: 3.25097\n",
      "[epoch 207, batch     9] loss: 2.58339\n",
      "[epoch 207, batch    10] loss: 3.55900\n",
      "[epoch 207, batch    11] loss: 2.84596\n",
      "[epoch 207, batch    12] loss: 3.56125\n",
      "[epoch 207, batch    13] loss: 2.94044\n",
      "[epoch 207, batch    14] loss: 2.53809\n",
      "[epoch 207, batch    15] loss: 2.85781\n",
      "[epoch 207, batch    16] loss: 2.84786\n",
      "[epoch 207, batch    17] loss: 2.96236\n",
      "[epoch 207, batch    18] loss: 2.70859\n",
      "[epoch 207, batch    19] loss: 3.34161\n",
      "[epoch 207, batch    20] loss: 2.93519\n",
      "[epoch 207, batch    21] loss: 2.94503\n",
      "[epoch 207, batch    22] loss: 3.83530\n",
      "[epoch 207, batch    23] loss: 3.54991\n",
      "[epoch 207, batch    24] loss: 2.30344\n",
      "[epoch 207, batch    25] loss: 2.18564\n",
      "[epoch 207, batch    26] loss: 3.63597\n",
      "[epoch 207, batch    27] loss: 3.77605\n",
      "[epoch 207, batch    28] loss: 2.98713\n",
      "[epoch 207, batch    29] loss: 3.20752\n",
      "[epoch 207, batch    30] loss: 2.72772\n",
      "[epoch 207, batch    31] loss: 3.45380\n",
      "[epoch 207, batch    32] loss: 2.50317\n",
      "[epoch 208, batch     1] loss: 3.35469\n",
      "[epoch 208, batch     2] loss: 3.05294\n",
      "[epoch 208, batch     3] loss: 3.36596\n",
      "[epoch 208, batch     4] loss: 2.91738\n",
      "[epoch 208, batch     5] loss: 2.98473\n",
      "[epoch 208, batch     6] loss: 2.43288\n",
      "[epoch 208, batch     7] loss: 2.76223\n",
      "[epoch 208, batch     8] loss: 2.14534\n",
      "[epoch 208, batch     9] loss: 2.88539\n",
      "[epoch 208, batch    10] loss: 2.47940\n",
      "[epoch 208, batch    11] loss: 2.77895\n",
      "[epoch 208, batch    12] loss: 4.38309\n",
      "[epoch 208, batch    13] loss: 3.40237\n",
      "[epoch 208, batch    14] loss: 2.99607\n",
      "[epoch 208, batch    15] loss: 3.32444\n",
      "[epoch 208, batch    16] loss: 3.25561\n",
      "[epoch 208, batch    17] loss: 3.07570\n",
      "[epoch 208, batch    18] loss: 3.25951\n",
      "[epoch 208, batch    19] loss: 3.41830\n",
      "[epoch 208, batch    20] loss: 2.54782\n",
      "[epoch 208, batch    21] loss: 2.60243\n",
      "[epoch 208, batch    22] loss: 2.86689\n",
      "[epoch 208, batch    23] loss: 3.12323\n",
      "[epoch 208, batch    24] loss: 3.37562\n",
      "[epoch 208, batch    25] loss: 2.56541\n",
      "[epoch 208, batch    26] loss: 3.03008\n",
      "[epoch 208, batch    27] loss: 2.58069\n",
      "[epoch 208, batch    28] loss: 3.96970\n",
      "[epoch 208, batch    29] loss: 2.89863\n",
      "[epoch 208, batch    30] loss: 2.84519\n",
      "[epoch 208, batch    31] loss: 2.82319\n",
      "[epoch 208, batch    32] loss: 3.92904\n",
      "[epoch 209, batch     1] loss: 3.13399\n",
      "[epoch 209, batch     2] loss: 2.80725\n",
      "[epoch 209, batch     3] loss: 2.97901\n",
      "[epoch 209, batch     4] loss: 3.56117\n",
      "[epoch 209, batch     5] loss: 3.40652\n",
      "[epoch 209, batch     6] loss: 3.01825\n",
      "[epoch 209, batch     7] loss: 3.52716\n",
      "[epoch 209, batch     8] loss: 3.50648\n",
      "[epoch 209, batch     9] loss: 2.16878\n",
      "[epoch 209, batch    10] loss: 3.33570\n",
      "[epoch 209, batch    11] loss: 3.20894\n",
      "[epoch 209, batch    12] loss: 2.71588\n",
      "[epoch 209, batch    13] loss: 2.87779\n",
      "[epoch 209, batch    14] loss: 2.77662\n",
      "[epoch 209, batch    15] loss: 2.59279\n",
      "[epoch 209, batch    16] loss: 2.77701\n",
      "[epoch 209, batch    17] loss: 3.78673\n",
      "[epoch 209, batch    18] loss: 3.15468\n",
      "[epoch 209, batch    19] loss: 4.04193\n",
      "[epoch 209, batch    20] loss: 2.97542\n",
      "[epoch 209, batch    21] loss: 3.07089\n",
      "[epoch 209, batch    22] loss: 2.43256\n",
      "[epoch 209, batch    23] loss: 3.35612\n",
      "[epoch 209, batch    24] loss: 2.70211\n",
      "[epoch 209, batch    25] loss: 2.51836\n",
      "[epoch 209, batch    26] loss: 2.71233\n",
      "[epoch 209, batch    27] loss: 3.16167\n",
      "[epoch 209, batch    28] loss: 2.58717\n",
      "[epoch 209, batch    29] loss: 3.40836\n",
      "[epoch 209, batch    30] loss: 3.10505\n",
      "[epoch 209, batch    31] loss: 2.83786\n",
      "[epoch 209, batch    32] loss: 2.91580\n",
      "[epoch 210, batch     1] loss: 3.36868\n",
      "[epoch 210, batch     2] loss: 2.05381\n",
      "[epoch 210, batch     3] loss: 3.27426\n",
      "[epoch 210, batch     4] loss: 4.21095\n",
      "[epoch 210, batch     5] loss: 3.07976\n",
      "[epoch 210, batch     6] loss: 4.69668\n",
      "[epoch 210, batch     7] loss: 2.69665\n",
      "[epoch 210, batch     8] loss: 3.04798\n",
      "[epoch 210, batch     9] loss: 3.08347\n",
      "[epoch 210, batch    10] loss: 3.64611\n",
      "[epoch 210, batch    11] loss: 2.49034\n",
      "[epoch 210, batch    12] loss: 3.28272\n",
      "[epoch 210, batch    13] loss: 2.57812\n",
      "[epoch 210, batch    14] loss: 2.14432\n",
      "[epoch 210, batch    15] loss: 2.98358\n",
      "[epoch 210, batch    16] loss: 3.45236\n",
      "[epoch 210, batch    17] loss: 3.53734\n",
      "[epoch 210, batch    18] loss: 2.67548\n",
      "[epoch 210, batch    19] loss: 3.06844\n",
      "[epoch 210, batch    20] loss: 3.31127\n",
      "[epoch 210, batch    21] loss: 2.68928\n",
      "[epoch 210, batch    22] loss: 3.13116\n",
      "[epoch 210, batch    23] loss: 2.53451\n",
      "[epoch 210, batch    24] loss: 3.03668\n",
      "[epoch 210, batch    25] loss: 2.99792\n",
      "[epoch 210, batch    26] loss: 3.31740\n",
      "[epoch 210, batch    27] loss: 2.77537\n",
      "[epoch 210, batch    28] loss: 2.75810\n",
      "[epoch 210, batch    29] loss: 3.07052\n",
      "[epoch 210, batch    30] loss: 2.98357\n",
      "[epoch 210, batch    31] loss: 2.17792\n",
      "[epoch 210, batch    32] loss: 2.80204\n",
      "[epoch 211, batch     1] loss: 3.19390\n",
      "[epoch 211, batch     2] loss: 2.98018\n",
      "[epoch 211, batch     3] loss: 3.53722\n",
      "[epoch 211, batch     4] loss: 2.70913\n",
      "[epoch 211, batch     5] loss: 3.02625\n",
      "[epoch 211, batch     6] loss: 2.96236\n",
      "[epoch 211, batch     7] loss: 3.55924\n",
      "[epoch 211, batch     8] loss: 3.57002\n",
      "[epoch 211, batch     9] loss: 2.68991\n",
      "[epoch 211, batch    10] loss: 2.56573\n",
      "[epoch 211, batch    11] loss: 2.80325\n",
      "[epoch 211, batch    12] loss: 2.01254\n",
      "[epoch 211, batch    13] loss: 2.81541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 211, batch    14] loss: 4.35192\n",
      "[epoch 211, batch    15] loss: 2.60176\n",
      "[epoch 211, batch    16] loss: 3.39450\n",
      "[epoch 211, batch    17] loss: 3.01174\n",
      "[epoch 211, batch    18] loss: 2.64853\n",
      "[epoch 211, batch    19] loss: 3.61502\n",
      "[epoch 211, batch    20] loss: 3.94754\n",
      "[epoch 211, batch    21] loss: 2.88951\n",
      "[epoch 211, batch    22] loss: 2.67590\n",
      "[epoch 211, batch    23] loss: 2.83968\n",
      "[epoch 211, batch    24] loss: 2.24452\n",
      "[epoch 211, batch    25] loss: 2.78637\n",
      "[epoch 211, batch    26] loss: 2.85115\n",
      "[epoch 211, batch    27] loss: 2.73705\n",
      "[epoch 211, batch    28] loss: 2.26434\n",
      "[epoch 211, batch    29] loss: 4.00768\n",
      "[epoch 211, batch    30] loss: 3.38145\n",
      "[epoch 211, batch    31] loss: 3.62477\n",
      "[epoch 211, batch    32] loss: 2.45405\n",
      "[epoch 212, batch     1] loss: 2.67168\n",
      "[epoch 212, batch     2] loss: 4.32105\n",
      "[epoch 212, batch     3] loss: 2.99132\n",
      "[epoch 212, batch     4] loss: 2.28043\n",
      "[epoch 212, batch     5] loss: 2.69367\n",
      "[epoch 212, batch     6] loss: 3.20311\n",
      "[epoch 212, batch     7] loss: 2.72089\n",
      "[epoch 212, batch     8] loss: 3.51148\n",
      "[epoch 212, batch     9] loss: 2.97204\n",
      "[epoch 212, batch    10] loss: 2.98336\n",
      "[epoch 212, batch    11] loss: 2.71489\n",
      "[epoch 212, batch    12] loss: 3.27622\n",
      "[epoch 212, batch    13] loss: 2.65631\n",
      "[epoch 212, batch    14] loss: 2.34620\n",
      "[epoch 212, batch    15] loss: 2.65504\n",
      "[epoch 212, batch    16] loss: 3.56720\n",
      "[epoch 212, batch    17] loss: 2.30618\n",
      "[epoch 212, batch    18] loss: 2.41392\n",
      "[epoch 212, batch    19] loss: 3.22673\n",
      "[epoch 212, batch    20] loss: 3.30826\n",
      "[epoch 212, batch    21] loss: 2.92605\n",
      "[epoch 212, batch    22] loss: 2.83553\n",
      "[epoch 212, batch    23] loss: 2.93507\n",
      "[epoch 212, batch    24] loss: 3.21225\n",
      "[epoch 212, batch    25] loss: 3.76805\n",
      "[epoch 212, batch    26] loss: 4.09755\n",
      "[epoch 212, batch    27] loss: 3.04450\n",
      "[epoch 212, batch    28] loss: 3.20490\n",
      "[epoch 212, batch    29] loss: 2.74741\n",
      "[epoch 212, batch    30] loss: 2.84960\n",
      "[epoch 212, batch    31] loss: 3.03056\n",
      "[epoch 212, batch    32] loss: 3.73686\n",
      "[epoch 213, batch     1] loss: 4.30377\n",
      "[epoch 213, batch     2] loss: 3.45782\n",
      "[epoch 213, batch     3] loss: 3.06571\n",
      "[epoch 213, batch     4] loss: 3.33510\n",
      "[epoch 213, batch     5] loss: 3.06568\n",
      "[epoch 213, batch     6] loss: 2.88446\n",
      "[epoch 213, batch     7] loss: 3.07726\n",
      "[epoch 213, batch     8] loss: 2.32116\n",
      "[epoch 213, batch     9] loss: 3.46469\n",
      "[epoch 213, batch    10] loss: 2.49283\n",
      "[epoch 213, batch    11] loss: 3.40520\n",
      "[epoch 213, batch    12] loss: 3.23646\n",
      "[epoch 213, batch    13] loss: 2.82985\n",
      "[epoch 213, batch    14] loss: 2.80026\n",
      "[epoch 213, batch    15] loss: 3.01741\n",
      "[epoch 213, batch    16] loss: 2.86590\n",
      "[epoch 213, batch    17] loss: 2.97036\n",
      "[epoch 213, batch    18] loss: 2.25477\n",
      "[epoch 213, batch    19] loss: 2.59655\n",
      "[epoch 213, batch    20] loss: 3.63975\n",
      "[epoch 213, batch    21] loss: 2.67740\n",
      "[epoch 213, batch    22] loss: 3.56815\n",
      "[epoch 213, batch    23] loss: 3.30557\n",
      "[epoch 213, batch    24] loss: 3.72269\n",
      "[epoch 213, batch    25] loss: 3.22851\n",
      "[epoch 213, batch    26] loss: 2.84837\n",
      "[epoch 213, batch    27] loss: 3.12377\n",
      "[epoch 213, batch    28] loss: 3.25157\n",
      "[epoch 213, batch    29] loss: 2.49215\n",
      "[epoch 213, batch    30] loss: 2.58466\n",
      "[epoch 213, batch    31] loss: 2.18742\n",
      "[epoch 213, batch    32] loss: 4.48143\n",
      "[epoch 214, batch     1] loss: 2.96748\n",
      "[epoch 214, batch     2] loss: 3.75035\n",
      "[epoch 214, batch     3] loss: 2.68322\n",
      "[epoch 214, batch     4] loss: 2.96488\n",
      "[epoch 214, batch     5] loss: 2.71832\n",
      "[epoch 214, batch     6] loss: 3.08280\n",
      "[epoch 214, batch     7] loss: 2.53776\n",
      "[epoch 214, batch     8] loss: 2.78087\n",
      "[epoch 214, batch     9] loss: 4.41118\n",
      "[epoch 214, batch    10] loss: 2.42169\n",
      "[epoch 214, batch    11] loss: 2.83166\n",
      "[epoch 214, batch    12] loss: 3.15698\n",
      "[epoch 214, batch    13] loss: 3.89594\n",
      "[epoch 214, batch    14] loss: 2.42435\n",
      "[epoch 214, batch    15] loss: 2.88664\n",
      "[epoch 214, batch    16] loss: 3.09833\n",
      "[epoch 214, batch    17] loss: 3.03474\n",
      "[epoch 214, batch    18] loss: 2.56082\n",
      "[epoch 214, batch    19] loss: 2.82057\n",
      "[epoch 214, batch    20] loss: 3.04106\n",
      "[epoch 214, batch    21] loss: 2.85815\n",
      "[epoch 214, batch    22] loss: 2.98290\n",
      "[epoch 214, batch    23] loss: 3.18005\n",
      "[epoch 214, batch    24] loss: 2.92565\n",
      "[epoch 214, batch    25] loss: 2.78638\n",
      "[epoch 214, batch    26] loss: 2.54462\n",
      "[epoch 214, batch    27] loss: 3.95546\n",
      "[epoch 214, batch    28] loss: 3.41279\n",
      "[epoch 214, batch    29] loss: 2.99479\n",
      "[epoch 214, batch    30] loss: 2.91983\n",
      "[epoch 214, batch    31] loss: 3.07156\n",
      "[epoch 214, batch    32] loss: 4.48828\n",
      "[epoch 215, batch     1] loss: 2.57001\n",
      "[epoch 215, batch     2] loss: 2.44420\n",
      "[epoch 215, batch     3] loss: 3.56068\n",
      "[epoch 215, batch     4] loss: 2.82099\n",
      "[epoch 215, batch     5] loss: 2.81025\n",
      "[epoch 215, batch     6] loss: 3.40755\n",
      "[epoch 215, batch     7] loss: 2.69572\n",
      "[epoch 215, batch     8] loss: 3.10601\n",
      "[epoch 215, batch     9] loss: 2.72982\n",
      "[epoch 215, batch    10] loss: 2.99856\n",
      "[epoch 215, batch    11] loss: 3.77095\n",
      "[epoch 215, batch    12] loss: 2.63262\n",
      "[epoch 215, batch    13] loss: 3.06557\n",
      "[epoch 215, batch    14] loss: 3.27912\n",
      "[epoch 215, batch    15] loss: 2.08176\n",
      "[epoch 215, batch    16] loss: 3.71985\n",
      "[epoch 215, batch    17] loss: 4.12511\n",
      "[epoch 215, batch    18] loss: 3.27589\n",
      "[epoch 215, batch    19] loss: 3.74961\n",
      "[epoch 215, batch    20] loss: 2.39863\n",
      "[epoch 215, batch    21] loss: 2.77165\n",
      "[epoch 215, batch    22] loss: 2.94903\n",
      "[epoch 215, batch    23] loss: 2.54172\n",
      "[epoch 215, batch    24] loss: 3.73624\n",
      "[epoch 215, batch    25] loss: 2.42489\n",
      "[epoch 215, batch    26] loss: 3.48746\n",
      "[epoch 215, batch    27] loss: 2.94479\n",
      "[epoch 215, batch    28] loss: 3.02568\n",
      "[epoch 215, batch    29] loss: 2.86945\n",
      "[epoch 215, batch    30] loss: 2.92976\n",
      "[epoch 215, batch    31] loss: 3.16706\n",
      "[epoch 215, batch    32] loss: 2.34237\n",
      "[epoch 216, batch     1] loss: 3.49217\n",
      "[epoch 216, batch     2] loss: 3.02078\n",
      "[epoch 216, batch     3] loss: 3.30481\n",
      "[epoch 216, batch     4] loss: 2.86827\n",
      "[epoch 216, batch     5] loss: 2.92835\n",
      "[epoch 216, batch     6] loss: 2.33492\n",
      "[epoch 216, batch     7] loss: 3.38254\n",
      "[epoch 216, batch     8] loss: 2.74642\n",
      "[epoch 216, batch     9] loss: 4.52757\n",
      "[epoch 216, batch    10] loss: 3.47728\n",
      "[epoch 216, batch    11] loss: 2.53110\n",
      "[epoch 216, batch    12] loss: 2.86666\n",
      "[epoch 216, batch    13] loss: 2.49229\n",
      "[epoch 216, batch    14] loss: 3.08652\n",
      "[epoch 216, batch    15] loss: 3.32281\n",
      "[epoch 216, batch    16] loss: 3.23961\n",
      "[epoch 216, batch    17] loss: 2.30178\n",
      "[epoch 216, batch    18] loss: 3.94516\n",
      "[epoch 216, batch    19] loss: 2.40985\n",
      "[epoch 216, batch    20] loss: 3.53795\n",
      "[epoch 216, batch    21] loss: 3.13484\n",
      "[epoch 216, batch    22] loss: 3.04125\n",
      "[epoch 216, batch    23] loss: 3.34693\n",
      "[epoch 216, batch    24] loss: 3.96729\n",
      "[epoch 216, batch    25] loss: 3.08376\n",
      "[epoch 216, batch    26] loss: 2.62921\n",
      "[epoch 216, batch    27] loss: 1.85497\n",
      "[epoch 216, batch    28] loss: 2.06688\n",
      "[epoch 216, batch    29] loss: 3.53003\n",
      "[epoch 216, batch    30] loss: 2.77603\n",
      "[epoch 216, batch    31] loss: 3.52636\n",
      "[epoch 216, batch    32] loss: 2.34076\n",
      "[epoch 217, batch     1] loss: 2.82174\n",
      "[epoch 217, batch     2] loss: 2.34632\n",
      "[epoch 217, batch     3] loss: 3.84037\n",
      "[epoch 217, batch     4] loss: 2.89593\n",
      "[epoch 217, batch     5] loss: 2.70082\n",
      "[epoch 217, batch     6] loss: 3.18672\n",
      "[epoch 217, batch     7] loss: 3.39074\n",
      "[epoch 217, batch     8] loss: 2.73974\n",
      "[epoch 217, batch     9] loss: 3.46053\n",
      "[epoch 217, batch    10] loss: 2.81399\n",
      "[epoch 217, batch    11] loss: 3.44854\n",
      "[epoch 217, batch    12] loss: 3.29604\n",
      "[epoch 217, batch    13] loss: 3.26358\n",
      "[epoch 217, batch    14] loss: 2.47160\n",
      "[epoch 217, batch    15] loss: 3.66363\n",
      "[epoch 217, batch    16] loss: 3.98553\n",
      "[epoch 217, batch    17] loss: 2.44581\n",
      "[epoch 217, batch    18] loss: 3.17328\n",
      "[epoch 217, batch    19] loss: 2.33402\n",
      "[epoch 217, batch    20] loss: 2.47378\n",
      "[epoch 217, batch    21] loss: 3.08626\n",
      "[epoch 217, batch    22] loss: 2.55877\n",
      "[epoch 217, batch    23] loss: 2.35698\n",
      "[epoch 217, batch    24] loss: 2.79531\n",
      "[epoch 217, batch    25] loss: 3.86194\n",
      "[epoch 217, batch    26] loss: 3.30199\n",
      "[epoch 217, batch    27] loss: 2.71635\n",
      "[epoch 217, batch    28] loss: 3.09884\n",
      "[epoch 217, batch    29] loss: 2.48089\n",
      "[epoch 217, batch    30] loss: 3.57992\n",
      "[epoch 217, batch    31] loss: 2.96841\n",
      "[epoch 217, batch    32] loss: 4.34711\n",
      "[epoch 218, batch     1] loss: 2.64839\n",
      "[epoch 218, batch     2] loss: 3.92744\n",
      "[epoch 218, batch     3] loss: 3.19922\n",
      "[epoch 218, batch     4] loss: 2.66464\n",
      "[epoch 218, batch     5] loss: 2.73916\n",
      "[epoch 218, batch     6] loss: 2.38863\n",
      "[epoch 218, batch     7] loss: 4.09536\n",
      "[epoch 218, batch     8] loss: 3.82881\n",
      "[epoch 218, batch     9] loss: 3.10922\n",
      "[epoch 218, batch    10] loss: 3.06621\n",
      "[epoch 218, batch    11] loss: 3.33232\n",
      "[epoch 218, batch    12] loss: 3.04263\n",
      "[epoch 218, batch    13] loss: 2.91040\n",
      "[epoch 218, batch    14] loss: 3.09035\n",
      "[epoch 218, batch    15] loss: 3.38542\n",
      "[epoch 218, batch    16] loss: 2.89509\n",
      "[epoch 218, batch    17] loss: 1.95214\n",
      "[epoch 218, batch    18] loss: 2.93360\n",
      "[epoch 218, batch    19] loss: 3.04323\n",
      "[epoch 218, batch    20] loss: 3.03135\n",
      "[epoch 218, batch    21] loss: 3.20664\n",
      "[epoch 218, batch    22] loss: 3.23049\n",
      "[epoch 218, batch    23] loss: 2.58761\n",
      "[epoch 218, batch    24] loss: 2.85859\n",
      "[epoch 218, batch    25] loss: 3.36660\n",
      "[epoch 218, batch    26] loss: 3.31270\n",
      "[epoch 218, batch    27] loss: 2.19482\n",
      "[epoch 218, batch    28] loss: 2.57476\n",
      "[epoch 218, batch    29] loss: 3.10806\n",
      "[epoch 218, batch    30] loss: 3.14831\n",
      "[epoch 218, batch    31] loss: 2.97504\n",
      "[epoch 218, batch    32] loss: 3.74304\n",
      "[epoch 219, batch     1] loss: 3.45966\n",
      "[epoch 219, batch     2] loss: 3.38733\n",
      "[epoch 219, batch     3] loss: 3.54526\n",
      "[epoch 219, batch     4] loss: 2.74512\n",
      "[epoch 219, batch     5] loss: 2.89700\n",
      "[epoch 219, batch     6] loss: 3.03091\n",
      "[epoch 219, batch     7] loss: 2.38624\n",
      "[epoch 219, batch     8] loss: 2.82489\n",
      "[epoch 219, batch     9] loss: 2.56594\n",
      "[epoch 219, batch    10] loss: 3.31953\n",
      "[epoch 219, batch    11] loss: 3.11471\n",
      "[epoch 219, batch    12] loss: 3.94946\n",
      "[epoch 219, batch    13] loss: 2.95707\n",
      "[epoch 219, batch    14] loss: 3.45252\n",
      "[epoch 219, batch    15] loss: 2.34891\n",
      "[epoch 219, batch    16] loss: 2.97271\n",
      "[epoch 219, batch    17] loss: 2.50319\n",
      "[epoch 219, batch    18] loss: 3.36192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 219, batch    19] loss: 2.09981\n",
      "[epoch 219, batch    20] loss: 3.80851\n",
      "[epoch 219, batch    21] loss: 3.44672\n",
      "[epoch 219, batch    22] loss: 3.61752\n",
      "[epoch 219, batch    23] loss: 3.59532\n",
      "[epoch 219, batch    24] loss: 2.59440\n",
      "[epoch 219, batch    25] loss: 2.19938\n",
      "[epoch 219, batch    26] loss: 3.30513\n",
      "[epoch 219, batch    27] loss: 2.09517\n",
      "[epoch 219, batch    28] loss: 3.64844\n",
      "[epoch 219, batch    29] loss: 3.08407\n",
      "[epoch 219, batch    30] loss: 2.74696\n",
      "[epoch 219, batch    31] loss: 3.16975\n",
      "[epoch 219, batch    32] loss: 2.46169\n",
      "[epoch 220, batch     1] loss: 4.18875\n",
      "[epoch 220, batch     2] loss: 3.00838\n",
      "[epoch 220, batch     3] loss: 3.73049\n",
      "[epoch 220, batch     4] loss: 2.79386\n",
      "[epoch 220, batch     5] loss: 2.32917\n",
      "[epoch 220, batch     6] loss: 2.86899\n",
      "[epoch 220, batch     7] loss: 3.04602\n",
      "[epoch 220, batch     8] loss: 2.50056\n",
      "[epoch 220, batch     9] loss: 2.68822\n",
      "[epoch 220, batch    10] loss: 2.63634\n",
      "[epoch 220, batch    11] loss: 3.00056\n",
      "[epoch 220, batch    12] loss: 2.97167\n",
      "[epoch 220, batch    13] loss: 2.65332\n",
      "[epoch 220, batch    14] loss: 3.42841\n",
      "[epoch 220, batch    15] loss: 3.73358\n",
      "[epoch 220, batch    16] loss: 3.09408\n",
      "[epoch 220, batch    17] loss: 3.16487\n",
      "[epoch 220, batch    18] loss: 4.25743\n",
      "[epoch 220, batch    19] loss: 2.88929\n",
      "[epoch 220, batch    20] loss: 2.34636\n",
      "[epoch 220, batch    21] loss: 2.91018\n",
      "[epoch 220, batch    22] loss: 3.33154\n",
      "[epoch 220, batch    23] loss: 3.88605\n",
      "[epoch 220, batch    24] loss: 2.48648\n",
      "[epoch 220, batch    25] loss: 3.04187\n",
      "[epoch 220, batch    26] loss: 3.69534\n",
      "[epoch 220, batch    27] loss: 2.55039\n",
      "[epoch 220, batch    28] loss: 3.13909\n",
      "[epoch 220, batch    29] loss: 2.85333\n",
      "[epoch 220, batch    30] loss: 2.73518\n",
      "[epoch 220, batch    31] loss: 1.96918\n",
      "[epoch 220, batch    32] loss: 3.66137\n",
      "[epoch 221, batch     1] loss: 2.47328\n",
      "[epoch 221, batch     2] loss: 3.32892\n",
      "[epoch 221, batch     3] loss: 3.17920\n",
      "[epoch 221, batch     4] loss: 3.08445\n",
      "[epoch 221, batch     5] loss: 2.89805\n",
      "[epoch 221, batch     6] loss: 3.27062\n",
      "[epoch 221, batch     7] loss: 2.27442\n",
      "[epoch 221, batch     8] loss: 3.40562\n",
      "[epoch 221, batch     9] loss: 3.38905\n",
      "[epoch 221, batch    10] loss: 3.06013\n",
      "[epoch 221, batch    11] loss: 3.06824\n",
      "[epoch 221, batch    12] loss: 3.61552\n",
      "[epoch 221, batch    13] loss: 2.47902\n",
      "[epoch 221, batch    14] loss: 2.49578\n",
      "[epoch 221, batch    15] loss: 3.76473\n",
      "[epoch 221, batch    16] loss: 2.31817\n",
      "[epoch 221, batch    17] loss: 3.35773\n",
      "[epoch 221, batch    18] loss: 3.07528\n",
      "[epoch 221, batch    19] loss: 2.78830\n",
      "[epoch 221, batch    20] loss: 2.53578\n",
      "[epoch 221, batch    21] loss: 3.26376\n",
      "[epoch 221, batch    22] loss: 3.39885\n",
      "[epoch 221, batch    23] loss: 3.65307\n",
      "[epoch 221, batch    24] loss: 2.72273\n",
      "[epoch 221, batch    25] loss: 3.47242\n",
      "[epoch 221, batch    26] loss: 2.42122\n",
      "[epoch 221, batch    27] loss: 2.62602\n",
      "[epoch 221, batch    28] loss: 3.72555\n",
      "[epoch 221, batch    29] loss: 2.85283\n",
      "[epoch 221, batch    30] loss: 3.22750\n",
      "[epoch 221, batch    31] loss: 2.80940\n",
      "[epoch 221, batch    32] loss: 2.41018\n",
      "[epoch 222, batch     1] loss: 2.91116\n",
      "[epoch 222, batch     2] loss: 2.88218\n",
      "[epoch 222, batch     3] loss: 2.10720\n",
      "[epoch 222, batch     4] loss: 4.45279\n",
      "[epoch 222, batch     5] loss: 2.65368\n",
      "[epoch 222, batch     6] loss: 2.72572\n",
      "[epoch 222, batch     7] loss: 3.60492\n",
      "[epoch 222, batch     8] loss: 2.51799\n",
      "[epoch 222, batch     9] loss: 2.91588\n",
      "[epoch 222, batch    10] loss: 4.06034\n",
      "[epoch 222, batch    11] loss: 3.23836\n",
      "[epoch 222, batch    12] loss: 2.90076\n",
      "[epoch 222, batch    13] loss: 3.26741\n",
      "[epoch 222, batch    14] loss: 2.52489\n",
      "[epoch 222, batch    15] loss: 2.18844\n",
      "[epoch 222, batch    16] loss: 2.80354\n",
      "[epoch 222, batch    17] loss: 2.52110\n",
      "[epoch 222, batch    18] loss: 2.16007\n",
      "[epoch 222, batch    19] loss: 2.65062\n",
      "[epoch 222, batch    20] loss: 2.78033\n",
      "[epoch 222, batch    21] loss: 3.84033\n",
      "[epoch 222, batch    22] loss: 2.36752\n",
      "[epoch 222, batch    23] loss: 3.28436\n",
      "[epoch 222, batch    24] loss: 2.92969\n",
      "[epoch 222, batch    25] loss: 3.74631\n",
      "[epoch 222, batch    26] loss: 2.76409\n",
      "[epoch 222, batch    27] loss: 2.36066\n",
      "[epoch 222, batch    28] loss: 3.91203\n",
      "[epoch 222, batch    29] loss: 3.95518\n",
      "[epoch 222, batch    30] loss: 3.34553\n",
      "[epoch 222, batch    31] loss: 3.35137\n",
      "[epoch 222, batch    32] loss: 2.93424\n",
      "[epoch 223, batch     1] loss: 3.13102\n",
      "[epoch 223, batch     2] loss: 2.79335\n",
      "[epoch 223, batch     3] loss: 3.33351\n",
      "[epoch 223, batch     4] loss: 2.72064\n",
      "[epoch 223, batch     5] loss: 3.03083\n",
      "[epoch 223, batch     6] loss: 2.79015\n",
      "[epoch 223, batch     7] loss: 2.75661\n",
      "[epoch 223, batch     8] loss: 3.10029\n",
      "[epoch 223, batch     9] loss: 4.02864\n",
      "[epoch 223, batch    10] loss: 3.01991\n",
      "[epoch 223, batch    11] loss: 2.64707\n",
      "[epoch 223, batch    12] loss: 3.20480\n",
      "[epoch 223, batch    13] loss: 3.40928\n",
      "[epoch 223, batch    14] loss: 2.98533\n",
      "[epoch 223, batch    15] loss: 2.94822\n",
      "[epoch 223, batch    16] loss: 3.40717\n",
      "[epoch 223, batch    17] loss: 2.98115\n",
      "[epoch 223, batch    18] loss: 3.04881\n",
      "[epoch 223, batch    19] loss: 3.10081\n",
      "[epoch 223, batch    20] loss: 3.05785\n",
      "[epoch 223, batch    21] loss: 3.31989\n",
      "[epoch 223, batch    22] loss: 2.93125\n",
      "[epoch 223, batch    23] loss: 3.17716\n",
      "[epoch 223, batch    24] loss: 2.77921\n",
      "[epoch 223, batch    25] loss: 2.96497\n",
      "[epoch 223, batch    26] loss: 2.89175\n",
      "[epoch 223, batch    27] loss: 3.15594\n",
      "[epoch 223, batch    28] loss: 3.17281\n",
      "[epoch 223, batch    29] loss: 2.63163\n",
      "[epoch 223, batch    30] loss: 3.60082\n",
      "[epoch 223, batch    31] loss: 2.30467\n",
      "[epoch 223, batch    32] loss: 1.82337\n",
      "[epoch 224, batch     1] loss: 2.55356\n",
      "[epoch 224, batch     2] loss: 2.87982\n",
      "[epoch 224, batch     3] loss: 2.67765\n",
      "[epoch 224, batch     4] loss: 3.08356\n",
      "[epoch 224, batch     5] loss: 2.56372\n",
      "[epoch 224, batch     6] loss: 2.86636\n",
      "[epoch 224, batch     7] loss: 4.04713\n",
      "[epoch 224, batch     8] loss: 2.44068\n",
      "[epoch 224, batch     9] loss: 2.61567\n",
      "[epoch 224, batch    10] loss: 3.47885\n",
      "[epoch 224, batch    11] loss: 2.62705\n",
      "[epoch 224, batch    12] loss: 2.48983\n",
      "[epoch 224, batch    13] loss: 3.23332\n",
      "[epoch 224, batch    14] loss: 2.85038\n",
      "[epoch 224, batch    15] loss: 3.80967\n",
      "[epoch 224, batch    16] loss: 3.40181\n",
      "[epoch 224, batch    17] loss: 3.18046\n",
      "[epoch 224, batch    18] loss: 2.89745\n",
      "[epoch 224, batch    19] loss: 3.26685\n",
      "[epoch 224, batch    20] loss: 2.82127\n",
      "[epoch 224, batch    21] loss: 3.22083\n",
      "[epoch 224, batch    22] loss: 2.98251\n",
      "[epoch 224, batch    23] loss: 3.76370\n",
      "[epoch 224, batch    24] loss: 3.06531\n",
      "[epoch 224, batch    25] loss: 3.88189\n",
      "[epoch 224, batch    26] loss: 2.54416\n",
      "[epoch 224, batch    27] loss: 3.09354\n",
      "[epoch 224, batch    28] loss: 3.38902\n",
      "[epoch 224, batch    29] loss: 2.65892\n",
      "[epoch 224, batch    30] loss: 3.31818\n",
      "[epoch 224, batch    31] loss: 2.69449\n",
      "[epoch 224, batch    32] loss: 2.31645\n",
      "[epoch 225, batch     1] loss: 3.17520\n",
      "[epoch 225, batch     2] loss: 3.36128\n",
      "[epoch 225, batch     3] loss: 3.28781\n",
      "[epoch 225, batch     4] loss: 3.72891\n",
      "[epoch 225, batch     5] loss: 3.16206\n",
      "[epoch 225, batch     6] loss: 2.93398\n",
      "[epoch 225, batch     7] loss: 3.37857\n",
      "[epoch 225, batch     8] loss: 3.28417\n",
      "[epoch 225, batch     9] loss: 2.68220\n",
      "[epoch 225, batch    10] loss: 2.63684\n",
      "[epoch 225, batch    11] loss: 2.82968\n",
      "[epoch 225, batch    12] loss: 3.09005\n",
      "[epoch 225, batch    13] loss: 2.99709\n",
      "[epoch 225, batch    14] loss: 4.01189\n",
      "[epoch 225, batch    15] loss: 2.64918\n",
      "[epoch 225, batch    16] loss: 3.35045\n",
      "[epoch 225, batch    17] loss: 2.68316\n",
      "[epoch 225, batch    18] loss: 2.20579\n",
      "[epoch 225, batch    19] loss: 2.56983\n",
      "[epoch 225, batch    20] loss: 3.43524\n",
      "[epoch 225, batch    21] loss: 3.59397\n",
      "[epoch 225, batch    22] loss: 3.03527\n",
      "[epoch 225, batch    23] loss: 2.82305\n",
      "[epoch 225, batch    24] loss: 3.22690\n",
      "[epoch 225, batch    25] loss: 3.40772\n",
      "[epoch 225, batch    26] loss: 2.53703\n",
      "[epoch 225, batch    27] loss: 3.00366\n",
      "[epoch 225, batch    28] loss: 3.35218\n",
      "[epoch 225, batch    29] loss: 3.39065\n",
      "[epoch 225, batch    30] loss: 2.98596\n",
      "[epoch 225, batch    31] loss: 2.02973\n",
      "[epoch 225, batch    32] loss: 1.49198\n",
      "[epoch 226, batch     1] loss: 3.44077\n",
      "[epoch 226, batch     2] loss: 2.81960\n",
      "[epoch 226, batch     3] loss: 3.30111\n",
      "[epoch 226, batch     4] loss: 2.61101\n",
      "[epoch 226, batch     5] loss: 2.65038\n",
      "[epoch 226, batch     6] loss: 2.56848\n",
      "[epoch 226, batch     7] loss: 2.20511\n",
      "[epoch 226, batch     8] loss: 3.93909\n",
      "[epoch 226, batch     9] loss: 2.70546\n",
      "[epoch 226, batch    10] loss: 2.27820\n",
      "[epoch 226, batch    11] loss: 2.71452\n",
      "[epoch 226, batch    12] loss: 3.17002\n",
      "[epoch 226, batch    13] loss: 3.73695\n",
      "[epoch 226, batch    14] loss: 2.00700\n",
      "[epoch 226, batch    15] loss: 2.81517\n",
      "[epoch 226, batch    16] loss: 3.33399\n",
      "[epoch 226, batch    17] loss: 3.49194\n",
      "[epoch 226, batch    18] loss: 3.27195\n",
      "[epoch 226, batch    19] loss: 2.69900\n",
      "[epoch 226, batch    20] loss: 2.84779\n",
      "[epoch 226, batch    21] loss: 2.46045\n",
      "[epoch 226, batch    22] loss: 3.02770\n",
      "[epoch 226, batch    23] loss: 3.22503\n",
      "[epoch 226, batch    24] loss: 3.92700\n",
      "[epoch 226, batch    25] loss: 2.61405\n",
      "[epoch 226, batch    26] loss: 3.68431\n",
      "[epoch 226, batch    27] loss: 3.04627\n",
      "[epoch 226, batch    28] loss: 4.27411\n",
      "[epoch 226, batch    29] loss: 2.61287\n",
      "[epoch 226, batch    30] loss: 3.80359\n",
      "[epoch 226, batch    31] loss: 3.28035\n",
      "[epoch 226, batch    32] loss: 2.18059\n",
      "[epoch 227, batch     1] loss: 2.46440\n",
      "[epoch 227, batch     2] loss: 4.03504\n",
      "[epoch 227, batch     3] loss: 2.53149\n",
      "[epoch 227, batch     4] loss: 2.41326\n",
      "[epoch 227, batch     5] loss: 3.41183\n",
      "[epoch 227, batch     6] loss: 2.36015\n",
      "[epoch 227, batch     7] loss: 2.52284\n",
      "[epoch 227, batch     8] loss: 2.47798\n",
      "[epoch 227, batch     9] loss: 3.13499\n",
      "[epoch 227, batch    10] loss: 3.03890\n",
      "[epoch 227, batch    11] loss: 2.89822\n",
      "[epoch 227, batch    12] loss: 2.11099\n",
      "[epoch 227, batch    13] loss: 3.24930\n",
      "[epoch 227, batch    14] loss: 2.84880\n",
      "[epoch 227, batch    15] loss: 2.84362\n",
      "[epoch 227, batch    16] loss: 4.07635\n",
      "[epoch 227, batch    17] loss: 4.31029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 227, batch    18] loss: 2.71428\n",
      "[epoch 227, batch    19] loss: 3.28208\n",
      "[epoch 227, batch    20] loss: 3.06624\n",
      "[epoch 227, batch    21] loss: 3.28169\n",
      "[epoch 227, batch    22] loss: 3.35398\n",
      "[epoch 227, batch    23] loss: 3.67620\n",
      "[epoch 227, batch    24] loss: 3.45388\n",
      "[epoch 227, batch    25] loss: 2.72150\n",
      "[epoch 227, batch    26] loss: 2.82574\n",
      "[epoch 227, batch    27] loss: 3.00497\n",
      "[epoch 227, batch    28] loss: 3.21694\n",
      "[epoch 227, batch    29] loss: 2.83923\n",
      "[epoch 227, batch    30] loss: 3.41785\n",
      "[epoch 227, batch    31] loss: 3.01480\n",
      "[epoch 227, batch    32] loss: 1.97501\n",
      "[epoch 228, batch     1] loss: 2.41286\n",
      "[epoch 228, batch     2] loss: 3.80422\n",
      "[epoch 228, batch     3] loss: 2.48081\n",
      "[epoch 228, batch     4] loss: 3.15722\n",
      "[epoch 228, batch     5] loss: 2.90752\n",
      "[epoch 228, batch     6] loss: 3.26182\n",
      "[epoch 228, batch     7] loss: 2.95989\n",
      "[epoch 228, batch     8] loss: 3.64000\n",
      "[epoch 228, batch     9] loss: 3.39479\n",
      "[epoch 228, batch    10] loss: 3.34545\n",
      "[epoch 228, batch    11] loss: 2.82535\n",
      "[epoch 228, batch    12] loss: 3.55428\n",
      "[epoch 228, batch    13] loss: 3.06882\n",
      "[epoch 228, batch    14] loss: 2.97824\n",
      "[epoch 228, batch    15] loss: 3.38351\n",
      "[epoch 228, batch    16] loss: 2.81314\n",
      "[epoch 228, batch    17] loss: 2.74225\n",
      "[epoch 228, batch    18] loss: 2.21367\n",
      "[epoch 228, batch    19] loss: 2.64455\n",
      "[epoch 228, batch    20] loss: 3.48847\n",
      "[epoch 228, batch    21] loss: 2.74513\n",
      "[epoch 228, batch    22] loss: 3.12865\n",
      "[epoch 228, batch    23] loss: 3.30925\n",
      "[epoch 228, batch    24] loss: 2.78715\n",
      "[epoch 228, batch    25] loss: 2.97964\n",
      "[epoch 228, batch    26] loss: 2.93072\n",
      "[epoch 228, batch    27] loss: 2.64549\n",
      "[epoch 228, batch    28] loss: 2.60058\n",
      "[epoch 228, batch    29] loss: 3.67759\n",
      "[epoch 228, batch    30] loss: 2.89064\n",
      "[epoch 228, batch    31] loss: 2.68703\n",
      "[epoch 228, batch    32] loss: 4.22889\n",
      "[epoch 229, batch     1] loss: 2.80391\n",
      "[epoch 229, batch     2] loss: 3.05030\n",
      "[epoch 229, batch     3] loss: 2.90311\n",
      "[epoch 229, batch     4] loss: 3.51692\n",
      "[epoch 229, batch     5] loss: 2.54440\n",
      "[epoch 229, batch     6] loss: 2.70742\n",
      "[epoch 229, batch     7] loss: 2.97988\n",
      "[epoch 229, batch     8] loss: 3.70154\n",
      "[epoch 229, batch     9] loss: 3.58882\n",
      "[epoch 229, batch    10] loss: 2.81501\n",
      "[epoch 229, batch    11] loss: 3.38004\n",
      "[epoch 229, batch    12] loss: 3.02021\n",
      "[epoch 229, batch    13] loss: 3.32173\n",
      "[epoch 229, batch    14] loss: 3.58826\n",
      "[epoch 229, batch    15] loss: 2.75586\n",
      "[epoch 229, batch    16] loss: 2.68632\n",
      "[epoch 229, batch    17] loss: 3.33725\n",
      "[epoch 229, batch    18] loss: 3.44524\n",
      "[epoch 229, batch    19] loss: 3.24946\n",
      "[epoch 229, batch    20] loss: 2.96006\n",
      "[epoch 229, batch    21] loss: 3.35734\n",
      "[epoch 229, batch    22] loss: 2.86048\n",
      "[epoch 229, batch    23] loss: 2.46514\n",
      "[epoch 229, batch    24] loss: 3.33699\n",
      "[epoch 229, batch    25] loss: 2.90143\n",
      "[epoch 229, batch    26] loss: 2.29783\n",
      "[epoch 229, batch    27] loss: 2.87931\n",
      "[epoch 229, batch    28] loss: 3.71794\n",
      "[epoch 229, batch    29] loss: 2.86264\n",
      "[epoch 229, batch    30] loss: 2.77563\n",
      "[epoch 229, batch    31] loss: 2.41922\n",
      "[epoch 229, batch    32] loss: 1.85285\n",
      "[epoch 230, batch     1] loss: 2.97222\n",
      "[epoch 230, batch     2] loss: 3.58203\n",
      "[epoch 230, batch     3] loss: 3.39645\n",
      "[epoch 230, batch     4] loss: 2.69472\n",
      "[epoch 230, batch     5] loss: 3.34357\n",
      "[epoch 230, batch     6] loss: 3.01513\n",
      "[epoch 230, batch     7] loss: 3.70247\n",
      "[epoch 230, batch     8] loss: 2.73040\n",
      "[epoch 230, batch     9] loss: 2.94076\n",
      "[epoch 230, batch    10] loss: 2.89413\n",
      "[epoch 230, batch    11] loss: 3.70518\n",
      "[epoch 230, batch    12] loss: 3.60317\n",
      "[epoch 230, batch    13] loss: 2.65799\n",
      "[epoch 230, batch    14] loss: 2.79618\n",
      "[epoch 230, batch    15] loss: 3.24592\n",
      "[epoch 230, batch    16] loss: 2.74699\n",
      "[epoch 230, batch    17] loss: 2.71645\n",
      "[epoch 230, batch    18] loss: 3.30678\n",
      "[epoch 230, batch    19] loss: 2.40133\n",
      "[epoch 230, batch    20] loss: 2.63780\n",
      "[epoch 230, batch    21] loss: 3.00618\n",
      "[epoch 230, batch    22] loss: 3.38452\n",
      "[epoch 230, batch    23] loss: 2.87891\n",
      "[epoch 230, batch    24] loss: 3.07343\n",
      "[epoch 230, batch    25] loss: 3.13476\n",
      "[epoch 230, batch    26] loss: 2.74411\n",
      "[epoch 230, batch    27] loss: 1.87213\n",
      "[epoch 230, batch    28] loss: 3.11059\n",
      "[epoch 230, batch    29] loss: 2.95347\n",
      "[epoch 230, batch    30] loss: 3.78376\n",
      "[epoch 230, batch    31] loss: 3.56422\n",
      "[epoch 230, batch    32] loss: 2.04377\n",
      "[epoch 231, batch     1] loss: 2.66664\n",
      "[epoch 231, batch     2] loss: 3.15096\n",
      "[epoch 231, batch     3] loss: 3.07939\n",
      "[epoch 231, batch     4] loss: 3.13947\n",
      "[epoch 231, batch     5] loss: 3.69470\n",
      "[epoch 231, batch     6] loss: 3.08647\n",
      "[epoch 231, batch     7] loss: 3.63804\n",
      "[epoch 231, batch     8] loss: 3.35224\n",
      "[epoch 231, batch     9] loss: 3.17417\n",
      "[epoch 231, batch    10] loss: 2.28012\n",
      "[epoch 231, batch    11] loss: 3.36780\n",
      "[epoch 231, batch    12] loss: 3.28041\n",
      "[epoch 231, batch    13] loss: 3.37980\n",
      "[epoch 231, batch    14] loss: 3.32220\n",
      "[epoch 231, batch    15] loss: 3.17861\n",
      "[epoch 231, batch    16] loss: 3.45972\n",
      "[epoch 231, batch    17] loss: 2.40504\n",
      "[epoch 231, batch    18] loss: 3.58775\n",
      "[epoch 231, batch    19] loss: 3.03046\n",
      "[epoch 231, batch    20] loss: 3.42420\n",
      "[epoch 231, batch    21] loss: 3.34361\n",
      "[epoch 231, batch    22] loss: 2.71057\n",
      "[epoch 231, batch    23] loss: 2.90885\n",
      "[epoch 231, batch    24] loss: 2.94121\n",
      "[epoch 231, batch    25] loss: 2.72086\n",
      "[epoch 231, batch    26] loss: 2.65468\n",
      "[epoch 231, batch    27] loss: 3.49035\n",
      "[epoch 231, batch    28] loss: 2.27196\n",
      "[epoch 231, batch    29] loss: 2.49474\n",
      "[epoch 231, batch    30] loss: 3.10431\n",
      "[epoch 231, batch    31] loss: 2.24354\n",
      "[epoch 231, batch    32] loss: 2.93252\n",
      "[epoch 232, batch     1] loss: 2.90955\n",
      "[epoch 232, batch     2] loss: 3.28553\n",
      "[epoch 232, batch     3] loss: 2.63289\n",
      "[epoch 232, batch     4] loss: 3.99652\n",
      "[epoch 232, batch     5] loss: 3.40143\n",
      "[epoch 232, batch     6] loss: 2.69549\n",
      "[epoch 232, batch     7] loss: 2.61406\n",
      "[epoch 232, batch     8] loss: 3.61697\n",
      "[epoch 232, batch     9] loss: 3.26996\n",
      "[epoch 232, batch    10] loss: 2.56372\n",
      "[epoch 232, batch    11] loss: 3.18949\n",
      "[epoch 232, batch    12] loss: 2.87477\n",
      "[epoch 232, batch    13] loss: 3.29704\n",
      "[epoch 232, batch    14] loss: 3.36619\n",
      "[epoch 232, batch    15] loss: 2.74212\n",
      "[epoch 232, batch    16] loss: 2.93180\n",
      "[epoch 232, batch    17] loss: 3.33360\n",
      "[epoch 232, batch    18] loss: 2.73318\n",
      "[epoch 232, batch    19] loss: 2.49621\n",
      "[epoch 232, batch    20] loss: 3.45877\n",
      "[epoch 232, batch    21] loss: 2.81491\n",
      "[epoch 232, batch    22] loss: 1.92603\n",
      "[epoch 232, batch    23] loss: 2.91828\n",
      "[epoch 232, batch    24] loss: 3.83517\n",
      "[epoch 232, batch    25] loss: 2.89039\n",
      "[epoch 232, batch    26] loss: 3.33275\n",
      "[epoch 232, batch    27] loss: 3.19999\n",
      "[epoch 232, batch    28] loss: 3.14521\n",
      "[epoch 232, batch    29] loss: 2.70106\n",
      "[epoch 232, batch    30] loss: 2.55786\n",
      "[epoch 232, batch    31] loss: 3.83224\n",
      "[epoch 232, batch    32] loss: 2.24328\n",
      "[epoch 233, batch     1] loss: 3.10262\n",
      "[epoch 233, batch     2] loss: 3.24863\n",
      "[epoch 233, batch     3] loss: 2.56918\n",
      "[epoch 233, batch     4] loss: 3.39053\n",
      "[epoch 233, batch     5] loss: 2.78591\n",
      "[epoch 233, batch     6] loss: 2.37794\n",
      "[epoch 233, batch     7] loss: 4.25502\n",
      "[epoch 233, batch     8] loss: 2.74323\n",
      "[epoch 233, batch     9] loss: 3.42891\n",
      "[epoch 233, batch    10] loss: 3.38687\n",
      "[epoch 233, batch    11] loss: 3.66062\n",
      "[epoch 233, batch    12] loss: 3.01521\n",
      "[epoch 233, batch    13] loss: 3.05125\n",
      "[epoch 233, batch    14] loss: 2.11597\n",
      "[epoch 233, batch    15] loss: 3.30776\n",
      "[epoch 233, batch    16] loss: 3.30686\n",
      "[epoch 233, batch    17] loss: 2.98407\n",
      "[epoch 233, batch    18] loss: 3.26647\n",
      "[epoch 233, batch    19] loss: 3.18598\n",
      "[epoch 233, batch    20] loss: 2.88208\n",
      "[epoch 233, batch    21] loss: 3.06304\n",
      "[epoch 233, batch    22] loss: 3.96802\n",
      "[epoch 233, batch    23] loss: 2.23582\n",
      "[epoch 233, batch    24] loss: 3.22267\n",
      "[epoch 233, batch    25] loss: 3.09211\n",
      "[epoch 233, batch    26] loss: 2.74141\n",
      "[epoch 233, batch    27] loss: 2.65571\n",
      "[epoch 233, batch    28] loss: 3.11661\n",
      "[epoch 233, batch    29] loss: 2.99508\n",
      "[epoch 233, batch    30] loss: 2.45340\n",
      "[epoch 233, batch    31] loss: 2.50555\n",
      "[epoch 233, batch    32] loss: 3.06017\n",
      "[epoch 234, batch     1] loss: 3.54276\n",
      "[epoch 234, batch     2] loss: 2.94265\n",
      "[epoch 234, batch     3] loss: 3.44700\n",
      "[epoch 234, batch     4] loss: 2.82361\n",
      "[epoch 234, batch     5] loss: 2.30248\n",
      "[epoch 234, batch     6] loss: 3.02809\n",
      "[epoch 234, batch     7] loss: 3.83321\n",
      "[epoch 234, batch     8] loss: 3.29381\n",
      "[epoch 234, batch     9] loss: 2.44453\n",
      "[epoch 234, batch    10] loss: 2.66362\n",
      "[epoch 234, batch    11] loss: 3.24614\n",
      "[epoch 234, batch    12] loss: 2.55884\n",
      "[epoch 234, batch    13] loss: 2.84045\n",
      "[epoch 234, batch    14] loss: 2.82243\n",
      "[epoch 234, batch    15] loss: 3.38335\n",
      "[epoch 234, batch    16] loss: 3.02925\n",
      "[epoch 234, batch    17] loss: 2.78720\n",
      "[epoch 234, batch    18] loss: 2.46882\n",
      "[epoch 234, batch    19] loss: 3.28065\n",
      "[epoch 234, batch    20] loss: 2.86625\n",
      "[epoch 234, batch    21] loss: 2.77979\n",
      "[epoch 234, batch    22] loss: 3.59234\n",
      "[epoch 234, batch    23] loss: 3.05783\n",
      "[epoch 234, batch    24] loss: 3.77176\n",
      "[epoch 234, batch    25] loss: 3.05749\n",
      "[epoch 234, batch    26] loss: 3.32425\n",
      "[epoch 234, batch    27] loss: 3.59655\n",
      "[epoch 234, batch    28] loss: 2.88484\n",
      "[epoch 234, batch    29] loss: 2.88765\n",
      "[epoch 234, batch    30] loss: 2.38045\n",
      "[epoch 234, batch    31] loss: 2.98093\n",
      "[epoch 234, batch    32] loss: 3.03684\n",
      "[epoch 235, batch     1] loss: 3.17733\n",
      "[epoch 235, batch     2] loss: 2.95010\n",
      "[epoch 235, batch     3] loss: 3.23165\n",
      "[epoch 235, batch     4] loss: 2.98026\n",
      "[epoch 235, batch     5] loss: 3.64592\n",
      "[epoch 235, batch     6] loss: 2.56917\n",
      "[epoch 235, batch     7] loss: 2.99335\n",
      "[epoch 235, batch     8] loss: 2.82849\n",
      "[epoch 235, batch     9] loss: 3.29375\n",
      "[epoch 235, batch    10] loss: 3.11094\n",
      "[epoch 235, batch    11] loss: 2.76500\n",
      "[epoch 235, batch    12] loss: 3.46152\n",
      "[epoch 235, batch    13] loss: 2.44534\n",
      "[epoch 235, batch    14] loss: 3.49116\n",
      "[epoch 235, batch    15] loss: 2.29678\n",
      "[epoch 235, batch    16] loss: 3.27351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 235, batch    17] loss: 3.12234\n",
      "[epoch 235, batch    18] loss: 3.46970\n",
      "[epoch 235, batch    19] loss: 2.90250\n",
      "[epoch 235, batch    20] loss: 2.49805\n",
      "[epoch 235, batch    21] loss: 2.75096\n",
      "[epoch 235, batch    22] loss: 3.92492\n",
      "[epoch 235, batch    23] loss: 3.43196\n",
      "[epoch 235, batch    24] loss: 2.78438\n",
      "[epoch 235, batch    25] loss: 3.49131\n",
      "[epoch 235, batch    26] loss: 2.83308\n",
      "[epoch 235, batch    27] loss: 2.46157\n",
      "[epoch 235, batch    28] loss: 3.37107\n",
      "[epoch 235, batch    29] loss: 2.82731\n",
      "[epoch 235, batch    30] loss: 2.91356\n",
      "[epoch 235, batch    31] loss: 3.01649\n",
      "[epoch 235, batch    32] loss: 3.18955\n",
      "[epoch 236, batch     1] loss: 2.75929\n",
      "[epoch 236, batch     2] loss: 1.98248\n",
      "[epoch 236, batch     3] loss: 2.52422\n",
      "[epoch 236, batch     4] loss: 3.53882\n",
      "[epoch 236, batch     5] loss: 2.46314\n",
      "[epoch 236, batch     6] loss: 3.12970\n",
      "[epoch 236, batch     7] loss: 2.92843\n",
      "[epoch 236, batch     8] loss: 2.97482\n",
      "[epoch 236, batch     9] loss: 3.58197\n",
      "[epoch 236, batch    10] loss: 4.03772\n",
      "[epoch 236, batch    11] loss: 4.00013\n",
      "[epoch 236, batch    12] loss: 2.91933\n",
      "[epoch 236, batch    13] loss: 2.92721\n",
      "[epoch 236, batch    14] loss: 2.77600\n",
      "[epoch 236, batch    15] loss: 2.43930\n",
      "[epoch 236, batch    16] loss: 2.93541\n",
      "[epoch 236, batch    17] loss: 3.00506\n",
      "[epoch 236, batch    18] loss: 3.08649\n",
      "[epoch 236, batch    19] loss: 3.16793\n",
      "[epoch 236, batch    20] loss: 3.27356\n",
      "[epoch 236, batch    21] loss: 3.37087\n",
      "[epoch 236, batch    22] loss: 3.25437\n",
      "[epoch 236, batch    23] loss: 3.75678\n",
      "[epoch 236, batch    24] loss: 3.02811\n",
      "[epoch 236, batch    25] loss: 2.30103\n",
      "[epoch 236, batch    26] loss: 3.23013\n",
      "[epoch 236, batch    27] loss: 3.16097\n",
      "[epoch 236, batch    28] loss: 2.00740\n",
      "[epoch 236, batch    29] loss: 3.12818\n",
      "[epoch 236, batch    30] loss: 3.34174\n",
      "[epoch 236, batch    31] loss: 2.75313\n",
      "[epoch 236, batch    32] loss: 2.57722\n",
      "[epoch 237, batch     1] loss: 2.56646\n",
      "[epoch 237, batch     2] loss: 1.97873\n",
      "[epoch 237, batch     3] loss: 3.47091\n",
      "[epoch 237, batch     4] loss: 2.54917\n",
      "[epoch 237, batch     5] loss: 3.48063\n",
      "[epoch 237, batch     6] loss: 3.08772\n",
      "[epoch 237, batch     7] loss: 2.79699\n",
      "[epoch 237, batch     8] loss: 3.63279\n",
      "[epoch 237, batch     9] loss: 3.36021\n",
      "[epoch 237, batch    10] loss: 2.91376\n",
      "[epoch 237, batch    11] loss: 3.29547\n",
      "[epoch 237, batch    12] loss: 2.80695\n",
      "[epoch 237, batch    13] loss: 3.22520\n",
      "[epoch 237, batch    14] loss: 2.80879\n",
      "[epoch 237, batch    15] loss: 2.49741\n",
      "[epoch 237, batch    16] loss: 2.37719\n",
      "[epoch 237, batch    17] loss: 2.54921\n",
      "[epoch 237, batch    18] loss: 3.51248\n",
      "[epoch 237, batch    19] loss: 3.46566\n",
      "[epoch 237, batch    20] loss: 2.81776\n",
      "[epoch 237, batch    21] loss: 2.37116\n",
      "[epoch 237, batch    22] loss: 2.89566\n",
      "[epoch 237, batch    23] loss: 3.10974\n",
      "[epoch 237, batch    24] loss: 2.32270\n",
      "[epoch 237, batch    25] loss: 3.72613\n",
      "[epoch 237, batch    26] loss: 3.93349\n",
      "[epoch 237, batch    27] loss: 2.77396\n",
      "[epoch 237, batch    28] loss: 3.54484\n",
      "[epoch 237, batch    29] loss: 3.42267\n",
      "[epoch 237, batch    30] loss: 3.86063\n",
      "[epoch 237, batch    31] loss: 3.78628\n",
      "[epoch 237, batch    32] loss: 2.47642\n",
      "[epoch 238, batch     1] loss: 3.28469\n",
      "[epoch 238, batch     2] loss: 2.71574\n",
      "[epoch 238, batch     3] loss: 2.02030\n",
      "[epoch 238, batch     4] loss: 3.02398\n",
      "[epoch 238, batch     5] loss: 3.33001\n",
      "[epoch 238, batch     6] loss: 3.99935\n",
      "[epoch 238, batch     7] loss: 3.41800\n",
      "[epoch 238, batch     8] loss: 3.09024\n",
      "[epoch 238, batch     9] loss: 3.17225\n",
      "[epoch 238, batch    10] loss: 3.10683\n",
      "[epoch 238, batch    11] loss: 3.15602\n",
      "[epoch 238, batch    12] loss: 2.35436\n",
      "[epoch 238, batch    13] loss: 3.41694\n",
      "[epoch 238, batch    14] loss: 3.35514\n",
      "[epoch 238, batch    15] loss: 3.07105\n",
      "[epoch 238, batch    16] loss: 2.76658\n",
      "[epoch 238, batch    17] loss: 3.04676\n",
      "[epoch 238, batch    18] loss: 3.45457\n",
      "[epoch 238, batch    19] loss: 3.05098\n",
      "[epoch 238, batch    20] loss: 3.21340\n",
      "[epoch 238, batch    21] loss: 2.57601\n",
      "[epoch 238, batch    22] loss: 2.88205\n",
      "[epoch 238, batch    23] loss: 2.66195\n",
      "[epoch 238, batch    24] loss: 3.20605\n",
      "[epoch 238, batch    25] loss: 2.38396\n",
      "[epoch 238, batch    26] loss: 2.98097\n",
      "[epoch 238, batch    27] loss: 3.09379\n",
      "[epoch 238, batch    28] loss: 4.07229\n",
      "[epoch 238, batch    29] loss: 2.52117\n",
      "[epoch 238, batch    30] loss: 2.28265\n",
      "[epoch 238, batch    31] loss: 3.80179\n",
      "[epoch 238, batch    32] loss: 2.44820\n",
      "[epoch 239, batch     1] loss: 3.66132\n",
      "[epoch 239, batch     2] loss: 2.83472\n",
      "[epoch 239, batch     3] loss: 2.49184\n",
      "[epoch 239, batch     4] loss: 1.94040\n",
      "[epoch 239, batch     5] loss: 3.31203\n",
      "[epoch 239, batch     6] loss: 2.67847\n",
      "[epoch 239, batch     7] loss: 2.71692\n",
      "[epoch 239, batch     8] loss: 2.88859\n",
      "[epoch 239, batch     9] loss: 4.02137\n",
      "[epoch 239, batch    10] loss: 2.22020\n",
      "[epoch 239, batch    11] loss: 3.56159\n",
      "[epoch 239, batch    12] loss: 3.04432\n",
      "[epoch 239, batch    13] loss: 3.11312\n",
      "[epoch 239, batch    14] loss: 3.83836\n",
      "[epoch 239, batch    15] loss: 3.51861\n",
      "[epoch 239, batch    16] loss: 3.20123\n",
      "[epoch 239, batch    17] loss: 2.99223\n",
      "[epoch 239, batch    18] loss: 1.96469\n",
      "[epoch 239, batch    19] loss: 2.78746\n",
      "[epoch 239, batch    20] loss: 3.37702\n",
      "[epoch 239, batch    21] loss: 3.61003\n",
      "[epoch 239, batch    22] loss: 2.91355\n",
      "[epoch 239, batch    23] loss: 3.86995\n",
      "[epoch 239, batch    24] loss: 3.18450\n",
      "[epoch 239, batch    25] loss: 3.07254\n",
      "[epoch 239, batch    26] loss: 3.66841\n",
      "[epoch 239, batch    27] loss: 2.48678\n",
      "[epoch 239, batch    28] loss: 2.58637\n",
      "[epoch 239, batch    29] loss: 3.58899\n",
      "[epoch 239, batch    30] loss: 2.35934\n",
      "[epoch 239, batch    31] loss: 2.97468\n",
      "[epoch 239, batch    32] loss: 3.13912\n",
      "[epoch 240, batch     1] loss: 3.78025\n",
      "[epoch 240, batch     2] loss: 2.21833\n",
      "[epoch 240, batch     3] loss: 3.41623\n",
      "[epoch 240, batch     4] loss: 2.45521\n",
      "[epoch 240, batch     5] loss: 3.37777\n",
      "[epoch 240, batch     6] loss: 3.30943\n",
      "[epoch 240, batch     7] loss: 2.98181\n",
      "[epoch 240, batch     8] loss: 3.01700\n",
      "[epoch 240, batch     9] loss: 3.50791\n",
      "[epoch 240, batch    10] loss: 2.58807\n",
      "[epoch 240, batch    11] loss: 3.60156\n",
      "[epoch 240, batch    12] loss: 2.83270\n",
      "[epoch 240, batch    13] loss: 2.42886\n",
      "[epoch 240, batch    14] loss: 3.66141\n",
      "[epoch 240, batch    15] loss: 3.01405\n",
      "[epoch 240, batch    16] loss: 3.07247\n",
      "[epoch 240, batch    17] loss: 2.13011\n",
      "[epoch 240, batch    18] loss: 2.89414\n",
      "[epoch 240, batch    19] loss: 2.93961\n",
      "[epoch 240, batch    20] loss: 3.32838\n",
      "[epoch 240, batch    21] loss: 3.70890\n",
      "[epoch 240, batch    22] loss: 2.93509\n",
      "[epoch 240, batch    23] loss: 3.31902\n",
      "[epoch 240, batch    24] loss: 3.11967\n",
      "[epoch 240, batch    25] loss: 2.47544\n",
      "[epoch 240, batch    26] loss: 2.61769\n",
      "[epoch 240, batch    27] loss: 2.17139\n",
      "[epoch 240, batch    28] loss: 4.40642\n",
      "[epoch 240, batch    29] loss: 3.50124\n",
      "[epoch 240, batch    30] loss: 2.93627\n",
      "[epoch 240, batch    31] loss: 2.76865\n",
      "[epoch 240, batch    32] loss: 3.13985\n",
      "[epoch 241, batch     1] loss: 3.31041\n",
      "[epoch 241, batch     2] loss: 3.45555\n",
      "[epoch 241, batch     3] loss: 2.86864\n",
      "[epoch 241, batch     4] loss: 3.99851\n",
      "[epoch 241, batch     5] loss: 2.62567\n",
      "[epoch 241, batch     6] loss: 3.17445\n",
      "[epoch 241, batch     7] loss: 2.99214\n",
      "[epoch 241, batch     8] loss: 3.00113\n",
      "[epoch 241, batch     9] loss: 3.63200\n",
      "[epoch 241, batch    10] loss: 3.32781\n",
      "[epoch 241, batch    11] loss: 3.11259\n",
      "[epoch 241, batch    12] loss: 3.00983\n",
      "[epoch 241, batch    13] loss: 2.95223\n",
      "[epoch 241, batch    14] loss: 2.77150\n",
      "[epoch 241, batch    15] loss: 2.76485\n",
      "[epoch 241, batch    16] loss: 2.49875\n",
      "[epoch 241, batch    17] loss: 2.57813\n",
      "[epoch 241, batch    18] loss: 3.20114\n",
      "[epoch 241, batch    19] loss: 3.10699\n",
      "[epoch 241, batch    20] loss: 2.96000\n",
      "[epoch 241, batch    21] loss: 2.71980\n",
      "[epoch 241, batch    22] loss: 3.64268\n",
      "[epoch 241, batch    23] loss: 2.96656\n",
      "[epoch 241, batch    24] loss: 3.18421\n",
      "[epoch 241, batch    25] loss: 3.83830\n",
      "[epoch 241, batch    26] loss: 2.74770\n",
      "[epoch 241, batch    27] loss: 2.87014\n",
      "[epoch 241, batch    28] loss: 2.79475\n",
      "[epoch 241, batch    29] loss: 2.91327\n",
      "[epoch 241, batch    30] loss: 2.90851\n",
      "[epoch 241, batch    31] loss: 2.31669\n",
      "[epoch 241, batch    32] loss: 2.75102\n",
      "[epoch 242, batch     1] loss: 2.69841\n",
      "[epoch 242, batch     2] loss: 2.60757\n",
      "[epoch 242, batch     3] loss: 4.80124\n",
      "[epoch 242, batch     4] loss: 3.57219\n",
      "[epoch 242, batch     5] loss: 2.69591\n",
      "[epoch 242, batch     6] loss: 3.42530\n",
      "[epoch 242, batch     7] loss: 2.94690\n",
      "[epoch 242, batch     8] loss: 2.64950\n",
      "[epoch 242, batch     9] loss: 3.50505\n",
      "[epoch 242, batch    10] loss: 3.01316\n",
      "[epoch 242, batch    11] loss: 2.09689\n",
      "[epoch 242, batch    12] loss: 3.65398\n",
      "[epoch 242, batch    13] loss: 3.38434\n",
      "[epoch 242, batch    14] loss: 3.17902\n",
      "[epoch 242, batch    15] loss: 3.16967\n",
      "[epoch 242, batch    16] loss: 2.88158\n",
      "[epoch 242, batch    17] loss: 2.71490\n",
      "[epoch 242, batch    18] loss: 2.43616\n",
      "[epoch 242, batch    19] loss: 3.51241\n",
      "[epoch 242, batch    20] loss: 2.55860\n",
      "[epoch 242, batch    21] loss: 2.25674\n",
      "[epoch 242, batch    22] loss: 3.08398\n",
      "[epoch 242, batch    23] loss: 2.74918\n",
      "[epoch 242, batch    24] loss: 3.24906\n",
      "[epoch 242, batch    25] loss: 3.40414\n",
      "[epoch 242, batch    26] loss: 2.27995\n",
      "[epoch 242, batch    27] loss: 4.06861\n",
      "[epoch 242, batch    28] loss: 2.94762\n",
      "[epoch 242, batch    29] loss: 2.91122\n",
      "[epoch 242, batch    30] loss: 2.99033\n",
      "[epoch 242, batch    31] loss: 2.64036\n",
      "[epoch 242, batch    32] loss: 3.47517\n",
      "[epoch 243, batch     1] loss: 2.67429\n",
      "[epoch 243, batch     2] loss: 2.25020\n",
      "[epoch 243, batch     3] loss: 2.87326\n",
      "[epoch 243, batch     4] loss: 2.36481\n",
      "[epoch 243, batch     5] loss: 3.94876\n",
      "[epoch 243, batch     6] loss: 3.06710\n",
      "[epoch 243, batch     7] loss: 2.72092\n",
      "[epoch 243, batch     8] loss: 2.60230\n",
      "[epoch 243, batch     9] loss: 3.82713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 243, batch    10] loss: 2.86939\n",
      "[epoch 243, batch    11] loss: 2.73791\n",
      "[epoch 243, batch    12] loss: 3.02953\n",
      "[epoch 243, batch    13] loss: 3.95595\n",
      "[epoch 243, batch    14] loss: 2.84750\n",
      "[epoch 243, batch    15] loss: 2.48336\n",
      "[epoch 243, batch    16] loss: 3.54058\n",
      "[epoch 243, batch    17] loss: 2.57881\n",
      "[epoch 243, batch    18] loss: 3.08681\n",
      "[epoch 243, batch    19] loss: 3.57677\n",
      "[epoch 243, batch    20] loss: 2.98768\n",
      "[epoch 243, batch    21] loss: 3.68812\n",
      "[epoch 243, batch    22] loss: 2.94805\n",
      "[epoch 243, batch    23] loss: 2.72859\n",
      "[epoch 243, batch    24] loss: 2.71952\n",
      "[epoch 243, batch    25] loss: 3.64179\n",
      "[epoch 243, batch    26] loss: 3.45055\n",
      "[epoch 243, batch    27] loss: 2.92364\n",
      "[epoch 243, batch    28] loss: 1.81742\n",
      "[epoch 243, batch    29] loss: 2.82804\n",
      "[epoch 243, batch    30] loss: 3.78076\n",
      "[epoch 243, batch    31] loss: 3.43923\n",
      "[epoch 243, batch    32] loss: 2.43273\n",
      "[epoch 244, batch     1] loss: 3.48844\n",
      "[epoch 244, batch     2] loss: 1.63807\n",
      "[epoch 244, batch     3] loss: 2.76656\n",
      "[epoch 244, batch     4] loss: 3.21045\n",
      "[epoch 244, batch     5] loss: 2.62536\n",
      "[epoch 244, batch     6] loss: 3.87846\n",
      "[epoch 244, batch     7] loss: 2.29487\n",
      "[epoch 244, batch     8] loss: 3.15129\n",
      "[epoch 244, batch     9] loss: 3.10183\n",
      "[epoch 244, batch    10] loss: 2.85495\n",
      "[epoch 244, batch    11] loss: 2.58471\n",
      "[epoch 244, batch    12] loss: 3.39514\n",
      "[epoch 244, batch    13] loss: 3.06362\n",
      "[epoch 244, batch    14] loss: 2.78156\n",
      "[epoch 244, batch    15] loss: 3.09912\n",
      "[epoch 244, batch    16] loss: 3.05851\n",
      "[epoch 244, batch    17] loss: 3.58167\n",
      "[epoch 244, batch    18] loss: 2.99660\n",
      "[epoch 244, batch    19] loss: 2.97228\n",
      "[epoch 244, batch    20] loss: 3.41567\n",
      "[epoch 244, batch    21] loss: 2.94162\n",
      "[epoch 244, batch    22] loss: 3.36626\n",
      "[epoch 244, batch    23] loss: 2.90017\n",
      "[epoch 244, batch    24] loss: 2.74047\n",
      "[epoch 244, batch    25] loss: 3.52397\n",
      "[epoch 244, batch    26] loss: 3.26296\n",
      "[epoch 244, batch    27] loss: 3.18683\n",
      "[epoch 244, batch    28] loss: 3.49636\n",
      "[epoch 244, batch    29] loss: 3.51056\n",
      "[epoch 244, batch    30] loss: 2.68273\n",
      "[epoch 244, batch    31] loss: 3.02341\n",
      "[epoch 244, batch    32] loss: 2.84324\n",
      "[epoch 245, batch     1] loss: 2.60991\n",
      "[epoch 245, batch     2] loss: 1.89489\n",
      "[epoch 245, batch     3] loss: 3.00406\n",
      "[epoch 245, batch     4] loss: 3.19432\n",
      "[epoch 245, batch     5] loss: 3.61653\n",
      "[epoch 245, batch     6] loss: 3.58760\n",
      "[epoch 245, batch     7] loss: 3.56925\n",
      "[epoch 245, batch     8] loss: 2.32191\n",
      "[epoch 245, batch     9] loss: 2.35465\n",
      "[epoch 245, batch    10] loss: 2.69390\n",
      "[epoch 245, batch    11] loss: 3.28155\n",
      "[epoch 245, batch    12] loss: 3.14037\n",
      "[epoch 245, batch    13] loss: 2.91741\n",
      "[epoch 245, batch    14] loss: 2.70454\n",
      "[epoch 245, batch    15] loss: 2.97048\n",
      "[epoch 245, batch    16] loss: 3.46881\n",
      "[epoch 245, batch    17] loss: 2.12186\n",
      "[epoch 245, batch    18] loss: 3.94413\n",
      "[epoch 245, batch    19] loss: 3.59674\n",
      "[epoch 245, batch    20] loss: 2.27174\n",
      "[epoch 245, batch    21] loss: 3.29467\n",
      "[epoch 245, batch    22] loss: 3.07472\n",
      "[epoch 245, batch    23] loss: 3.56365\n",
      "[epoch 245, batch    24] loss: 2.98217\n",
      "[epoch 245, batch    25] loss: 3.13291\n",
      "[epoch 245, batch    26] loss: 2.81854\n",
      "[epoch 245, batch    27] loss: 3.38353\n",
      "[epoch 245, batch    28] loss: 3.21282\n",
      "[epoch 245, batch    29] loss: 3.33754\n",
      "[epoch 245, batch    30] loss: 3.21433\n",
      "[epoch 245, batch    31] loss: 3.01030\n",
      "[epoch 245, batch    32] loss: 3.26371\n",
      "[epoch 246, batch     1] loss: 2.72264\n",
      "[epoch 246, batch     2] loss: 4.12134\n",
      "[epoch 246, batch     3] loss: 2.78697\n",
      "[epoch 246, batch     4] loss: 3.20493\n",
      "[epoch 246, batch     5] loss: 3.65483\n",
      "[epoch 246, batch     6] loss: 2.56787\n",
      "[epoch 246, batch     7] loss: 2.97173\n",
      "[epoch 246, batch     8] loss: 2.93565\n",
      "[epoch 246, batch     9] loss: 2.78675\n",
      "[epoch 246, batch    10] loss: 2.92357\n",
      "[epoch 246, batch    11] loss: 3.03116\n",
      "[epoch 246, batch    12] loss: 2.55347\n",
      "[epoch 246, batch    13] loss: 4.07265\n",
      "[epoch 246, batch    14] loss: 2.58142\n",
      "[epoch 246, batch    15] loss: 2.74381\n",
      "[epoch 246, batch    16] loss: 2.72502\n",
      "[epoch 246, batch    17] loss: 3.07411\n",
      "[epoch 246, batch    18] loss: 3.51571\n",
      "[epoch 246, batch    19] loss: 2.53291\n",
      "[epoch 246, batch    20] loss: 2.90449\n",
      "[epoch 246, batch    21] loss: 3.59756\n",
      "[epoch 246, batch    22] loss: 3.02208\n",
      "[epoch 246, batch    23] loss: 3.47547\n",
      "[epoch 246, batch    24] loss: 3.05351\n",
      "[epoch 246, batch    25] loss: 2.87698\n",
      "[epoch 246, batch    26] loss: 3.07525\n",
      "[epoch 246, batch    27] loss: 2.78927\n",
      "[epoch 246, batch    28] loss: 2.48863\n",
      "[epoch 246, batch    29] loss: 3.53537\n",
      "[epoch 246, batch    30] loss: 2.92068\n",
      "[epoch 246, batch    31] loss: 3.06959\n",
      "[epoch 246, batch    32] loss: 2.96281\n",
      "[epoch 247, batch     1] loss: 2.72216\n",
      "[epoch 247, batch     2] loss: 2.15298\n",
      "[epoch 247, batch     3] loss: 2.89453\n",
      "[epoch 247, batch     4] loss: 3.04846\n",
      "[epoch 247, batch     5] loss: 2.21622\n",
      "[epoch 247, batch     6] loss: 3.62216\n",
      "[epoch 247, batch     7] loss: 3.37551\n",
      "[epoch 247, batch     8] loss: 3.06256\n",
      "[epoch 247, batch     9] loss: 3.57657\n",
      "[epoch 247, batch    10] loss: 3.00577\n",
      "[epoch 247, batch    11] loss: 2.83616\n",
      "[epoch 247, batch    12] loss: 3.14711\n",
      "[epoch 247, batch    13] loss: 2.52826\n",
      "[epoch 247, batch    14] loss: 2.74948\n",
      "[epoch 247, batch    15] loss: 2.63098\n",
      "[epoch 247, batch    16] loss: 3.04148\n",
      "[epoch 247, batch    17] loss: 3.36929\n",
      "[epoch 247, batch    18] loss: 3.03935\n",
      "[epoch 247, batch    19] loss: 2.89746\n",
      "[epoch 247, batch    20] loss: 3.63562\n",
      "[epoch 247, batch    21] loss: 3.68175\n",
      "[epoch 247, batch    22] loss: 2.74672\n",
      "[epoch 247, batch    23] loss: 2.66972\n",
      "[epoch 247, batch    24] loss: 3.35852\n",
      "[epoch 247, batch    25] loss: 2.78843\n",
      "[epoch 247, batch    26] loss: 3.10746\n",
      "[epoch 247, batch    27] loss: 3.61003\n",
      "[epoch 247, batch    28] loss: 3.67938\n",
      "[epoch 247, batch    29] loss: 2.98312\n",
      "[epoch 247, batch    30] loss: 2.17304\n",
      "[epoch 247, batch    31] loss: 3.11179\n",
      "[epoch 247, batch    32] loss: 3.66562\n",
      "[epoch 248, batch     1] loss: 3.21807\n",
      "[epoch 248, batch     2] loss: 2.99281\n",
      "[epoch 248, batch     3] loss: 3.09044\n",
      "[epoch 248, batch     4] loss: 2.71316\n",
      "[epoch 248, batch     5] loss: 2.97606\n",
      "[epoch 248, batch     6] loss: 2.43894\n",
      "[epoch 248, batch     7] loss: 2.56142\n",
      "[epoch 248, batch     8] loss: 3.26189\n",
      "[epoch 248, batch     9] loss: 3.19454\n",
      "[epoch 248, batch    10] loss: 2.79565\n",
      "[epoch 248, batch    11] loss: 2.90890\n",
      "[epoch 248, batch    12] loss: 2.68867\n",
      "[epoch 248, batch    13] loss: 3.18394\n",
      "[epoch 248, batch    14] loss: 2.13859\n",
      "[epoch 248, batch    15] loss: 3.15018\n",
      "[epoch 248, batch    16] loss: 3.69532\n",
      "[epoch 248, batch    17] loss: 3.44476\n",
      "[epoch 248, batch    18] loss: 4.18445\n",
      "[epoch 248, batch    19] loss: 3.79333\n",
      "[epoch 248, batch    20] loss: 3.28648\n",
      "[epoch 248, batch    21] loss: 3.49615\n",
      "[epoch 248, batch    22] loss: 2.78629\n",
      "[epoch 248, batch    23] loss: 2.59491\n",
      "[epoch 248, batch    24] loss: 2.85986\n",
      "[epoch 248, batch    25] loss: 3.33162\n",
      "[epoch 248, batch    26] loss: 2.91409\n",
      "[epoch 248, batch    27] loss: 2.38231\n",
      "[epoch 248, batch    28] loss: 2.65428\n",
      "[epoch 248, batch    29] loss: 3.56108\n",
      "[epoch 248, batch    30] loss: 2.66637\n",
      "[epoch 248, batch    31] loss: 3.48371\n",
      "[epoch 248, batch    32] loss: 1.99464\n",
      "[epoch 249, batch     1] loss: 3.66659\n",
      "[epoch 249, batch     2] loss: 3.53387\n",
      "[epoch 249, batch     3] loss: 3.69662\n",
      "[epoch 249, batch     4] loss: 3.19001\n",
      "[epoch 249, batch     5] loss: 3.46731\n",
      "[epoch 249, batch     6] loss: 2.94862\n",
      "[epoch 249, batch     7] loss: 2.91966\n",
      "[epoch 249, batch     8] loss: 3.74717\n",
      "[epoch 249, batch     9] loss: 2.77106\n",
      "[epoch 249, batch    10] loss: 2.74262\n",
      "[epoch 249, batch    11] loss: 3.44719\n",
      "[epoch 249, batch    12] loss: 2.85342\n",
      "[epoch 249, batch    13] loss: 2.51759\n",
      "[epoch 249, batch    14] loss: 2.87949\n",
      "[epoch 249, batch    15] loss: 2.77835\n",
      "[epoch 249, batch    16] loss: 3.23166\n",
      "[epoch 249, batch    17] loss: 2.94047\n",
      "[epoch 249, batch    18] loss: 3.37384\n",
      "[epoch 249, batch    19] loss: 2.67228\n",
      "[epoch 249, batch    20] loss: 1.97105\n",
      "[epoch 249, batch    21] loss: 2.11883\n",
      "[epoch 249, batch    22] loss: 3.62554\n",
      "[epoch 249, batch    23] loss: 3.73185\n",
      "[epoch 249, batch    24] loss: 2.61548\n",
      "[epoch 249, batch    25] loss: 3.85850\n",
      "[epoch 249, batch    26] loss: 3.14093\n",
      "[epoch 249, batch    27] loss: 2.41706\n",
      "[epoch 249, batch    28] loss: 3.25395\n",
      "[epoch 249, batch    29] loss: 2.66900\n",
      "[epoch 249, batch    30] loss: 2.31247\n",
      "[epoch 249, batch    31] loss: 2.79406\n",
      "[epoch 249, batch    32] loss: 3.40678\n",
      "[epoch 250, batch     1] loss: 2.93144\n",
      "[epoch 250, batch     2] loss: 2.77469\n",
      "[epoch 250, batch     3] loss: 2.85808\n",
      "[epoch 250, batch     4] loss: 3.73384\n",
      "[epoch 250, batch     5] loss: 2.66141\n",
      "[epoch 250, batch     6] loss: 2.51769\n",
      "[epoch 250, batch     7] loss: 3.36193\n",
      "[epoch 250, batch     8] loss: 3.12633\n",
      "[epoch 250, batch     9] loss: 2.81216\n",
      "[epoch 250, batch    10] loss: 3.02020\n",
      "[epoch 250, batch    11] loss: 3.63612\n",
      "[epoch 250, batch    12] loss: 2.67794\n",
      "[epoch 250, batch    13] loss: 1.95732\n",
      "[epoch 250, batch    14] loss: 3.78785\n",
      "[epoch 250, batch    15] loss: 2.80972\n",
      "[epoch 250, batch    16] loss: 3.33417\n",
      "[epoch 250, batch    17] loss: 3.72259\n",
      "[epoch 250, batch    18] loss: 3.95708\n",
      "[epoch 250, batch    19] loss: 2.36168\n",
      "[epoch 250, batch    20] loss: 3.05914\n",
      "[epoch 250, batch    21] loss: 2.95350\n",
      "[epoch 250, batch    22] loss: 2.96454\n",
      "[epoch 250, batch    23] loss: 3.55959\n",
      "[epoch 250, batch    24] loss: 2.45444\n",
      "[epoch 250, batch    25] loss: 3.18393\n",
      "[epoch 250, batch    26] loss: 3.20334\n",
      "[epoch 250, batch    27] loss: 2.93456\n",
      "[epoch 250, batch    28] loss: 3.32089\n",
      "[epoch 250, batch    29] loss: 3.06919\n",
      "[epoch 250, batch    30] loss: 3.28451\n",
      "[epoch 250, batch    31] loss: 2.46098\n",
      "[epoch 250, batch    32] loss: 2.70961\n",
      "[epoch 251, batch     1] loss: 2.96154\n",
      "[epoch 251, batch     2] loss: 3.68220\n",
      "[epoch 251, batch     3] loss: 3.78026\n",
      "[epoch 251, batch     4] loss: 3.01635\n",
      "[epoch 251, batch     5] loss: 3.24231\n",
      "[epoch 251, batch     6] loss: 3.08493\n",
      "[epoch 251, batch     7] loss: 2.04578\n",
      "[epoch 251, batch     8] loss: 1.66367\n",
      "[epoch 251, batch     9] loss: 3.18107\n",
      "[epoch 251, batch    10] loss: 3.09260\n",
      "[epoch 251, batch    11] loss: 2.47745\n",
      "[epoch 251, batch    12] loss: 2.16405\n",
      "[epoch 251, batch    13] loss: 3.64364\n",
      "[epoch 251, batch    14] loss: 3.49611\n",
      "[epoch 251, batch    15] loss: 2.52768\n",
      "[epoch 251, batch    16] loss: 3.23707\n",
      "[epoch 251, batch    17] loss: 3.45646\n",
      "[epoch 251, batch    18] loss: 3.57530\n",
      "[epoch 251, batch    19] loss: 3.15091\n",
      "[epoch 251, batch    20] loss: 2.77631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 251, batch    21] loss: 3.41745\n",
      "[epoch 251, batch    22] loss: 2.49489\n",
      "[epoch 251, batch    23] loss: 2.94030\n",
      "[epoch 251, batch    24] loss: 3.47098\n",
      "[epoch 251, batch    25] loss: 2.65360\n",
      "[epoch 251, batch    26] loss: 3.55423\n",
      "[epoch 251, batch    27] loss: 2.86420\n",
      "[epoch 251, batch    28] loss: 3.16325\n",
      "[epoch 251, batch    29] loss: 2.42896\n",
      "[epoch 251, batch    30] loss: 3.49474\n",
      "[epoch 251, batch    31] loss: 3.65814\n",
      "[epoch 251, batch    32] loss: 2.25935\n",
      "[epoch 252, batch     1] loss: 4.39988\n",
      "[epoch 252, batch     2] loss: 3.00898\n",
      "[epoch 252, batch     3] loss: 2.80408\n",
      "[epoch 252, batch     4] loss: 3.04238\n",
      "[epoch 252, batch     5] loss: 2.72683\n",
      "[epoch 252, batch     6] loss: 2.52089\n",
      "[epoch 252, batch     7] loss: 2.36616\n",
      "[epoch 252, batch     8] loss: 2.61361\n",
      "[epoch 252, batch     9] loss: 2.40179\n",
      "[epoch 252, batch    10] loss: 3.32554\n",
      "[epoch 252, batch    11] loss: 2.74473\n",
      "[epoch 252, batch    12] loss: 3.07405\n",
      "[epoch 252, batch    13] loss: 2.87683\n",
      "[epoch 252, batch    14] loss: 3.83820\n",
      "[epoch 252, batch    15] loss: 3.40427\n",
      "[epoch 252, batch    16] loss: 2.55994\n",
      "[epoch 252, batch    17] loss: 3.04180\n",
      "[epoch 252, batch    18] loss: 2.98138\n",
      "[epoch 252, batch    19] loss: 3.20409\n",
      "[epoch 252, batch    20] loss: 3.23599\n",
      "[epoch 252, batch    21] loss: 3.02040\n",
      "[epoch 252, batch    22] loss: 2.92418\n",
      "[epoch 252, batch    23] loss: 3.03013\n",
      "[epoch 252, batch    24] loss: 2.78057\n",
      "[epoch 252, batch    25] loss: 3.15228\n",
      "[epoch 252, batch    26] loss: 3.44644\n",
      "[epoch 252, batch    27] loss: 3.23059\n",
      "[epoch 252, batch    28] loss: 3.39973\n",
      "[epoch 252, batch    29] loss: 2.73644\n",
      "[epoch 252, batch    30] loss: 4.05050\n",
      "[epoch 252, batch    31] loss: 2.63058\n",
      "[epoch 252, batch    32] loss: 2.81648\n",
      "[epoch 253, batch     1] loss: 3.25970\n",
      "[epoch 253, batch     2] loss: 2.95594\n",
      "[epoch 253, batch     3] loss: 2.71422\n",
      "[epoch 253, batch     4] loss: 3.74783\n",
      "[epoch 253, batch     5] loss: 3.67935\n",
      "[epoch 253, batch     6] loss: 3.42107\n",
      "[epoch 253, batch     7] loss: 2.56062\n",
      "[epoch 253, batch     8] loss: 3.13654\n",
      "[epoch 253, batch     9] loss: 3.19160\n",
      "[epoch 253, batch    10] loss: 2.96535\n",
      "[epoch 253, batch    11] loss: 3.50811\n",
      "[epoch 253, batch    12] loss: 3.29019\n",
      "[epoch 253, batch    13] loss: 3.18875\n",
      "[epoch 253, batch    14] loss: 3.02961\n",
      "[epoch 253, batch    15] loss: 3.22411\n",
      "[epoch 253, batch    16] loss: 3.80022\n",
      "[epoch 253, batch    17] loss: 2.45902\n",
      "[epoch 253, batch    18] loss: 2.31674\n",
      "[epoch 253, batch    19] loss: 3.46073\n",
      "[epoch 253, batch    20] loss: 2.20205\n",
      "[epoch 253, batch    21] loss: 2.94039\n",
      "[epoch 253, batch    22] loss: 2.59583\n",
      "[epoch 253, batch    23] loss: 2.80248\n",
      "[epoch 253, batch    24] loss: 2.49380\n",
      "[epoch 253, batch    25] loss: 2.89279\n",
      "[epoch 253, batch    26] loss: 2.87367\n",
      "[epoch 253, batch    27] loss: 3.16976\n",
      "[epoch 253, batch    28] loss: 3.24590\n",
      "[epoch 253, batch    29] loss: 3.11864\n",
      "[epoch 253, batch    30] loss: 2.41435\n",
      "[epoch 253, batch    31] loss: 3.66921\n",
      "[epoch 253, batch    32] loss: 3.04384\n",
      "[epoch 254, batch     1] loss: 3.48794\n",
      "[epoch 254, batch     2] loss: 3.05364\n",
      "[epoch 254, batch     3] loss: 3.32331\n",
      "[epoch 254, batch     4] loss: 2.32183\n",
      "[epoch 254, batch     5] loss: 2.15256\n",
      "[epoch 254, batch     6] loss: 3.06163\n",
      "[epoch 254, batch     7] loss: 2.01974\n",
      "[epoch 254, batch     8] loss: 3.14446\n",
      "[epoch 254, batch     9] loss: 3.44462\n",
      "[epoch 254, batch    10] loss: 4.09081\n",
      "[epoch 254, batch    11] loss: 2.78720\n",
      "[epoch 254, batch    12] loss: 2.48002\n",
      "[epoch 254, batch    13] loss: 2.57803\n",
      "[epoch 254, batch    14] loss: 3.32631\n",
      "[epoch 254, batch    15] loss: 2.85958\n",
      "[epoch 254, batch    16] loss: 3.43634\n",
      "[epoch 254, batch    17] loss: 2.56013\n",
      "[epoch 254, batch    18] loss: 2.17690\n",
      "[epoch 254, batch    19] loss: 3.07902\n",
      "[epoch 254, batch    20] loss: 3.60726\n",
      "[epoch 254, batch    21] loss: 3.30105\n",
      "[epoch 254, batch    22] loss: 3.30907\n",
      "[epoch 254, batch    23] loss: 2.96875\n",
      "[epoch 254, batch    24] loss: 3.53770\n",
      "[epoch 254, batch    25] loss: 3.21249\n",
      "[epoch 254, batch    26] loss: 3.96954\n",
      "[epoch 254, batch    27] loss: 3.10717\n",
      "[epoch 254, batch    28] loss: 2.67970\n",
      "[epoch 254, batch    29] loss: 2.14144\n",
      "[epoch 254, batch    30] loss: 3.31751\n",
      "[epoch 254, batch    31] loss: 3.21798\n",
      "[epoch 254, batch    32] loss: 3.38709\n",
      "[epoch 255, batch     1] loss: 3.05946\n",
      "[epoch 255, batch     2] loss: 3.69697\n",
      "[epoch 255, batch     3] loss: 2.72785\n",
      "[epoch 255, batch     4] loss: 3.12522\n",
      "[epoch 255, batch     5] loss: 1.90861\n",
      "[epoch 255, batch     6] loss: 3.01371\n",
      "[epoch 255, batch     7] loss: 3.22611\n",
      "[epoch 255, batch     8] loss: 2.58424\n",
      "[epoch 255, batch     9] loss: 2.17986\n",
      "[epoch 255, batch    10] loss: 3.88964\n",
      "[epoch 255, batch    11] loss: 2.64995\n",
      "[epoch 255, batch    12] loss: 2.72309\n",
      "[epoch 255, batch    13] loss: 3.46949\n",
      "[epoch 255, batch    14] loss: 3.20008\n",
      "[epoch 255, batch    15] loss: 3.83805\n",
      "[epoch 255, batch    16] loss: 2.82585\n",
      "[epoch 255, batch    17] loss: 3.34896\n",
      "[epoch 255, batch    18] loss: 3.06039\n",
      "[epoch 255, batch    19] loss: 3.19496\n",
      "[epoch 255, batch    20] loss: 2.83435\n",
      "[epoch 255, batch    21] loss: 4.51864\n",
      "[epoch 255, batch    22] loss: 2.78266\n",
      "[epoch 255, batch    23] loss: 2.44452\n",
      "[epoch 255, batch    24] loss: 2.52538\n",
      "[epoch 255, batch    25] loss: 2.58763\n",
      "[epoch 255, batch    26] loss: 3.64392\n",
      "[epoch 255, batch    27] loss: 3.79707\n",
      "[epoch 255, batch    28] loss: 3.12694\n",
      "[epoch 255, batch    29] loss: 2.80439\n",
      "[epoch 255, batch    30] loss: 2.98362\n",
      "[epoch 255, batch    31] loss: 2.61790\n",
      "[epoch 255, batch    32] loss: 1.49285\n",
      "[epoch 256, batch     1] loss: 2.56990\n",
      "[epoch 256, batch     2] loss: 3.24701\n",
      "[epoch 256, batch     3] loss: 2.53134\n",
      "[epoch 256, batch     4] loss: 3.15368\n",
      "[epoch 256, batch     5] loss: 3.71819\n",
      "[epoch 256, batch     6] loss: 2.86841\n",
      "[epoch 256, batch     7] loss: 2.89717\n",
      "[epoch 256, batch     8] loss: 3.49821\n",
      "[epoch 256, batch     9] loss: 2.64978\n",
      "[epoch 256, batch    10] loss: 4.21447\n",
      "[epoch 256, batch    11] loss: 3.75599\n",
      "[epoch 256, batch    12] loss: 4.03906\n",
      "[epoch 256, batch    13] loss: 2.51805\n",
      "[epoch 256, batch    14] loss: 2.16363\n",
      "[epoch 256, batch    15] loss: 3.30432\n",
      "[epoch 256, batch    16] loss: 2.68863\n",
      "[epoch 256, batch    17] loss: 3.75349\n",
      "[epoch 256, batch    18] loss: 3.47472\n",
      "[epoch 256, batch    19] loss: 3.36431\n",
      "[epoch 256, batch    20] loss: 2.64004\n",
      "[epoch 256, batch    21] loss: 3.05465\n",
      "[epoch 256, batch    22] loss: 2.44951\n",
      "[epoch 256, batch    23] loss: 3.07914\n",
      "[epoch 256, batch    24] loss: 2.65726\n",
      "[epoch 256, batch    25] loss: 2.58597\n",
      "[epoch 256, batch    26] loss: 3.50169\n",
      "[epoch 256, batch    27] loss: 2.07481\n",
      "[epoch 256, batch    28] loss: 2.88870\n",
      "[epoch 256, batch    29] loss: 3.23281\n",
      "[epoch 256, batch    30] loss: 3.34513\n",
      "[epoch 256, batch    31] loss: 3.05637\n",
      "[epoch 256, batch    32] loss: 1.91120\n",
      "[epoch 257, batch     1] loss: 2.64533\n",
      "[epoch 257, batch     2] loss: 3.23414\n",
      "[epoch 257, batch     3] loss: 2.49442\n",
      "[epoch 257, batch     4] loss: 3.81669\n",
      "[epoch 257, batch     5] loss: 3.07416\n",
      "[epoch 257, batch     6] loss: 3.79040\n",
      "[epoch 257, batch     7] loss: 3.20025\n",
      "[epoch 257, batch     8] loss: 2.22914\n",
      "[epoch 257, batch     9] loss: 3.21611\n",
      "[epoch 257, batch    10] loss: 3.22140\n",
      "[epoch 257, batch    11] loss: 3.02916\n",
      "[epoch 257, batch    12] loss: 2.75759\n",
      "[epoch 257, batch    13] loss: 3.54711\n",
      "[epoch 257, batch    14] loss: 3.54690\n",
      "[epoch 257, batch    15] loss: 2.41157\n",
      "[epoch 257, batch    16] loss: 3.04697\n",
      "[epoch 257, batch    17] loss: 3.03369\n",
      "[epoch 257, batch    18] loss: 3.29973\n",
      "[epoch 257, batch    19] loss: 3.02197\n",
      "[epoch 257, batch    20] loss: 2.46809\n",
      "[epoch 257, batch    21] loss: 2.26774\n",
      "[epoch 257, batch    22] loss: 3.16556\n",
      "[epoch 257, batch    23] loss: 2.06289\n",
      "[epoch 257, batch    24] loss: 2.96152\n",
      "[epoch 257, batch    25] loss: 3.17568\n",
      "[epoch 257, batch    26] loss: 3.14322\n",
      "[epoch 257, batch    27] loss: 3.36290\n",
      "[epoch 257, batch    28] loss: 3.74279\n",
      "[epoch 257, batch    29] loss: 3.14630\n",
      "[epoch 257, batch    30] loss: 2.66392\n",
      "[epoch 257, batch    31] loss: 3.23283\n",
      "[epoch 257, batch    32] loss: 2.22424\n",
      "[epoch 258, batch     1] loss: 3.17567\n",
      "[epoch 258, batch     2] loss: 2.34564\n",
      "[epoch 258, batch     3] loss: 2.53254\n",
      "[epoch 258, batch     4] loss: 2.98469\n",
      "[epoch 258, batch     5] loss: 3.14624\n",
      "[epoch 258, batch     6] loss: 3.97750\n",
      "[epoch 258, batch     7] loss: 3.66301\n",
      "[epoch 258, batch     8] loss: 2.69275\n",
      "[epoch 258, batch     9] loss: 3.11451\n",
      "[epoch 258, batch    10] loss: 2.88204\n",
      "[epoch 258, batch    11] loss: 3.09143\n",
      "[epoch 258, batch    12] loss: 2.67974\n",
      "[epoch 258, batch    13] loss: 2.83115\n",
      "[epoch 258, batch    14] loss: 3.22295\n",
      "[epoch 258, batch    15] loss: 2.56689\n",
      "[epoch 258, batch    16] loss: 3.33117\n",
      "[epoch 258, batch    17] loss: 3.44659\n",
      "[epoch 258, batch    18] loss: 3.24484\n",
      "[epoch 258, batch    19] loss: 2.50381\n",
      "[epoch 258, batch    20] loss: 3.07188\n",
      "[epoch 258, batch    21] loss: 3.34473\n",
      "[epoch 258, batch    22] loss: 3.19434\n",
      "[epoch 258, batch    23] loss: 3.17921\n",
      "[epoch 258, batch    24] loss: 2.78116\n",
      "[epoch 258, batch    25] loss: 2.59043\n",
      "[epoch 258, batch    26] loss: 3.53981\n",
      "[epoch 258, batch    27] loss: 3.48918\n",
      "[epoch 258, batch    28] loss: 3.39229\n",
      "[epoch 258, batch    29] loss: 2.74845\n",
      "[epoch 258, batch    30] loss: 2.44578\n",
      "[epoch 258, batch    31] loss: 2.88485\n",
      "[epoch 258, batch    32] loss: 4.46221\n",
      "[epoch 259, batch     1] loss: 2.64442\n",
      "[epoch 259, batch     2] loss: 3.44215\n",
      "[epoch 259, batch     3] loss: 3.70138\n",
      "[epoch 259, batch     4] loss: 3.89203\n",
      "[epoch 259, batch     5] loss: 3.21261\n",
      "[epoch 259, batch     6] loss: 2.71603\n",
      "[epoch 259, batch     7] loss: 2.76525\n",
      "[epoch 259, batch     8] loss: 3.14738\n",
      "[epoch 259, batch     9] loss: 3.32240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 259, batch    10] loss: 1.98076\n",
      "[epoch 259, batch    11] loss: 3.28083\n",
      "[epoch 259, batch    12] loss: 2.56010\n",
      "[epoch 259, batch    13] loss: 3.52068\n",
      "[epoch 259, batch    14] loss: 2.04889\n",
      "[epoch 259, batch    15] loss: 3.01438\n",
      "[epoch 259, batch    16] loss: 3.28756\n",
      "[epoch 259, batch    17] loss: 3.45929\n",
      "[epoch 259, batch    18] loss: 3.57518\n",
      "[epoch 259, batch    19] loss: 2.92808\n",
      "[epoch 259, batch    20] loss: 3.33324\n",
      "[epoch 259, batch    21] loss: 2.66633\n",
      "[epoch 259, batch    22] loss: 2.47200\n",
      "[epoch 259, batch    23] loss: 3.16073\n",
      "[epoch 259, batch    24] loss: 2.94515\n",
      "[epoch 259, batch    25] loss: 2.92690\n",
      "[epoch 259, batch    26] loss: 3.05031\n",
      "[epoch 259, batch    27] loss: 3.38355\n",
      "[epoch 259, batch    28] loss: 3.42743\n",
      "[epoch 259, batch    29] loss: 2.63551\n",
      "[epoch 259, batch    30] loss: 3.18850\n",
      "[epoch 259, batch    31] loss: 2.21958\n",
      "[epoch 259, batch    32] loss: 4.86338\n",
      "[epoch 260, batch     1] loss: 2.97956\n",
      "[epoch 260, batch     2] loss: 3.08024\n",
      "[epoch 260, batch     3] loss: 2.58931\n",
      "[epoch 260, batch     4] loss: 2.86463\n",
      "[epoch 260, batch     5] loss: 2.98684\n",
      "[epoch 260, batch     6] loss: 3.04340\n",
      "[epoch 260, batch     7] loss: 3.24618\n",
      "[epoch 260, batch     8] loss: 2.95244\n",
      "[epoch 260, batch     9] loss: 2.22959\n",
      "[epoch 260, batch    10] loss: 2.11622\n",
      "[epoch 260, batch    11] loss: 3.57782\n",
      "[epoch 260, batch    12] loss: 3.41550\n",
      "[epoch 260, batch    13] loss: 2.72794\n",
      "[epoch 260, batch    14] loss: 3.66621\n",
      "[epoch 260, batch    15] loss: 2.33597\n",
      "[epoch 260, batch    16] loss: 2.85477\n",
      "[epoch 260, batch    17] loss: 3.09069\n",
      "[epoch 260, batch    18] loss: 2.95718\n",
      "[epoch 260, batch    19] loss: 3.83252\n",
      "[epoch 260, batch    20] loss: 3.56463\n",
      "[epoch 260, batch    21] loss: 3.51715\n",
      "[epoch 260, batch    22] loss: 1.64214\n",
      "[epoch 260, batch    23] loss: 2.88350\n",
      "[epoch 260, batch    24] loss: 3.08130\n",
      "[epoch 260, batch    25] loss: 3.97724\n",
      "[epoch 260, batch    26] loss: 3.34167\n",
      "[epoch 260, batch    27] loss: 2.82143\n",
      "[epoch 260, batch    28] loss: 3.66992\n",
      "[epoch 260, batch    29] loss: 3.04366\n",
      "[epoch 260, batch    30] loss: 2.31636\n",
      "[epoch 260, batch    31] loss: 4.21000\n",
      "[epoch 260, batch    32] loss: 2.76076\n",
      "[epoch 261, batch     1] loss: 3.44473\n",
      "[epoch 261, batch     2] loss: 3.73063\n",
      "[epoch 261, batch     3] loss: 2.46488\n",
      "[epoch 261, batch     4] loss: 2.53942\n",
      "[epoch 261, batch     5] loss: 2.91613\n",
      "[epoch 261, batch     6] loss: 2.42914\n",
      "[epoch 261, batch     7] loss: 3.29083\n",
      "[epoch 261, batch     8] loss: 3.61383\n",
      "[epoch 261, batch     9] loss: 3.43163\n",
      "[epoch 261, batch    10] loss: 2.60591\n",
      "[epoch 261, batch    11] loss: 3.67192\n",
      "[epoch 261, batch    12] loss: 3.19711\n",
      "[epoch 261, batch    13] loss: 3.42593\n",
      "[epoch 261, batch    14] loss: 2.61215\n",
      "[epoch 261, batch    15] loss: 2.87578\n",
      "[epoch 261, batch    16] loss: 3.38776\n",
      "[epoch 261, batch    17] loss: 2.37151\n",
      "[epoch 261, batch    18] loss: 4.36274\n",
      "[epoch 261, batch    19] loss: 3.23966\n",
      "[epoch 261, batch    20] loss: 3.16622\n",
      "[epoch 261, batch    21] loss: 2.64159\n",
      "[epoch 261, batch    22] loss: 3.29603\n",
      "[epoch 261, batch    23] loss: 2.68398\n",
      "[epoch 261, batch    24] loss: 2.68546\n",
      "[epoch 261, batch    25] loss: 2.63179\n",
      "[epoch 261, batch    26] loss: 3.36303\n",
      "[epoch 261, batch    27] loss: 2.98442\n",
      "[epoch 261, batch    28] loss: 3.15262\n",
      "[epoch 261, batch    29] loss: 2.51644\n",
      "[epoch 261, batch    30] loss: 3.34001\n",
      "[epoch 261, batch    31] loss: 1.99218\n",
      "[epoch 261, batch    32] loss: 2.36271\n",
      "[epoch 262, batch     1] loss: 2.93370\n",
      "[epoch 262, batch     2] loss: 3.07573\n",
      "[epoch 262, batch     3] loss: 3.28647\n",
      "[epoch 262, batch     4] loss: 3.62215\n",
      "[epoch 262, batch     5] loss: 2.44088\n",
      "[epoch 262, batch     6] loss: 2.83500\n",
      "[epoch 262, batch     7] loss: 2.84434\n",
      "[epoch 262, batch     8] loss: 3.39141\n",
      "[epoch 262, batch     9] loss: 3.46464\n",
      "[epoch 262, batch    10] loss: 3.66992\n",
      "[epoch 262, batch    11] loss: 2.69195\n",
      "[epoch 262, batch    12] loss: 2.73294\n",
      "[epoch 262, batch    13] loss: 2.43803\n",
      "[epoch 262, batch    14] loss: 3.11304\n",
      "[epoch 262, batch    15] loss: 4.36896\n",
      "[epoch 262, batch    16] loss: 2.80800\n",
      "[epoch 262, batch    17] loss: 2.91264\n",
      "[epoch 262, batch    18] loss: 4.10147\n",
      "[epoch 262, batch    19] loss: 2.12263\n",
      "[epoch 262, batch    20] loss: 3.28292\n",
      "[epoch 262, batch    21] loss: 3.02826\n",
      "[epoch 262, batch    22] loss: 2.29192\n",
      "[epoch 262, batch    23] loss: 3.17921\n",
      "[epoch 262, batch    24] loss: 3.34916\n",
      "[epoch 262, batch    25] loss: 3.16269\n",
      "[epoch 262, batch    26] loss: 3.59183\n",
      "[epoch 262, batch    27] loss: 2.66485\n",
      "[epoch 262, batch    28] loss: 2.19028\n",
      "[epoch 262, batch    29] loss: 3.03123\n",
      "[epoch 262, batch    30] loss: 2.83869\n",
      "[epoch 262, batch    31] loss: 3.20912\n",
      "[epoch 262, batch    32] loss: 2.64767\n",
      "[epoch 263, batch     1] loss: 2.63311\n",
      "[epoch 263, batch     2] loss: 3.35907\n",
      "[epoch 263, batch     3] loss: 3.37858\n",
      "[epoch 263, batch     4] loss: 2.63293\n",
      "[epoch 263, batch     5] loss: 2.90770\n",
      "[epoch 263, batch     6] loss: 2.27650\n",
      "[epoch 263, batch     7] loss: 4.09627\n",
      "[epoch 263, batch     8] loss: 3.30359\n",
      "[epoch 263, batch     9] loss: 2.76442\n",
      "[epoch 263, batch    10] loss: 2.57700\n",
      "[epoch 263, batch    11] loss: 2.83242\n",
      "[epoch 263, batch    12] loss: 2.85788\n",
      "[epoch 263, batch    13] loss: 2.67315\n",
      "[epoch 263, batch    14] loss: 2.36560\n",
      "[epoch 263, batch    15] loss: 3.32346\n",
      "[epoch 263, batch    16] loss: 3.46980\n",
      "[epoch 263, batch    17] loss: 2.51821\n",
      "[epoch 263, batch    18] loss: 3.94885\n",
      "[epoch 263, batch    19] loss: 3.56554\n",
      "[epoch 263, batch    20] loss: 2.67508\n",
      "[epoch 263, batch    21] loss: 2.59549\n",
      "[epoch 263, batch    22] loss: 3.36537\n",
      "[epoch 263, batch    23] loss: 2.48505\n",
      "[epoch 263, batch    24] loss: 3.36908\n",
      "[epoch 263, batch    25] loss: 3.08919\n",
      "[epoch 263, batch    26] loss: 3.42928\n",
      "[epoch 263, batch    27] loss: 3.87412\n",
      "[epoch 263, batch    28] loss: 3.00839\n",
      "[epoch 263, batch    29] loss: 3.58658\n",
      "[epoch 263, batch    30] loss: 2.90682\n",
      "[epoch 263, batch    31] loss: 2.38836\n",
      "[epoch 263, batch    32] loss: 2.89681\n",
      "[epoch 264, batch     1] loss: 2.95081\n",
      "[epoch 264, batch     2] loss: 3.47038\n",
      "[epoch 264, batch     3] loss: 3.52040\n",
      "[epoch 264, batch     4] loss: 2.80934\n",
      "[epoch 264, batch     5] loss: 2.34076\n",
      "[epoch 264, batch     6] loss: 3.62797\n",
      "[epoch 264, batch     7] loss: 2.80556\n",
      "[epoch 264, batch     8] loss: 2.46176\n",
      "[epoch 264, batch     9] loss: 2.71714\n",
      "[epoch 264, batch    10] loss: 3.03625\n",
      "[epoch 264, batch    11] loss: 3.22702\n",
      "[epoch 264, batch    12] loss: 3.03897\n",
      "[epoch 264, batch    13] loss: 2.72818\n",
      "[epoch 264, batch    14] loss: 2.26930\n",
      "[epoch 264, batch    15] loss: 3.32138\n",
      "[epoch 264, batch    16] loss: 2.11636\n",
      "[epoch 264, batch    17] loss: 2.49166\n",
      "[epoch 264, batch    18] loss: 2.90481\n",
      "[epoch 264, batch    19] loss: 3.76319\n",
      "[epoch 264, batch    20] loss: 3.39508\n",
      "[epoch 264, batch    21] loss: 3.52115\n",
      "[epoch 264, batch    22] loss: 3.44304\n",
      "[epoch 264, batch    23] loss: 2.62586\n",
      "[epoch 264, batch    24] loss: 3.35562\n",
      "[epoch 264, batch    25] loss: 2.12814\n",
      "[epoch 264, batch    26] loss: 2.81340\n",
      "[epoch 264, batch    27] loss: 3.61012\n",
      "[epoch 264, batch    28] loss: 2.81829\n",
      "[epoch 264, batch    29] loss: 3.66553\n",
      "[epoch 264, batch    30] loss: 3.08667\n",
      "[epoch 264, batch    31] loss: 3.63967\n",
      "[epoch 264, batch    32] loss: 3.54290\n",
      "[epoch 265, batch     1] loss: 2.35206\n",
      "[epoch 265, batch     2] loss: 3.00678\n",
      "[epoch 265, batch     3] loss: 3.02231\n",
      "[epoch 265, batch     4] loss: 2.43682\n",
      "[epoch 265, batch     5] loss: 2.85012\n",
      "[epoch 265, batch     6] loss: 2.47447\n",
      "[epoch 265, batch     7] loss: 3.31760\n",
      "[epoch 265, batch     8] loss: 2.88788\n",
      "[epoch 265, batch     9] loss: 3.53236\n",
      "[epoch 265, batch    10] loss: 3.59465\n",
      "[epoch 265, batch    11] loss: 3.46050\n",
      "[epoch 265, batch    12] loss: 3.03504\n",
      "[epoch 265, batch    13] loss: 2.63536\n",
      "[epoch 265, batch    14] loss: 3.42035\n",
      "[epoch 265, batch    15] loss: 3.50448\n",
      "[epoch 265, batch    16] loss: 2.54850\n",
      "[epoch 265, batch    17] loss: 2.56686\n",
      "[epoch 265, batch    18] loss: 3.10247\n",
      "[epoch 265, batch    19] loss: 3.56480\n",
      "[epoch 265, batch    20] loss: 2.65685\n",
      "[epoch 265, batch    21] loss: 2.54881\n",
      "[epoch 265, batch    22] loss: 3.17510\n",
      "[epoch 265, batch    23] loss: 3.48219\n",
      "[epoch 265, batch    24] loss: 3.02990\n",
      "[epoch 265, batch    25] loss: 3.27041\n",
      "[epoch 265, batch    26] loss: 2.93934\n",
      "[epoch 265, batch    27] loss: 3.36869\n",
      "[epoch 265, batch    28] loss: 3.34350\n",
      "[epoch 265, batch    29] loss: 3.20238\n",
      "[epoch 265, batch    30] loss: 3.06002\n",
      "[epoch 265, batch    31] loss: 2.24046\n",
      "[epoch 265, batch    32] loss: 3.96114\n",
      "[epoch 266, batch     1] loss: 2.99754\n",
      "[epoch 266, batch     2] loss: 2.48453\n",
      "[epoch 266, batch     3] loss: 1.88212\n",
      "[epoch 266, batch     4] loss: 2.35867\n",
      "[epoch 266, batch     5] loss: 3.12620\n",
      "[epoch 266, batch     6] loss: 3.55058\n",
      "[epoch 266, batch     7] loss: 2.80187\n",
      "[epoch 266, batch     8] loss: 3.44344\n",
      "[epoch 266, batch     9] loss: 3.54864\n",
      "[epoch 266, batch    10] loss: 2.61455\n",
      "[epoch 266, batch    11] loss: 2.95985\n",
      "[epoch 266, batch    12] loss: 2.25156\n",
      "[epoch 266, batch    13] loss: 2.95126\n",
      "[epoch 266, batch    14] loss: 2.43749\n",
      "[epoch 266, batch    15] loss: 3.08386\n",
      "[epoch 266, batch    16] loss: 3.20071\n",
      "[epoch 266, batch    17] loss: 3.71517\n",
      "[epoch 266, batch    18] loss: 3.23176\n",
      "[epoch 266, batch    19] loss: 3.32080\n",
      "[epoch 266, batch    20] loss: 3.59271\n",
      "[epoch 266, batch    21] loss: 3.19600\n",
      "[epoch 266, batch    22] loss: 3.52589\n",
      "[epoch 266, batch    23] loss: 3.27351\n",
      "[epoch 266, batch    24] loss: 3.08488\n",
      "[epoch 266, batch    25] loss: 3.27205\n",
      "[epoch 266, batch    26] loss: 2.15635\n",
      "[epoch 266, batch    27] loss: 3.37533\n",
      "[epoch 266, batch    28] loss: 2.80481\n",
      "[epoch 266, batch    29] loss: 2.96782\n",
      "[epoch 266, batch    30] loss: 2.85518\n",
      "[epoch 266, batch    31] loss: 3.33470\n",
      "[epoch 266, batch    32] loss: 5.35507\n",
      "[epoch 267, batch     1] loss: 3.14721\n",
      "[epoch 267, batch     2] loss: 3.38606\n",
      "[epoch 267, batch     3] loss: 3.10585\n",
      "[epoch 267, batch     4] loss: 3.16414\n",
      "[epoch 267, batch     5] loss: 2.95279\n",
      "[epoch 267, batch     6] loss: 3.08593\n",
      "[epoch 267, batch     7] loss: 3.26638\n",
      "[epoch 267, batch     8] loss: 2.61670\n",
      "[epoch 267, batch     9] loss: 2.93864\n",
      "[epoch 267, batch    10] loss: 3.04509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 267, batch    11] loss: 2.63374\n",
      "[epoch 267, batch    12] loss: 3.55273\n",
      "[epoch 267, batch    13] loss: 2.81236\n",
      "[epoch 267, batch    14] loss: 2.89588\n",
      "[epoch 267, batch    15] loss: 3.15748\n",
      "[epoch 267, batch    16] loss: 3.35546\n",
      "[epoch 267, batch    17] loss: 2.64172\n",
      "[epoch 267, batch    18] loss: 2.60038\n",
      "[epoch 267, batch    19] loss: 2.84176\n",
      "[epoch 267, batch    20] loss: 2.68910\n",
      "[epoch 267, batch    21] loss: 3.12668\n",
      "[epoch 267, batch    22] loss: 2.36027\n",
      "[epoch 267, batch    23] loss: 3.30853\n",
      "[epoch 267, batch    24] loss: 2.99250\n",
      "[epoch 267, batch    25] loss: 2.16650\n",
      "[epoch 267, batch    26] loss: 3.59046\n",
      "[epoch 267, batch    27] loss: 3.43518\n",
      "[epoch 267, batch    28] loss: 3.08490\n",
      "[epoch 267, batch    29] loss: 3.77894\n",
      "[epoch 267, batch    30] loss: 3.58730\n",
      "[epoch 267, batch    31] loss: 2.87042\n",
      "[epoch 267, batch    32] loss: 3.90460\n",
      "[epoch 268, batch     1] loss: 3.28219\n",
      "[epoch 268, batch     2] loss: 3.25957\n",
      "[epoch 268, batch     3] loss: 2.66268\n",
      "[epoch 268, batch     4] loss: 1.74566\n",
      "[epoch 268, batch     5] loss: 3.61505\n",
      "[epoch 268, batch     6] loss: 2.89419\n",
      "[epoch 268, batch     7] loss: 4.18716\n",
      "[epoch 268, batch     8] loss: 3.96210\n",
      "[epoch 268, batch     9] loss: 3.19043\n",
      "[epoch 268, batch    10] loss: 2.32028\n",
      "[epoch 268, batch    11] loss: 2.72115\n",
      "[epoch 268, batch    12] loss: 3.02286\n",
      "[epoch 268, batch    13] loss: 2.91057\n",
      "[epoch 268, batch    14] loss: 3.65357\n",
      "[epoch 268, batch    15] loss: 3.45276\n",
      "[epoch 268, batch    16] loss: 2.89022\n",
      "[epoch 268, batch    17] loss: 2.51502\n",
      "[epoch 268, batch    18] loss: 3.29254\n",
      "[epoch 268, batch    19] loss: 2.30399\n",
      "[epoch 268, batch    20] loss: 3.80806\n",
      "[epoch 268, batch    21] loss: 1.78176\n",
      "[epoch 268, batch    22] loss: 3.31835\n",
      "[epoch 268, batch    23] loss: 2.87398\n",
      "[epoch 268, batch    24] loss: 3.42770\n",
      "[epoch 268, batch    25] loss: 3.07656\n",
      "[epoch 268, batch    26] loss: 2.79880\n",
      "[epoch 268, batch    27] loss: 3.04720\n",
      "[epoch 268, batch    28] loss: 3.09292\n",
      "[epoch 268, batch    29] loss: 2.60147\n",
      "[epoch 268, batch    30] loss: 2.84941\n",
      "[epoch 268, batch    31] loss: 3.65155\n",
      "[epoch 268, batch    32] loss: 1.99391\n",
      "[epoch 269, batch     1] loss: 3.37114\n",
      "[epoch 269, batch     2] loss: 3.81317\n",
      "[epoch 269, batch     3] loss: 2.38093\n",
      "[epoch 269, batch     4] loss: 3.11768\n",
      "[epoch 269, batch     5] loss: 3.52012\n",
      "[epoch 269, batch     6] loss: 2.70776\n",
      "[epoch 269, batch     7] loss: 2.64853\n",
      "[epoch 269, batch     8] loss: 2.97134\n",
      "[epoch 269, batch     9] loss: 2.81082\n",
      "[epoch 269, batch    10] loss: 3.95920\n",
      "[epoch 269, batch    11] loss: 3.10960\n",
      "[epoch 269, batch    12] loss: 3.49180\n",
      "[epoch 269, batch    13] loss: 2.26527\n",
      "[epoch 269, batch    14] loss: 3.06395\n",
      "[epoch 269, batch    15] loss: 3.03935\n",
      "[epoch 269, batch    16] loss: 3.30418\n",
      "[epoch 269, batch    17] loss: 3.56994\n",
      "[epoch 269, batch    18] loss: 3.48613\n",
      "[epoch 269, batch    19] loss: 2.50815\n",
      "[epoch 269, batch    20] loss: 3.42709\n",
      "[epoch 269, batch    21] loss: 2.57102\n",
      "[epoch 269, batch    22] loss: 3.23761\n",
      "[epoch 269, batch    23] loss: 2.88501\n",
      "[epoch 269, batch    24] loss: 3.33165\n",
      "[epoch 269, batch    25] loss: 2.92045\n",
      "[epoch 269, batch    26] loss: 2.75168\n",
      "[epoch 269, batch    27] loss: 2.76458\n",
      "[epoch 269, batch    28] loss: 2.78742\n",
      "[epoch 269, batch    29] loss: 2.85532\n",
      "[epoch 269, batch    30] loss: 2.92402\n",
      "[epoch 269, batch    31] loss: 2.51311\n",
      "[epoch 269, batch    32] loss: 2.62124\n",
      "[epoch 270, batch     1] loss: 3.34705\n",
      "[epoch 270, batch     2] loss: 3.45905\n",
      "[epoch 270, batch     3] loss: 2.89615\n",
      "[epoch 270, batch     4] loss: 3.90667\n",
      "[epoch 270, batch     5] loss: 2.83625\n",
      "[epoch 270, batch     6] loss: 3.63696\n",
      "[epoch 270, batch     7] loss: 2.39692\n",
      "[epoch 270, batch     8] loss: 2.14336\n",
      "[epoch 270, batch     9] loss: 2.64637\n",
      "[epoch 270, batch    10] loss: 2.40909\n",
      "[epoch 270, batch    11] loss: 2.43231\n",
      "[epoch 270, batch    12] loss: 3.04031\n",
      "[epoch 270, batch    13] loss: 4.01623\n",
      "[epoch 270, batch    14] loss: 3.24334\n",
      "[epoch 270, batch    15] loss: 2.34678\n",
      "[epoch 270, batch    16] loss: 3.39256\n",
      "[epoch 270, batch    17] loss: 2.53526\n",
      "[epoch 270, batch    18] loss: 3.32402\n",
      "[epoch 270, batch    19] loss: 2.82950\n",
      "[epoch 270, batch    20] loss: 4.07768\n",
      "[epoch 270, batch    21] loss: 2.86435\n",
      "[epoch 270, batch    22] loss: 3.68955\n",
      "[epoch 270, batch    23] loss: 2.59728\n",
      "[epoch 270, batch    24] loss: 2.21091\n",
      "[epoch 270, batch    25] loss: 2.28050\n",
      "[epoch 270, batch    26] loss: 2.72755\n",
      "[epoch 270, batch    27] loss: 2.89047\n",
      "[epoch 270, batch    28] loss: 2.93045\n",
      "[epoch 270, batch    29] loss: 3.87577\n",
      "[epoch 270, batch    30] loss: 4.18874\n",
      "[epoch 270, batch    31] loss: 3.04357\n",
      "[epoch 270, batch    32] loss: 2.14609\n",
      "[epoch 271, batch     1] loss: 2.75108\n",
      "[epoch 271, batch     2] loss: 2.44893\n",
      "[epoch 271, batch     3] loss: 2.66693\n",
      "[epoch 271, batch     4] loss: 2.87356\n",
      "[epoch 271, batch     5] loss: 3.30440\n",
      "[epoch 271, batch     6] loss: 3.57205\n",
      "[epoch 271, batch     7] loss: 2.78236\n",
      "[epoch 271, batch     8] loss: 2.80802\n",
      "[epoch 271, batch     9] loss: 2.60461\n",
      "[epoch 271, batch    10] loss: 4.46574\n",
      "[epoch 271, batch    11] loss: 2.38455\n",
      "[epoch 271, batch    12] loss: 3.58219\n",
      "[epoch 271, batch    13] loss: 3.48139\n",
      "[epoch 271, batch    14] loss: 2.27637\n",
      "[epoch 271, batch    15] loss: 3.31156\n",
      "[epoch 271, batch    16] loss: 3.41648\n",
      "[epoch 271, batch    17] loss: 3.65185\n",
      "[epoch 271, batch    18] loss: 2.76363\n",
      "[epoch 271, batch    19] loss: 3.79452\n",
      "[epoch 271, batch    20] loss: 2.51822\n",
      "[epoch 271, batch    21] loss: 2.69769\n",
      "[epoch 271, batch    22] loss: 3.35498\n",
      "[epoch 271, batch    23] loss: 3.37106\n",
      "[epoch 271, batch    24] loss: 3.56704\n",
      "[epoch 271, batch    25] loss: 2.66296\n",
      "[epoch 271, batch    26] loss: 2.68988\n",
      "[epoch 271, batch    27] loss: 2.12203\n",
      "[epoch 271, batch    28] loss: 2.72668\n",
      "[epoch 271, batch    29] loss: 4.00237\n",
      "[epoch 271, batch    30] loss: 2.79075\n",
      "[epoch 271, batch    31] loss: 2.88766\n",
      "[epoch 271, batch    32] loss: 3.87475\n",
      "[epoch 272, batch     1] loss: 3.26667\n",
      "[epoch 272, batch     2] loss: 3.54242\n",
      "[epoch 272, batch     3] loss: 3.14571\n",
      "[epoch 272, batch     4] loss: 3.72177\n",
      "[epoch 272, batch     5] loss: 3.23866\n",
      "[epoch 272, batch     6] loss: 2.84632\n",
      "[epoch 272, batch     7] loss: 2.37679\n",
      "[epoch 272, batch     8] loss: 1.98417\n",
      "[epoch 272, batch     9] loss: 3.20823\n",
      "[epoch 272, batch    10] loss: 3.04028\n",
      "[epoch 272, batch    11] loss: 3.05368\n",
      "[epoch 272, batch    12] loss: 2.19315\n",
      "[epoch 272, batch    13] loss: 3.53448\n",
      "[epoch 272, batch    14] loss: 3.19000\n",
      "[epoch 272, batch    15] loss: 2.76939\n",
      "[epoch 272, batch    16] loss: 3.02153\n",
      "[epoch 272, batch    17] loss: 3.34096\n",
      "[epoch 272, batch    18] loss: 2.89975\n",
      "[epoch 272, batch    19] loss: 2.70018\n",
      "[epoch 272, batch    20] loss: 2.70114\n",
      "[epoch 272, batch    21] loss: 3.38489\n",
      "[epoch 272, batch    22] loss: 3.31550\n",
      "[epoch 272, batch    23] loss: 3.11032\n",
      "[epoch 272, batch    24] loss: 2.82091\n",
      "[epoch 272, batch    25] loss: 2.61308\n",
      "[epoch 272, batch    26] loss: 3.00163\n",
      "[epoch 272, batch    27] loss: 3.26558\n",
      "[epoch 272, batch    28] loss: 3.28734\n",
      "[epoch 272, batch    29] loss: 3.89800\n",
      "[epoch 272, batch    30] loss: 2.84471\n",
      "[epoch 272, batch    31] loss: 2.68993\n",
      "[epoch 272, batch    32] loss: 3.40181\n",
      "[epoch 273, batch     1] loss: 3.16246\n",
      "[epoch 273, batch     2] loss: 2.31567\n",
      "[epoch 273, batch     3] loss: 2.59587\n",
      "[epoch 273, batch     4] loss: 3.82019\n",
      "[epoch 273, batch     5] loss: 2.18348\n",
      "[epoch 273, batch     6] loss: 2.35788\n",
      "[epoch 273, batch     7] loss: 3.07000\n",
      "[epoch 273, batch     8] loss: 2.68854\n",
      "[epoch 273, batch     9] loss: 2.90707\n",
      "[epoch 273, batch    10] loss: 3.14222\n",
      "[epoch 273, batch    11] loss: 3.26175\n",
      "[epoch 273, batch    12] loss: 3.09792\n",
      "[epoch 273, batch    13] loss: 3.58142\n",
      "[epoch 273, batch    14] loss: 3.06070\n",
      "[epoch 273, batch    15] loss: 3.37262\n",
      "[epoch 273, batch    16] loss: 3.26446\n",
      "[epoch 273, batch    17] loss: 3.57231\n",
      "[epoch 273, batch    18] loss: 2.85696\n",
      "[epoch 273, batch    19] loss: 2.67366\n",
      "[epoch 273, batch    20] loss: 3.47858\n",
      "[epoch 273, batch    21] loss: 2.82069\n",
      "[epoch 273, batch    22] loss: 3.30994\n",
      "[epoch 273, batch    23] loss: 3.35224\n",
      "[epoch 273, batch    24] loss: 2.76635\n",
      "[epoch 273, batch    25] loss: 2.85320\n",
      "[epoch 273, batch    26] loss: 3.92962\n",
      "[epoch 273, batch    27] loss: 2.65969\n",
      "[epoch 273, batch    28] loss: 2.71562\n",
      "[epoch 273, batch    29] loss: 2.64766\n",
      "[epoch 273, batch    30] loss: 3.05324\n",
      "[epoch 273, batch    31] loss: 3.21022\n",
      "[epoch 273, batch    32] loss: 4.04472\n",
      "[epoch 274, batch     1] loss: 2.78515\n",
      "[epoch 274, batch     2] loss: 4.38787\n",
      "[epoch 274, batch     3] loss: 2.95568\n",
      "[epoch 274, batch     4] loss: 3.12044\n",
      "[epoch 274, batch     5] loss: 3.64200\n",
      "[epoch 274, batch     6] loss: 2.20834\n",
      "[epoch 274, batch     7] loss: 2.81694\n",
      "[epoch 274, batch     8] loss: 3.25878\n",
      "[epoch 274, batch     9] loss: 3.12023\n",
      "[epoch 274, batch    10] loss: 2.29831\n",
      "[epoch 274, batch    11] loss: 3.77009\n",
      "[epoch 274, batch    12] loss: 3.30173\n",
      "[epoch 274, batch    13] loss: 3.42279\n",
      "[epoch 274, batch    14] loss: 3.32309\n",
      "[epoch 274, batch    15] loss: 2.60598\n",
      "[epoch 274, batch    16] loss: 2.82161\n",
      "[epoch 274, batch    17] loss: 2.15142\n",
      "[epoch 274, batch    18] loss: 2.53974\n",
      "[epoch 274, batch    19] loss: 3.03439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 274, batch    20] loss: 3.66176\n",
      "[epoch 274, batch    21] loss: 3.73402\n",
      "[epoch 274, batch    22] loss: 3.10640\n",
      "[epoch 274, batch    23] loss: 2.19510\n",
      "[epoch 274, batch    24] loss: 3.34695\n",
      "[epoch 274, batch    25] loss: 3.29106\n",
      "[epoch 274, batch    26] loss: 2.91965\n",
      "[epoch 274, batch    27] loss: 2.85288\n",
      "[epoch 274, batch    28] loss: 2.00913\n",
      "[epoch 274, batch    29] loss: 2.79890\n",
      "[epoch 274, batch    30] loss: 3.34276\n",
      "[epoch 274, batch    31] loss: 3.46947\n",
      "[epoch 274, batch    32] loss: 4.99375\n",
      "[epoch 275, batch     1] loss: 2.88358\n",
      "[epoch 275, batch     2] loss: 2.76865\n",
      "[epoch 275, batch     3] loss: 3.10515\n",
      "[epoch 275, batch     4] loss: 3.37754\n",
      "[epoch 275, batch     5] loss: 2.96410\n",
      "[epoch 275, batch     6] loss: 2.97123\n",
      "[epoch 275, batch     7] loss: 3.30839\n",
      "[epoch 275, batch     8] loss: 2.57083\n",
      "[epoch 275, batch     9] loss: 2.99740\n",
      "[epoch 275, batch    10] loss: 2.91223\n",
      "[epoch 275, batch    11] loss: 2.08517\n",
      "[epoch 275, batch    12] loss: 3.31089\n",
      "[epoch 275, batch    13] loss: 2.11822\n",
      "[epoch 275, batch    14] loss: 3.42489\n",
      "[epoch 275, batch    15] loss: 2.77433\n",
      "[epoch 275, batch    16] loss: 2.41760\n",
      "[epoch 275, batch    17] loss: 3.52510\n",
      "[epoch 275, batch    18] loss: 3.38763\n",
      "[epoch 275, batch    19] loss: 2.36939\n",
      "[epoch 275, batch    20] loss: 3.40451\n",
      "[epoch 275, batch    21] loss: 2.40508\n",
      "[epoch 275, batch    22] loss: 3.40682\n",
      "[epoch 275, batch    23] loss: 3.87424\n",
      "[epoch 275, batch    24] loss: 3.05458\n",
      "[epoch 275, batch    25] loss: 2.60934\n",
      "[epoch 275, batch    26] loss: 3.30033\n",
      "[epoch 275, batch    27] loss: 3.21135\n",
      "[epoch 275, batch    28] loss: 4.32477\n",
      "[epoch 275, batch    29] loss: 3.26071\n",
      "[epoch 275, batch    30] loss: 3.05600\n",
      "[epoch 275, batch    31] loss: 3.07015\n",
      "[epoch 275, batch    32] loss: 2.22142\n",
      "[epoch 276, batch     1] loss: 3.49386\n",
      "[epoch 276, batch     2] loss: 2.55680\n",
      "[epoch 276, batch     3] loss: 3.67767\n",
      "[epoch 276, batch     4] loss: 2.73687\n",
      "[epoch 276, batch     5] loss: 2.80325\n",
      "[epoch 276, batch     6] loss: 3.16629\n",
      "[epoch 276, batch     7] loss: 2.59780\n",
      "[epoch 276, batch     8] loss: 2.70751\n",
      "[epoch 276, batch     9] loss: 1.87556\n",
      "[epoch 276, batch    10] loss: 2.74664\n",
      "[epoch 276, batch    11] loss: 2.62907\n",
      "[epoch 276, batch    12] loss: 2.33236\n",
      "[epoch 276, batch    13] loss: 3.43447\n",
      "[epoch 276, batch    14] loss: 3.29708\n",
      "[epoch 276, batch    15] loss: 3.57969\n",
      "[epoch 276, batch    16] loss: 2.51730\n",
      "[epoch 276, batch    17] loss: 2.39851\n",
      "[epoch 276, batch    18] loss: 2.78010\n",
      "[epoch 276, batch    19] loss: 2.73599\n",
      "[epoch 276, batch    20] loss: 3.38423\n",
      "[epoch 276, batch    21] loss: 2.82897\n",
      "[epoch 276, batch    22] loss: 3.42949\n",
      "[epoch 276, batch    23] loss: 3.33426\n",
      "[epoch 276, batch    24] loss: 4.82442\n",
      "[epoch 276, batch    25] loss: 3.56722\n",
      "[epoch 276, batch    26] loss: 2.35737\n",
      "[epoch 276, batch    27] loss: 3.83240\n",
      "[epoch 276, batch    28] loss: 2.71007\n",
      "[epoch 276, batch    29] loss: 3.56638\n",
      "[epoch 276, batch    30] loss: 2.88810\n",
      "[epoch 276, batch    31] loss: 3.75662\n",
      "[epoch 276, batch    32] loss: 2.47519\n",
      "[epoch 277, batch     1] loss: 2.50206\n",
      "[epoch 277, batch     2] loss: 2.75215\n",
      "[epoch 277, batch     3] loss: 2.76315\n",
      "[epoch 277, batch     4] loss: 3.39935\n",
      "[epoch 277, batch     5] loss: 2.33896\n",
      "[epoch 277, batch     6] loss: 3.36707\n",
      "[epoch 277, batch     7] loss: 3.16589\n",
      "[epoch 277, batch     8] loss: 3.42607\n",
      "[epoch 277, batch     9] loss: 3.42005\n",
      "[epoch 277, batch    10] loss: 3.00609\n",
      "[epoch 277, batch    11] loss: 3.21786\n",
      "[epoch 277, batch    12] loss: 3.08640\n",
      "[epoch 277, batch    13] loss: 2.60803\n",
      "[epoch 277, batch    14] loss: 2.01946\n",
      "[epoch 277, batch    15] loss: 3.30651\n",
      "[epoch 277, batch    16] loss: 2.42531\n",
      "[epoch 277, batch    17] loss: 3.44238\n",
      "[epoch 277, batch    18] loss: 3.14438\n",
      "[epoch 277, batch    19] loss: 3.67712\n",
      "[epoch 277, batch    20] loss: 3.19907\n",
      "[epoch 277, batch    21] loss: 2.80269\n",
      "[epoch 277, batch    22] loss: 3.45029\n",
      "[epoch 277, batch    23] loss: 2.69229\n",
      "[epoch 277, batch    24] loss: 2.84190\n",
      "[epoch 277, batch    25] loss: 4.24667\n",
      "[epoch 277, batch    26] loss: 2.99627\n",
      "[epoch 277, batch    27] loss: 2.40922\n",
      "[epoch 277, batch    28] loss: 2.93509\n",
      "[epoch 277, batch    29] loss: 3.00249\n",
      "[epoch 277, batch    30] loss: 2.75950\n",
      "[epoch 277, batch    31] loss: 2.55268\n",
      "[epoch 277, batch    32] loss: 5.86016\n",
      "[epoch 278, batch     1] loss: 2.72779\n",
      "[epoch 278, batch     2] loss: 3.86531\n",
      "[epoch 278, batch     3] loss: 2.73738\n",
      "[epoch 278, batch     4] loss: 2.92373\n",
      "[epoch 278, batch     5] loss: 2.79368\n",
      "[epoch 278, batch     6] loss: 2.82852\n",
      "[epoch 278, batch     7] loss: 3.59938\n",
      "[epoch 278, batch     8] loss: 2.73609\n",
      "[epoch 278, batch     9] loss: 2.32340\n",
      "[epoch 278, batch    10] loss: 3.07470\n",
      "[epoch 278, batch    11] loss: 3.51928\n",
      "[epoch 278, batch    12] loss: 3.31852\n",
      "[epoch 278, batch    13] loss: 2.77103\n",
      "[epoch 278, batch    14] loss: 2.67871\n",
      "[epoch 278, batch    15] loss: 2.11699\n",
      "[epoch 278, batch    16] loss: 3.72699\n",
      "[epoch 278, batch    17] loss: 2.82151\n",
      "[epoch 278, batch    18] loss: 3.27238\n",
      "[epoch 278, batch    19] loss: 2.31751\n",
      "[epoch 278, batch    20] loss: 3.36778\n",
      "[epoch 278, batch    21] loss: 3.34774\n",
      "[epoch 278, batch    22] loss: 3.73918\n",
      "[epoch 278, batch    23] loss: 3.23110\n",
      "[epoch 278, batch    24] loss: 2.76366\n",
      "[epoch 278, batch    25] loss: 2.74082\n",
      "[epoch 278, batch    26] loss: 2.99456\n",
      "[epoch 278, batch    27] loss: 3.78470\n",
      "[epoch 278, batch    28] loss: 3.00889\n",
      "[epoch 278, batch    29] loss: 3.25405\n",
      "[epoch 278, batch    30] loss: 3.00317\n",
      "[epoch 278, batch    31] loss: 2.88545\n",
      "[epoch 278, batch    32] loss: 1.75425\n",
      "[epoch 279, batch     1] loss: 2.40406\n",
      "[epoch 279, batch     2] loss: 2.66253\n",
      "[epoch 279, batch     3] loss: 2.47895\n",
      "[epoch 279, batch     4] loss: 2.68102\n",
      "[epoch 279, batch     5] loss: 3.22923\n",
      "[epoch 279, batch     6] loss: 2.91411\n",
      "[epoch 279, batch     7] loss: 2.60940\n",
      "[epoch 279, batch     8] loss: 4.16408\n",
      "[epoch 279, batch     9] loss: 2.91716\n",
      "[epoch 279, batch    10] loss: 3.54501\n",
      "[epoch 279, batch    11] loss: 3.08223\n",
      "[epoch 279, batch    12] loss: 3.28080\n",
      "[epoch 279, batch    13] loss: 2.14888\n",
      "[epoch 279, batch    14] loss: 2.86059\n",
      "[epoch 279, batch    15] loss: 2.69309\n",
      "[epoch 279, batch    16] loss: 3.41214\n",
      "[epoch 279, batch    17] loss: 2.61574\n",
      "[epoch 279, batch    18] loss: 2.81902\n",
      "[epoch 279, batch    19] loss: 3.09169\n",
      "[epoch 279, batch    20] loss: 2.85155\n",
      "[epoch 279, batch    21] loss: 3.08069\n",
      "[epoch 279, batch    22] loss: 3.77318\n",
      "[epoch 279, batch    23] loss: 3.64811\n",
      "[epoch 279, batch    24] loss: 3.22548\n",
      "[epoch 279, batch    25] loss: 2.97188\n",
      "[epoch 279, batch    26] loss: 3.22936\n",
      "[epoch 279, batch    27] loss: 3.85840\n",
      "[epoch 279, batch    28] loss: 3.74637\n",
      "[epoch 279, batch    29] loss: 2.56193\n",
      "[epoch 279, batch    30] loss: 2.45326\n",
      "[epoch 279, batch    31] loss: 3.42059\n",
      "[epoch 279, batch    32] loss: 2.59637\n",
      "[epoch 280, batch     1] loss: 3.61773\n",
      "[epoch 280, batch     2] loss: 2.36920\n",
      "[epoch 280, batch     3] loss: 3.08861\n",
      "[epoch 280, batch     4] loss: 2.95116\n",
      "[epoch 280, batch     5] loss: 2.81099\n",
      "[epoch 280, batch     6] loss: 2.65757\n",
      "[epoch 280, batch     7] loss: 2.66728\n",
      "[epoch 280, batch     8] loss: 3.06282\n",
      "[epoch 280, batch     9] loss: 2.91126\n",
      "[epoch 280, batch    10] loss: 3.37954\n",
      "[epoch 280, batch    11] loss: 2.92343\n",
      "[epoch 280, batch    12] loss: 3.62151\n",
      "[epoch 280, batch    13] loss: 3.65238\n",
      "[epoch 280, batch    14] loss: 2.60281\n",
      "[epoch 280, batch    15] loss: 3.89273\n",
      "[epoch 280, batch    16] loss: 2.77838\n",
      "[epoch 280, batch    17] loss: 2.93165\n",
      "[epoch 280, batch    18] loss: 3.05846\n",
      "[epoch 280, batch    19] loss: 3.19817\n",
      "[epoch 280, batch    20] loss: 2.63154\n",
      "[epoch 280, batch    21] loss: 2.34758\n",
      "[epoch 280, batch    22] loss: 3.38632\n",
      "[epoch 280, batch    23] loss: 2.91072\n",
      "[epoch 280, batch    24] loss: 3.29735\n",
      "[epoch 280, batch    25] loss: 3.35618\n",
      "[epoch 280, batch    26] loss: 2.67689\n",
      "[epoch 280, batch    27] loss: 3.26746\n",
      "[epoch 280, batch    28] loss: 2.60968\n",
      "[epoch 280, batch    29] loss: 3.08817\n",
      "[epoch 280, batch    30] loss: 3.16380\n",
      "[epoch 280, batch    31] loss: 2.59221\n",
      "[epoch 280, batch    32] loss: 2.96200\n",
      "[epoch 281, batch     1] loss: 3.13560\n",
      "[epoch 281, batch     2] loss: 2.33747\n",
      "[epoch 281, batch     3] loss: 2.56725\n",
      "[epoch 281, batch     4] loss: 3.00808\n",
      "[epoch 281, batch     5] loss: 2.81171\n",
      "[epoch 281, batch     6] loss: 3.32426\n",
      "[epoch 281, batch     7] loss: 2.38618\n",
      "[epoch 281, batch     8] loss: 3.49709\n",
      "[epoch 281, batch     9] loss: 2.82646\n",
      "[epoch 281, batch    10] loss: 3.01797\n",
      "[epoch 281, batch    11] loss: 3.29327\n",
      "[epoch 281, batch    12] loss: 3.29753\n",
      "[epoch 281, batch    13] loss: 2.74359\n",
      "[epoch 281, batch    14] loss: 3.67235\n",
      "[epoch 281, batch    15] loss: 3.66450\n",
      "[epoch 281, batch    16] loss: 2.44329\n",
      "[epoch 281, batch    17] loss: 3.12367\n",
      "[epoch 281, batch    18] loss: 2.99378\n",
      "[epoch 281, batch    19] loss: 2.93613\n",
      "[epoch 281, batch    20] loss: 2.41727\n",
      "[epoch 281, batch    21] loss: 2.87788\n",
      "[epoch 281, batch    22] loss: 2.90093\n",
      "[epoch 281, batch    23] loss: 2.66412\n",
      "[epoch 281, batch    24] loss: 3.63528\n",
      "[epoch 281, batch    25] loss: 3.34637\n",
      "[epoch 281, batch    26] loss: 2.93685\n",
      "[epoch 281, batch    27] loss: 2.80152\n",
      "[epoch 281, batch    28] loss: 3.81483\n",
      "[epoch 281, batch    29] loss: 3.09661\n",
      "[epoch 281, batch    30] loss: 3.58708\n",
      "[epoch 281, batch    31] loss: 2.65302\n",
      "[epoch 281, batch    32] loss: 3.28557\n",
      "[epoch 282, batch     1] loss: 3.08313\n",
      "[epoch 282, batch     2] loss: 2.73456\n",
      "[epoch 282, batch     3] loss: 2.52783\n",
      "[epoch 282, batch     4] loss: 3.31960\n",
      "[epoch 282, batch     5] loss: 4.04242\n",
      "[epoch 282, batch     6] loss: 2.36508\n",
      "[epoch 282, batch     7] loss: 3.28941\n",
      "[epoch 282, batch     8] loss: 3.06215\n",
      "[epoch 282, batch     9] loss: 2.56742\n",
      "[epoch 282, batch    10] loss: 3.04525\n",
      "[epoch 282, batch    11] loss: 2.67212\n",
      "[epoch 282, batch    12] loss: 2.11651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 282, batch    13] loss: 2.65850\n",
      "[epoch 282, batch    14] loss: 3.11991\n",
      "[epoch 282, batch    15] loss: 3.16091\n",
      "[epoch 282, batch    16] loss: 1.98909\n",
      "[epoch 282, batch    17] loss: 2.58262\n",
      "[epoch 282, batch    18] loss: 3.44061\n",
      "[epoch 282, batch    19] loss: 2.35814\n",
      "[epoch 282, batch    20] loss: 3.24802\n",
      "[epoch 282, batch    21] loss: 3.59347\n",
      "[epoch 282, batch    22] loss: 2.43923\n",
      "[epoch 282, batch    23] loss: 5.46132\n",
      "[epoch 282, batch    24] loss: 2.61545\n",
      "[epoch 282, batch    25] loss: 3.52617\n",
      "[epoch 282, batch    26] loss: 2.98988\n",
      "[epoch 282, batch    27] loss: 2.87310\n",
      "[epoch 282, batch    28] loss: 2.86577\n",
      "[epoch 282, batch    29] loss: 3.96582\n",
      "[epoch 282, batch    30] loss: 2.36144\n",
      "[epoch 282, batch    31] loss: 4.09668\n",
      "[epoch 282, batch    32] loss: 4.27372\n",
      "[epoch 283, batch     1] loss: 3.65036\n",
      "[epoch 283, batch     2] loss: 3.53692\n",
      "[epoch 283, batch     3] loss: 3.15540\n",
      "[epoch 283, batch     4] loss: 3.93648\n",
      "[epoch 283, batch     5] loss: 2.02005\n",
      "[epoch 283, batch     6] loss: 3.21906\n",
      "[epoch 283, batch     7] loss: 3.28282\n",
      "[epoch 283, batch     8] loss: 3.28736\n",
      "[epoch 283, batch     9] loss: 1.91886\n",
      "[epoch 283, batch    10] loss: 2.90362\n",
      "[epoch 283, batch    11] loss: 2.48818\n",
      "[epoch 283, batch    12] loss: 3.84089\n",
      "[epoch 283, batch    13] loss: 3.91595\n",
      "[epoch 283, batch    14] loss: 3.43041\n",
      "[epoch 283, batch    15] loss: 2.28682\n",
      "[epoch 283, batch    16] loss: 3.38842\n",
      "[epoch 283, batch    17] loss: 3.28211\n",
      "[epoch 283, batch    18] loss: 2.51069\n",
      "[epoch 283, batch    19] loss: 2.75254\n",
      "[epoch 283, batch    20] loss: 2.29481\n",
      "[epoch 283, batch    21] loss: 2.99794\n",
      "[epoch 283, batch    22] loss: 3.40042\n",
      "[epoch 283, batch    23] loss: 2.89503\n",
      "[epoch 283, batch    24] loss: 3.55531\n",
      "[epoch 283, batch    25] loss: 2.52237\n",
      "[epoch 283, batch    26] loss: 3.11810\n",
      "[epoch 283, batch    27] loss: 2.79416\n",
      "[epoch 283, batch    28] loss: 2.70992\n",
      "[epoch 283, batch    29] loss: 3.49761\n",
      "[epoch 283, batch    30] loss: 2.80082\n",
      "[epoch 283, batch    31] loss: 2.78915\n",
      "[epoch 283, batch    32] loss: 4.11481\n",
      "[epoch 284, batch     1] loss: 3.20418\n",
      "[epoch 284, batch     2] loss: 2.43713\n",
      "[epoch 284, batch     3] loss: 2.93474\n",
      "[epoch 284, batch     4] loss: 3.11933\n",
      "[epoch 284, batch     5] loss: 3.11404\n",
      "[epoch 284, batch     6] loss: 2.53905\n",
      "[epoch 284, batch     7] loss: 2.95806\n",
      "[epoch 284, batch     8] loss: 2.62759\n",
      "[epoch 284, batch     9] loss: 3.57545\n",
      "[epoch 284, batch    10] loss: 3.41924\n",
      "[epoch 284, batch    11] loss: 2.86132\n",
      "[epoch 284, batch    12] loss: 2.63889\n",
      "[epoch 284, batch    13] loss: 2.39538\n",
      "[epoch 284, batch    14] loss: 2.70817\n",
      "[epoch 284, batch    15] loss: 3.17120\n",
      "[epoch 284, batch    16] loss: 3.79667\n",
      "[epoch 284, batch    17] loss: 3.09445\n",
      "[epoch 284, batch    18] loss: 2.51044\n",
      "[epoch 284, batch    19] loss: 3.64157\n",
      "[epoch 284, batch    20] loss: 2.63994\n",
      "[epoch 284, batch    21] loss: 3.94615\n",
      "[epoch 284, batch    22] loss: 3.11230\n",
      "[epoch 284, batch    23] loss: 4.40480\n",
      "[epoch 284, batch    24] loss: 2.46014\n",
      "[epoch 284, batch    25] loss: 3.16445\n",
      "[epoch 284, batch    26] loss: 2.70354\n",
      "[epoch 284, batch    27] loss: 2.98415\n",
      "[epoch 284, batch    28] loss: 3.71563\n",
      "[epoch 284, batch    29] loss: 2.72612\n",
      "[epoch 284, batch    30] loss: 2.82065\n",
      "[epoch 284, batch    31] loss: 2.95946\n",
      "[epoch 284, batch    32] loss: 2.15963\n",
      "[epoch 285, batch     1] loss: 2.01443\n",
      "[epoch 285, batch     2] loss: 2.85714\n",
      "[epoch 285, batch     3] loss: 2.80360\n",
      "[epoch 285, batch     4] loss: 3.47326\n",
      "[epoch 285, batch     5] loss: 2.26683\n",
      "[epoch 285, batch     6] loss: 2.75392\n",
      "[epoch 285, batch     7] loss: 2.24886\n",
      "[epoch 285, batch     8] loss: 2.91844\n",
      "[epoch 285, batch     9] loss: 3.56257\n",
      "[epoch 285, batch    10] loss: 2.54022\n",
      "[epoch 285, batch    11] loss: 2.94375\n",
      "[epoch 285, batch    12] loss: 4.46735\n",
      "[epoch 285, batch    13] loss: 3.60110\n",
      "[epoch 285, batch    14] loss: 2.84048\n",
      "[epoch 285, batch    15] loss: 2.24310\n",
      "[epoch 285, batch    16] loss: 2.63354\n",
      "[epoch 285, batch    17] loss: 2.69295\n",
      "[epoch 285, batch    18] loss: 3.71740\n",
      "[epoch 285, batch    19] loss: 3.41606\n",
      "[epoch 285, batch    20] loss: 3.43583\n",
      "[epoch 285, batch    21] loss: 2.63488\n",
      "[epoch 285, batch    22] loss: 2.23575\n",
      "[epoch 285, batch    23] loss: 3.97112\n",
      "[epoch 285, batch    24] loss: 4.25598\n",
      "[epoch 285, batch    25] loss: 3.45746\n",
      "[epoch 285, batch    26] loss: 3.82870\n",
      "[epoch 285, batch    27] loss: 3.14467\n",
      "[epoch 285, batch    28] loss: 3.25249\n",
      "[epoch 285, batch    29] loss: 3.22511\n",
      "[epoch 285, batch    30] loss: 2.44277\n",
      "[epoch 285, batch    31] loss: 2.70923\n",
      "[epoch 285, batch    32] loss: 1.64575\n",
      "[epoch 286, batch     1] loss: 2.65967\n",
      "[epoch 286, batch     2] loss: 2.52470\n",
      "[epoch 286, batch     3] loss: 2.53731\n",
      "[epoch 286, batch     4] loss: 2.91020\n",
      "[epoch 286, batch     5] loss: 3.16787\n",
      "[epoch 286, batch     6] loss: 3.55925\n",
      "[epoch 286, batch     7] loss: 3.19050\n",
      "[epoch 286, batch     8] loss: 3.15382\n",
      "[epoch 286, batch     9] loss: 2.80203\n",
      "[epoch 286, batch    10] loss: 3.06347\n",
      "[epoch 286, batch    11] loss: 2.42132\n",
      "[epoch 286, batch    12] loss: 3.15170\n",
      "[epoch 286, batch    13] loss: 4.19214\n",
      "[epoch 286, batch    14] loss: 3.22638\n",
      "[epoch 286, batch    15] loss: 3.00807\n",
      "[epoch 286, batch    16] loss: 2.84783\n",
      "[epoch 286, batch    17] loss: 2.87884\n",
      "[epoch 286, batch    18] loss: 3.42534\n",
      "[epoch 286, batch    19] loss: 2.16829\n",
      "[epoch 286, batch    20] loss: 3.48603\n",
      "[epoch 286, batch    21] loss: 3.09609\n",
      "[epoch 286, batch    22] loss: 2.83847\n",
      "[epoch 286, batch    23] loss: 2.69928\n",
      "[epoch 286, batch    24] loss: 3.18615\n",
      "[epoch 286, batch    25] loss: 2.37119\n",
      "[epoch 286, batch    26] loss: 2.54316\n",
      "[epoch 286, batch    27] loss: 3.62519\n",
      "[epoch 286, batch    28] loss: 3.33945\n",
      "[epoch 286, batch    29] loss: 3.28924\n",
      "[epoch 286, batch    30] loss: 3.68339\n",
      "[epoch 286, batch    31] loss: 3.21204\n",
      "[epoch 286, batch    32] loss: 3.37987\n",
      "[epoch 287, batch     1] loss: 2.39247\n",
      "[epoch 287, batch     2] loss: 4.21699\n",
      "[epoch 287, batch     3] loss: 3.13977\n",
      "[epoch 287, batch     4] loss: 2.27910\n",
      "[epoch 287, batch     5] loss: 2.50706\n",
      "[epoch 287, batch     6] loss: 2.82739\n",
      "[epoch 287, batch     7] loss: 3.27238\n",
      "[epoch 287, batch     8] loss: 3.53533\n",
      "[epoch 287, batch     9] loss: 2.84373\n",
      "[epoch 287, batch    10] loss: 3.12075\n",
      "[epoch 287, batch    11] loss: 2.75180\n",
      "[epoch 287, batch    12] loss: 3.27672\n",
      "[epoch 287, batch    13] loss: 3.92425\n",
      "[epoch 287, batch    14] loss: 2.57966\n",
      "[epoch 287, batch    15] loss: 3.98844\n",
      "[epoch 287, batch    16] loss: 2.84200\n",
      "[epoch 287, batch    17] loss: 3.13791\n",
      "[epoch 287, batch    18] loss: 2.55435\n",
      "[epoch 287, batch    19] loss: 3.30963\n",
      "[epoch 287, batch    20] loss: 2.66938\n",
      "[epoch 287, batch    21] loss: 3.31302\n",
      "[epoch 287, batch    22] loss: 2.36836\n",
      "[epoch 287, batch    23] loss: 2.51862\n",
      "[epoch 287, batch    24] loss: 2.71454\n",
      "[epoch 287, batch    25] loss: 2.69991\n",
      "[epoch 287, batch    26] loss: 2.76801\n",
      "[epoch 287, batch    27] loss: 3.09747\n",
      "[epoch 287, batch    28] loss: 2.88823\n",
      "[epoch 287, batch    29] loss: 3.03357\n",
      "[epoch 287, batch    30] loss: 3.99715\n",
      "[epoch 287, batch    31] loss: 3.39902\n",
      "[epoch 287, batch    32] loss: 2.71456\n",
      "[epoch 288, batch     1] loss: 3.17521\n",
      "[epoch 288, batch     2] loss: 3.34741\n",
      "[epoch 288, batch     3] loss: 3.08131\n",
      "[epoch 288, batch     4] loss: 2.53951\n",
      "[epoch 288, batch     5] loss: 2.88797\n",
      "[epoch 288, batch     6] loss: 2.90587\n",
      "[epoch 288, batch     7] loss: 2.71723\n",
      "[epoch 288, batch     8] loss: 2.27121\n",
      "[epoch 288, batch     9] loss: 3.81165\n",
      "[epoch 288, batch    10] loss: 3.04593\n",
      "[epoch 288, batch    11] loss: 3.37786\n",
      "[epoch 288, batch    12] loss: 3.08510\n",
      "[epoch 288, batch    13] loss: 2.84362\n",
      "[epoch 288, batch    14] loss: 3.14301\n",
      "[epoch 288, batch    15] loss: 3.09462\n",
      "[epoch 288, batch    16] loss: 3.37725\n",
      "[epoch 288, batch    17] loss: 4.07242\n",
      "[epoch 288, batch    18] loss: 2.61129\n",
      "[epoch 288, batch    19] loss: 3.36482\n",
      "[epoch 288, batch    20] loss: 2.69342\n",
      "[epoch 288, batch    21] loss: 2.64579\n",
      "[epoch 288, batch    22] loss: 2.97387\n",
      "[epoch 288, batch    23] loss: 2.83222\n",
      "[epoch 288, batch    24] loss: 2.61539\n",
      "[epoch 288, batch    25] loss: 2.61320\n",
      "[epoch 288, batch    26] loss: 3.29749\n",
      "[epoch 288, batch    27] loss: 2.37844\n",
      "[epoch 288, batch    28] loss: 4.03095\n",
      "[epoch 288, batch    29] loss: 3.38731\n",
      "[epoch 288, batch    30] loss: 3.36245\n",
      "[epoch 288, batch    31] loss: 2.70032\n",
      "[epoch 288, batch    32] loss: 4.36121\n",
      "[epoch 289, batch     1] loss: 3.06684\n",
      "[epoch 289, batch     2] loss: 3.11342\n",
      "[epoch 289, batch     3] loss: 2.56056\n",
      "[epoch 289, batch     4] loss: 3.11442\n",
      "[epoch 289, batch     5] loss: 2.54413\n",
      "[epoch 289, batch     6] loss: 2.56329\n",
      "[epoch 289, batch     7] loss: 2.84852\n",
      "[epoch 289, batch     8] loss: 2.54138\n",
      "[epoch 289, batch     9] loss: 3.38474\n",
      "[epoch 289, batch    10] loss: 3.65588\n",
      "[epoch 289, batch    11] loss: 2.87686\n",
      "[epoch 289, batch    12] loss: 3.64967\n",
      "[epoch 289, batch    13] loss: 2.50759\n",
      "[epoch 289, batch    14] loss: 2.03218\n",
      "[epoch 289, batch    15] loss: 3.47016\n",
      "[epoch 289, batch    16] loss: 3.08622\n",
      "[epoch 289, batch    17] loss: 3.49560\n",
      "[epoch 289, batch    18] loss: 3.56304\n",
      "[epoch 289, batch    19] loss: 3.82225\n",
      "[epoch 289, batch    20] loss: 2.66148\n",
      "[epoch 289, batch    21] loss: 3.43635\n",
      "[epoch 289, batch    22] loss: 3.22143\n",
      "[epoch 289, batch    23] loss: 2.50811\n",
      "[epoch 289, batch    24] loss: 2.50178\n",
      "[epoch 289, batch    25] loss: 3.55424\n",
      "[epoch 289, batch    26] loss: 3.11073\n",
      "[epoch 289, batch    27] loss: 3.18575\n",
      "[epoch 289, batch    28] loss: 3.88785\n",
      "[epoch 289, batch    29] loss: 2.63303\n",
      "[epoch 289, batch    30] loss: 2.57019\n",
      "[epoch 289, batch    31] loss: 2.72944\n",
      "[epoch 289, batch    32] loss: 3.29377\n",
      "[epoch 290, batch     1] loss: 3.18887\n",
      "[epoch 290, batch     2] loss: 3.48087\n",
      "[epoch 290, batch     3] loss: 2.29836\n",
      "[epoch 290, batch     4] loss: 2.95231\n",
      "[epoch 290, batch     5] loss: 3.71008\n",
      "[epoch 290, batch     6] loss: 2.54044\n",
      "[epoch 290, batch     7] loss: 2.96253\n",
      "[epoch 290, batch     8] loss: 2.61608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 290, batch     9] loss: 2.42188\n",
      "[epoch 290, batch    10] loss: 4.05132\n",
      "[epoch 290, batch    11] loss: 2.74947\n",
      "[epoch 290, batch    12] loss: 3.91219\n",
      "[epoch 290, batch    13] loss: 2.82159\n",
      "[epoch 290, batch    14] loss: 2.53383\n",
      "[epoch 290, batch    15] loss: 3.75081\n",
      "[epoch 290, batch    16] loss: 3.08056\n",
      "[epoch 290, batch    17] loss: 2.89914\n",
      "[epoch 290, batch    18] loss: 3.60306\n",
      "[epoch 290, batch    19] loss: 2.49634\n",
      "[epoch 290, batch    20] loss: 3.12512\n",
      "[epoch 290, batch    21] loss: 2.98583\n",
      "[epoch 290, batch    22] loss: 3.04058\n",
      "[epoch 290, batch    23] loss: 2.73264\n",
      "[epoch 290, batch    24] loss: 2.64391\n",
      "[epoch 290, batch    25] loss: 3.25577\n",
      "[epoch 290, batch    26] loss: 3.51022\n",
      "[epoch 290, batch    27] loss: 3.48189\n",
      "[epoch 290, batch    28] loss: 2.74461\n",
      "[epoch 290, batch    29] loss: 3.77617\n",
      "[epoch 290, batch    30] loss: 2.34110\n",
      "[epoch 290, batch    31] loss: 2.81187\n",
      "[epoch 290, batch    32] loss: 2.90602\n",
      "[epoch 291, batch     1] loss: 3.75363\n",
      "[epoch 291, batch     2] loss: 4.10295\n",
      "[epoch 291, batch     3] loss: 2.38834\n",
      "[epoch 291, batch     4] loss: 3.22184\n",
      "[epoch 291, batch     5] loss: 3.43025\n",
      "[epoch 291, batch     6] loss: 2.88246\n",
      "[epoch 291, batch     7] loss: 2.55445\n",
      "[epoch 291, batch     8] loss: 3.34670\n",
      "[epoch 291, batch     9] loss: 3.61081\n",
      "[epoch 291, batch    10] loss: 3.52800\n",
      "[epoch 291, batch    11] loss: 2.62746\n",
      "[epoch 291, batch    12] loss: 2.98627\n",
      "[epoch 291, batch    13] loss: 3.20852\n",
      "[epoch 291, batch    14] loss: 2.93035\n",
      "[epoch 291, batch    15] loss: 3.06797\n",
      "[epoch 291, batch    16] loss: 2.48152\n",
      "[epoch 291, batch    17] loss: 2.54738\n",
      "[epoch 291, batch    18] loss: 2.33595\n",
      "[epoch 291, batch    19] loss: 2.87595\n",
      "[epoch 291, batch    20] loss: 2.47300\n",
      "[epoch 291, batch    21] loss: 2.97170\n",
      "[epoch 291, batch    22] loss: 3.14090\n",
      "[epoch 291, batch    23] loss: 3.31545\n",
      "[epoch 291, batch    24] loss: 2.87335\n",
      "[epoch 291, batch    25] loss: 2.88840\n",
      "[epoch 291, batch    26] loss: 3.56492\n",
      "[epoch 291, batch    27] loss: 2.55467\n",
      "[epoch 291, batch    28] loss: 3.90017\n",
      "[epoch 291, batch    29] loss: 2.97298\n",
      "[epoch 291, batch    30] loss: 2.85742\n",
      "[epoch 291, batch    31] loss: 3.05614\n",
      "[epoch 291, batch    32] loss: 2.05612\n",
      "[epoch 292, batch     1] loss: 2.54873\n",
      "[epoch 292, batch     2] loss: 2.41319\n",
      "[epoch 292, batch     3] loss: 3.14265\n",
      "[epoch 292, batch     4] loss: 3.32908\n",
      "[epoch 292, batch     5] loss: 3.77380\n",
      "[epoch 292, batch     6] loss: 2.63354\n",
      "[epoch 292, batch     7] loss: 2.58214\n",
      "[epoch 292, batch     8] loss: 3.86473\n",
      "[epoch 292, batch     9] loss: 2.67659\n",
      "[epoch 292, batch    10] loss: 2.74658\n",
      "[epoch 292, batch    11] loss: 2.69441\n",
      "[epoch 292, batch    12] loss: 2.36816\n",
      "[epoch 292, batch    13] loss: 2.66076\n",
      "[epoch 292, batch    14] loss: 4.05536\n",
      "[epoch 292, batch    15] loss: 2.67740\n",
      "[epoch 292, batch    16] loss: 2.65954\n",
      "[epoch 292, batch    17] loss: 3.11512\n",
      "[epoch 292, batch    18] loss: 2.74552\n",
      "[epoch 292, batch    19] loss: 3.55083\n",
      "[epoch 292, batch    20] loss: 2.89402\n",
      "[epoch 292, batch    21] loss: 3.60346\n",
      "[epoch 292, batch    22] loss: 2.97237\n",
      "[epoch 292, batch    23] loss: 2.88765\n",
      "[epoch 292, batch    24] loss: 2.62469\n",
      "[epoch 292, batch    25] loss: 4.07381\n",
      "[epoch 292, batch    26] loss: 2.77923\n",
      "[epoch 292, batch    27] loss: 3.77775\n",
      "[epoch 292, batch    28] loss: 3.38754\n",
      "[epoch 292, batch    29] loss: 2.24069\n",
      "[epoch 292, batch    30] loss: 3.16947\n",
      "[epoch 292, batch    31] loss: 3.47342\n",
      "[epoch 292, batch    32] loss: 2.40636\n",
      "[epoch 293, batch     1] loss: 2.78764\n",
      "[epoch 293, batch     2] loss: 2.43277\n",
      "[epoch 293, batch     3] loss: 2.67438\n",
      "[epoch 293, batch     4] loss: 3.06241\n",
      "[epoch 293, batch     5] loss: 3.03627\n",
      "[epoch 293, batch     6] loss: 3.66405\n",
      "[epoch 293, batch     7] loss: 3.14462\n",
      "[epoch 293, batch     8] loss: 3.20619\n",
      "[epoch 293, batch     9] loss: 3.24564\n",
      "[epoch 293, batch    10] loss: 2.84079\n",
      "[epoch 293, batch    11] loss: 4.44265\n",
      "[epoch 293, batch    12] loss: 2.50908\n",
      "[epoch 293, batch    13] loss: 2.93323\n",
      "[epoch 293, batch    14] loss: 3.02272\n",
      "[epoch 293, batch    15] loss: 2.65203\n",
      "[epoch 293, batch    16] loss: 3.17772\n",
      "[epoch 293, batch    17] loss: 2.66596\n",
      "[epoch 293, batch    18] loss: 3.44619\n",
      "[epoch 293, batch    19] loss: 3.19002\n",
      "[epoch 293, batch    20] loss: 3.33381\n",
      "[epoch 293, batch    21] loss: 4.15053\n",
      "[epoch 293, batch    22] loss: 3.23349\n",
      "[epoch 293, batch    23] loss: 3.33684\n",
      "[epoch 293, batch    24] loss: 3.01786\n",
      "[epoch 293, batch    25] loss: 2.47721\n",
      "[epoch 293, batch    26] loss: 2.76912\n",
      "[epoch 293, batch    27] loss: 2.01167\n",
      "[epoch 293, batch    28] loss: 3.21247\n",
      "[epoch 293, batch    29] loss: 3.06060\n",
      "[epoch 293, batch    30] loss: 3.17432\n",
      "[epoch 293, batch    31] loss: 2.85440\n",
      "[epoch 293, batch    32] loss: 2.39535\n",
      "[epoch 294, batch     1] loss: 3.03302\n",
      "[epoch 294, batch     2] loss: 3.29015\n",
      "[epoch 294, batch     3] loss: 3.00713\n",
      "[epoch 294, batch     4] loss: 3.19462\n",
      "[epoch 294, batch     5] loss: 3.37794\n",
      "[epoch 294, batch     6] loss: 2.39504\n",
      "[epoch 294, batch     7] loss: 3.26924\n",
      "[epoch 294, batch     8] loss: 2.39548\n",
      "[epoch 294, batch     9] loss: 3.18674\n",
      "[epoch 294, batch    10] loss: 2.73884\n",
      "[epoch 294, batch    11] loss: 3.04167\n",
      "[epoch 294, batch    12] loss: 2.48131\n",
      "[epoch 294, batch    13] loss: 2.76412\n",
      "[epoch 294, batch    14] loss: 3.17589\n",
      "[epoch 294, batch    15] loss: 2.71099\n",
      "[epoch 294, batch    16] loss: 2.88679\n",
      "[epoch 294, batch    17] loss: 2.74520\n",
      "[epoch 294, batch    18] loss: 2.30810\n",
      "[epoch 294, batch    19] loss: 3.28900\n",
      "[epoch 294, batch    20] loss: 3.50655\n",
      "[epoch 294, batch    21] loss: 3.10323\n",
      "[epoch 294, batch    22] loss: 3.08715\n",
      "[epoch 294, batch    23] loss: 4.71393\n",
      "[epoch 294, batch    24] loss: 3.49096\n",
      "[epoch 294, batch    25] loss: 2.50164\n",
      "[epoch 294, batch    26] loss: 3.07066\n",
      "[epoch 294, batch    27] loss: 3.16111\n",
      "[epoch 294, batch    28] loss: 3.47492\n",
      "[epoch 294, batch    29] loss: 2.69556\n",
      "[epoch 294, batch    30] loss: 3.00482\n",
      "[epoch 294, batch    31] loss: 2.79767\n",
      "[epoch 294, batch    32] loss: 3.82157\n",
      "[epoch 295, batch     1] loss: 2.87336\n",
      "[epoch 295, batch     2] loss: 2.88316\n",
      "[epoch 295, batch     3] loss: 2.71554\n",
      "[epoch 295, batch     4] loss: 2.57386\n",
      "[epoch 295, batch     5] loss: 2.44930\n",
      "[epoch 295, batch     6] loss: 2.53930\n",
      "[epoch 295, batch     7] loss: 2.69704\n",
      "[epoch 295, batch     8] loss: 2.75216\n",
      "[epoch 295, batch     9] loss: 2.59216\n",
      "[epoch 295, batch    10] loss: 3.34984\n",
      "[epoch 295, batch    11] loss: 3.28149\n",
      "[epoch 295, batch    12] loss: 2.52332\n",
      "[epoch 295, batch    13] loss: 3.01564\n",
      "[epoch 295, batch    14] loss: 3.94857\n",
      "[epoch 295, batch    15] loss: 3.66092\n",
      "[epoch 295, batch    16] loss: 2.95128\n",
      "[epoch 295, batch    17] loss: 3.12313\n",
      "[epoch 295, batch    18] loss: 3.49053\n",
      "[epoch 295, batch    19] loss: 3.44188\n",
      "[epoch 295, batch    20] loss: 3.74136\n",
      "[epoch 295, batch    21] loss: 3.35874\n",
      "[epoch 295, batch    22] loss: 3.59772\n",
      "[epoch 295, batch    23] loss: 2.49141\n",
      "[epoch 295, batch    24] loss: 2.58952\n",
      "[epoch 295, batch    25] loss: 4.00805\n",
      "[epoch 295, batch    26] loss: 2.78699\n",
      "[epoch 295, batch    27] loss: 3.01854\n",
      "[epoch 295, batch    28] loss: 2.56004\n",
      "[epoch 295, batch    29] loss: 3.43926\n",
      "[epoch 295, batch    30] loss: 3.41216\n",
      "[epoch 295, batch    31] loss: 2.88004\n",
      "[epoch 295, batch    32] loss: 1.75334\n",
      "[epoch 296, batch     1] loss: 2.08858\n",
      "[epoch 296, batch     2] loss: 3.68068\n",
      "[epoch 296, batch     3] loss: 2.65671\n",
      "[epoch 296, batch     4] loss: 2.81074\n",
      "[epoch 296, batch     5] loss: 2.63067\n",
      "[epoch 296, batch     6] loss: 3.29491\n",
      "[epoch 296, batch     7] loss: 3.44187\n",
      "[epoch 296, batch     8] loss: 3.85541\n",
      "[epoch 296, batch     9] loss: 2.79556\n",
      "[epoch 296, batch    10] loss: 3.17992\n",
      "[epoch 296, batch    11] loss: 3.02164\n",
      "[epoch 296, batch    12] loss: 2.47126\n",
      "[epoch 296, batch    13] loss: 2.61723\n",
      "[epoch 296, batch    14] loss: 3.07258\n",
      "[epoch 296, batch    15] loss: 2.85770\n",
      "[epoch 296, batch    16] loss: 2.52116\n",
      "[epoch 296, batch    17] loss: 2.98516\n",
      "[epoch 296, batch    18] loss: 2.74694\n",
      "[epoch 296, batch    19] loss: 3.99400\n",
      "[epoch 296, batch    20] loss: 3.17339\n",
      "[epoch 296, batch    21] loss: 3.35662\n",
      "[epoch 296, batch    22] loss: 2.68400\n",
      "[epoch 296, batch    23] loss: 2.60334\n",
      "[epoch 296, batch    24] loss: 2.64036\n",
      "[epoch 296, batch    25] loss: 3.76805\n",
      "[epoch 296, batch    26] loss: 3.98565\n",
      "[epoch 296, batch    27] loss: 3.32218\n",
      "[epoch 296, batch    28] loss: 3.26540\n",
      "[epoch 296, batch    29] loss: 3.74602\n",
      "[epoch 296, batch    30] loss: 2.53162\n",
      "[epoch 296, batch    31] loss: 2.49629\n",
      "[epoch 296, batch    32] loss: 2.05287\n",
      "[epoch 297, batch     1] loss: 3.75154\n",
      "[epoch 297, batch     2] loss: 3.75578\n",
      "[epoch 297, batch     3] loss: 3.19557\n",
      "[epoch 297, batch     4] loss: 3.39944\n",
      "[epoch 297, batch     5] loss: 2.79388\n",
      "[epoch 297, batch     6] loss: 2.37389\n",
      "[epoch 297, batch     7] loss: 2.73217\n",
      "[epoch 297, batch     8] loss: 3.27713\n",
      "[epoch 297, batch     9] loss: 2.98091\n",
      "[epoch 297, batch    10] loss: 2.59654\n",
      "[epoch 297, batch    11] loss: 3.35943\n",
      "[epoch 297, batch    12] loss: 2.95966\n",
      "[epoch 297, batch    13] loss: 3.38384\n",
      "[epoch 297, batch    14] loss: 3.36934\n",
      "[epoch 297, batch    15] loss: 2.98589\n",
      "[epoch 297, batch    16] loss: 3.20644\n",
      "[epoch 297, batch    17] loss: 3.34121\n",
      "[epoch 297, batch    18] loss: 2.63257\n",
      "[epoch 297, batch    19] loss: 3.35023\n",
      "[epoch 297, batch    20] loss: 2.16413\n",
      "[epoch 297, batch    21] loss: 2.88601\n",
      "[epoch 297, batch    22] loss: 2.94856\n",
      "[epoch 297, batch    23] loss: 2.66058\n",
      "[epoch 297, batch    24] loss: 3.15263\n",
      "[epoch 297, batch    25] loss: 2.57410\n",
      "[epoch 297, batch    26] loss: 2.94599\n",
      "[epoch 297, batch    27] loss: 3.47096\n",
      "[epoch 297, batch    28] loss: 2.98590\n",
      "[epoch 297, batch    29] loss: 2.19904\n",
      "[epoch 297, batch    30] loss: 2.90833\n",
      "[epoch 297, batch    31] loss: 3.55273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 297, batch    32] loss: 4.27736\n",
      "[epoch 298, batch     1] loss: 3.84213\n",
      "[epoch 298, batch     2] loss: 2.58983\n",
      "[epoch 298, batch     3] loss: 2.95657\n",
      "[epoch 298, batch     4] loss: 2.69255\n",
      "[epoch 298, batch     5] loss: 3.29108\n",
      "[epoch 298, batch     6] loss: 3.19617\n",
      "[epoch 298, batch     7] loss: 3.18011\n",
      "[epoch 298, batch     8] loss: 2.75916\n",
      "[epoch 298, batch     9] loss: 2.64149\n",
      "[epoch 298, batch    10] loss: 2.29082\n",
      "[epoch 298, batch    11] loss: 2.99732\n",
      "[epoch 298, batch    12] loss: 2.70323\n",
      "[epoch 298, batch    13] loss: 3.08500\n",
      "[epoch 298, batch    14] loss: 3.06676\n",
      "[epoch 298, batch    15] loss: 2.96544\n",
      "[epoch 298, batch    16] loss: 3.04968\n",
      "[epoch 298, batch    17] loss: 3.48109\n",
      "[epoch 298, batch    18] loss: 3.30871\n",
      "[epoch 298, batch    19] loss: 2.44266\n",
      "[epoch 298, batch    20] loss: 2.54763\n",
      "[epoch 298, batch    21] loss: 2.55097\n",
      "[epoch 298, batch    22] loss: 3.00373\n",
      "[epoch 298, batch    23] loss: 3.54623\n",
      "[epoch 298, batch    24] loss: 3.56519\n",
      "[epoch 298, batch    25] loss: 2.94474\n",
      "[epoch 298, batch    26] loss: 3.30210\n",
      "[epoch 298, batch    27] loss: 3.44539\n",
      "[epoch 298, batch    28] loss: 3.42983\n",
      "[epoch 298, batch    29] loss: 3.42996\n",
      "[epoch 298, batch    30] loss: 2.46519\n",
      "[epoch 298, batch    31] loss: 3.41169\n",
      "[epoch 298, batch    32] loss: 3.76685\n",
      "[epoch 299, batch     1] loss: 2.74064\n",
      "[epoch 299, batch     2] loss: 2.51059\n",
      "[epoch 299, batch     3] loss: 2.62962\n",
      "[epoch 299, batch     4] loss: 2.56376\n",
      "[epoch 299, batch     5] loss: 3.62749\n",
      "[epoch 299, batch     6] loss: 2.98235\n",
      "[epoch 299, batch     7] loss: 3.05941\n",
      "[epoch 299, batch     8] loss: 3.22746\n",
      "[epoch 299, batch     9] loss: 2.52697\n",
      "[epoch 299, batch    10] loss: 3.06800\n",
      "[epoch 299, batch    11] loss: 3.17367\n",
      "[epoch 299, batch    12] loss: 3.73388\n",
      "[epoch 299, batch    13] loss: 2.90292\n",
      "[epoch 299, batch    14] loss: 3.23592\n",
      "[epoch 299, batch    15] loss: 3.02301\n",
      "[epoch 299, batch    16] loss: 3.71685\n",
      "[epoch 299, batch    17] loss: 2.80649\n",
      "[epoch 299, batch    18] loss: 2.83627\n",
      "[epoch 299, batch    19] loss: 3.64782\n",
      "[epoch 299, batch    20] loss: 2.79919\n",
      "[epoch 299, batch    21] loss: 2.69007\n",
      "[epoch 299, batch    22] loss: 1.95391\n",
      "[epoch 299, batch    23] loss: 3.37608\n",
      "[epoch 299, batch    24] loss: 3.27034\n",
      "[epoch 299, batch    25] loss: 3.52053\n",
      "[epoch 299, batch    26] loss: 2.76760\n",
      "[epoch 299, batch    27] loss: 3.82193\n",
      "[epoch 299, batch    28] loss: 3.51402\n",
      "[epoch 299, batch    29] loss: 3.80177\n",
      "[epoch 299, batch    30] loss: 2.86683\n",
      "[epoch 299, batch    31] loss: 2.23875\n",
      "[epoch 299, batch    32] loss: 1.70898\n",
      "[epoch 300, batch     1] loss: 3.89172\n",
      "[epoch 300, batch     2] loss: 2.82699\n",
      "[epoch 300, batch     3] loss: 3.61470\n",
      "[epoch 300, batch     4] loss: 3.73015\n",
      "[epoch 300, batch     5] loss: 2.60587\n",
      "[epoch 300, batch     6] loss: 1.93338\n",
      "[epoch 300, batch     7] loss: 2.32196\n",
      "[epoch 300, batch     8] loss: 2.44765\n",
      "[epoch 300, batch     9] loss: 2.70477\n",
      "[epoch 300, batch    10] loss: 2.89902\n",
      "[epoch 300, batch    11] loss: 3.22654\n",
      "[epoch 300, batch    12] loss: 3.75314\n",
      "[epoch 300, batch    13] loss: 3.34557\n",
      "[epoch 300, batch    14] loss: 3.61246\n",
      "[epoch 300, batch    15] loss: 3.00812\n",
      "[epoch 300, batch    16] loss: 3.00625\n",
      "[epoch 300, batch    17] loss: 4.11195\n",
      "[epoch 300, batch    18] loss: 3.14444\n",
      "[epoch 300, batch    19] loss: 2.99847\n",
      "[epoch 300, batch    20] loss: 1.95097\n",
      "[epoch 300, batch    21] loss: 2.89534\n",
      "[epoch 300, batch    22] loss: 3.06319\n",
      "[epoch 300, batch    23] loss: 3.04087\n",
      "[epoch 300, batch    24] loss: 2.97395\n",
      "[epoch 300, batch    25] loss: 3.32814\n",
      "[epoch 300, batch    26] loss: 3.06454\n",
      "[epoch 300, batch    27] loss: 3.31112\n",
      "[epoch 300, batch    28] loss: 3.37992\n",
      "[epoch 300, batch    29] loss: 2.21760\n",
      "[epoch 300, batch    30] loss: 3.26576\n",
      "[epoch 300, batch    31] loss: 2.58305\n",
      "[epoch 300, batch    32] loss: 1.17589\n",
      "[epoch 301, batch     1] loss: 2.62086\n",
      "[epoch 301, batch     2] loss: 3.38461\n",
      "[epoch 301, batch     3] loss: 3.16818\n",
      "[epoch 301, batch     4] loss: 3.30153\n",
      "[epoch 301, batch     5] loss: 3.34471\n",
      "[epoch 301, batch     6] loss: 2.90399\n",
      "[epoch 301, batch     7] loss: 2.93029\n",
      "[epoch 301, batch     8] loss: 3.33668\n",
      "[epoch 301, batch     9] loss: 2.91150\n",
      "[epoch 301, batch    10] loss: 2.42805\n",
      "[epoch 301, batch    11] loss: 2.75798\n",
      "[epoch 301, batch    12] loss: 1.99760\n",
      "[epoch 301, batch    13] loss: 2.89979\n",
      "[epoch 301, batch    14] loss: 3.31874\n",
      "[epoch 301, batch    15] loss: 3.22630\n",
      "[epoch 301, batch    16] loss: 3.75864\n",
      "[epoch 301, batch    17] loss: 3.01111\n",
      "[epoch 301, batch    18] loss: 3.42942\n",
      "[epoch 301, batch    19] loss: 3.72686\n",
      "[epoch 301, batch    20] loss: 3.33602\n",
      "[epoch 301, batch    21] loss: 2.82686\n",
      "[epoch 301, batch    22] loss: 3.80103\n",
      "[epoch 301, batch    23] loss: 3.46401\n",
      "[epoch 301, batch    24] loss: 2.63920\n",
      "[epoch 301, batch    25] loss: 3.01395\n",
      "[epoch 301, batch    26] loss: 3.44286\n",
      "[epoch 301, batch    27] loss: 2.92910\n",
      "[epoch 301, batch    28] loss: 2.78285\n",
      "[epoch 301, batch    29] loss: 3.69124\n",
      "[epoch 301, batch    30] loss: 2.48843\n",
      "[epoch 301, batch    31] loss: 1.98674\n",
      "[epoch 301, batch    32] loss: 2.70647\n",
      "[epoch 302, batch     1] loss: 3.50857\n",
      "[epoch 302, batch     2] loss: 2.88336\n",
      "[epoch 302, batch     3] loss: 2.35862\n",
      "[epoch 302, batch     4] loss: 2.66682\n",
      "[epoch 302, batch     5] loss: 2.51824\n",
      "[epoch 302, batch     6] loss: 2.80765\n",
      "[epoch 302, batch     7] loss: 2.93952\n",
      "[epoch 302, batch     8] loss: 2.36063\n",
      "[epoch 302, batch     9] loss: 2.21131\n",
      "[epoch 302, batch    10] loss: 3.28998\n",
      "[epoch 302, batch    11] loss: 3.05231\n",
      "[epoch 302, batch    12] loss: 3.56593\n",
      "[epoch 302, batch    13] loss: 2.50455\n",
      "[epoch 302, batch    14] loss: 3.28045\n",
      "[epoch 302, batch    15] loss: 3.20713\n",
      "[epoch 302, batch    16] loss: 3.64649\n",
      "[epoch 302, batch    17] loss: 3.11846\n",
      "[epoch 302, batch    18] loss: 3.77794\n",
      "[epoch 302, batch    19] loss: 3.60959\n",
      "[epoch 302, batch    20] loss: 3.09490\n",
      "[epoch 302, batch    21] loss: 3.72355\n",
      "[epoch 302, batch    22] loss: 4.40240\n",
      "[epoch 302, batch    23] loss: 3.21911\n",
      "[epoch 302, batch    24] loss: 2.66410\n",
      "[epoch 302, batch    25] loss: 3.52045\n",
      "[epoch 302, batch    26] loss: 2.21087\n",
      "[epoch 302, batch    27] loss: 2.38020\n",
      "[epoch 302, batch    28] loss: 2.55883\n",
      "[epoch 302, batch    29] loss: 2.95450\n",
      "[epoch 302, batch    30] loss: 3.19281\n",
      "[epoch 302, batch    31] loss: 2.81798\n",
      "[epoch 302, batch    32] loss: 2.10005\n",
      "[epoch 303, batch     1] loss: 2.93067\n",
      "[epoch 303, batch     2] loss: 3.60042\n",
      "[epoch 303, batch     3] loss: 2.53854\n",
      "[epoch 303, batch     4] loss: 3.11038\n",
      "[epoch 303, batch     5] loss: 2.90911\n",
      "[epoch 303, batch     6] loss: 2.69986\n",
      "[epoch 303, batch     7] loss: 3.14765\n",
      "[epoch 303, batch     8] loss: 3.74090\n",
      "[epoch 303, batch     9] loss: 4.25715\n",
      "[epoch 303, batch    10] loss: 3.50952\n",
      "[epoch 303, batch    11] loss: 2.71705\n",
      "[epoch 303, batch    12] loss: 2.91784\n",
      "[epoch 303, batch    13] loss: 3.61876\n",
      "[epoch 303, batch    14] loss: 2.23658\n",
      "[epoch 303, batch    15] loss: 2.71767\n",
      "[epoch 303, batch    16] loss: 2.89804\n",
      "[epoch 303, batch    17] loss: 3.20256\n",
      "[epoch 303, batch    18] loss: 2.53053\n",
      "[epoch 303, batch    19] loss: 3.08322\n",
      "[epoch 303, batch    20] loss: 3.37311\n",
      "[epoch 303, batch    21] loss: 3.52977\n",
      "[epoch 303, batch    22] loss: 2.41416\n",
      "[epoch 303, batch    23] loss: 2.88222\n",
      "[epoch 303, batch    24] loss: 2.85535\n",
      "[epoch 303, batch    25] loss: 3.04978\n",
      "[epoch 303, batch    26] loss: 3.27755\n",
      "[epoch 303, batch    27] loss: 2.94878\n",
      "[epoch 303, batch    28] loss: 3.48823\n",
      "[epoch 303, batch    29] loss: 2.90551\n",
      "[epoch 303, batch    30] loss: 2.03849\n",
      "[epoch 303, batch    31] loss: 3.28408\n",
      "[epoch 303, batch    32] loss: 3.06986\n",
      "[epoch 304, batch     1] loss: 4.04459\n",
      "[epoch 304, batch     2] loss: 2.75196\n",
      "[epoch 304, batch     3] loss: 2.83881\n",
      "[epoch 304, batch     4] loss: 3.81604\n",
      "[epoch 304, batch     5] loss: 3.27135\n",
      "[epoch 304, batch     6] loss: 2.84957\n",
      "[epoch 304, batch     7] loss: 2.70480\n",
      "[epoch 304, batch     8] loss: 2.93436\n",
      "[epoch 304, batch     9] loss: 3.05200\n",
      "[epoch 304, batch    10] loss: 2.24392\n",
      "[epoch 304, batch    11] loss: 3.31247\n",
      "[epoch 304, batch    12] loss: 3.15639\n",
      "[epoch 304, batch    13] loss: 2.82170\n",
      "[epoch 304, batch    14] loss: 2.74548\n",
      "[epoch 304, batch    15] loss: 3.59992\n",
      "[epoch 304, batch    16] loss: 2.45122\n",
      "[epoch 304, batch    17] loss: 3.28307\n",
      "[epoch 304, batch    18] loss: 2.79560\n",
      "[epoch 304, batch    19] loss: 2.96625\n",
      "[epoch 304, batch    20] loss: 3.14458\n",
      "[epoch 304, batch    21] loss: 2.64645\n",
      "[epoch 304, batch    22] loss: 3.03631\n",
      "[epoch 304, batch    23] loss: 2.38807\n",
      "[epoch 304, batch    24] loss: 3.12991\n",
      "[epoch 304, batch    25] loss: 3.44905\n",
      "[epoch 304, batch    26] loss: 3.78926\n",
      "[epoch 304, batch    27] loss: 3.12980\n",
      "[epoch 304, batch    28] loss: 2.99480\n",
      "[epoch 304, batch    29] loss: 3.25062\n",
      "[epoch 304, batch    30] loss: 2.59963\n",
      "[epoch 304, batch    31] loss: 2.83646\n",
      "[epoch 304, batch    32] loss: 3.35990\n",
      "[epoch 305, batch     1] loss: 2.59820\n",
      "[epoch 305, batch     2] loss: 2.76490\n",
      "[epoch 305, batch     3] loss: 3.29336\n",
      "[epoch 305, batch     4] loss: 3.52805\n",
      "[epoch 305, batch     5] loss: 3.73040\n",
      "[epoch 305, batch     6] loss: 3.88638\n",
      "[epoch 305, batch     7] loss: 3.67717\n",
      "[epoch 305, batch     8] loss: 3.36041\n",
      "[epoch 305, batch     9] loss: 2.87391\n",
      "[epoch 305, batch    10] loss: 3.24000\n",
      "[epoch 305, batch    11] loss: 2.23655\n",
      "[epoch 305, batch    12] loss: 2.84793\n",
      "[epoch 305, batch    13] loss: 2.99307\n",
      "[epoch 305, batch    14] loss: 2.80133\n",
      "[epoch 305, batch    15] loss: 3.62665\n",
      "[epoch 305, batch    16] loss: 3.35714\n",
      "[epoch 305, batch    17] loss: 3.17325\n",
      "[epoch 305, batch    18] loss: 2.56579\n",
      "[epoch 305, batch    19] loss: 3.05834\n",
      "[epoch 305, batch    20] loss: 3.02667\n",
      "[epoch 305, batch    21] loss: 3.01759\n",
      "[epoch 305, batch    22] loss: 3.08834\n",
      "[epoch 305, batch    23] loss: 1.98418\n",
      "[epoch 305, batch    24] loss: 2.79281\n",
      "[epoch 305, batch    25] loss: 4.15861\n",
      "[epoch 305, batch    26] loss: 2.74626\n",
      "[epoch 305, batch    27] loss: 3.27886\n",
      "[epoch 305, batch    28] loss: 3.19064\n",
      "[epoch 305, batch    29] loss: 2.13471\n",
      "[epoch 305, batch    30] loss: 2.47546\n",
      "[epoch 305, batch    31] loss: 2.72111\n",
      "[epoch 305, batch    32] loss: 3.05309\n",
      "[epoch 306, batch     1] loss: 3.52727\n",
      "[epoch 306, batch     2] loss: 2.33436\n",
      "[epoch 306, batch     3] loss: 3.09204\n",
      "[epoch 306, batch     4] loss: 3.44383\n",
      "[epoch 306, batch     5] loss: 3.14452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 306, batch     6] loss: 3.17388\n",
      "[epoch 306, batch     7] loss: 3.14573\n",
      "[epoch 306, batch     8] loss: 2.89725\n",
      "[epoch 306, batch     9] loss: 3.38878\n",
      "[epoch 306, batch    10] loss: 2.97382\n",
      "[epoch 306, batch    11] loss: 2.80804\n",
      "[epoch 306, batch    12] loss: 2.35508\n",
      "[epoch 306, batch    13] loss: 3.29985\n",
      "[epoch 306, batch    14] loss: 3.19130\n",
      "[epoch 306, batch    15] loss: 2.06438\n",
      "[epoch 306, batch    16] loss: 3.31945\n",
      "[epoch 306, batch    17] loss: 2.97430\n",
      "[epoch 306, batch    18] loss: 3.64207\n",
      "[epoch 306, batch    19] loss: 2.81048\n",
      "[epoch 306, batch    20] loss: 1.95251\n",
      "[epoch 306, batch    21] loss: 3.08369\n",
      "[epoch 306, batch    22] loss: 3.21506\n",
      "[epoch 306, batch    23] loss: 3.16468\n",
      "[epoch 306, batch    24] loss: 3.01663\n",
      "[epoch 306, batch    25] loss: 3.36849\n",
      "[epoch 306, batch    26] loss: 3.20049\n",
      "[epoch 306, batch    27] loss: 2.64292\n",
      "[epoch 306, batch    28] loss: 3.00835\n",
      "[epoch 306, batch    29] loss: 2.18616\n",
      "[epoch 306, batch    30] loss: 4.30837\n",
      "[epoch 306, batch    31] loss: 3.62143\n",
      "[epoch 306, batch    32] loss: 3.35363\n",
      "[epoch 307, batch     1] loss: 3.47649\n",
      "[epoch 307, batch     2] loss: 3.23623\n",
      "[epoch 307, batch     3] loss: 2.32452\n",
      "[epoch 307, batch     4] loss: 2.54555\n",
      "[epoch 307, batch     5] loss: 2.78334\n",
      "[epoch 307, batch     6] loss: 2.41761\n",
      "[epoch 307, batch     7] loss: 2.83884\n",
      "[epoch 307, batch     8] loss: 3.97359\n",
      "[epoch 307, batch     9] loss: 2.97187\n",
      "[epoch 307, batch    10] loss: 3.39781\n",
      "[epoch 307, batch    11] loss: 3.37808\n",
      "[epoch 307, batch    12] loss: 2.47599\n",
      "[epoch 307, batch    13] loss: 4.34521\n",
      "[epoch 307, batch    14] loss: 2.90613\n",
      "[epoch 307, batch    15] loss: 2.43109\n",
      "[epoch 307, batch    16] loss: 2.79691\n",
      "[epoch 307, batch    17] loss: 2.47371\n",
      "[epoch 307, batch    18] loss: 2.80091\n",
      "[epoch 307, batch    19] loss: 3.15172\n",
      "[epoch 307, batch    20] loss: 2.61934\n",
      "[epoch 307, batch    21] loss: 4.43972\n",
      "[epoch 307, batch    22] loss: 1.87902\n",
      "[epoch 307, batch    23] loss: 3.15169\n",
      "[epoch 307, batch    24] loss: 2.66065\n",
      "[epoch 307, batch    25] loss: 3.55950\n",
      "[epoch 307, batch    26] loss: 3.86273\n",
      "[epoch 307, batch    27] loss: 2.46027\n",
      "[epoch 307, batch    28] loss: 3.22979\n",
      "[epoch 307, batch    29] loss: 3.36045\n",
      "[epoch 307, batch    30] loss: 3.21603\n",
      "[epoch 307, batch    31] loss: 3.63137\n",
      "[epoch 307, batch    32] loss: 3.15041\n",
      "[epoch 308, batch     1] loss: 2.53341\n",
      "[epoch 308, batch     2] loss: 3.43576\n",
      "[epoch 308, batch     3] loss: 3.15555\n",
      "[epoch 308, batch     4] loss: 3.73193\n",
      "[epoch 308, batch     5] loss: 3.06198\n",
      "[epoch 308, batch     6] loss: 2.20224\n",
      "[epoch 308, batch     7] loss: 3.11786\n",
      "[epoch 308, batch     8] loss: 3.68254\n",
      "[epoch 308, batch     9] loss: 4.18693\n",
      "[epoch 308, batch    10] loss: 2.87666\n",
      "[epoch 308, batch    11] loss: 2.54298\n",
      "[epoch 308, batch    12] loss: 3.62966\n",
      "[epoch 308, batch    13] loss: 3.28538\n",
      "[epoch 308, batch    14] loss: 3.17507\n",
      "[epoch 308, batch    15] loss: 2.85746\n",
      "[epoch 308, batch    16] loss: 2.69149\n",
      "[epoch 308, batch    17] loss: 2.32476\n",
      "[epoch 308, batch    18] loss: 3.32385\n",
      "[epoch 308, batch    19] loss: 3.24674\n",
      "[epoch 308, batch    20] loss: 2.95846\n",
      "[epoch 308, batch    21] loss: 2.75060\n",
      "[epoch 308, batch    22] loss: 2.64272\n",
      "[epoch 308, batch    23] loss: 2.05375\n",
      "[epoch 308, batch    24] loss: 2.97830\n",
      "[epoch 308, batch    25] loss: 3.63959\n",
      "[epoch 308, batch    26] loss: 3.01137\n",
      "[epoch 308, batch    27] loss: 3.38167\n",
      "[epoch 308, batch    28] loss: 3.18241\n",
      "[epoch 308, batch    29] loss: 2.37989\n",
      "[epoch 308, batch    30] loss: 3.15633\n",
      "[epoch 308, batch    31] loss: 3.50191\n",
      "[epoch 308, batch    32] loss: 1.16573\n",
      "[epoch 309, batch     1] loss: 2.80142\n",
      "[epoch 309, batch     2] loss: 2.90479\n",
      "[epoch 309, batch     3] loss: 2.49482\n",
      "[epoch 309, batch     4] loss: 3.74652\n",
      "[epoch 309, batch     5] loss: 3.29326\n",
      "[epoch 309, batch     6] loss: 3.41293\n",
      "[epoch 309, batch     7] loss: 2.14784\n",
      "[epoch 309, batch     8] loss: 2.51263\n",
      "[epoch 309, batch     9] loss: 2.62739\n",
      "[epoch 309, batch    10] loss: 3.76984\n",
      "[epoch 309, batch    11] loss: 3.24786\n",
      "[epoch 309, batch    12] loss: 3.07925\n",
      "[epoch 309, batch    13] loss: 2.54421\n",
      "[epoch 309, batch    14] loss: 3.26979\n",
      "[epoch 309, batch    15] loss: 3.46550\n",
      "[epoch 309, batch    16] loss: 2.79160\n",
      "[epoch 309, batch    17] loss: 2.86338\n",
      "[epoch 309, batch    18] loss: 3.30058\n",
      "[epoch 309, batch    19] loss: 2.59612\n",
      "[epoch 309, batch    20] loss: 2.79467\n",
      "[epoch 309, batch    21] loss: 3.59435\n",
      "[epoch 309, batch    22] loss: 3.27584\n",
      "[epoch 309, batch    23] loss: 2.31355\n",
      "[epoch 309, batch    24] loss: 3.23778\n",
      "[epoch 309, batch    25] loss: 3.17579\n",
      "[epoch 309, batch    26] loss: 3.12940\n",
      "[epoch 309, batch    27] loss: 3.63755\n",
      "[epoch 309, batch    28] loss: 3.22337\n",
      "[epoch 309, batch    29] loss: 2.95740\n",
      "[epoch 309, batch    30] loss: 2.61504\n",
      "[epoch 309, batch    31] loss: 3.38628\n",
      "[epoch 309, batch    32] loss: 3.14091\n",
      "[epoch 310, batch     1] loss: 2.39401\n",
      "[epoch 310, batch     2] loss: 3.49432\n",
      "[epoch 310, batch     3] loss: 3.46017\n",
      "[epoch 310, batch     4] loss: 3.10426\n",
      "[epoch 310, batch     5] loss: 2.52993\n",
      "[epoch 310, batch     6] loss: 3.64431\n",
      "[epoch 310, batch     7] loss: 2.41787\n",
      "[epoch 310, batch     8] loss: 2.65913\n",
      "[epoch 310, batch     9] loss: 3.07900\n",
      "[epoch 310, batch    10] loss: 3.07315\n",
      "[epoch 310, batch    11] loss: 3.14755\n",
      "[epoch 310, batch    12] loss: 3.37171\n",
      "[epoch 310, batch    13] loss: 2.32215\n",
      "[epoch 310, batch    14] loss: 3.16584\n",
      "[epoch 310, batch    15] loss: 3.11570\n",
      "[epoch 310, batch    16] loss: 2.46181\n",
      "[epoch 310, batch    17] loss: 1.97790\n",
      "[epoch 310, batch    18] loss: 2.73731\n",
      "[epoch 310, batch    19] loss: 3.31429\n",
      "[epoch 310, batch    20] loss: 2.06428\n",
      "[epoch 310, batch    21] loss: 3.26855\n",
      "[epoch 310, batch    22] loss: 3.15823\n",
      "[epoch 310, batch    23] loss: 3.82075\n",
      "[epoch 310, batch    24] loss: 3.79994\n",
      "[epoch 310, batch    25] loss: 2.51474\n",
      "[epoch 310, batch    26] loss: 3.51183\n",
      "[epoch 310, batch    27] loss: 3.14199\n",
      "[epoch 310, batch    28] loss: 3.79377\n",
      "[epoch 310, batch    29] loss: 2.98694\n",
      "[epoch 310, batch    30] loss: 3.12126\n",
      "[epoch 310, batch    31] loss: 3.15757\n",
      "[epoch 310, batch    32] loss: 2.90947\n",
      "[epoch 311, batch     1] loss: 2.87298\n",
      "[epoch 311, batch     2] loss: 2.81081\n",
      "[epoch 311, batch     3] loss: 3.15681\n",
      "[epoch 311, batch     4] loss: 3.02280\n",
      "[epoch 311, batch     5] loss: 2.71981\n",
      "[epoch 311, batch     6] loss: 3.08951\n",
      "[epoch 311, batch     7] loss: 3.34992\n",
      "[epoch 311, batch     8] loss: 3.50025\n",
      "[epoch 311, batch     9] loss: 3.20886\n",
      "[epoch 311, batch    10] loss: 3.90381\n",
      "[epoch 311, batch    11] loss: 3.31798\n",
      "[epoch 311, batch    12] loss: 3.22833\n",
      "[epoch 311, batch    13] loss: 2.68048\n",
      "[epoch 311, batch    14] loss: 3.41085\n",
      "[epoch 311, batch    15] loss: 2.72391\n",
      "[epoch 311, batch    16] loss: 3.01243\n",
      "[epoch 311, batch    17] loss: 3.15696\n",
      "[epoch 311, batch    18] loss: 3.64923\n",
      "[epoch 311, batch    19] loss: 3.72677\n",
      "[epoch 311, batch    20] loss: 2.68938\n",
      "[epoch 311, batch    21] loss: 3.11340\n",
      "[epoch 311, batch    22] loss: 2.94372\n",
      "[epoch 311, batch    23] loss: 2.27376\n",
      "[epoch 311, batch    24] loss: 2.74146\n",
      "[epoch 311, batch    25] loss: 3.76601\n",
      "[epoch 311, batch    26] loss: 3.15192\n",
      "[epoch 311, batch    27] loss: 2.47168\n",
      "[epoch 311, batch    28] loss: 2.53535\n",
      "[epoch 311, batch    29] loss: 3.30872\n",
      "[epoch 311, batch    30] loss: 1.97053\n",
      "[epoch 311, batch    31] loss: 2.91293\n",
      "[epoch 311, batch    32] loss: 3.07901\n",
      "[epoch 312, batch     1] loss: 2.67328\n",
      "[epoch 312, batch     2] loss: 2.66758\n",
      "[epoch 312, batch     3] loss: 3.03057\n",
      "[epoch 312, batch     4] loss: 3.14384\n",
      "[epoch 312, batch     5] loss: 2.92080\n",
      "[epoch 312, batch     6] loss: 3.24267\n",
      "[epoch 312, batch     7] loss: 2.14050\n",
      "[epoch 312, batch     8] loss: 2.28815\n",
      "[epoch 312, batch     9] loss: 3.08405\n",
      "[epoch 312, batch    10] loss: 3.55307\n",
      "[epoch 312, batch    11] loss: 4.23978\n",
      "[epoch 312, batch    12] loss: 3.87409\n",
      "[epoch 312, batch    13] loss: 2.82778\n",
      "[epoch 312, batch    14] loss: 2.65949\n",
      "[epoch 312, batch    15] loss: 2.89005\n",
      "[epoch 312, batch    16] loss: 2.76601\n",
      "[epoch 312, batch    17] loss: 3.08377\n",
      "[epoch 312, batch    18] loss: 2.84450\n",
      "[epoch 312, batch    19] loss: 2.56523\n",
      "[epoch 312, batch    20] loss: 3.53468\n",
      "[epoch 312, batch    21] loss: 3.73338\n",
      "[epoch 312, batch    22] loss: 3.15497\n",
      "[epoch 312, batch    23] loss: 2.58426\n",
      "[epoch 312, batch    24] loss: 2.95953\n",
      "[epoch 312, batch    25] loss: 3.11804\n",
      "[epoch 312, batch    26] loss: 2.92583\n",
      "[epoch 312, batch    27] loss: 3.66840\n",
      "[epoch 312, batch    28] loss: 3.23265\n",
      "[epoch 312, batch    29] loss: 2.48081\n",
      "[epoch 312, batch    30] loss: 3.57622\n",
      "[epoch 312, batch    31] loss: 3.10693\n",
      "[epoch 312, batch    32] loss: 1.44207\n",
      "[epoch 313, batch     1] loss: 3.09883\n",
      "[epoch 313, batch     2] loss: 2.95757\n",
      "[epoch 313, batch     3] loss: 3.88057\n",
      "[epoch 313, batch     4] loss: 3.34061\n",
      "[epoch 313, batch     5] loss: 3.46846\n",
      "[epoch 313, batch     6] loss: 2.67021\n",
      "[epoch 313, batch     7] loss: 4.05066\n",
      "[epoch 313, batch     8] loss: 3.83992\n",
      "[epoch 313, batch     9] loss: 2.61250\n",
      "[epoch 313, batch    10] loss: 2.70158\n",
      "[epoch 313, batch    11] loss: 2.81600\n",
      "[epoch 313, batch    12] loss: 2.84716\n",
      "[epoch 313, batch    13] loss: 2.44733\n",
      "[epoch 313, batch    14] loss: 3.62873\n",
      "[epoch 313, batch    15] loss: 3.35769\n",
      "[epoch 313, batch    16] loss: 2.61532\n",
      "[epoch 313, batch    17] loss: 1.89130\n",
      "[epoch 313, batch    18] loss: 2.99239\n",
      "[epoch 313, batch    19] loss: 3.63468\n",
      "[epoch 313, batch    20] loss: 3.43059\n",
      "[epoch 313, batch    21] loss: 1.81024\n",
      "[epoch 313, batch    22] loss: 3.18938\n",
      "[epoch 313, batch    23] loss: 2.88963\n",
      "[epoch 313, batch    24] loss: 2.68411\n",
      "[epoch 313, batch    25] loss: 3.18806\n",
      "[epoch 313, batch    26] loss: 3.35791\n",
      "[epoch 313, batch    27] loss: 2.28843\n",
      "[epoch 313, batch    28] loss: 3.25038\n",
      "[epoch 313, batch    29] loss: 2.80019\n",
      "[epoch 313, batch    30] loss: 3.53237\n",
      "[epoch 313, batch    31] loss: 2.58670\n",
      "[epoch 313, batch    32] loss: 2.64767\n",
      "[epoch 314, batch     1] loss: 3.48796\n",
      "[epoch 314, batch     2] loss: 2.14033\n",
      "[epoch 314, batch     3] loss: 2.25234\n",
      "[epoch 314, batch     4] loss: 2.65252\n",
      "[epoch 314, batch     5] loss: 3.13119\n",
      "[epoch 314, batch     6] loss: 3.13527\n",
      "[epoch 314, batch     7] loss: 2.93972\n",
      "[epoch 314, batch     8] loss: 3.36269\n",
      "[epoch 314, batch     9] loss: 3.33196\n",
      "[epoch 314, batch    10] loss: 3.84470\n",
      "[epoch 314, batch    11] loss: 3.70359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 314, batch    12] loss: 3.54223\n",
      "[epoch 314, batch    13] loss: 2.78279\n",
      "[epoch 314, batch    14] loss: 3.27018\n",
      "[epoch 314, batch    15] loss: 3.08165\n",
      "[epoch 314, batch    16] loss: 3.12780\n",
      "[epoch 314, batch    17] loss: 3.10438\n",
      "[epoch 314, batch    18] loss: 2.75073\n",
      "[epoch 314, batch    19] loss: 3.09379\n",
      "[epoch 314, batch    20] loss: 2.73576\n",
      "[epoch 314, batch    21] loss: 3.27251\n",
      "[epoch 314, batch    22] loss: 2.87635\n",
      "[epoch 314, batch    23] loss: 2.32481\n",
      "[epoch 314, batch    24] loss: 3.78624\n",
      "[epoch 314, batch    25] loss: 2.93995\n",
      "[epoch 314, batch    26] loss: 2.63226\n",
      "[epoch 314, batch    27] loss: 2.65860\n",
      "[epoch 314, batch    28] loss: 4.10165\n",
      "[epoch 314, batch    29] loss: 3.20368\n",
      "[epoch 314, batch    30] loss: 2.77700\n",
      "[epoch 314, batch    31] loss: 2.06386\n",
      "[epoch 314, batch    32] loss: 2.94450\n",
      "[epoch 315, batch     1] loss: 3.03994\n",
      "[epoch 315, batch     2] loss: 3.19472\n",
      "[epoch 315, batch     3] loss: 2.15396\n",
      "[epoch 315, batch     4] loss: 2.74945\n",
      "[epoch 315, batch     5] loss: 3.99446\n",
      "[epoch 315, batch     6] loss: 2.13110\n",
      "[epoch 315, batch     7] loss: 3.04136\n",
      "[epoch 315, batch     8] loss: 2.65378\n",
      "[epoch 315, batch     9] loss: 2.86636\n",
      "[epoch 315, batch    10] loss: 3.52241\n",
      "[epoch 315, batch    11] loss: 3.70642\n",
      "[epoch 315, batch    12] loss: 2.92014\n",
      "[epoch 315, batch    13] loss: 3.38599\n",
      "[epoch 315, batch    14] loss: 2.70583\n",
      "[epoch 315, batch    15] loss: 1.91820\n",
      "[epoch 315, batch    16] loss: 2.47452\n",
      "[epoch 315, batch    17] loss: 3.01200\n",
      "[epoch 315, batch    18] loss: 2.94520\n",
      "[epoch 315, batch    19] loss: 2.34903\n",
      "[epoch 315, batch    20] loss: 3.55205\n",
      "[epoch 315, batch    21] loss: 4.22417\n",
      "[epoch 315, batch    22] loss: 2.81766\n",
      "[epoch 315, batch    23] loss: 3.46980\n",
      "[epoch 315, batch    24] loss: 2.58904\n",
      "[epoch 315, batch    25] loss: 3.22857\n",
      "[epoch 315, batch    26] loss: 3.72166\n",
      "[epoch 315, batch    27] loss: 3.00089\n",
      "[epoch 315, batch    28] loss: 2.74052\n",
      "[epoch 315, batch    29] loss: 2.77008\n",
      "[epoch 315, batch    30] loss: 3.42747\n",
      "[epoch 315, batch    31] loss: 3.70031\n",
      "[epoch 315, batch    32] loss: 4.18210\n",
      "[epoch 316, batch     1] loss: 3.39495\n",
      "[epoch 316, batch     2] loss: 2.87930\n",
      "[epoch 316, batch     3] loss: 3.32276\n",
      "[epoch 316, batch     4] loss: 3.33751\n",
      "[epoch 316, batch     5] loss: 3.45206\n",
      "[epoch 316, batch     6] loss: 2.01807\n",
      "[epoch 316, batch     7] loss: 2.79910\n",
      "[epoch 316, batch     8] loss: 2.39262\n",
      "[epoch 316, batch     9] loss: 3.29541\n",
      "[epoch 316, batch    10] loss: 3.99061\n",
      "[epoch 316, batch    11] loss: 3.24035\n",
      "[epoch 316, batch    12] loss: 2.84018\n",
      "[epoch 316, batch    13] loss: 3.14998\n",
      "[epoch 316, batch    14] loss: 2.74411\n",
      "[epoch 316, batch    15] loss: 4.09576\n",
      "[epoch 316, batch    16] loss: 2.77953\n",
      "[epoch 316, batch    17] loss: 2.54124\n",
      "[epoch 316, batch    18] loss: 2.94285\n",
      "[epoch 316, batch    19] loss: 3.12568\n",
      "[epoch 316, batch    20] loss: 2.51243\n",
      "[epoch 316, batch    21] loss: 3.01498\n",
      "[epoch 316, batch    22] loss: 2.54599\n",
      "[epoch 316, batch    23] loss: 3.58183\n",
      "[epoch 316, batch    24] loss: 2.77584\n",
      "[epoch 316, batch    25] loss: 3.34850\n",
      "[epoch 316, batch    26] loss: 2.97100\n",
      "[epoch 316, batch    27] loss: 3.08799\n",
      "[epoch 316, batch    28] loss: 2.59570\n",
      "[epoch 316, batch    29] loss: 3.34902\n",
      "[epoch 316, batch    30] loss: 2.75036\n",
      "[epoch 316, batch    31] loss: 2.94358\n",
      "[epoch 316, batch    32] loss: 3.56579\n",
      "[epoch 317, batch     1] loss: 2.56910\n",
      "[epoch 317, batch     2] loss: 3.15452\n",
      "[epoch 317, batch     3] loss: 3.58792\n",
      "[epoch 317, batch     4] loss: 3.93234\n",
      "[epoch 317, batch     5] loss: 3.00926\n",
      "[epoch 317, batch     6] loss: 2.82623\n",
      "[epoch 317, batch     7] loss: 2.61381\n",
      "[epoch 317, batch     8] loss: 3.77685\n",
      "[epoch 317, batch     9] loss: 3.05902\n",
      "[epoch 317, batch    10] loss: 2.71948\n",
      "[epoch 317, batch    11] loss: 1.99831\n",
      "[epoch 317, batch    12] loss: 2.43169\n",
      "[epoch 317, batch    13] loss: 2.15289\n",
      "[epoch 317, batch    14] loss: 2.61686\n",
      "[epoch 317, batch    15] loss: 2.89755\n",
      "[epoch 317, batch    16] loss: 3.28895\n",
      "[epoch 317, batch    17] loss: 3.37225\n",
      "[epoch 317, batch    18] loss: 2.92575\n",
      "[epoch 317, batch    19] loss: 3.20287\n",
      "[epoch 317, batch    20] loss: 3.07658\n",
      "[epoch 317, batch    21] loss: 3.07079\n",
      "[epoch 317, batch    22] loss: 3.33256\n",
      "[epoch 317, batch    23] loss: 2.74960\n",
      "[epoch 317, batch    24] loss: 3.62019\n",
      "[epoch 317, batch    25] loss: 3.25517\n",
      "[epoch 317, batch    26] loss: 3.27583\n",
      "[epoch 317, batch    27] loss: 3.78876\n",
      "[epoch 317, batch    28] loss: 2.85398\n",
      "[epoch 317, batch    29] loss: 2.32780\n",
      "[epoch 317, batch    30] loss: 2.84582\n",
      "[epoch 317, batch    31] loss: 3.25433\n",
      "[epoch 317, batch    32] loss: 3.35133\n",
      "[epoch 318, batch     1] loss: 2.87536\n",
      "[epoch 318, batch     2] loss: 2.41229\n",
      "[epoch 318, batch     3] loss: 2.54118\n",
      "[epoch 318, batch     4] loss: 3.37347\n",
      "[epoch 318, batch     5] loss: 2.88509\n",
      "[epoch 318, batch     6] loss: 3.13771\n",
      "[epoch 318, batch     7] loss: 3.64264\n",
      "[epoch 318, batch     8] loss: 3.17319\n",
      "[epoch 318, batch     9] loss: 2.97624\n",
      "[epoch 318, batch    10] loss: 3.27154\n",
      "[epoch 318, batch    11] loss: 3.56938\n",
      "[epoch 318, batch    12] loss: 3.11609\n",
      "[epoch 318, batch    13] loss: 3.55838\n",
      "[epoch 318, batch    14] loss: 2.88594\n",
      "[epoch 318, batch    15] loss: 3.56443\n",
      "[epoch 318, batch    16] loss: 3.03659\n",
      "[epoch 318, batch    17] loss: 2.93486\n",
      "[epoch 318, batch    18] loss: 2.90167\n",
      "[epoch 318, batch    19] loss: 2.19515\n",
      "[epoch 318, batch    20] loss: 2.92051\n",
      "[epoch 318, batch    21] loss: 2.33635\n",
      "[epoch 318, batch    22] loss: 3.26509\n",
      "[epoch 318, batch    23] loss: 3.12048\n",
      "[epoch 318, batch    24] loss: 2.51443\n",
      "[epoch 318, batch    25] loss: 3.57258\n",
      "[epoch 318, batch    26] loss: 2.37681\n",
      "[epoch 318, batch    27] loss: 3.45333\n",
      "[epoch 318, batch    28] loss: 2.59534\n",
      "[epoch 318, batch    29] loss: 3.56423\n",
      "[epoch 318, batch    30] loss: 2.86670\n",
      "[epoch 318, batch    31] loss: 3.17632\n",
      "[epoch 318, batch    32] loss: 3.38728\n",
      "[epoch 319, batch     1] loss: 4.32110\n",
      "[epoch 319, batch     2] loss: 3.06862\n",
      "[epoch 319, batch     3] loss: 2.50163\n",
      "[epoch 319, batch     4] loss: 2.44654\n",
      "[epoch 319, batch     5] loss: 2.79133\n",
      "[epoch 319, batch     6] loss: 3.09522\n",
      "[epoch 319, batch     7] loss: 2.88205\n",
      "[epoch 319, batch     8] loss: 3.26913\n",
      "[epoch 319, batch     9] loss: 3.26198\n",
      "[epoch 319, batch    10] loss: 3.18017\n",
      "[epoch 319, batch    11] loss: 2.91877\n",
      "[epoch 319, batch    12] loss: 2.90741\n",
      "[epoch 319, batch    13] loss: 3.87076\n",
      "[epoch 319, batch    14] loss: 2.23706\n",
      "[epoch 319, batch    15] loss: 3.09901\n",
      "[epoch 319, batch    16] loss: 2.59631\n",
      "[epoch 319, batch    17] loss: 3.17587\n",
      "[epoch 319, batch    18] loss: 3.02365\n",
      "[epoch 319, batch    19] loss: 3.08769\n",
      "[epoch 319, batch    20] loss: 3.53218\n",
      "[epoch 319, batch    21] loss: 2.70324\n",
      "[epoch 319, batch    22] loss: 3.34755\n",
      "[epoch 319, batch    23] loss: 2.76568\n",
      "[epoch 319, batch    24] loss: 3.51666\n",
      "[epoch 319, batch    25] loss: 2.09965\n",
      "[epoch 319, batch    26] loss: 3.15188\n",
      "[epoch 319, batch    27] loss: 3.37539\n",
      "[epoch 319, batch    28] loss: 2.88400\n",
      "[epoch 319, batch    29] loss: 3.53189\n",
      "[epoch 319, batch    30] loss: 2.56807\n",
      "[epoch 319, batch    31] loss: 3.34197\n",
      "[epoch 319, batch    32] loss: 1.98501\n",
      "[epoch 320, batch     1] loss: 3.03706\n",
      "[epoch 320, batch     2] loss: 3.24909\n",
      "[epoch 320, batch     3] loss: 2.96218\n",
      "[epoch 320, batch     4] loss: 2.81018\n",
      "[epoch 320, batch     5] loss: 3.37952\n",
      "[epoch 320, batch     6] loss: 2.50931\n",
      "[epoch 320, batch     7] loss: 2.90674\n",
      "[epoch 320, batch     8] loss: 2.51451\n",
      "[epoch 320, batch     9] loss: 2.38506\n",
      "[epoch 320, batch    10] loss: 3.23661\n",
      "[epoch 320, batch    11] loss: 3.51779\n",
      "[epoch 320, batch    12] loss: 3.44493\n",
      "[epoch 320, batch    13] loss: 2.93278\n",
      "[epoch 320, batch    14] loss: 3.69835\n",
      "[epoch 320, batch    15] loss: 2.71788\n",
      "[epoch 320, batch    16] loss: 3.05748\n",
      "[epoch 320, batch    17] loss: 3.07664\n",
      "[epoch 320, batch    18] loss: 2.61394\n",
      "[epoch 320, batch    19] loss: 2.97737\n",
      "[epoch 320, batch    20] loss: 2.97869\n",
      "[epoch 320, batch    21] loss: 3.24367\n",
      "[epoch 320, batch    22] loss: 3.44245\n",
      "[epoch 320, batch    23] loss: 3.44585\n",
      "[epoch 320, batch    24] loss: 3.32887\n",
      "[epoch 320, batch    25] loss: 3.29510\n",
      "[epoch 320, batch    26] loss: 2.51474\n",
      "[epoch 320, batch    27] loss: 3.41710\n",
      "[epoch 320, batch    28] loss: 3.10536\n",
      "[epoch 320, batch    29] loss: 3.14938\n",
      "[epoch 320, batch    30] loss: 2.37646\n",
      "[epoch 320, batch    31] loss: 2.60140\n",
      "[epoch 320, batch    32] loss: 4.34211\n",
      "[epoch 321, batch     1] loss: 2.67413\n",
      "[epoch 321, batch     2] loss: 2.49888\n",
      "[epoch 321, batch     3] loss: 3.31161\n",
      "[epoch 321, batch     4] loss: 2.12121\n",
      "[epoch 321, batch     5] loss: 3.02013\n",
      "[epoch 321, batch     6] loss: 3.24416\n",
      "[epoch 321, batch     7] loss: 2.84805\n",
      "[epoch 321, batch     8] loss: 2.57866\n",
      "[epoch 321, batch     9] loss: 2.83120\n",
      "[epoch 321, batch    10] loss: 3.74489\n",
      "[epoch 321, batch    11] loss: 2.77995\n",
      "[epoch 321, batch    12] loss: 3.26680\n",
      "[epoch 321, batch    13] loss: 3.35528\n",
      "[epoch 321, batch    14] loss: 3.12499\n",
      "[epoch 321, batch    15] loss: 2.64875\n",
      "[epoch 321, batch    16] loss: 3.38252\n",
      "[epoch 321, batch    17] loss: 3.37619\n",
      "[epoch 321, batch    18] loss: 2.84869\n",
      "[epoch 321, batch    19] loss: 2.45237\n",
      "[epoch 321, batch    20] loss: 3.08294\n",
      "[epoch 321, batch    21] loss: 2.69177\n",
      "[epoch 321, batch    22] loss: 3.38845\n",
      "[epoch 321, batch    23] loss: 3.30636\n",
      "[epoch 321, batch    24] loss: 2.86379\n",
      "[epoch 321, batch    25] loss: 2.51000\n",
      "[epoch 321, batch    26] loss: 4.41218\n",
      "[epoch 321, batch    27] loss: 3.55598\n",
      "[epoch 321, batch    28] loss: 2.72656\n",
      "[epoch 321, batch    29] loss: 3.32035\n",
      "[epoch 321, batch    30] loss: 3.38838\n",
      "[epoch 321, batch    31] loss: 3.04822\n",
      "[epoch 321, batch    32] loss: 3.08963\n",
      "[epoch 322, batch     1] loss: 2.89609\n",
      "[epoch 322, batch     2] loss: 2.95366\n",
      "[epoch 322, batch     3] loss: 3.10203\n",
      "[epoch 322, batch     4] loss: 3.28267\n",
      "[epoch 322, batch     5] loss: 2.92363\n",
      "[epoch 322, batch     6] loss: 3.52128\n",
      "[epoch 322, batch     7] loss: 3.08137\n",
      "[epoch 322, batch     8] loss: 2.87608\n",
      "[epoch 322, batch     9] loss: 3.78535\n",
      "[epoch 322, batch    10] loss: 3.64239\n",
      "[epoch 322, batch    11] loss: 2.12792\n",
      "[epoch 322, batch    12] loss: 3.08610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 322, batch    13] loss: 3.30802\n",
      "[epoch 322, batch    14] loss: 2.97505\n",
      "[epoch 322, batch    15] loss: 2.86917\n",
      "[epoch 322, batch    16] loss: 2.63834\n",
      "[epoch 322, batch    17] loss: 2.48088\n",
      "[epoch 322, batch    18] loss: 2.13671\n",
      "[epoch 322, batch    19] loss: 2.57603\n",
      "[epoch 322, batch    20] loss: 2.80018\n",
      "[epoch 322, batch    21] loss: 2.24086\n",
      "[epoch 322, batch    22] loss: 3.69073\n",
      "[epoch 322, batch    23] loss: 3.18348\n",
      "[epoch 322, batch    24] loss: 2.74452\n",
      "[epoch 322, batch    25] loss: 3.45951\n",
      "[epoch 322, batch    26] loss: 3.68576\n",
      "[epoch 322, batch    27] loss: 3.21313\n",
      "[epoch 322, batch    28] loss: 3.09933\n",
      "[epoch 322, batch    29] loss: 3.10389\n",
      "[epoch 322, batch    30] loss: 4.04073\n",
      "[epoch 322, batch    31] loss: 2.24924\n",
      "[epoch 322, batch    32] loss: 2.74638\n",
      "[epoch 323, batch     1] loss: 2.90226\n",
      "[epoch 323, batch     2] loss: 3.02977\n",
      "[epoch 323, batch     3] loss: 3.99095\n",
      "[epoch 323, batch     4] loss: 3.33841\n",
      "[epoch 323, batch     5] loss: 3.87384\n",
      "[epoch 323, batch     6] loss: 3.61611\n",
      "[epoch 323, batch     7] loss: 3.38103\n",
      "[epoch 323, batch     8] loss: 3.10471\n",
      "[epoch 323, batch     9] loss: 3.46993\n",
      "[epoch 323, batch    10] loss: 2.90783\n",
      "[epoch 323, batch    11] loss: 3.25765\n",
      "[epoch 323, batch    12] loss: 2.74662\n",
      "[epoch 323, batch    13] loss: 3.12851\n",
      "[epoch 323, batch    14] loss: 2.71008\n",
      "[epoch 323, batch    15] loss: 2.52781\n",
      "[epoch 323, batch    16] loss: 2.67633\n",
      "[epoch 323, batch    17] loss: 2.79508\n",
      "[epoch 323, batch    18] loss: 2.96626\n",
      "[epoch 323, batch    19] loss: 3.12694\n",
      "[epoch 323, batch    20] loss: 2.63745\n",
      "[epoch 323, batch    21] loss: 2.42171\n",
      "[epoch 323, batch    22] loss: 2.84302\n",
      "[epoch 323, batch    23] loss: 3.33361\n",
      "[epoch 323, batch    24] loss: 2.99967\n",
      "[epoch 323, batch    25] loss: 3.15671\n",
      "[epoch 323, batch    26] loss: 2.83102\n",
      "[epoch 323, batch    27] loss: 3.07197\n",
      "[epoch 323, batch    28] loss: 2.44084\n",
      "[epoch 323, batch    29] loss: 3.10295\n",
      "[epoch 323, batch    30] loss: 2.69404\n",
      "[epoch 323, batch    31] loss: 3.41154\n",
      "[epoch 323, batch    32] loss: 1.27268\n",
      "[epoch 324, batch     1] loss: 3.82699\n",
      "[epoch 324, batch     2] loss: 3.61730\n",
      "[epoch 324, batch     3] loss: 2.87120\n",
      "[epoch 324, batch     4] loss: 2.77277\n",
      "[epoch 324, batch     5] loss: 3.75485\n",
      "[epoch 324, batch     6] loss: 3.41308\n",
      "[epoch 324, batch     7] loss: 2.93880\n",
      "[epoch 324, batch     8] loss: 2.48535\n",
      "[epoch 324, batch     9] loss: 2.49078\n",
      "[epoch 324, batch    10] loss: 3.90356\n",
      "[epoch 324, batch    11] loss: 2.61851\n",
      "[epoch 324, batch    12] loss: 3.00647\n",
      "[epoch 324, batch    13] loss: 3.74617\n",
      "[epoch 324, batch    14] loss: 3.04854\n",
      "[epoch 324, batch    15] loss: 2.99974\n",
      "[epoch 324, batch    16] loss: 2.80647\n",
      "[epoch 324, batch    17] loss: 3.18714\n",
      "[epoch 324, batch    18] loss: 3.32515\n",
      "[epoch 324, batch    19] loss: 2.81151\n",
      "[epoch 324, batch    20] loss: 3.67471\n",
      "[epoch 324, batch    21] loss: 3.09521\n",
      "[epoch 324, batch    22] loss: 3.18325\n",
      "[epoch 324, batch    23] loss: 2.62502\n",
      "[epoch 324, batch    24] loss: 3.35945\n",
      "[epoch 324, batch    25] loss: 3.14005\n",
      "[epoch 324, batch    26] loss: 2.53420\n",
      "[epoch 324, batch    27] loss: 2.28643\n",
      "[epoch 324, batch    28] loss: 3.30648\n",
      "[epoch 324, batch    29] loss: 3.31663\n",
      "[epoch 324, batch    30] loss: 3.02924\n",
      "[epoch 324, batch    31] loss: 2.03894\n",
      "[epoch 324, batch    32] loss: 1.89825\n",
      "[epoch 325, batch     1] loss: 2.50632\n",
      "[epoch 325, batch     2] loss: 3.14100\n",
      "[epoch 325, batch     3] loss: 3.42385\n",
      "[epoch 325, batch     4] loss: 2.63165\n",
      "[epoch 325, batch     5] loss: 3.22126\n",
      "[epoch 325, batch     6] loss: 2.27082\n",
      "[epoch 325, batch     7] loss: 2.98278\n",
      "[epoch 325, batch     8] loss: 2.56827\n",
      "[epoch 325, batch     9] loss: 2.59921\n",
      "[epoch 325, batch    10] loss: 3.36027\n",
      "[epoch 325, batch    11] loss: 3.64078\n",
      "[epoch 325, batch    12] loss: 2.90780\n",
      "[epoch 325, batch    13] loss: 2.99704\n",
      "[epoch 325, batch    14] loss: 3.19517\n",
      "[epoch 325, batch    15] loss: 3.37957\n",
      "[epoch 325, batch    16] loss: 3.76212\n",
      "[epoch 325, batch    17] loss: 2.37416\n",
      "[epoch 325, batch    18] loss: 3.10427\n",
      "[epoch 325, batch    19] loss: 3.50315\n",
      "[epoch 325, batch    20] loss: 2.63343\n",
      "[epoch 325, batch    21] loss: 2.87030\n",
      "[epoch 325, batch    22] loss: 4.16193\n",
      "[epoch 325, batch    23] loss: 2.70750\n",
      "[epoch 325, batch    24] loss: 2.95085\n",
      "[epoch 325, batch    25] loss: 4.35906\n",
      "[epoch 325, batch    26] loss: 2.23488\n",
      "[epoch 325, batch    27] loss: 3.21032\n",
      "[epoch 325, batch    28] loss: 2.64550\n",
      "[epoch 325, batch    29] loss: 3.48670\n",
      "[epoch 325, batch    30] loss: 2.61300\n",
      "[epoch 325, batch    31] loss: 2.80064\n",
      "[epoch 325, batch    32] loss: 1.60759\n",
      "[epoch 326, batch     1] loss: 3.81276\n",
      "[epoch 326, batch     2] loss: 2.87501\n",
      "[epoch 326, batch     3] loss: 4.05832\n",
      "[epoch 326, batch     4] loss: 2.75057\n",
      "[epoch 326, batch     5] loss: 3.20899\n",
      "[epoch 326, batch     6] loss: 3.70038\n",
      "[epoch 326, batch     7] loss: 2.90999\n",
      "[epoch 326, batch     8] loss: 3.32241\n",
      "[epoch 326, batch     9] loss: 2.27679\n",
      "[epoch 326, batch    10] loss: 2.56319\n",
      "[epoch 326, batch    11] loss: 2.77231\n",
      "[epoch 326, batch    12] loss: 3.64934\n",
      "[epoch 326, batch    13] loss: 2.15173\n",
      "[epoch 326, batch    14] loss: 3.64494\n",
      "[epoch 326, batch    15] loss: 3.26847\n",
      "[epoch 326, batch    16] loss: 2.62770\n",
      "[epoch 326, batch    17] loss: 3.09362\n",
      "[epoch 326, batch    18] loss: 3.21154\n",
      "[epoch 326, batch    19] loss: 2.37946\n",
      "[epoch 326, batch    20] loss: 2.99854\n",
      "[epoch 326, batch    21] loss: 2.35601\n",
      "[epoch 326, batch    22] loss: 2.49693\n",
      "[epoch 326, batch    23] loss: 3.66413\n",
      "[epoch 326, batch    24] loss: 3.25272\n",
      "[epoch 326, batch    25] loss: 3.00229\n",
      "[epoch 326, batch    26] loss: 3.72194\n",
      "[epoch 326, batch    27] loss: 3.13268\n",
      "[epoch 326, batch    28] loss: 3.08777\n",
      "[epoch 326, batch    29] loss: 2.78274\n",
      "[epoch 326, batch    30] loss: 2.86400\n",
      "[epoch 326, batch    31] loss: 2.34089\n",
      "[epoch 326, batch    32] loss: 3.22996\n",
      "[epoch 327, batch     1] loss: 2.46437\n",
      "[epoch 327, batch     2] loss: 2.42299\n",
      "[epoch 327, batch     3] loss: 2.78802\n",
      "[epoch 327, batch     4] loss: 3.29731\n",
      "[epoch 327, batch     5] loss: 2.03527\n",
      "[epoch 327, batch     6] loss: 3.04932\n",
      "[epoch 327, batch     7] loss: 3.26855\n",
      "[epoch 327, batch     8] loss: 4.14829\n",
      "[epoch 327, batch     9] loss: 2.98443\n",
      "[epoch 327, batch    10] loss: 2.26080\n",
      "[epoch 327, batch    11] loss: 3.62339\n",
      "[epoch 327, batch    12] loss: 3.67557\n",
      "[epoch 327, batch    13] loss: 2.91751\n",
      "[epoch 327, batch    14] loss: 2.70955\n",
      "[epoch 327, batch    15] loss: 2.22208\n",
      "[epoch 327, batch    16] loss: 4.00795\n",
      "[epoch 327, batch    17] loss: 2.60747\n",
      "[epoch 327, batch    18] loss: 2.97692\n",
      "[epoch 327, batch    19] loss: 3.25082\n",
      "[epoch 327, batch    20] loss: 3.10724\n",
      "[epoch 327, batch    21] loss: 2.74025\n",
      "[epoch 327, batch    22] loss: 3.56585\n",
      "[epoch 327, batch    23] loss: 2.88075\n",
      "[epoch 327, batch    24] loss: 2.78669\n",
      "[epoch 327, batch    25] loss: 3.01481\n",
      "[epoch 327, batch    26] loss: 3.29164\n",
      "[epoch 327, batch    27] loss: 3.16417\n",
      "[epoch 327, batch    28] loss: 2.86082\n",
      "[epoch 327, batch    29] loss: 2.96668\n",
      "[epoch 327, batch    30] loss: 2.77229\n",
      "[epoch 327, batch    31] loss: 4.61910\n",
      "[epoch 327, batch    32] loss: 2.49564\n",
      "[epoch 328, batch     1] loss: 3.02785\n",
      "[epoch 328, batch     2] loss: 3.17414\n",
      "[epoch 328, batch     3] loss: 3.77158\n",
      "[epoch 328, batch     4] loss: 2.96026\n",
      "[epoch 328, batch     5] loss: 2.89759\n",
      "[epoch 328, batch     6] loss: 3.40376\n",
      "[epoch 328, batch     7] loss: 2.80428\n",
      "[epoch 328, batch     8] loss: 2.82671\n",
      "[epoch 328, batch     9] loss: 3.52414\n",
      "[epoch 328, batch    10] loss: 2.40881\n",
      "[epoch 328, batch    11] loss: 3.56476\n",
      "[epoch 328, batch    12] loss: 2.93100\n",
      "[epoch 328, batch    13] loss: 2.79516\n",
      "[epoch 328, batch    14] loss: 2.63701\n",
      "[epoch 328, batch    15] loss: 2.91845\n",
      "[epoch 328, batch    16] loss: 3.94298\n",
      "[epoch 328, batch    17] loss: 3.31901\n",
      "[epoch 328, batch    18] loss: 2.80290\n",
      "[epoch 328, batch    19] loss: 2.69220\n",
      "[epoch 328, batch    20] loss: 3.02154\n",
      "[epoch 328, batch    21] loss: 2.80884\n",
      "[epoch 328, batch    22] loss: 2.73292\n",
      "[epoch 328, batch    23] loss: 2.84767\n",
      "[epoch 328, batch    24] loss: 3.49286\n",
      "[epoch 328, batch    25] loss: 3.03574\n",
      "[epoch 328, batch    26] loss: 3.89975\n",
      "[epoch 328, batch    27] loss: 2.27965\n",
      "[epoch 328, batch    28] loss: 2.82790\n",
      "[epoch 328, batch    29] loss: 2.27499\n",
      "[epoch 328, batch    30] loss: 3.55194\n",
      "[epoch 328, batch    31] loss: 2.77013\n",
      "[epoch 328, batch    32] loss: 3.31778\n",
      "[epoch 329, batch     1] loss: 2.35715\n",
      "[epoch 329, batch     2] loss: 2.50019\n",
      "[epoch 329, batch     3] loss: 2.77079\n",
      "[epoch 329, batch     4] loss: 3.29738\n",
      "[epoch 329, batch     5] loss: 3.11839\n",
      "[epoch 329, batch     6] loss: 3.41931\n",
      "[epoch 329, batch     7] loss: 3.41951\n",
      "[epoch 329, batch     8] loss: 3.19451\n",
      "[epoch 329, batch     9] loss: 3.40266\n",
      "[epoch 329, batch    10] loss: 3.10628\n",
      "[epoch 329, batch    11] loss: 2.20239\n",
      "[epoch 329, batch    12] loss: 2.93618\n",
      "[epoch 329, batch    13] loss: 3.36034\n",
      "[epoch 329, batch    14] loss: 2.35525\n",
      "[epoch 329, batch    15] loss: 3.93937\n",
      "[epoch 329, batch    16] loss: 4.54622\n",
      "[epoch 329, batch    17] loss: 2.83068\n",
      "[epoch 329, batch    18] loss: 2.96824\n",
      "[epoch 329, batch    19] loss: 2.35457\n",
      "[epoch 329, batch    20] loss: 2.33276\n",
      "[epoch 329, batch    21] loss: 3.22412\n",
      "[epoch 329, batch    22] loss: 3.36251\n",
      "[epoch 329, batch    23] loss: 3.00779\n",
      "[epoch 329, batch    24] loss: 3.03898\n",
      "[epoch 329, batch    25] loss: 2.99981\n",
      "[epoch 329, batch    26] loss: 2.74692\n",
      "[epoch 329, batch    27] loss: 2.44008\n",
      "[epoch 329, batch    28] loss: 3.35320\n",
      "[epoch 329, batch    29] loss: 2.63324\n",
      "[epoch 329, batch    30] loss: 3.15036\n",
      "[epoch 329, batch    31] loss: 3.11639\n",
      "[epoch 329, batch    32] loss: 3.59003\n",
      "[epoch 330, batch     1] loss: 3.13406\n",
      "[epoch 330, batch     2] loss: 3.17366\n",
      "[epoch 330, batch     3] loss: 3.69941\n",
      "[epoch 330, batch     4] loss: 2.97838\n",
      "[epoch 330, batch     5] loss: 3.27843\n",
      "[epoch 330, batch     6] loss: 3.84728\n",
      "[epoch 330, batch     7] loss: 3.82932\n",
      "[epoch 330, batch     8] loss: 3.38157\n",
      "[epoch 330, batch     9] loss: 2.49810\n",
      "[epoch 330, batch    10] loss: 3.02562\n",
      "[epoch 330, batch    11] loss: 2.35843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 330, batch    12] loss: 2.39258\n",
      "[epoch 330, batch    13] loss: 3.91131\n",
      "[epoch 330, batch    14] loss: 2.89860\n",
      "[epoch 330, batch    15] loss: 2.13441\n",
      "[epoch 330, batch    16] loss: 3.09021\n",
      "[epoch 330, batch    17] loss: 2.52735\n",
      "[epoch 330, batch    18] loss: 4.69319\n",
      "[epoch 330, batch    19] loss: 3.18375\n",
      "[epoch 330, batch    20] loss: 2.85745\n",
      "[epoch 330, batch    21] loss: 2.81008\n",
      "[epoch 330, batch    22] loss: 2.45283\n",
      "[epoch 330, batch    23] loss: 2.86133\n",
      "[epoch 330, batch    24] loss: 2.66692\n",
      "[epoch 330, batch    25] loss: 3.25777\n",
      "[epoch 330, batch    26] loss: 2.99676\n",
      "[epoch 330, batch    27] loss: 2.43990\n",
      "[epoch 330, batch    28] loss: 2.79092\n",
      "[epoch 330, batch    29] loss: 2.87861\n",
      "[epoch 330, batch    30] loss: 3.33397\n",
      "[epoch 330, batch    31] loss: 3.21971\n",
      "[epoch 330, batch    32] loss: 2.21787\n",
      "[epoch 331, batch     1] loss: 2.72255\n",
      "[epoch 331, batch     2] loss: 2.58054\n",
      "[epoch 331, batch     3] loss: 2.58768\n",
      "[epoch 331, batch     4] loss: 2.42026\n",
      "[epoch 331, batch     5] loss: 2.65866\n",
      "[epoch 331, batch     6] loss: 3.20682\n",
      "[epoch 331, batch     7] loss: 3.08498\n",
      "[epoch 331, batch     8] loss: 2.36628\n",
      "[epoch 331, batch     9] loss: 4.15074\n",
      "[epoch 331, batch    10] loss: 2.40621\n",
      "[epoch 331, batch    11] loss: 3.11898\n",
      "[epoch 331, batch    12] loss: 2.81544\n",
      "[epoch 331, batch    13] loss: 3.14633\n",
      "[epoch 331, batch    14] loss: 2.99067\n",
      "[epoch 331, batch    15] loss: 3.80514\n",
      "[epoch 331, batch    16] loss: 3.37362\n",
      "[epoch 331, batch    17] loss: 2.78447\n",
      "[epoch 331, batch    18] loss: 3.32446\n",
      "[epoch 331, batch    19] loss: 2.75665\n",
      "[epoch 331, batch    20] loss: 2.38595\n",
      "[epoch 331, batch    21] loss: 2.82753\n",
      "[epoch 331, batch    22] loss: 3.66781\n",
      "[epoch 331, batch    23] loss: 2.26372\n",
      "[epoch 331, batch    24] loss: 2.69855\n",
      "[epoch 331, batch    25] loss: 3.89892\n",
      "[epoch 331, batch    26] loss: 3.28309\n",
      "[epoch 331, batch    27] loss: 3.54562\n",
      "[epoch 331, batch    28] loss: 2.62951\n",
      "[epoch 331, batch    29] loss: 3.19213\n",
      "[epoch 331, batch    30] loss: 4.14987\n",
      "[epoch 331, batch    31] loss: 3.20589\n",
      "[epoch 331, batch    32] loss: 3.18582\n",
      "[epoch 332, batch     1] loss: 2.92266\n",
      "[epoch 332, batch     2] loss: 3.18899\n",
      "[epoch 332, batch     3] loss: 2.29260\n",
      "[epoch 332, batch     4] loss: 2.53996\n",
      "[epoch 332, batch     5] loss: 2.62311\n",
      "[epoch 332, batch     6] loss: 3.28676\n",
      "[epoch 332, batch     7] loss: 3.16659\n",
      "[epoch 332, batch     8] loss: 2.97265\n",
      "[epoch 332, batch     9] loss: 2.05386\n",
      "[epoch 332, batch    10] loss: 2.89489\n",
      "[epoch 332, batch    11] loss: 3.30965\n",
      "[epoch 332, batch    12] loss: 3.76477\n",
      "[epoch 332, batch    13] loss: 2.37716\n",
      "[epoch 332, batch    14] loss: 3.43261\n",
      "[epoch 332, batch    15] loss: 3.86658\n",
      "[epoch 332, batch    16] loss: 3.72076\n",
      "[epoch 332, batch    17] loss: 2.52517\n",
      "[epoch 332, batch    18] loss: 3.07252\n",
      "[epoch 332, batch    19] loss: 2.87859\n",
      "[epoch 332, batch    20] loss: 3.36970\n",
      "[epoch 332, batch    21] loss: 3.05415\n",
      "[epoch 332, batch    22] loss: 3.14816\n",
      "[epoch 332, batch    23] loss: 3.17116\n",
      "[epoch 332, batch    24] loss: 3.24800\n",
      "[epoch 332, batch    25] loss: 2.45190\n",
      "[epoch 332, batch    26] loss: 2.89462\n",
      "[epoch 332, batch    27] loss: 3.20621\n",
      "[epoch 332, batch    28] loss: 3.62291\n",
      "[epoch 332, batch    29] loss: 3.17268\n",
      "[epoch 332, batch    30] loss: 3.31066\n",
      "[epoch 332, batch    31] loss: 2.85817\n",
      "[epoch 332, batch    32] loss: 2.78425\n",
      "[epoch 333, batch     1] loss: 2.70471\n",
      "[epoch 333, batch     2] loss: 2.95794\n",
      "[epoch 333, batch     3] loss: 2.22569\n",
      "[epoch 333, batch     4] loss: 2.99291\n",
      "[epoch 333, batch     5] loss: 3.62308\n",
      "[epoch 333, batch     6] loss: 3.46261\n",
      "[epoch 333, batch     7] loss: 2.50661\n",
      "[epoch 333, batch     8] loss: 3.16114\n",
      "[epoch 333, batch     9] loss: 4.17924\n",
      "[epoch 333, batch    10] loss: 3.06194\n",
      "[epoch 333, batch    11] loss: 2.30654\n",
      "[epoch 333, batch    12] loss: 2.91761\n",
      "[epoch 333, batch    13] loss: 2.44648\n",
      "[epoch 333, batch    14] loss: 3.58530\n",
      "[epoch 333, batch    15] loss: 3.65561\n",
      "[epoch 333, batch    16] loss: 2.78129\n",
      "[epoch 333, batch    17] loss: 3.02609\n",
      "[epoch 333, batch    18] loss: 3.35993\n",
      "[epoch 333, batch    19] loss: 2.61431\n",
      "[epoch 333, batch    20] loss: 2.92584\n",
      "[epoch 333, batch    21] loss: 3.74946\n",
      "[epoch 333, batch    22] loss: 3.28237\n",
      "[epoch 333, batch    23] loss: 2.97132\n",
      "[epoch 333, batch    24] loss: 2.35883\n",
      "[epoch 333, batch    25] loss: 2.82681\n",
      "[epoch 333, batch    26] loss: 2.99357\n",
      "[epoch 333, batch    27] loss: 3.38227\n",
      "[epoch 333, batch    28] loss: 3.26200\n",
      "[epoch 333, batch    29] loss: 2.80964\n",
      "[epoch 333, batch    30] loss: 3.37757\n",
      "[epoch 333, batch    31] loss: 3.16233\n",
      "[epoch 333, batch    32] loss: 1.57937\n",
      "[epoch 334, batch     1] loss: 3.46298\n",
      "[epoch 334, batch     2] loss: 3.82548\n",
      "[epoch 334, batch     3] loss: 2.81712\n",
      "[epoch 334, batch     4] loss: 3.06910\n",
      "[epoch 334, batch     5] loss: 2.07593\n",
      "[epoch 334, batch     6] loss: 2.90433\n",
      "[epoch 334, batch     7] loss: 3.47262\n",
      "[epoch 334, batch     8] loss: 4.31712\n",
      "[epoch 334, batch     9] loss: 2.33834\n",
      "[epoch 334, batch    10] loss: 2.98338\n",
      "[epoch 334, batch    11] loss: 3.37792\n",
      "[epoch 334, batch    12] loss: 4.15000\n",
      "[epoch 334, batch    13] loss: 3.02140\n",
      "[epoch 334, batch    14] loss: 2.71374\n",
      "[epoch 334, batch    15] loss: 2.59850\n",
      "[epoch 334, batch    16] loss: 2.33984\n",
      "[epoch 334, batch    17] loss: 2.44179\n",
      "[epoch 334, batch    18] loss: 3.59821\n",
      "[epoch 334, batch    19] loss: 3.00902\n",
      "[epoch 334, batch    20] loss: 2.22196\n",
      "[epoch 334, batch    21] loss: 2.84184\n",
      "[epoch 334, batch    22] loss: 3.08989\n",
      "[epoch 334, batch    23] loss: 3.40810\n",
      "[epoch 334, batch    24] loss: 3.96631\n",
      "[epoch 334, batch    25] loss: 1.93959\n",
      "[epoch 334, batch    26] loss: 2.40324\n",
      "[epoch 334, batch    27] loss: 3.41855\n",
      "[epoch 334, batch    28] loss: 3.00692\n",
      "[epoch 334, batch    29] loss: 3.24377\n",
      "[epoch 334, batch    30] loss: 3.08540\n",
      "[epoch 334, batch    31] loss: 3.08830\n",
      "[epoch 334, batch    32] loss: 2.79603\n",
      "[epoch 335, batch     1] loss: 3.49881\n",
      "[epoch 335, batch     2] loss: 3.25550\n",
      "[epoch 335, batch     3] loss: 2.38512\n",
      "[epoch 335, batch     4] loss: 2.34893\n",
      "[epoch 335, batch     5] loss: 3.91010\n",
      "[epoch 335, batch     6] loss: 2.66719\n",
      "[epoch 335, batch     7] loss: 2.67311\n",
      "[epoch 335, batch     8] loss: 3.47045\n",
      "[epoch 335, batch     9] loss: 2.83135\n",
      "[epoch 335, batch    10] loss: 2.36109\n",
      "[epoch 335, batch    11] loss: 2.49683\n",
      "[epoch 335, batch    12] loss: 2.39452\n",
      "[epoch 335, batch    13] loss: 3.33630\n",
      "[epoch 335, batch    14] loss: 3.31149\n",
      "[epoch 335, batch    15] loss: 4.31092\n",
      "[epoch 335, batch    16] loss: 4.33436\n",
      "[epoch 335, batch    17] loss: 2.84384\n",
      "[epoch 335, batch    18] loss: 3.33481\n",
      "[epoch 335, batch    19] loss: 2.34760\n",
      "[epoch 335, batch    20] loss: 2.42973\n",
      "[epoch 335, batch    21] loss: 2.72504\n",
      "[epoch 335, batch    22] loss: 2.50059\n",
      "[epoch 335, batch    23] loss: 3.43375\n",
      "[epoch 335, batch    24] loss: 2.34683\n",
      "[epoch 335, batch    25] loss: 2.95649\n",
      "[epoch 335, batch    26] loss: 3.23006\n",
      "[epoch 335, batch    27] loss: 3.07445\n",
      "[epoch 335, batch    28] loss: 3.10427\n",
      "[epoch 335, batch    29] loss: 3.28078\n",
      "[epoch 335, batch    30] loss: 3.20375\n",
      "[epoch 335, batch    31] loss: 3.61289\n",
      "[epoch 335, batch    32] loss: 3.43264\n",
      "[epoch 336, batch     1] loss: 2.39042\n",
      "[epoch 336, batch     2] loss: 3.00599\n",
      "[epoch 336, batch     3] loss: 3.16659\n",
      "[epoch 336, batch     4] loss: 3.75675\n",
      "[epoch 336, batch     5] loss: 2.56454\n",
      "[epoch 336, batch     6] loss: 2.89399\n",
      "[epoch 336, batch     7] loss: 2.92541\n",
      "[epoch 336, batch     8] loss: 2.50870\n",
      "[epoch 336, batch     9] loss: 3.36125\n",
      "[epoch 336, batch    10] loss: 3.59872\n",
      "[epoch 336, batch    11] loss: 3.36323\n",
      "[epoch 336, batch    12] loss: 2.64598\n",
      "[epoch 336, batch    13] loss: 2.84055\n",
      "[epoch 336, batch    14] loss: 2.26956\n",
      "[epoch 336, batch    15] loss: 3.70387\n",
      "[epoch 336, batch    16] loss: 2.90284\n",
      "[epoch 336, batch    17] loss: 2.63934\n",
      "[epoch 336, batch    18] loss: 2.70652\n",
      "[epoch 336, batch    19] loss: 3.34054\n",
      "[epoch 336, batch    20] loss: 2.89967\n",
      "[epoch 336, batch    21] loss: 2.63035\n",
      "[epoch 336, batch    22] loss: 3.63052\n",
      "[epoch 336, batch    23] loss: 3.13991\n",
      "[epoch 336, batch    24] loss: 3.07132\n",
      "[epoch 336, batch    25] loss: 3.75367\n",
      "[epoch 336, batch    26] loss: 3.57572\n",
      "[epoch 336, batch    27] loss: 3.62190\n",
      "[epoch 336, batch    28] loss: 2.80919\n",
      "[epoch 336, batch    29] loss: 3.26627\n",
      "[epoch 336, batch    30] loss: 2.26825\n",
      "[epoch 336, batch    31] loss: 3.01899\n",
      "[epoch 336, batch    32] loss: 3.33647\n",
      "[epoch 337, batch     1] loss: 3.70857\n",
      "[epoch 337, batch     2] loss: 3.03006\n",
      "[epoch 337, batch     3] loss: 2.99205\n",
      "[epoch 337, batch     4] loss: 3.29188\n",
      "[epoch 337, batch     5] loss: 3.04417\n",
      "[epoch 337, batch     6] loss: 2.65673\n",
      "[epoch 337, batch     7] loss: 3.12880\n",
      "[epoch 337, batch     8] loss: 3.46663\n",
      "[epoch 337, batch     9] loss: 3.82227\n",
      "[epoch 337, batch    10] loss: 3.39559\n",
      "[epoch 337, batch    11] loss: 2.87466\n",
      "[epoch 337, batch    12] loss: 2.17768\n",
      "[epoch 337, batch    13] loss: 3.13310\n",
      "[epoch 337, batch    14] loss: 2.99097\n",
      "[epoch 337, batch    15] loss: 2.92135\n",
      "[epoch 337, batch    16] loss: 3.41141\n",
      "[epoch 337, batch    17] loss: 3.63997\n",
      "[epoch 337, batch    18] loss: 2.00007\n",
      "[epoch 337, batch    19] loss: 3.76380\n",
      "[epoch 337, batch    20] loss: 2.31564\n",
      "[epoch 337, batch    21] loss: 2.86864\n",
      "[epoch 337, batch    22] loss: 2.80792\n",
      "[epoch 337, batch    23] loss: 3.09048\n",
      "[epoch 337, batch    24] loss: 3.69840\n",
      "[epoch 337, batch    25] loss: 1.91233\n",
      "[epoch 337, batch    26] loss: 2.65764\n",
      "[epoch 337, batch    27] loss: 2.72332\n",
      "[epoch 337, batch    28] loss: 2.61873\n",
      "[epoch 337, batch    29] loss: 4.11251\n",
      "[epoch 337, batch    30] loss: 2.94885\n",
      "[epoch 337, batch    31] loss: 3.30064\n",
      "[epoch 337, batch    32] loss: 2.01982\n",
      "[epoch 338, batch     1] loss: 3.21646\n",
      "[epoch 338, batch     2] loss: 3.55226\n",
      "[epoch 338, batch     3] loss: 3.28980\n",
      "[epoch 338, batch     4] loss: 3.07215\n",
      "[epoch 338, batch     5] loss: 3.27721\n",
      "[epoch 338, batch     6] loss: 1.88792\n",
      "[epoch 338, batch     7] loss: 2.49008\n",
      "[epoch 338, batch     8] loss: 2.95101\n",
      "[epoch 338, batch     9] loss: 3.46723\n",
      "[epoch 338, batch    10] loss: 3.01798\n",
      "[epoch 338, batch    11] loss: 2.36335\n",
      "[epoch 338, batch    12] loss: 2.43196\n",
      "[epoch 338, batch    13] loss: 3.08865\n",
      "[epoch 338, batch    14] loss: 3.63528\n",
      "[epoch 338, batch    15] loss: 2.73580\n",
      "[epoch 338, batch    16] loss: 3.04597\n",
      "[epoch 338, batch    17] loss: 3.49459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 338, batch    18] loss: 3.40307\n",
      "[epoch 338, batch    19] loss: 3.63991\n",
      "[epoch 338, batch    20] loss: 3.85279\n",
      "[epoch 338, batch    21] loss: 2.95558\n",
      "[epoch 338, batch    22] loss: 2.49924\n",
      "[epoch 338, batch    23] loss: 2.73239\n",
      "[epoch 338, batch    24] loss: 3.20577\n",
      "[epoch 338, batch    25] loss: 3.52531\n",
      "[epoch 338, batch    26] loss: 2.49373\n",
      "[epoch 338, batch    27] loss: 2.84529\n",
      "[epoch 338, batch    28] loss: 2.50647\n",
      "[epoch 338, batch    29] loss: 2.26244\n",
      "[epoch 338, batch    30] loss: 3.41627\n",
      "[epoch 338, batch    31] loss: 3.54404\n",
      "[epoch 338, batch    32] loss: 3.01934\n",
      "[epoch 339, batch     1] loss: 3.32616\n",
      "[epoch 339, batch     2] loss: 2.33236\n",
      "[epoch 339, batch     3] loss: 3.41485\n",
      "[epoch 339, batch     4] loss: 2.34706\n",
      "[epoch 339, batch     5] loss: 1.87130\n",
      "[epoch 339, batch     6] loss: 3.49249\n",
      "[epoch 339, batch     7] loss: 3.06607\n",
      "[epoch 339, batch     8] loss: 2.82581\n",
      "[epoch 339, batch     9] loss: 4.21985\n",
      "[epoch 339, batch    10] loss: 2.83130\n",
      "[epoch 339, batch    11] loss: 2.67302\n",
      "[epoch 339, batch    12] loss: 2.78516\n",
      "[epoch 339, batch    13] loss: 2.28007\n",
      "[epoch 339, batch    14] loss: 3.29781\n",
      "[epoch 339, batch    15] loss: 2.84858\n",
      "[epoch 339, batch    16] loss: 2.84319\n",
      "[epoch 339, batch    17] loss: 2.63204\n",
      "[epoch 339, batch    18] loss: 3.20630\n",
      "[epoch 339, batch    19] loss: 3.09511\n",
      "[epoch 339, batch    20] loss: 2.52861\n",
      "[epoch 339, batch    21] loss: 3.69957\n",
      "[epoch 339, batch    22] loss: 3.75734\n",
      "[epoch 339, batch    23] loss: 2.76449\n",
      "[epoch 339, batch    24] loss: 4.15543\n",
      "[epoch 339, batch    25] loss: 3.28484\n",
      "[epoch 339, batch    26] loss: 3.19195\n",
      "[epoch 339, batch    27] loss: 3.20632\n",
      "[epoch 339, batch    28] loss: 3.39090\n",
      "[epoch 339, batch    29] loss: 3.39750\n",
      "[epoch 339, batch    30] loss: 3.26493\n",
      "[epoch 339, batch    31] loss: 2.70802\n",
      "[epoch 339, batch    32] loss: 2.54488\n",
      "[epoch 340, batch     1] loss: 2.87445\n",
      "[epoch 340, batch     2] loss: 2.63238\n",
      "[epoch 340, batch     3] loss: 3.91841\n",
      "[epoch 340, batch     4] loss: 2.86700\n",
      "[epoch 340, batch     5] loss: 2.62276\n",
      "[epoch 340, batch     6] loss: 4.05946\n",
      "[epoch 340, batch     7] loss: 2.76280\n",
      "[epoch 340, batch     8] loss: 3.36577\n",
      "[epoch 340, batch     9] loss: 3.11576\n",
      "[epoch 340, batch    10] loss: 3.39558\n",
      "[epoch 340, batch    11] loss: 3.43760\n",
      "[epoch 340, batch    12] loss: 3.86914\n",
      "[epoch 340, batch    13] loss: 3.80931\n",
      "[epoch 340, batch    14] loss: 3.12713\n",
      "[epoch 340, batch    15] loss: 1.94608\n",
      "[epoch 340, batch    16] loss: 3.16237\n",
      "[epoch 340, batch    17] loss: 2.37571\n",
      "[epoch 340, batch    18] loss: 3.58553\n",
      "[epoch 340, batch    19] loss: 3.37506\n",
      "[epoch 340, batch    20] loss: 2.91335\n",
      "[epoch 340, batch    21] loss: 2.32083\n",
      "[epoch 340, batch    22] loss: 3.40823\n",
      "[epoch 340, batch    23] loss: 2.46745\n",
      "[epoch 340, batch    24] loss: 2.88288\n",
      "[epoch 340, batch    25] loss: 1.96520\n",
      "[epoch 340, batch    26] loss: 3.50331\n",
      "[epoch 340, batch    27] loss: 2.59346\n",
      "[epoch 340, batch    28] loss: 2.64453\n",
      "[epoch 340, batch    29] loss: 3.02943\n",
      "[epoch 340, batch    30] loss: 3.09150\n",
      "[epoch 340, batch    31] loss: 3.18739\n",
      "[epoch 340, batch    32] loss: 2.94223\n",
      "[epoch 341, batch     1] loss: 3.05574\n",
      "[epoch 341, batch     2] loss: 3.53752\n",
      "[epoch 341, batch     3] loss: 2.83402\n",
      "[epoch 341, batch     4] loss: 2.78210\n",
      "[epoch 341, batch     5] loss: 2.63195\n",
      "[epoch 341, batch     6] loss: 3.01678\n",
      "[epoch 341, batch     7] loss: 2.36315\n",
      "[epoch 341, batch     8] loss: 3.55789\n",
      "[epoch 341, batch     9] loss: 2.92999\n",
      "[epoch 341, batch    10] loss: 3.14674\n",
      "[epoch 341, batch    11] loss: 3.67585\n",
      "[epoch 341, batch    12] loss: 2.86375\n",
      "[epoch 341, batch    13] loss: 3.27575\n",
      "[epoch 341, batch    14] loss: 2.21278\n",
      "[epoch 341, batch    15] loss: 3.46182\n",
      "[epoch 341, batch    16] loss: 2.91701\n",
      "[epoch 341, batch    17] loss: 3.76697\n",
      "[epoch 341, batch    18] loss: 2.96343\n",
      "[epoch 341, batch    19] loss: 2.29940\n",
      "[epoch 341, batch    20] loss: 2.29670\n",
      "[epoch 341, batch    21] loss: 3.26930\n",
      "[epoch 341, batch    22] loss: 4.16104\n",
      "[epoch 341, batch    23] loss: 3.01962\n",
      "[epoch 341, batch    24] loss: 3.24519\n",
      "[epoch 341, batch    25] loss: 3.40509\n",
      "[epoch 341, batch    26] loss: 3.41691\n",
      "[epoch 341, batch    27] loss: 2.38247\n",
      "[epoch 341, batch    28] loss: 3.32069\n",
      "[epoch 341, batch    29] loss: 3.01092\n",
      "[epoch 341, batch    30] loss: 2.70652\n",
      "[epoch 341, batch    31] loss: 2.84932\n",
      "[epoch 341, batch    32] loss: 2.82054\n",
      "[epoch 342, batch     1] loss: 3.18219\n",
      "[epoch 342, batch     2] loss: 3.03146\n",
      "[epoch 342, batch     3] loss: 3.40152\n",
      "[epoch 342, batch     4] loss: 3.11781\n",
      "[epoch 342, batch     5] loss: 2.63625\n",
      "[epoch 342, batch     6] loss: 2.73719\n",
      "[epoch 342, batch     7] loss: 2.39964\n",
      "[epoch 342, batch     8] loss: 3.29404\n",
      "[epoch 342, batch     9] loss: 2.61043\n",
      "[epoch 342, batch    10] loss: 2.64536\n",
      "[epoch 342, batch    11] loss: 3.71197\n",
      "[epoch 342, batch    12] loss: 3.76048\n",
      "[epoch 342, batch    13] loss: 3.37704\n",
      "[epoch 342, batch    14] loss: 3.37862\n",
      "[epoch 342, batch    15] loss: 3.41824\n",
      "[epoch 342, batch    16] loss: 2.90439\n",
      "[epoch 342, batch    17] loss: 3.27813\n",
      "[epoch 342, batch    18] loss: 3.02421\n",
      "[epoch 342, batch    19] loss: 3.16397\n",
      "[epoch 342, batch    20] loss: 3.28398\n",
      "[epoch 342, batch    21] loss: 2.57597\n",
      "[epoch 342, batch    22] loss: 2.21126\n",
      "[epoch 342, batch    23] loss: 2.75608\n",
      "[epoch 342, batch    24] loss: 2.92044\n",
      "[epoch 342, batch    25] loss: 3.37247\n",
      "[epoch 342, batch    26] loss: 2.75895\n",
      "[epoch 342, batch    27] loss: 3.11318\n",
      "[epoch 342, batch    28] loss: 3.18046\n",
      "[epoch 342, batch    29] loss: 2.92560\n",
      "[epoch 342, batch    30] loss: 2.56121\n",
      "[epoch 342, batch    31] loss: 3.01381\n",
      "[epoch 342, batch    32] loss: 2.84948\n",
      "[epoch 343, batch     1] loss: 3.41907\n",
      "[epoch 343, batch     2] loss: 2.57295\n",
      "[epoch 343, batch     3] loss: 4.26988\n",
      "[epoch 343, batch     4] loss: 2.74961\n",
      "[epoch 343, batch     5] loss: 2.87568\n",
      "[epoch 343, batch     6] loss: 3.05122\n",
      "[epoch 343, batch     7] loss: 2.72307\n",
      "[epoch 343, batch     8] loss: 4.07982\n",
      "[epoch 343, batch     9] loss: 2.90192\n",
      "[epoch 343, batch    10] loss: 3.16754\n",
      "[epoch 343, batch    11] loss: 3.18560\n",
      "[epoch 343, batch    12] loss: 2.77971\n",
      "[epoch 343, batch    13] loss: 3.37793\n",
      "[epoch 343, batch    14] loss: 3.24496\n",
      "[epoch 343, batch    15] loss: 3.39656\n",
      "[epoch 343, batch    16] loss: 2.80314\n",
      "[epoch 343, batch    17] loss: 2.51336\n",
      "[epoch 343, batch    18] loss: 2.90658\n",
      "[epoch 343, batch    19] loss: 2.67813\n",
      "[epoch 343, batch    20] loss: 3.53192\n",
      "[epoch 343, batch    21] loss: 2.50514\n",
      "[epoch 343, batch    22] loss: 2.55814\n",
      "[epoch 343, batch    23] loss: 2.68857\n",
      "[epoch 343, batch    24] loss: 2.63025\n",
      "[epoch 343, batch    25] loss: 3.31576\n",
      "[epoch 343, batch    26] loss: 3.30482\n",
      "[epoch 343, batch    27] loss: 2.64508\n",
      "[epoch 343, batch    28] loss: 3.17063\n",
      "[epoch 343, batch    29] loss: 3.01654\n",
      "[epoch 343, batch    30] loss: 2.50152\n",
      "[epoch 343, batch    31] loss: 3.42376\n",
      "[epoch 343, batch    32] loss: 2.79518\n",
      "[epoch 344, batch     1] loss: 3.93760\n",
      "[epoch 344, batch     2] loss: 2.62351\n",
      "[epoch 344, batch     3] loss: 2.44052\n",
      "[epoch 344, batch     4] loss: 3.21878\n",
      "[epoch 344, batch     5] loss: 3.28454\n",
      "[epoch 344, batch     6] loss: 2.49785\n",
      "[epoch 344, batch     7] loss: 2.87649\n",
      "[epoch 344, batch     8] loss: 2.94217\n",
      "[epoch 344, batch     9] loss: 2.70937\n",
      "[epoch 344, batch    10] loss: 3.75944\n",
      "[epoch 344, batch    11] loss: 3.03677\n",
      "[epoch 344, batch    12] loss: 3.93304\n",
      "[epoch 344, batch    13] loss: 3.69224\n",
      "[epoch 344, batch    14] loss: 2.99040\n",
      "[epoch 344, batch    15] loss: 2.82984\n",
      "[epoch 344, batch    16] loss: 3.64885\n",
      "[epoch 344, batch    17] loss: 3.66983\n",
      "[epoch 344, batch    18] loss: 2.41237\n",
      "[epoch 344, batch    19] loss: 3.81059\n",
      "[epoch 344, batch    20] loss: 2.16132\n",
      "[epoch 344, batch    21] loss: 2.26142\n",
      "[epoch 344, batch    22] loss: 2.20574\n",
      "[epoch 344, batch    23] loss: 2.33333\n",
      "[epoch 344, batch    24] loss: 2.73938\n",
      "[epoch 344, batch    25] loss: 2.98942\n",
      "[epoch 344, batch    26] loss: 3.30016\n",
      "[epoch 344, batch    27] loss: 2.97610\n",
      "[epoch 344, batch    28] loss: 3.16421\n",
      "[epoch 344, batch    29] loss: 2.98426\n",
      "[epoch 344, batch    30] loss: 3.46320\n",
      "[epoch 344, batch    31] loss: 3.16099\n",
      "[epoch 344, batch    32] loss: 3.13778\n",
      "[epoch 345, batch     1] loss: 2.37829\n",
      "[epoch 345, batch     2] loss: 3.02402\n",
      "[epoch 345, batch     3] loss: 2.81740\n",
      "[epoch 345, batch     4] loss: 2.97857\n",
      "[epoch 345, batch     5] loss: 3.19080\n",
      "[epoch 345, batch     6] loss: 2.82802\n",
      "[epoch 345, batch     7] loss: 3.44616\n",
      "[epoch 345, batch     8] loss: 2.13875\n",
      "[epoch 345, batch     9] loss: 2.93880\n",
      "[epoch 345, batch    10] loss: 2.95335\n",
      "[epoch 345, batch    11] loss: 3.27772\n",
      "[epoch 345, batch    12] loss: 3.13869\n",
      "[epoch 345, batch    13] loss: 3.80505\n",
      "[epoch 345, batch    14] loss: 3.15483\n",
      "[epoch 345, batch    15] loss: 3.14303\n",
      "[epoch 345, batch    16] loss: 3.72282\n",
      "[epoch 345, batch    17] loss: 3.49793\n",
      "[epoch 345, batch    18] loss: 3.51809\n",
      "[epoch 345, batch    19] loss: 2.64673\n",
      "[epoch 345, batch    20] loss: 3.56922\n",
      "[epoch 345, batch    21] loss: 2.85792\n",
      "[epoch 345, batch    22] loss: 3.89720\n",
      "[epoch 345, batch    23] loss: 2.91318\n",
      "[epoch 345, batch    24] loss: 2.91610\n",
      "[epoch 345, batch    25] loss: 2.78544\n",
      "[epoch 345, batch    26] loss: 3.00031\n",
      "[epoch 345, batch    27] loss: 2.82637\n",
      "[epoch 345, batch    28] loss: 2.57846\n",
      "[epoch 345, batch    29] loss: 2.94733\n",
      "[epoch 345, batch    30] loss: 2.83269\n",
      "[epoch 345, batch    31] loss: 2.63606\n",
      "[epoch 345, batch    32] loss: 3.75250\n",
      "[epoch 346, batch     1] loss: 2.99390\n",
      "[epoch 346, batch     2] loss: 2.68398\n",
      "[epoch 346, batch     3] loss: 3.24174\n",
      "[epoch 346, batch     4] loss: 2.91038\n",
      "[epoch 346, batch     5] loss: 3.76481\n",
      "[epoch 346, batch     6] loss: 2.47535\n",
      "[epoch 346, batch     7] loss: 3.08000\n",
      "[epoch 346, batch     8] loss: 2.54578\n",
      "[epoch 346, batch     9] loss: 2.86391\n",
      "[epoch 346, batch    10] loss: 3.22832\n",
      "[epoch 346, batch    11] loss: 2.40458\n",
      "[epoch 346, batch    12] loss: 2.58595\n",
      "[epoch 346, batch    13] loss: 3.46829\n",
      "[epoch 346, batch    14] loss: 4.07717\n",
      "[epoch 346, batch    15] loss: 2.87452\n",
      "[epoch 346, batch    16] loss: 2.49278\n",
      "[epoch 346, batch    17] loss: 3.37453\n",
      "[epoch 346, batch    18] loss: 3.10603\n",
      "[epoch 346, batch    19] loss: 2.63884\n",
      "[epoch 346, batch    20] loss: 3.06367\n",
      "[epoch 346, batch    21] loss: 2.67642\n",
      "[epoch 346, batch    22] loss: 3.80177\n",
      "[epoch 346, batch    23] loss: 3.12515\n",
      "[epoch 346, batch    24] loss: 3.70564\n",
      "[epoch 346, batch    25] loss: 2.98091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 346, batch    26] loss: 2.35499\n",
      "[epoch 346, batch    27] loss: 2.83593\n",
      "[epoch 346, batch    28] loss: 3.38081\n",
      "[epoch 346, batch    29] loss: 2.73982\n",
      "[epoch 346, batch    30] loss: 3.03979\n",
      "[epoch 346, batch    31] loss: 3.41687\n",
      "[epoch 346, batch    32] loss: 3.48746\n",
      "[epoch 347, batch     1] loss: 4.08855\n",
      "[epoch 347, batch     2] loss: 2.86683\n",
      "[epoch 347, batch     3] loss: 2.90333\n",
      "[epoch 347, batch     4] loss: 2.91605\n",
      "[epoch 347, batch     5] loss: 2.64743\n",
      "[epoch 347, batch     6] loss: 2.54037\n",
      "[epoch 347, batch     7] loss: 3.10488\n",
      "[epoch 347, batch     8] loss: 2.76785\n",
      "[epoch 347, batch     9] loss: 2.79754\n",
      "[epoch 347, batch    10] loss: 2.71772\n",
      "[epoch 347, batch    11] loss: 3.30244\n",
      "[epoch 347, batch    12] loss: 3.17761\n",
      "[epoch 347, batch    13] loss: 3.49218\n",
      "[epoch 347, batch    14] loss: 3.05090\n",
      "[epoch 347, batch    15] loss: 3.27870\n",
      "[epoch 347, batch    16] loss: 3.88082\n",
      "[epoch 347, batch    17] loss: 3.36198\n",
      "[epoch 347, batch    18] loss: 3.14839\n",
      "[epoch 347, batch    19] loss: 2.97274\n",
      "[epoch 347, batch    20] loss: 2.90993\n",
      "[epoch 347, batch    21] loss: 2.98082\n",
      "[epoch 347, batch    22] loss: 2.84485\n",
      "[epoch 347, batch    23] loss: 3.34745\n",
      "[epoch 347, batch    24] loss: 3.17989\n",
      "[epoch 347, batch    25] loss: 3.47360\n",
      "[epoch 347, batch    26] loss: 2.10241\n",
      "[epoch 347, batch    27] loss: 3.05947\n",
      "[epoch 347, batch    28] loss: 3.38934\n",
      "[epoch 347, batch    29] loss: 2.70242\n",
      "[epoch 347, batch    30] loss: 2.65892\n",
      "[epoch 347, batch    31] loss: 2.71694\n",
      "[epoch 347, batch    32] loss: 3.12055\n",
      "[epoch 348, batch     1] loss: 3.35310\n",
      "[epoch 348, batch     2] loss: 2.81351\n",
      "[epoch 348, batch     3] loss: 2.66554\n",
      "[epoch 348, batch     4] loss: 3.36268\n",
      "[epoch 348, batch     5] loss: 3.67786\n",
      "[epoch 348, batch     6] loss: 2.38850\n",
      "[epoch 348, batch     7] loss: 3.12989\n",
      "[epoch 348, batch     8] loss: 3.04238\n",
      "[epoch 348, batch     9] loss: 3.11973\n",
      "[epoch 348, batch    10] loss: 3.60131\n",
      "[epoch 348, batch    11] loss: 2.87509\n",
      "[epoch 348, batch    12] loss: 2.42134\n",
      "[epoch 348, batch    13] loss: 3.82941\n",
      "[epoch 348, batch    14] loss: 2.77811\n",
      "[epoch 348, batch    15] loss: 2.94341\n",
      "[epoch 348, batch    16] loss: 2.64031\n",
      "[epoch 348, batch    17] loss: 3.82297\n",
      "[epoch 348, batch    18] loss: 2.45521\n",
      "[epoch 348, batch    19] loss: 3.20974\n",
      "[epoch 348, batch    20] loss: 3.59839\n",
      "[epoch 348, batch    21] loss: 3.12338\n",
      "[epoch 348, batch    22] loss: 2.92410\n",
      "[epoch 348, batch    23] loss: 2.68383\n",
      "[epoch 348, batch    24] loss: 3.42000\n",
      "[epoch 348, batch    25] loss: 2.13115\n",
      "[epoch 348, batch    26] loss: 2.91646\n",
      "[epoch 348, batch    27] loss: 3.35557\n",
      "[epoch 348, batch    28] loss: 2.67802\n",
      "[epoch 348, batch    29] loss: 2.32563\n",
      "[epoch 348, batch    30] loss: 3.40558\n",
      "[epoch 348, batch    31] loss: 3.70060\n",
      "[epoch 348, batch    32] loss: 3.54249\n",
      "[epoch 349, batch     1] loss: 3.24478\n",
      "[epoch 349, batch     2] loss: 3.42529\n",
      "[epoch 349, batch     3] loss: 2.76150\n",
      "[epoch 349, batch     4] loss: 3.00268\n",
      "[epoch 349, batch     5] loss: 3.30810\n",
      "[epoch 349, batch     6] loss: 2.91313\n",
      "[epoch 349, batch     7] loss: 2.48805\n",
      "[epoch 349, batch     8] loss: 3.50263\n",
      "[epoch 349, batch     9] loss: 3.40774\n",
      "[epoch 349, batch    10] loss: 2.89739\n",
      "[epoch 349, batch    11] loss: 2.85287\n",
      "[epoch 349, batch    12] loss: 2.44540\n",
      "[epoch 349, batch    13] loss: 3.28509\n",
      "[epoch 349, batch    14] loss: 2.61910\n",
      "[epoch 349, batch    15] loss: 3.05790\n",
      "[epoch 349, batch    16] loss: 1.91452\n",
      "[epoch 349, batch    17] loss: 2.86933\n",
      "[epoch 349, batch    18] loss: 3.31944\n",
      "[epoch 349, batch    19] loss: 2.84507\n",
      "[epoch 349, batch    20] loss: 3.67817\n",
      "[epoch 349, batch    21] loss: 2.63811\n",
      "[epoch 349, batch    22] loss: 3.15964\n",
      "[epoch 349, batch    23] loss: 3.12062\n",
      "[epoch 349, batch    24] loss: 3.61961\n",
      "[epoch 349, batch    25] loss: 3.03640\n",
      "[epoch 349, batch    26] loss: 2.86652\n",
      "[epoch 349, batch    27] loss: 3.30298\n",
      "[epoch 349, batch    28] loss: 3.20194\n",
      "[epoch 349, batch    29] loss: 3.05123\n",
      "[epoch 349, batch    30] loss: 3.58056\n",
      "[epoch 349, batch    31] loss: 2.93551\n",
      "[epoch 349, batch    32] loss: 3.66044\n",
      "[epoch 350, batch     1] loss: 2.97701\n",
      "[epoch 350, batch     2] loss: 2.86786\n",
      "[epoch 350, batch     3] loss: 2.72921\n",
      "[epoch 350, batch     4] loss: 3.70987\n",
      "[epoch 350, batch     5] loss: 2.52093\n",
      "[epoch 350, batch     6] loss: 3.96345\n",
      "[epoch 350, batch     7] loss: 2.81157\n",
      "[epoch 350, batch     8] loss: 3.73130\n",
      "[epoch 350, batch     9] loss: 3.15172\n",
      "[epoch 350, batch    10] loss: 3.06889\n",
      "[epoch 350, batch    11] loss: 2.78409\n",
      "[epoch 350, batch    12] loss: 2.99373\n",
      "[epoch 350, batch    13] loss: 2.83948\n",
      "[epoch 350, batch    14] loss: 3.28897\n",
      "[epoch 350, batch    15] loss: 3.74782\n",
      "[epoch 350, batch    16] loss: 2.84290\n",
      "[epoch 350, batch    17] loss: 3.06957\n",
      "[epoch 350, batch    18] loss: 3.28168\n",
      "[epoch 350, batch    19] loss: 3.27499\n",
      "[epoch 350, batch    20] loss: 2.60450\n",
      "[epoch 350, batch    21] loss: 3.20238\n",
      "[epoch 350, batch    22] loss: 2.74029\n",
      "[epoch 350, batch    23] loss: 3.04319\n",
      "[epoch 350, batch    24] loss: 2.28380\n",
      "[epoch 350, batch    25] loss: 3.43500\n",
      "[epoch 350, batch    26] loss: 2.42426\n",
      "[epoch 350, batch    27] loss: 3.46018\n",
      "[epoch 350, batch    28] loss: 2.89966\n",
      "[epoch 350, batch    29] loss: 3.12997\n",
      "[epoch 350, batch    30] loss: 2.75727\n",
      "[epoch 350, batch    31] loss: 3.01050\n",
      "[epoch 350, batch    32] loss: 2.48793\n",
      "[epoch 351, batch     1] loss: 3.00888\n",
      "[epoch 351, batch     2] loss: 2.61682\n",
      "[epoch 351, batch     3] loss: 2.53360\n",
      "[epoch 351, batch     4] loss: 3.48094\n",
      "[epoch 351, batch     5] loss: 3.20153\n",
      "[epoch 351, batch     6] loss: 3.94602\n",
      "[epoch 351, batch     7] loss: 2.21256\n",
      "[epoch 351, batch     8] loss: 2.14163\n",
      "[epoch 351, batch     9] loss: 2.24948\n",
      "[epoch 351, batch    10] loss: 3.82870\n",
      "[epoch 351, batch    11] loss: 3.88137\n",
      "[epoch 351, batch    12] loss: 2.68698\n",
      "[epoch 351, batch    13] loss: 3.06713\n",
      "[epoch 351, batch    14] loss: 3.08885\n",
      "[epoch 351, batch    15] loss: 3.14959\n",
      "[epoch 351, batch    16] loss: 3.60071\n",
      "[epoch 351, batch    17] loss: 1.75309\n",
      "[epoch 351, batch    18] loss: 3.60510\n",
      "[epoch 351, batch    19] loss: 2.49480\n",
      "[epoch 351, batch    20] loss: 2.65923\n",
      "[epoch 351, batch    21] loss: 2.80870\n",
      "[epoch 351, batch    22] loss: 3.77701\n",
      "[epoch 351, batch    23] loss: 3.52521\n",
      "[epoch 351, batch    24] loss: 3.31880\n",
      "[epoch 351, batch    25] loss: 3.14078\n",
      "[epoch 351, batch    26] loss: 3.54621\n",
      "[epoch 351, batch    27] loss: 2.66850\n",
      "[epoch 351, batch    28] loss: 3.92827\n",
      "[epoch 351, batch    29] loss: 3.11695\n",
      "[epoch 351, batch    30] loss: 2.66386\n",
      "[epoch 351, batch    31] loss: 2.54932\n",
      "[epoch 351, batch    32] loss: 3.03885\n",
      "[epoch 352, batch     1] loss: 3.32557\n",
      "[epoch 352, batch     2] loss: 2.64550\n",
      "[epoch 352, batch     3] loss: 2.82232\n",
      "[epoch 352, batch     4] loss: 3.71336\n",
      "[epoch 352, batch     5] loss: 2.50341\n",
      "[epoch 352, batch     6] loss: 2.85320\n",
      "[epoch 352, batch     7] loss: 2.40431\n",
      "[epoch 352, batch     8] loss: 2.56794\n",
      "[epoch 352, batch     9] loss: 3.52800\n",
      "[epoch 352, batch    10] loss: 2.17814\n",
      "[epoch 352, batch    11] loss: 3.55341\n",
      "[epoch 352, batch    12] loss: 2.84088\n",
      "[epoch 352, batch    13] loss: 3.14292\n",
      "[epoch 352, batch    14] loss: 3.92221\n",
      "[epoch 352, batch    15] loss: 3.57004\n",
      "[epoch 352, batch    16] loss: 2.78527\n",
      "[epoch 352, batch    17] loss: 3.13767\n",
      "[epoch 352, batch    18] loss: 2.45746\n",
      "[epoch 352, batch    19] loss: 3.23613\n",
      "[epoch 352, batch    20] loss: 3.67113\n",
      "[epoch 352, batch    21] loss: 2.92793\n",
      "[epoch 352, batch    22] loss: 2.89136\n",
      "[epoch 352, batch    23] loss: 3.57285\n",
      "[epoch 352, batch    24] loss: 2.49647\n",
      "[epoch 352, batch    25] loss: 2.31181\n",
      "[epoch 352, batch    26] loss: 2.60108\n",
      "[epoch 352, batch    27] loss: 4.00240\n",
      "[epoch 352, batch    28] loss: 3.44075\n",
      "[epoch 352, batch    29] loss: 2.70674\n",
      "[epoch 352, batch    30] loss: 2.95265\n",
      "[epoch 352, batch    31] loss: 2.81583\n",
      "[epoch 352, batch    32] loss: 5.27707\n",
      "[epoch 353, batch     1] loss: 2.48163\n",
      "[epoch 353, batch     2] loss: 3.88040\n",
      "[epoch 353, batch     3] loss: 3.04571\n",
      "[epoch 353, batch     4] loss: 3.24219\n",
      "[epoch 353, batch     5] loss: 2.98484\n",
      "[epoch 353, batch     6] loss: 2.67067\n",
      "[epoch 353, batch     7] loss: 2.41247\n",
      "[epoch 353, batch     8] loss: 2.42198\n",
      "[epoch 353, batch     9] loss: 3.33861\n",
      "[epoch 353, batch    10] loss: 4.02799\n",
      "[epoch 353, batch    11] loss: 2.91910\n",
      "[epoch 353, batch    12] loss: 3.22082\n",
      "[epoch 353, batch    13] loss: 2.98764\n",
      "[epoch 353, batch    14] loss: 2.79995\n",
      "[epoch 353, batch    15] loss: 2.63760\n",
      "[epoch 353, batch    16] loss: 3.20478\n",
      "[epoch 353, batch    17] loss: 3.25738\n",
      "[epoch 353, batch    18] loss: 3.07612\n",
      "[epoch 353, batch    19] loss: 3.52644\n",
      "[epoch 353, batch    20] loss: 2.97919\n",
      "[epoch 353, batch    21] loss: 4.09926\n",
      "[epoch 353, batch    22] loss: 3.01226\n",
      "[epoch 353, batch    23] loss: 3.15041\n",
      "[epoch 353, batch    24] loss: 2.82692\n",
      "[epoch 353, batch    25] loss: 3.01743\n",
      "[epoch 353, batch    26] loss: 2.21521\n",
      "[epoch 353, batch    27] loss: 2.52068\n",
      "[epoch 353, batch    28] loss: 2.21828\n",
      "[epoch 353, batch    29] loss: 2.47413\n",
      "[epoch 353, batch    30] loss: 3.13250\n",
      "[epoch 353, batch    31] loss: 4.43203\n",
      "[epoch 353, batch    32] loss: 2.81522\n",
      "[epoch 354, batch     1] loss: 2.80814\n",
      "[epoch 354, batch     2] loss: 3.12311\n",
      "[epoch 354, batch     3] loss: 2.88117\n",
      "[epoch 354, batch     4] loss: 2.63593\n",
      "[epoch 354, batch     5] loss: 3.13888\n",
      "[epoch 354, batch     6] loss: 3.52363\n",
      "[epoch 354, batch     7] loss: 3.31773\n",
      "[epoch 354, batch     8] loss: 3.98747\n",
      "[epoch 354, batch     9] loss: 3.57545\n",
      "[epoch 354, batch    10] loss: 3.00591\n",
      "[epoch 354, batch    11] loss: 3.33377\n",
      "[epoch 354, batch    12] loss: 3.43408\n",
      "[epoch 354, batch    13] loss: 2.50154\n",
      "[epoch 354, batch    14] loss: 2.29121\n",
      "[epoch 354, batch    15] loss: 2.84409\n",
      "[epoch 354, batch    16] loss: 2.82272\n",
      "[epoch 354, batch    17] loss: 2.83195\n",
      "[epoch 354, batch    18] loss: 3.83540\n",
      "[epoch 354, batch    19] loss: 2.79293\n",
      "[epoch 354, batch    20] loss: 3.07713\n",
      "[epoch 354, batch    21] loss: 2.64574\n",
      "[epoch 354, batch    22] loss: 2.67155\n",
      "[epoch 354, batch    23] loss: 2.67331\n",
      "[epoch 354, batch    24] loss: 2.52185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 354, batch    25] loss: 3.31106\n",
      "[epoch 354, batch    26] loss: 3.28111\n",
      "[epoch 354, batch    27] loss: 2.48282\n",
      "[epoch 354, batch    28] loss: 3.17864\n",
      "[epoch 354, batch    29] loss: 2.74129\n",
      "[epoch 354, batch    30] loss: 2.99106\n",
      "[epoch 354, batch    31] loss: 3.76010\n",
      "[epoch 354, batch    32] loss: 4.51399\n",
      "[epoch 355, batch     1] loss: 3.17806\n",
      "[epoch 355, batch     2] loss: 3.12758\n",
      "[epoch 355, batch     3] loss: 3.54227\n",
      "[epoch 355, batch     4] loss: 3.16368\n",
      "[epoch 355, batch     5] loss: 2.38131\n",
      "[epoch 355, batch     6] loss: 2.38876\n",
      "[epoch 355, batch     7] loss: 3.46642\n",
      "[epoch 355, batch     8] loss: 2.77026\n",
      "[epoch 355, batch     9] loss: 1.96434\n",
      "[epoch 355, batch    10] loss: 3.55094\n",
      "[epoch 355, batch    11] loss: 3.29890\n",
      "[epoch 355, batch    12] loss: 2.89922\n",
      "[epoch 355, batch    13] loss: 3.12152\n",
      "[epoch 355, batch    14] loss: 3.16048\n",
      "[epoch 355, batch    15] loss: 2.44841\n",
      "[epoch 355, batch    16] loss: 2.32266\n",
      "[epoch 355, batch    17] loss: 3.17643\n",
      "[epoch 355, batch    18] loss: 3.49393\n",
      "[epoch 355, batch    19] loss: 2.31068\n",
      "[epoch 355, batch    20] loss: 3.43351\n",
      "[epoch 355, batch    21] loss: 3.80782\n",
      "[epoch 355, batch    22] loss: 3.97051\n",
      "[epoch 355, batch    23] loss: 3.02162\n",
      "[epoch 355, batch    24] loss: 3.12952\n",
      "[epoch 355, batch    25] loss: 3.18931\n",
      "[epoch 355, batch    26] loss: 2.70828\n",
      "[epoch 355, batch    27] loss: 3.13682\n",
      "[epoch 355, batch    28] loss: 2.98241\n",
      "[epoch 355, batch    29] loss: 2.05150\n",
      "[epoch 355, batch    30] loss: 2.84754\n",
      "[epoch 355, batch    31] loss: 3.74754\n",
      "[epoch 355, batch    32] loss: 4.34181\n",
      "[epoch 356, batch     1] loss: 3.39828\n",
      "[epoch 356, batch     2] loss: 2.77499\n",
      "[epoch 356, batch     3] loss: 3.67004\n",
      "[epoch 356, batch     4] loss: 3.62886\n",
      "[epoch 356, batch     5] loss: 2.60142\n",
      "[epoch 356, batch     6] loss: 3.52837\n",
      "[epoch 356, batch     7] loss: 2.91556\n",
      "[epoch 356, batch     8] loss: 2.52410\n",
      "[epoch 356, batch     9] loss: 3.30235\n",
      "[epoch 356, batch    10] loss: 2.71446\n",
      "[epoch 356, batch    11] loss: 3.56972\n",
      "[epoch 356, batch    12] loss: 3.12568\n",
      "[epoch 356, batch    13] loss: 3.22177\n",
      "[epoch 356, batch    14] loss: 3.53570\n",
      "[epoch 356, batch    15] loss: 2.89015\n",
      "[epoch 356, batch    16] loss: 2.40145\n",
      "[epoch 356, batch    17] loss: 2.56151\n",
      "[epoch 356, batch    18] loss: 2.70125\n",
      "[epoch 356, batch    19] loss: 1.87185\n",
      "[epoch 356, batch    20] loss: 3.20042\n",
      "[epoch 356, batch    21] loss: 2.70816\n",
      "[epoch 356, batch    22] loss: 2.96373\n",
      "[epoch 356, batch    23] loss: 2.84972\n",
      "[epoch 356, batch    24] loss: 3.74720\n",
      "[epoch 356, batch    25] loss: 3.36421\n",
      "[epoch 356, batch    26] loss: 2.97835\n",
      "[epoch 356, batch    27] loss: 2.32691\n",
      "[epoch 356, batch    28] loss: 2.92616\n",
      "[epoch 356, batch    29] loss: 3.53188\n",
      "[epoch 356, batch    30] loss: 3.85768\n",
      "[epoch 356, batch    31] loss: 3.42044\n",
      "[epoch 356, batch    32] loss: 1.87311\n",
      "[epoch 357, batch     1] loss: 3.36035\n",
      "[epoch 357, batch     2] loss: 3.21918\n",
      "[epoch 357, batch     3] loss: 3.12965\n",
      "[epoch 357, batch     4] loss: 3.58327\n",
      "[epoch 357, batch     5] loss: 3.53117\n",
      "[epoch 357, batch     6] loss: 3.65453\n",
      "[epoch 357, batch     7] loss: 2.98540\n",
      "[epoch 357, batch     8] loss: 3.00424\n",
      "[epoch 357, batch     9] loss: 2.46659\n",
      "[epoch 357, batch    10] loss: 2.92144\n",
      "[epoch 357, batch    11] loss: 2.60201\n",
      "[epoch 357, batch    12] loss: 3.67806\n",
      "[epoch 357, batch    13] loss: 3.84328\n",
      "[epoch 357, batch    14] loss: 2.47052\n",
      "[epoch 357, batch    15] loss: 2.94528\n",
      "[epoch 357, batch    16] loss: 2.65559\n",
      "[epoch 357, batch    17] loss: 2.61794\n",
      "[epoch 357, batch    18] loss: 3.21893\n",
      "[epoch 357, batch    19] loss: 2.60264\n",
      "[epoch 357, batch    20] loss: 3.35755\n",
      "[epoch 357, batch    21] loss: 2.65468\n",
      "[epoch 357, batch    22] loss: 3.24089\n",
      "[epoch 357, batch    23] loss: 3.26137\n",
      "[epoch 357, batch    24] loss: 3.00326\n",
      "[epoch 357, batch    25] loss: 3.48973\n",
      "[epoch 357, batch    26] loss: 2.59742\n",
      "[epoch 357, batch    27] loss: 2.60686\n",
      "[epoch 357, batch    28] loss: 3.08389\n",
      "[epoch 357, batch    29] loss: 2.85193\n",
      "[epoch 357, batch    30] loss: 2.57487\n",
      "[epoch 357, batch    31] loss: 3.29024\n",
      "[epoch 357, batch    32] loss: 3.63628\n",
      "[epoch 358, batch     1] loss: 3.61767\n",
      "[epoch 358, batch     2] loss: 2.75860\n",
      "[epoch 358, batch     3] loss: 3.46980\n",
      "[epoch 358, batch     4] loss: 3.13365\n",
      "[epoch 358, batch     5] loss: 3.27596\n",
      "[epoch 358, batch     6] loss: 2.77098\n",
      "[epoch 358, batch     7] loss: 3.51549\n",
      "[epoch 358, batch     8] loss: 2.81696\n",
      "[epoch 358, batch     9] loss: 3.06059\n",
      "[epoch 358, batch    10] loss: 3.52287\n",
      "[epoch 358, batch    11] loss: 2.57729\n",
      "[epoch 358, batch    12] loss: 3.30151\n",
      "[epoch 358, batch    13] loss: 3.10714\n",
      "[epoch 358, batch    14] loss: 2.97840\n",
      "[epoch 358, batch    15] loss: 3.09937\n",
      "[epoch 358, batch    16] loss: 1.96976\n",
      "[epoch 358, batch    17] loss: 3.17202\n",
      "[epoch 358, batch    18] loss: 3.15501\n",
      "[epoch 358, batch    19] loss: 3.33924\n",
      "[epoch 358, batch    20] loss: 4.04786\n",
      "[epoch 358, batch    21] loss: 2.41436\n",
      "[epoch 358, batch    22] loss: 2.12677\n",
      "[epoch 358, batch    23] loss: 3.47153\n",
      "[epoch 358, batch    24] loss: 3.09638\n",
      "[epoch 358, batch    25] loss: 3.24558\n",
      "[epoch 358, batch    26] loss: 3.54137\n",
      "[epoch 358, batch    27] loss: 2.67582\n",
      "[epoch 358, batch    28] loss: 2.49611\n",
      "[epoch 358, batch    29] loss: 2.25276\n",
      "[epoch 358, batch    30] loss: 2.65227\n",
      "[epoch 358, batch    31] loss: 2.80735\n",
      "[epoch 358, batch    32] loss: 5.20787\n",
      "[epoch 359, batch     1] loss: 2.24262\n",
      "[epoch 359, batch     2] loss: 2.78717\n",
      "[epoch 359, batch     3] loss: 2.09313\n",
      "[epoch 359, batch     4] loss: 2.98376\n",
      "[epoch 359, batch     5] loss: 3.45187\n",
      "[epoch 359, batch     6] loss: 2.71254\n",
      "[epoch 359, batch     7] loss: 3.00085\n",
      "[epoch 359, batch     8] loss: 3.57163\n",
      "[epoch 359, batch     9] loss: 3.31221\n",
      "[epoch 359, batch    10] loss: 3.27972\n",
      "[epoch 359, batch    11] loss: 2.72237\n",
      "[epoch 359, batch    12] loss: 2.97219\n",
      "[epoch 359, batch    13] loss: 2.21447\n",
      "[epoch 359, batch    14] loss: 4.12060\n",
      "[epoch 359, batch    15] loss: 2.89394\n",
      "[epoch 359, batch    16] loss: 3.00639\n",
      "[epoch 359, batch    17] loss: 3.16567\n",
      "[epoch 359, batch    18] loss: 2.78522\n",
      "[epoch 359, batch    19] loss: 3.33556\n",
      "[epoch 359, batch    20] loss: 3.07571\n",
      "[epoch 359, batch    21] loss: 3.18580\n",
      "[epoch 359, batch    22] loss: 2.45559\n",
      "[epoch 359, batch    23] loss: 2.63096\n",
      "[epoch 359, batch    24] loss: 3.91837\n",
      "[epoch 359, batch    25] loss: 3.82473\n",
      "[epoch 359, batch    26] loss: 2.53624\n",
      "[epoch 359, batch    27] loss: 2.91702\n",
      "[epoch 359, batch    28] loss: 3.61039\n",
      "[epoch 359, batch    29] loss: 2.82432\n",
      "[epoch 359, batch    30] loss: 2.98299\n",
      "[epoch 359, batch    31] loss: 3.66778\n",
      "[epoch 359, batch    32] loss: 2.33787\n",
      "[epoch 360, batch     1] loss: 2.45692\n",
      "[epoch 360, batch     2] loss: 2.69570\n",
      "[epoch 360, batch     3] loss: 3.72172\n",
      "[epoch 360, batch     4] loss: 3.40650\n",
      "[epoch 360, batch     5] loss: 3.10219\n",
      "[epoch 360, batch     6] loss: 3.09837\n",
      "[epoch 360, batch     7] loss: 2.91016\n",
      "[epoch 360, batch     8] loss: 3.93711\n",
      "[epoch 360, batch     9] loss: 3.64258\n",
      "[epoch 360, batch    10] loss: 3.35955\n",
      "[epoch 360, batch    11] loss: 3.12098\n",
      "[epoch 360, batch    12] loss: 2.54927\n",
      "[epoch 360, batch    13] loss: 2.78859\n",
      "[epoch 360, batch    14] loss: 2.73498\n",
      "[epoch 360, batch    15] loss: 2.74179\n",
      "[epoch 360, batch    16] loss: 3.09425\n",
      "[epoch 360, batch    17] loss: 3.01947\n",
      "[epoch 360, batch    18] loss: 3.41782\n",
      "[epoch 360, batch    19] loss: 3.03172\n",
      "[epoch 360, batch    20] loss: 2.48370\n",
      "[epoch 360, batch    21] loss: 3.00959\n",
      "[epoch 360, batch    22] loss: 2.92029\n",
      "[epoch 360, batch    23] loss: 2.88775\n",
      "[epoch 360, batch    24] loss: 3.48764\n",
      "[epoch 360, batch    25] loss: 3.67056\n",
      "[epoch 360, batch    26] loss: 2.88532\n",
      "[epoch 360, batch    27] loss: 2.03081\n",
      "[epoch 360, batch    28] loss: 3.46046\n",
      "[epoch 360, batch    29] loss: 3.07755\n",
      "[epoch 360, batch    30] loss: 2.74122\n",
      "[epoch 360, batch    31] loss: 2.52061\n",
      "[epoch 360, batch    32] loss: 3.52913\n",
      "[epoch 361, batch     1] loss: 3.01795\n",
      "[epoch 361, batch     2] loss: 3.08411\n",
      "[epoch 361, batch     3] loss: 2.88321\n",
      "[epoch 361, batch     4] loss: 2.73222\n",
      "[epoch 361, batch     5] loss: 3.17422\n",
      "[epoch 361, batch     6] loss: 3.00661\n",
      "[epoch 361, batch     7] loss: 3.78552\n",
      "[epoch 361, batch     8] loss: 2.18488\n",
      "[epoch 361, batch     9] loss: 2.89667\n",
      "[epoch 361, batch    10] loss: 2.88961\n",
      "[epoch 361, batch    11] loss: 2.63546\n",
      "[epoch 361, batch    12] loss: 3.85753\n",
      "[epoch 361, batch    13] loss: 3.45139\n",
      "[epoch 361, batch    14] loss: 2.73660\n",
      "[epoch 361, batch    15] loss: 3.05485\n",
      "[epoch 361, batch    16] loss: 3.55779\n",
      "[epoch 361, batch    17] loss: 3.38486\n",
      "[epoch 361, batch    18] loss: 3.29512\n",
      "[epoch 361, batch    19] loss: 2.57318\n",
      "[epoch 361, batch    20] loss: 3.36915\n",
      "[epoch 361, batch    21] loss: 2.11924\n",
      "[epoch 361, batch    22] loss: 3.63787\n",
      "[epoch 361, batch    23] loss: 2.77358\n",
      "[epoch 361, batch    24] loss: 2.69299\n",
      "[epoch 361, batch    25] loss: 2.87164\n",
      "[epoch 361, batch    26] loss: 2.78903\n",
      "[epoch 361, batch    27] loss: 3.34047\n",
      "[epoch 361, batch    28] loss: 2.79864\n",
      "[epoch 361, batch    29] loss: 2.81959\n",
      "[epoch 361, batch    30] loss: 2.91590\n",
      "[epoch 361, batch    31] loss: 3.61489\n",
      "[epoch 361, batch    32] loss: 2.36836\n",
      "[epoch 362, batch     1] loss: 2.87148\n",
      "[epoch 362, batch     2] loss: 3.56428\n",
      "[epoch 362, batch     3] loss: 3.56437\n",
      "[epoch 362, batch     4] loss: 2.97409\n",
      "[epoch 362, batch     5] loss: 2.90386\n",
      "[epoch 362, batch     6] loss: 2.96625\n",
      "[epoch 362, batch     7] loss: 3.69338\n",
      "[epoch 362, batch     8] loss: 2.76814\n",
      "[epoch 362, batch     9] loss: 2.69297\n",
      "[epoch 362, batch    10] loss: 2.89463\n",
      "[epoch 362, batch    11] loss: 2.55013\n",
      "[epoch 362, batch    12] loss: 2.11941\n",
      "[epoch 362, batch    13] loss: 3.68345\n",
      "[epoch 362, batch    14] loss: 2.95698\n",
      "[epoch 362, batch    15] loss: 3.33634\n",
      "[epoch 362, batch    16] loss: 2.85147\n",
      "[epoch 362, batch    17] loss: 2.23201\n",
      "[epoch 362, batch    18] loss: 2.71763\n",
      "[epoch 362, batch    19] loss: 2.72656\n",
      "[epoch 362, batch    20] loss: 2.90951\n",
      "[epoch 362, batch    21] loss: 3.89910\n",
      "[epoch 362, batch    22] loss: 3.30968\n",
      "[epoch 362, batch    23] loss: 3.77489\n",
      "[epoch 362, batch    24] loss: 2.98557\n",
      "[epoch 362, batch    25] loss: 4.43851\n",
      "[epoch 362, batch    26] loss: 2.60129\n",
      "[epoch 362, batch    27] loss: 3.47481\n",
      "[epoch 362, batch    28] loss: 2.68044\n",
      "[epoch 362, batch    29] loss: 2.72558\n",
      "[epoch 362, batch    30] loss: 2.85504\n",
      "[epoch 362, batch    31] loss: 2.41997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 362, batch    32] loss: 1.95471\n",
      "[epoch 363, batch     1] loss: 3.21109\n",
      "[epoch 363, batch     2] loss: 2.42177\n",
      "[epoch 363, batch     3] loss: 1.97777\n",
      "[epoch 363, batch     4] loss: 3.00273\n",
      "[epoch 363, batch     5] loss: 2.56694\n",
      "[epoch 363, batch     6] loss: 2.43271\n",
      "[epoch 363, batch     7] loss: 2.45229\n",
      "[epoch 363, batch     8] loss: 3.01627\n",
      "[epoch 363, batch     9] loss: 3.44266\n",
      "[epoch 363, batch    10] loss: 3.38421\n",
      "[epoch 363, batch    11] loss: 3.42386\n",
      "[epoch 363, batch    12] loss: 2.56898\n",
      "[epoch 363, batch    13] loss: 3.84715\n",
      "[epoch 363, batch    14] loss: 2.96246\n",
      "[epoch 363, batch    15] loss: 4.27325\n",
      "[epoch 363, batch    16] loss: 2.88313\n",
      "[epoch 363, batch    17] loss: 3.48262\n",
      "[epoch 363, batch    18] loss: 3.18236\n",
      "[epoch 363, batch    19] loss: 2.73886\n",
      "[epoch 363, batch    20] loss: 3.36891\n",
      "[epoch 363, batch    21] loss: 2.91033\n",
      "[epoch 363, batch    22] loss: 2.77097\n",
      "[epoch 363, batch    23] loss: 3.51373\n",
      "[epoch 363, batch    24] loss: 3.46214\n",
      "[epoch 363, batch    25] loss: 3.13557\n",
      "[epoch 363, batch    26] loss: 3.22711\n",
      "[epoch 363, batch    27] loss: 2.99549\n",
      "[epoch 363, batch    28] loss: 2.94165\n",
      "[epoch 363, batch    29] loss: 2.03495\n",
      "[epoch 363, batch    30] loss: 2.71363\n",
      "[epoch 363, batch    31] loss: 3.19655\n",
      "[epoch 363, batch    32] loss: 4.58402\n",
      "[epoch 364, batch     1] loss: 2.44674\n",
      "[epoch 364, batch     2] loss: 2.77236\n",
      "[epoch 364, batch     3] loss: 2.84975\n",
      "[epoch 364, batch     4] loss: 2.95658\n",
      "[epoch 364, batch     5] loss: 4.59963\n",
      "[epoch 364, batch     6] loss: 3.46523\n",
      "[epoch 364, batch     7] loss: 2.73452\n",
      "[epoch 364, batch     8] loss: 2.65186\n",
      "[epoch 364, batch     9] loss: 2.63532\n",
      "[epoch 364, batch    10] loss: 2.37658\n",
      "[epoch 364, batch    11] loss: 2.89686\n",
      "[epoch 364, batch    12] loss: 3.02041\n",
      "[epoch 364, batch    13] loss: 2.68639\n",
      "[epoch 364, batch    14] loss: 3.98539\n",
      "[epoch 364, batch    15] loss: 2.56045\n",
      "[epoch 364, batch    16] loss: 2.41467\n",
      "[epoch 364, batch    17] loss: 3.14327\n",
      "[epoch 364, batch    18] loss: 3.20795\n",
      "[epoch 364, batch    19] loss: 3.98075\n",
      "[epoch 364, batch    20] loss: 4.19196\n",
      "[epoch 364, batch    21] loss: 3.71678\n",
      "[epoch 364, batch    22] loss: 3.78749\n",
      "[epoch 364, batch    23] loss: 2.39573\n",
      "[epoch 364, batch    24] loss: 3.63421\n",
      "[epoch 364, batch    25] loss: 2.85538\n",
      "[epoch 364, batch    26] loss: 2.45022\n",
      "[epoch 364, batch    27] loss: 2.90842\n",
      "[epoch 364, batch    28] loss: 2.54910\n",
      "[epoch 364, batch    29] loss: 2.69488\n",
      "[epoch 364, batch    30] loss: 2.78232\n",
      "[epoch 364, batch    31] loss: 2.91883\n",
      "[epoch 364, batch    32] loss: 2.28796\n",
      "[epoch 365, batch     1] loss: 3.57658\n",
      "[epoch 365, batch     2] loss: 2.16839\n",
      "[epoch 365, batch     3] loss: 2.48380\n",
      "[epoch 365, batch     4] loss: 2.54018\n",
      "[epoch 365, batch     5] loss: 4.08198\n",
      "[epoch 365, batch     6] loss: 3.29836\n",
      "[epoch 365, batch     7] loss: 3.39495\n",
      "[epoch 365, batch     8] loss: 3.42274\n",
      "[epoch 365, batch     9] loss: 2.86993\n",
      "[epoch 365, batch    10] loss: 3.80451\n",
      "[epoch 365, batch    11] loss: 2.52995\n",
      "[epoch 365, batch    12] loss: 3.60485\n",
      "[epoch 365, batch    13] loss: 3.52046\n",
      "[epoch 365, batch    14] loss: 2.08679\n",
      "[epoch 365, batch    15] loss: 2.55940\n",
      "[epoch 365, batch    16] loss: 2.84134\n",
      "[epoch 365, batch    17] loss: 2.87972\n",
      "[epoch 365, batch    18] loss: 2.86370\n",
      "[epoch 365, batch    19] loss: 3.55549\n",
      "[epoch 365, batch    20] loss: 3.46732\n",
      "[epoch 365, batch    21] loss: 3.56924\n",
      "[epoch 365, batch    22] loss: 3.36840\n",
      "[epoch 365, batch    23] loss: 2.80664\n",
      "[epoch 365, batch    24] loss: 2.37586\n",
      "[epoch 365, batch    25] loss: 3.08474\n",
      "[epoch 365, batch    26] loss: 2.84380\n",
      "[epoch 365, batch    27] loss: 4.02051\n",
      "[epoch 365, batch    28] loss: 2.90572\n",
      "[epoch 365, batch    29] loss: 2.44518\n",
      "[epoch 365, batch    30] loss: 3.48349\n",
      "[epoch 365, batch    31] loss: 2.22839\n",
      "[epoch 365, batch    32] loss: 2.63032\n",
      "[epoch 366, batch     1] loss: 3.46276\n",
      "[epoch 366, batch     2] loss: 4.12809\n",
      "[epoch 366, batch     3] loss: 3.74559\n",
      "[epoch 366, batch     4] loss: 1.82225\n",
      "[epoch 366, batch     5] loss: 2.79263\n",
      "[epoch 366, batch     6] loss: 4.18791\n",
      "[epoch 366, batch     7] loss: 2.82093\n",
      "[epoch 366, batch     8] loss: 3.05013\n",
      "[epoch 366, batch     9] loss: 2.75209\n",
      "[epoch 366, batch    10] loss: 2.39963\n",
      "[epoch 366, batch    11] loss: 1.91593\n",
      "[epoch 366, batch    12] loss: 2.90496\n",
      "[epoch 366, batch    13] loss: 3.56204\n",
      "[epoch 366, batch    14] loss: 2.57970\n",
      "[epoch 366, batch    15] loss: 2.71293\n",
      "[epoch 366, batch    16] loss: 3.29218\n",
      "[epoch 366, batch    17] loss: 3.40321\n",
      "[epoch 366, batch    18] loss: 2.82972\n",
      "[epoch 366, batch    19] loss: 2.94342\n",
      "[epoch 366, batch    20] loss: 3.04503\n",
      "[epoch 366, batch    21] loss: 3.08944\n",
      "[epoch 366, batch    22] loss: 2.54072\n",
      "[epoch 366, batch    23] loss: 2.87580\n",
      "[epoch 366, batch    24] loss: 4.11282\n",
      "[epoch 366, batch    25] loss: 2.58828\n",
      "[epoch 366, batch    26] loss: 3.12934\n",
      "[epoch 366, batch    27] loss: 2.48186\n",
      "[epoch 366, batch    28] loss: 2.84278\n",
      "[epoch 366, batch    29] loss: 3.73558\n",
      "[epoch 366, batch    30] loss: 2.95105\n",
      "[epoch 366, batch    31] loss: 3.27015\n",
      "[epoch 366, batch    32] loss: 3.89810\n",
      "[epoch 367, batch     1] loss: 2.94784\n",
      "[epoch 367, batch     2] loss: 2.67400\n",
      "[epoch 367, batch     3] loss: 2.90360\n",
      "[epoch 367, batch     4] loss: 2.51119\n",
      "[epoch 367, batch     5] loss: 3.38520\n",
      "[epoch 367, batch     6] loss: 3.19728\n",
      "[epoch 367, batch     7] loss: 2.88439\n",
      "[epoch 367, batch     8] loss: 2.78978\n",
      "[epoch 367, batch     9] loss: 2.74577\n",
      "[epoch 367, batch    10] loss: 2.61999\n",
      "[epoch 367, batch    11] loss: 2.89714\n",
      "[epoch 367, batch    12] loss: 2.82193\n",
      "[epoch 367, batch    13] loss: 2.91260\n",
      "[epoch 367, batch    14] loss: 2.95785\n",
      "[epoch 367, batch    15] loss: 3.36493\n",
      "[epoch 367, batch    16] loss: 3.14132\n",
      "[epoch 367, batch    17] loss: 2.79698\n",
      "[epoch 367, batch    18] loss: 3.11251\n",
      "[epoch 367, batch    19] loss: 2.53930\n",
      "[epoch 367, batch    20] loss: 3.46744\n",
      "[epoch 367, batch    21] loss: 4.09437\n",
      "[epoch 367, batch    22] loss: 2.78002\n",
      "[epoch 367, batch    23] loss: 2.76403\n",
      "[epoch 367, batch    24] loss: 3.98560\n",
      "[epoch 367, batch    25] loss: 2.60445\n",
      "[epoch 367, batch    26] loss: 2.38849\n",
      "[epoch 367, batch    27] loss: 3.60418\n",
      "[epoch 367, batch    28] loss: 4.11910\n",
      "[epoch 367, batch    29] loss: 3.59175\n",
      "[epoch 367, batch    30] loss: 2.84241\n",
      "[epoch 367, batch    31] loss: 3.08114\n",
      "[epoch 367, batch    32] loss: 2.24471\n",
      "[epoch 368, batch     1] loss: 2.24212\n",
      "[epoch 368, batch     2] loss: 3.75039\n",
      "[epoch 368, batch     3] loss: 3.17412\n",
      "[epoch 368, batch     4] loss: 3.35410\n",
      "[epoch 368, batch     5] loss: 2.57682\n",
      "[epoch 368, batch     6] loss: 3.41179\n",
      "[epoch 368, batch     7] loss: 2.49672\n",
      "[epoch 368, batch     8] loss: 3.52071\n",
      "[epoch 368, batch     9] loss: 3.15174\n",
      "[epoch 368, batch    10] loss: 3.23213\n",
      "[epoch 368, batch    11] loss: 2.98838\n",
      "[epoch 368, batch    12] loss: 2.79475\n",
      "[epoch 368, batch    13] loss: 2.29170\n",
      "[epoch 368, batch    14] loss: 2.90306\n",
      "[epoch 368, batch    15] loss: 3.83735\n",
      "[epoch 368, batch    16] loss: 3.06248\n",
      "[epoch 368, batch    17] loss: 3.16614\n",
      "[epoch 368, batch    18] loss: 3.55855\n",
      "[epoch 368, batch    19] loss: 3.02067\n",
      "[epoch 368, batch    20] loss: 3.20719\n",
      "[epoch 368, batch    21] loss: 2.88116\n",
      "[epoch 368, batch    22] loss: 2.55602\n",
      "[epoch 368, batch    23] loss: 3.29647\n",
      "[epoch 368, batch    24] loss: 3.01143\n",
      "[epoch 368, batch    25] loss: 2.66245\n",
      "[epoch 368, batch    26] loss: 2.50250\n",
      "[epoch 368, batch    27] loss: 3.05141\n",
      "[epoch 368, batch    28] loss: 3.07930\n",
      "[epoch 368, batch    29] loss: 3.76087\n",
      "[epoch 368, batch    30] loss: 2.53756\n",
      "[epoch 368, batch    31] loss: 2.84660\n",
      "[epoch 368, batch    32] loss: 3.23521\n",
      "[epoch 369, batch     1] loss: 3.29063\n",
      "[epoch 369, batch     2] loss: 3.84995\n",
      "[epoch 369, batch     3] loss: 2.04887\n",
      "[epoch 369, batch     4] loss: 3.52587\n",
      "[epoch 369, batch     5] loss: 3.08314\n",
      "[epoch 369, batch     6] loss: 3.08459\n",
      "[epoch 369, batch     7] loss: 2.96833\n",
      "[epoch 369, batch     8] loss: 2.91788\n",
      "[epoch 369, batch     9] loss: 2.80369\n",
      "[epoch 369, batch    10] loss: 2.71149\n",
      "[epoch 369, batch    11] loss: 3.43203\n",
      "[epoch 369, batch    12] loss: 3.29791\n",
      "[epoch 369, batch    13] loss: 2.78558\n",
      "[epoch 369, batch    14] loss: 2.67205\n",
      "[epoch 369, batch    15] loss: 3.14012\n",
      "[epoch 369, batch    16] loss: 2.29808\n",
      "[epoch 369, batch    17] loss: 2.95873\n",
      "[epoch 369, batch    18] loss: 2.44908\n",
      "[epoch 369, batch    19] loss: 3.72140\n",
      "[epoch 369, batch    20] loss: 3.34683\n",
      "[epoch 369, batch    21] loss: 3.68945\n",
      "[epoch 369, batch    22] loss: 3.20435\n",
      "[epoch 369, batch    23] loss: 2.67959\n",
      "[epoch 369, batch    24] loss: 2.77926\n",
      "[epoch 369, batch    25] loss: 3.06102\n",
      "[epoch 369, batch    26] loss: 2.72688\n",
      "[epoch 369, batch    27] loss: 3.37141\n",
      "[epoch 369, batch    28] loss: 3.25887\n",
      "[epoch 369, batch    29] loss: 2.90259\n",
      "[epoch 369, batch    30] loss: 3.50735\n",
      "[epoch 369, batch    31] loss: 3.26375\n",
      "[epoch 369, batch    32] loss: 2.07487\n",
      "[epoch 370, batch     1] loss: 3.48711\n",
      "[epoch 370, batch     2] loss: 3.26529\n",
      "[epoch 370, batch     3] loss: 2.80636\n",
      "[epoch 370, batch     4] loss: 3.15082\n",
      "[epoch 370, batch     5] loss: 3.17687\n",
      "[epoch 370, batch     6] loss: 2.72677\n",
      "[epoch 370, batch     7] loss: 2.83380\n",
      "[epoch 370, batch     8] loss: 2.95810\n",
      "[epoch 370, batch     9] loss: 3.89465\n",
      "[epoch 370, batch    10] loss: 3.75526\n",
      "[epoch 370, batch    11] loss: 2.73424\n",
      "[epoch 370, batch    12] loss: 2.03289\n",
      "[epoch 370, batch    13] loss: 3.90766\n",
      "[epoch 370, batch    14] loss: 2.24356\n",
      "[epoch 370, batch    15] loss: 2.67712\n",
      "[epoch 370, batch    16] loss: 2.74689\n",
      "[epoch 370, batch    17] loss: 3.01124\n",
      "[epoch 370, batch    18] loss: 3.02363\n",
      "[epoch 370, batch    19] loss: 2.81284\n",
      "[epoch 370, batch    20] loss: 3.06991\n",
      "[epoch 370, batch    21] loss: 3.01434\n",
      "[epoch 370, batch    22] loss: 3.09408\n",
      "[epoch 370, batch    23] loss: 2.96674\n",
      "[epoch 370, batch    24] loss: 2.30718\n",
      "[epoch 370, batch    25] loss: 3.15919\n",
      "[epoch 370, batch    26] loss: 3.66797\n",
      "[epoch 370, batch    27] loss: 2.95367\n",
      "[epoch 370, batch    28] loss: 3.13491\n",
      "[epoch 370, batch    29] loss: 4.34096\n",
      "[epoch 370, batch    30] loss: 2.09902\n",
      "[epoch 370, batch    31] loss: 3.24259\n",
      "[epoch 370, batch    32] loss: 3.13203\n",
      "[epoch 371, batch     1] loss: 3.67195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 371, batch     2] loss: 3.26190\n",
      "[epoch 371, batch     3] loss: 2.85643\n",
      "[epoch 371, batch     4] loss: 3.29804\n",
      "[epoch 371, batch     5] loss: 2.66371\n",
      "[epoch 371, batch     6] loss: 3.17164\n",
      "[epoch 371, batch     7] loss: 2.48350\n",
      "[epoch 371, batch     8] loss: 3.42225\n",
      "[epoch 371, batch     9] loss: 2.46907\n",
      "[epoch 371, batch    10] loss: 2.96293\n",
      "[epoch 371, batch    11] loss: 2.72986\n",
      "[epoch 371, batch    12] loss: 2.86755\n",
      "[epoch 371, batch    13] loss: 2.92564\n",
      "[epoch 371, batch    14] loss: 2.42120\n",
      "[epoch 371, batch    15] loss: 3.10275\n",
      "[epoch 371, batch    16] loss: 2.71178\n",
      "[epoch 371, batch    17] loss: 3.34282\n",
      "[epoch 371, batch    18] loss: 3.73766\n",
      "[epoch 371, batch    19] loss: 3.04722\n",
      "[epoch 371, batch    20] loss: 3.18449\n",
      "[epoch 371, batch    21] loss: 2.60130\n",
      "[epoch 371, batch    22] loss: 3.42369\n",
      "[epoch 371, batch    23] loss: 2.49734\n",
      "[epoch 371, batch    24] loss: 2.95384\n",
      "[epoch 371, batch    25] loss: 3.30460\n",
      "[epoch 371, batch    26] loss: 3.27153\n",
      "[epoch 371, batch    27] loss: 2.51955\n",
      "[epoch 371, batch    28] loss: 3.00207\n",
      "[epoch 371, batch    29] loss: 3.92662\n",
      "[epoch 371, batch    30] loss: 2.31269\n",
      "[epoch 371, batch    31] loss: 3.41831\n",
      "[epoch 371, batch    32] loss: 6.23255\n",
      "[epoch 372, batch     1] loss: 3.80791\n",
      "[epoch 372, batch     2] loss: 2.59867\n",
      "[epoch 372, batch     3] loss: 2.83425\n",
      "[epoch 372, batch     4] loss: 3.75532\n",
      "[epoch 372, batch     5] loss: 2.84366\n",
      "[epoch 372, batch     6] loss: 3.45936\n",
      "[epoch 372, batch     7] loss: 3.19990\n",
      "[epoch 372, batch     8] loss: 2.71490\n",
      "[epoch 372, batch     9] loss: 3.60081\n",
      "[epoch 372, batch    10] loss: 2.98270\n",
      "[epoch 372, batch    11] loss: 3.04490\n",
      "[epoch 372, batch    12] loss: 3.42975\n",
      "[epoch 372, batch    13] loss: 2.45169\n",
      "[epoch 372, batch    14] loss: 3.02564\n",
      "[epoch 372, batch    15] loss: 2.78298\n",
      "[epoch 372, batch    16] loss: 3.18510\n",
      "[epoch 372, batch    17] loss: 2.39689\n",
      "[epoch 372, batch    18] loss: 2.83112\n",
      "[epoch 372, batch    19] loss: 2.86660\n",
      "[epoch 372, batch    20] loss: 2.89415\n",
      "[epoch 372, batch    21] loss: 2.94621\n",
      "[epoch 372, batch    22] loss: 2.90984\n",
      "[epoch 372, batch    23] loss: 3.47914\n",
      "[epoch 372, batch    24] loss: 3.46180\n",
      "[epoch 372, batch    25] loss: 1.97413\n",
      "[epoch 372, batch    26] loss: 3.91076\n",
      "[epoch 372, batch    27] loss: 4.31521\n",
      "[epoch 372, batch    28] loss: 2.80987\n",
      "[epoch 372, batch    29] loss: 2.19970\n",
      "[epoch 372, batch    30] loss: 2.68964\n",
      "[epoch 372, batch    31] loss: 3.17033\n",
      "[epoch 372, batch    32] loss: 2.44033\n",
      "[epoch 373, batch     1] loss: 3.16519\n",
      "[epoch 373, batch     2] loss: 3.61997\n",
      "[epoch 373, batch     3] loss: 2.72575\n",
      "[epoch 373, batch     4] loss: 2.35962\n",
      "[epoch 373, batch     5] loss: 3.09873\n",
      "[epoch 373, batch     6] loss: 3.20902\n",
      "[epoch 373, batch     7] loss: 3.15869\n",
      "[epoch 373, batch     8] loss: 3.07015\n",
      "[epoch 373, batch     9] loss: 3.00835\n",
      "[epoch 373, batch    10] loss: 3.29888\n",
      "[epoch 373, batch    11] loss: 3.30860\n",
      "[epoch 373, batch    12] loss: 2.13216\n",
      "[epoch 373, batch    13] loss: 3.55603\n",
      "[epoch 373, batch    14] loss: 3.40054\n",
      "[epoch 373, batch    15] loss: 3.45862\n",
      "[epoch 373, batch    16] loss: 2.64857\n",
      "[epoch 373, batch    17] loss: 3.28634\n",
      "[epoch 373, batch    18] loss: 2.84488\n",
      "[epoch 373, batch    19] loss: 3.55490\n",
      "[epoch 373, batch    20] loss: 1.83566\n",
      "[epoch 373, batch    21] loss: 3.45605\n",
      "[epoch 373, batch    22] loss: 3.05071\n",
      "[epoch 373, batch    23] loss: 3.24063\n",
      "[epoch 373, batch    24] loss: 3.22313\n",
      "[epoch 373, batch    25] loss: 3.13966\n",
      "[epoch 373, batch    26] loss: 3.70570\n",
      "[epoch 373, batch    27] loss: 2.80188\n",
      "[epoch 373, batch    28] loss: 2.62161\n",
      "[epoch 373, batch    29] loss: 2.85915\n",
      "[epoch 373, batch    30] loss: 2.71190\n",
      "[epoch 373, batch    31] loss: 2.72930\n",
      "[epoch 373, batch    32] loss: 3.31389\n",
      "[epoch 374, batch     1] loss: 2.91887\n",
      "[epoch 374, batch     2] loss: 2.34417\n",
      "[epoch 374, batch     3] loss: 2.75872\n",
      "[epoch 374, batch     4] loss: 2.59661\n",
      "[epoch 374, batch     5] loss: 2.53844\n",
      "[epoch 374, batch     6] loss: 3.39119\n",
      "[epoch 374, batch     7] loss: 2.74987\n",
      "[epoch 374, batch     8] loss: 3.41887\n",
      "[epoch 374, batch     9] loss: 4.54798\n",
      "[epoch 374, batch    10] loss: 3.74373\n",
      "[epoch 374, batch    11] loss: 2.88074\n",
      "[epoch 374, batch    12] loss: 4.05609\n",
      "[epoch 374, batch    13] loss: 3.41173\n",
      "[epoch 374, batch    14] loss: 2.73504\n",
      "[epoch 374, batch    15] loss: 2.40564\n",
      "[epoch 374, batch    16] loss: 2.91441\n",
      "[epoch 374, batch    17] loss: 2.94640\n",
      "[epoch 374, batch    18] loss: 2.42838\n",
      "[epoch 374, batch    19] loss: 3.19416\n",
      "[epoch 374, batch    20] loss: 4.10920\n",
      "[epoch 374, batch    21] loss: 2.65854\n",
      "[epoch 374, batch    22] loss: 3.31290\n",
      "[epoch 374, batch    23] loss: 3.87487\n",
      "[epoch 374, batch    24] loss: 3.20431\n",
      "[epoch 374, batch    25] loss: 2.33766\n",
      "[epoch 374, batch    26] loss: 3.18485\n",
      "[epoch 374, batch    27] loss: 3.46546\n",
      "[epoch 374, batch    28] loss: 2.36756\n",
      "[epoch 374, batch    29] loss: 2.20197\n",
      "[epoch 374, batch    30] loss: 3.37774\n",
      "[epoch 374, batch    31] loss: 2.53209\n",
      "[epoch 374, batch    32] loss: 1.98313\n",
      "[epoch 375, batch     1] loss: 2.34730\n",
      "[epoch 375, batch     2] loss: 3.28871\n",
      "[epoch 375, batch     3] loss: 3.63739\n",
      "[epoch 375, batch     4] loss: 2.72866\n",
      "[epoch 375, batch     5] loss: 3.96722\n",
      "[epoch 375, batch     6] loss: 2.75690\n",
      "[epoch 375, batch     7] loss: 2.60584\n",
      "[epoch 375, batch     8] loss: 2.38041\n",
      "[epoch 375, batch     9] loss: 2.54162\n",
      "[epoch 375, batch    10] loss: 2.67289\n",
      "[epoch 375, batch    11] loss: 2.89476\n",
      "[epoch 375, batch    12] loss: 2.25140\n",
      "[epoch 375, batch    13] loss: 2.44999\n",
      "[epoch 375, batch    14] loss: 3.14205\n",
      "[epoch 375, batch    15] loss: 3.61651\n",
      "[epoch 375, batch    16] loss: 3.32095\n",
      "[epoch 375, batch    17] loss: 3.48232\n",
      "[epoch 375, batch    18] loss: 3.78496\n",
      "[epoch 375, batch    19] loss: 3.55687\n",
      "[epoch 375, batch    20] loss: 3.30383\n",
      "[epoch 375, batch    21] loss: 3.24656\n",
      "[epoch 375, batch    22] loss: 3.27296\n",
      "[epoch 375, batch    23] loss: 3.16897\n",
      "[epoch 375, batch    24] loss: 2.57648\n",
      "[epoch 375, batch    25] loss: 2.94889\n",
      "[epoch 375, batch    26] loss: 3.52340\n",
      "[epoch 375, batch    27] loss: 3.14592\n",
      "[epoch 375, batch    28] loss: 2.67088\n",
      "[epoch 375, batch    29] loss: 3.14544\n",
      "[epoch 375, batch    30] loss: 3.16375\n",
      "[epoch 375, batch    31] loss: 2.96149\n",
      "[epoch 375, batch    32] loss: 1.72445\n",
      "[epoch 376, batch     1] loss: 2.62921\n",
      "[epoch 376, batch     2] loss: 2.24822\n",
      "[epoch 376, batch     3] loss: 3.35695\n",
      "[epoch 376, batch     4] loss: 3.52254\n",
      "[epoch 376, batch     5] loss: 2.69261\n",
      "[epoch 376, batch     6] loss: 3.22710\n",
      "[epoch 376, batch     7] loss: 3.44950\n",
      "[epoch 376, batch     8] loss: 3.43619\n",
      "[epoch 376, batch     9] loss: 2.38807\n",
      "[epoch 376, batch    10] loss: 2.83300\n",
      "[epoch 376, batch    11] loss: 2.80817\n",
      "[epoch 376, batch    12] loss: 2.47685\n",
      "[epoch 376, batch    13] loss: 3.78090\n",
      "[epoch 376, batch    14] loss: 3.42327\n",
      "[epoch 376, batch    15] loss: 3.64789\n",
      "[epoch 376, batch    16] loss: 2.87392\n",
      "[epoch 376, batch    17] loss: 2.98169\n",
      "[epoch 376, batch    18] loss: 2.43049\n",
      "[epoch 376, batch    19] loss: 3.44200\n",
      "[epoch 376, batch    20] loss: 2.22831\n",
      "[epoch 376, batch    21] loss: 3.07357\n",
      "[epoch 376, batch    22] loss: 2.14081\n",
      "[epoch 376, batch    23] loss: 3.23680\n",
      "[epoch 376, batch    24] loss: 2.86136\n",
      "[epoch 376, batch    25] loss: 3.51909\n",
      "[epoch 376, batch    26] loss: 2.82653\n",
      "[epoch 376, batch    27] loss: 3.63986\n",
      "[epoch 376, batch    28] loss: 2.93528\n",
      "[epoch 376, batch    29] loss: 3.19940\n",
      "[epoch 376, batch    30] loss: 2.79631\n",
      "[epoch 376, batch    31] loss: 3.70045\n",
      "[epoch 376, batch    32] loss: 3.21563\n",
      "[epoch 377, batch     1] loss: 2.75702\n",
      "[epoch 377, batch     2] loss: 2.60186\n",
      "[epoch 377, batch     3] loss: 3.19093\n",
      "[epoch 377, batch     4] loss: 3.31728\n",
      "[epoch 377, batch     5] loss: 3.99136\n",
      "[epoch 377, batch     6] loss: 3.70202\n",
      "[epoch 377, batch     7] loss: 2.57511\n",
      "[epoch 377, batch     8] loss: 2.14545\n",
      "[epoch 377, batch     9] loss: 3.90549\n",
      "[epoch 377, batch    10] loss: 3.21099\n",
      "[epoch 377, batch    11] loss: 3.35954\n",
      "[epoch 377, batch    12] loss: 3.29817\n",
      "[epoch 377, batch    13] loss: 2.77997\n",
      "[epoch 377, batch    14] loss: 2.70312\n",
      "[epoch 377, batch    15] loss: 2.55621\n",
      "[epoch 377, batch    16] loss: 2.94589\n",
      "[epoch 377, batch    17] loss: 3.50255\n",
      "[epoch 377, batch    18] loss: 2.99288\n",
      "[epoch 377, batch    19] loss: 3.15323\n",
      "[epoch 377, batch    20] loss: 2.66764\n",
      "[epoch 377, batch    21] loss: 2.54160\n",
      "[epoch 377, batch    22] loss: 3.47556\n",
      "[epoch 377, batch    23] loss: 2.64872\n",
      "[epoch 377, batch    24] loss: 3.32234\n",
      "[epoch 377, batch    25] loss: 2.93575\n",
      "[epoch 377, batch    26] loss: 2.42762\n",
      "[epoch 377, batch    27] loss: 3.30190\n",
      "[epoch 377, batch    28] loss: 3.33109\n",
      "[epoch 377, batch    29] loss: 2.83001\n",
      "[epoch 377, batch    30] loss: 2.83811\n",
      "[epoch 377, batch    31] loss: 3.33383\n",
      "[epoch 377, batch    32] loss: 2.16011\n",
      "[epoch 378, batch     1] loss: 3.04760\n",
      "[epoch 378, batch     2] loss: 3.37597\n",
      "[epoch 378, batch     3] loss: 3.00949\n",
      "[epoch 378, batch     4] loss: 3.68674\n",
      "[epoch 378, batch     5] loss: 3.35477\n",
      "[epoch 378, batch     6] loss: 2.71691\n",
      "[epoch 378, batch     7] loss: 3.58104\n",
      "[epoch 378, batch     8] loss: 1.92474\n",
      "[epoch 378, batch     9] loss: 3.16398\n",
      "[epoch 378, batch    10] loss: 1.98006\n",
      "[epoch 378, batch    11] loss: 3.05549\n",
      "[epoch 378, batch    12] loss: 2.63078\n",
      "[epoch 378, batch    13] loss: 4.38468\n",
      "[epoch 378, batch    14] loss: 2.58221\n",
      "[epoch 378, batch    15] loss: 3.26680\n",
      "[epoch 378, batch    16] loss: 3.21681\n",
      "[epoch 378, batch    17] loss: 3.05967\n",
      "[epoch 378, batch    18] loss: 3.29524\n",
      "[epoch 378, batch    19] loss: 2.63033\n",
      "[epoch 378, batch    20] loss: 3.11738\n",
      "[epoch 378, batch    21] loss: 4.00339\n",
      "[epoch 378, batch    22] loss: 2.48880\n",
      "[epoch 378, batch    23] loss: 2.57196\n",
      "[epoch 378, batch    24] loss: 3.35451\n",
      "[epoch 378, batch    25] loss: 2.69921\n",
      "[epoch 378, batch    26] loss: 3.04471\n",
      "[epoch 378, batch    27] loss: 3.33405\n",
      "[epoch 378, batch    28] loss: 3.16578\n",
      "[epoch 378, batch    29] loss: 3.04528\n",
      "[epoch 378, batch    30] loss: 2.72910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 378, batch    31] loss: 2.66932\n",
      "[epoch 378, batch    32] loss: 3.25420\n",
      "[epoch 379, batch     1] loss: 2.60205\n",
      "[epoch 379, batch     2] loss: 2.80234\n",
      "[epoch 379, batch     3] loss: 2.82676\n",
      "[epoch 379, batch     4] loss: 3.54895\n",
      "[epoch 379, batch     5] loss: 2.68274\n",
      "[epoch 379, batch     6] loss: 3.28265\n",
      "[epoch 379, batch     7] loss: 2.63016\n",
      "[epoch 379, batch     8] loss: 3.13708\n",
      "[epoch 379, batch     9] loss: 2.95996\n",
      "[epoch 379, batch    10] loss: 2.77909\n",
      "[epoch 379, batch    11] loss: 3.84721\n",
      "[epoch 379, batch    12] loss: 2.92476\n",
      "[epoch 379, batch    13] loss: 2.98949\n",
      "[epoch 379, batch    14] loss: 3.02057\n",
      "[epoch 379, batch    15] loss: 3.32682\n",
      "[epoch 379, batch    16] loss: 2.49398\n",
      "[epoch 379, batch    17] loss: 2.77934\n",
      "[epoch 379, batch    18] loss: 2.74596\n",
      "[epoch 379, batch    19] loss: 2.80988\n",
      "[epoch 379, batch    20] loss: 2.92029\n",
      "[epoch 379, batch    21] loss: 3.22536\n",
      "[epoch 379, batch    22] loss: 3.40210\n",
      "[epoch 379, batch    23] loss: 3.08295\n",
      "[epoch 379, batch    24] loss: 3.20953\n",
      "[epoch 379, batch    25] loss: 3.24168\n",
      "[epoch 379, batch    26] loss: 3.90232\n",
      "[epoch 379, batch    27] loss: 3.11404\n",
      "[epoch 379, batch    28] loss: 2.84591\n",
      "[epoch 379, batch    29] loss: 2.64088\n",
      "[epoch 379, batch    30] loss: 3.43491\n",
      "[epoch 379, batch    31] loss: 2.71859\n",
      "[epoch 379, batch    32] loss: 3.27118\n",
      "[epoch 380, batch     1] loss: 3.70257\n",
      "[epoch 380, batch     2] loss: 2.47900\n",
      "[epoch 380, batch     3] loss: 3.62625\n",
      "[epoch 380, batch     4] loss: 2.82686\n",
      "[epoch 380, batch     5] loss: 2.53126\n",
      "[epoch 380, batch     6] loss: 3.25412\n",
      "[epoch 380, batch     7] loss: 3.84911\n",
      "[epoch 380, batch     8] loss: 3.11079\n",
      "[epoch 380, batch     9] loss: 2.14487\n",
      "[epoch 380, batch    10] loss: 3.82272\n",
      "[epoch 380, batch    11] loss: 2.68142\n",
      "[epoch 380, batch    12] loss: 3.40986\n",
      "[epoch 380, batch    13] loss: 3.80081\n",
      "[epoch 380, batch    14] loss: 3.28426\n",
      "[epoch 380, batch    15] loss: 3.16132\n",
      "[epoch 380, batch    16] loss: 2.71988\n",
      "[epoch 380, batch    17] loss: 3.50000\n",
      "[epoch 380, batch    18] loss: 2.14374\n",
      "[epoch 380, batch    19] loss: 2.97354\n",
      "[epoch 380, batch    20] loss: 3.54569\n",
      "[epoch 380, batch    21] loss: 3.29990\n",
      "[epoch 380, batch    22] loss: 2.50144\n",
      "[epoch 380, batch    23] loss: 2.29712\n",
      "[epoch 380, batch    24] loss: 2.30657\n",
      "[epoch 380, batch    25] loss: 2.19840\n",
      "[epoch 380, batch    26] loss: 2.82478\n",
      "[epoch 380, batch    27] loss: 4.24700\n",
      "[epoch 380, batch    28] loss: 2.96256\n",
      "[epoch 380, batch    29] loss: 2.87359\n",
      "[epoch 380, batch    30] loss: 2.34227\n",
      "[epoch 380, batch    31] loss: 3.58837\n",
      "[epoch 380, batch    32] loss: 2.73294\n",
      "[epoch 381, batch     1] loss: 2.08021\n",
      "[epoch 381, batch     2] loss: 2.60859\n",
      "[epoch 381, batch     3] loss: 3.65743\n",
      "[epoch 381, batch     4] loss: 3.83403\n",
      "[epoch 381, batch     5] loss: 2.03685\n",
      "[epoch 381, batch     6] loss: 3.42974\n",
      "[epoch 381, batch     7] loss: 2.79890\n",
      "[epoch 381, batch     8] loss: 3.16616\n",
      "[epoch 381, batch     9] loss: 3.19418\n",
      "[epoch 381, batch    10] loss: 3.67366\n",
      "[epoch 381, batch    11] loss: 2.89942\n",
      "[epoch 381, batch    12] loss: 2.60406\n",
      "[epoch 381, batch    13] loss: 2.88879\n",
      "[epoch 381, batch    14] loss: 2.86343\n",
      "[epoch 381, batch    15] loss: 3.67124\n",
      "[epoch 381, batch    16] loss: 1.88224\n",
      "[epoch 381, batch    17] loss: 3.26998\n",
      "[epoch 381, batch    18] loss: 4.21812\n",
      "[epoch 381, batch    19] loss: 3.07605\n",
      "[epoch 381, batch    20] loss: 2.73062\n",
      "[epoch 381, batch    21] loss: 2.99036\n",
      "[epoch 381, batch    22] loss: 3.28986\n",
      "[epoch 381, batch    23] loss: 2.60777\n",
      "[epoch 381, batch    24] loss: 3.13011\n",
      "[epoch 381, batch    25] loss: 2.58047\n",
      "[epoch 381, batch    26] loss: 3.13551\n",
      "[epoch 381, batch    27] loss: 3.79970\n",
      "[epoch 381, batch    28] loss: 2.98271\n",
      "[epoch 381, batch    29] loss: 2.52351\n",
      "[epoch 381, batch    30] loss: 2.98014\n",
      "[epoch 381, batch    31] loss: 3.67101\n",
      "[epoch 381, batch    32] loss: 2.45976\n",
      "[epoch 382, batch     1] loss: 3.45192\n",
      "[epoch 382, batch     2] loss: 2.91881\n",
      "[epoch 382, batch     3] loss: 2.58202\n",
      "[epoch 382, batch     4] loss: 3.13574\n",
      "[epoch 382, batch     5] loss: 3.38901\n",
      "[epoch 382, batch     6] loss: 3.41655\n",
      "[epoch 382, batch     7] loss: 3.80946\n",
      "[epoch 382, batch     8] loss: 2.70799\n",
      "[epoch 382, batch     9] loss: 3.48979\n",
      "[epoch 382, batch    10] loss: 3.69488\n",
      "[epoch 382, batch    11] loss: 2.96489\n",
      "[epoch 382, batch    12] loss: 3.63451\n",
      "[epoch 382, batch    13] loss: 2.43017\n",
      "[epoch 382, batch    14] loss: 2.43976\n",
      "[epoch 382, batch    15] loss: 3.00286\n",
      "[epoch 382, batch    16] loss: 2.96637\n",
      "[epoch 382, batch    17] loss: 3.02774\n",
      "[epoch 382, batch    18] loss: 3.36844\n",
      "[epoch 382, batch    19] loss: 2.31738\n",
      "[epoch 382, batch    20] loss: 2.64424\n",
      "[epoch 382, batch    21] loss: 2.57305\n",
      "[epoch 382, batch    22] loss: 2.65535\n",
      "[epoch 382, batch    23] loss: 3.10922\n",
      "[epoch 382, batch    24] loss: 2.72983\n",
      "[epoch 382, batch    25] loss: 2.81102\n",
      "[epoch 382, batch    26] loss: 2.18704\n",
      "[epoch 382, batch    27] loss: 3.41226\n",
      "[epoch 382, batch    28] loss: 3.40817\n",
      "[epoch 382, batch    29] loss: 3.19191\n",
      "[epoch 382, batch    30] loss: 3.20299\n",
      "[epoch 382, batch    31] loss: 3.12216\n",
      "[epoch 382, batch    32] loss: 3.58092\n",
      "[epoch 383, batch     1] loss: 2.72697\n",
      "[epoch 383, batch     2] loss: 2.53286\n",
      "[epoch 383, batch     3] loss: 2.83200\n",
      "[epoch 383, batch     4] loss: 3.32272\n",
      "[epoch 383, batch     5] loss: 3.12603\n",
      "[epoch 383, batch     6] loss: 4.21619\n",
      "[epoch 383, batch     7] loss: 2.58414\n",
      "[epoch 383, batch     8] loss: 3.11403\n",
      "[epoch 383, batch     9] loss: 2.98447\n",
      "[epoch 383, batch    10] loss: 3.07281\n",
      "[epoch 383, batch    11] loss: 3.31419\n",
      "[epoch 383, batch    12] loss: 2.77689\n",
      "[epoch 383, batch    13] loss: 4.03311\n",
      "[epoch 383, batch    14] loss: 2.57063\n",
      "[epoch 383, batch    15] loss: 3.34393\n",
      "[epoch 383, batch    16] loss: 2.58128\n",
      "[epoch 383, batch    17] loss: 2.36102\n",
      "[epoch 383, batch    18] loss: 2.66150\n",
      "[epoch 383, batch    19] loss: 2.65888\n",
      "[epoch 383, batch    20] loss: 2.95840\n",
      "[epoch 383, batch    21] loss: 2.91013\n",
      "[epoch 383, batch    22] loss: 3.36712\n",
      "[epoch 383, batch    23] loss: 3.14231\n",
      "[epoch 383, batch    24] loss: 3.49917\n",
      "[epoch 383, batch    25] loss: 3.19307\n",
      "[epoch 383, batch    26] loss: 2.99295\n",
      "[epoch 383, batch    27] loss: 2.71690\n",
      "[epoch 383, batch    28] loss: 3.45192\n",
      "[epoch 383, batch    29] loss: 2.85212\n",
      "[epoch 383, batch    30] loss: 2.43570\n",
      "[epoch 383, batch    31] loss: 3.29591\n",
      "[epoch 383, batch    32] loss: 2.94806\n",
      "[epoch 384, batch     1] loss: 3.26478\n",
      "[epoch 384, batch     2] loss: 3.03171\n",
      "[epoch 384, batch     3] loss: 3.37883\n",
      "[epoch 384, batch     4] loss: 3.43619\n",
      "[epoch 384, batch     5] loss: 2.94935\n",
      "[epoch 384, batch     6] loss: 3.47322\n",
      "[epoch 384, batch     7] loss: 3.17170\n",
      "[epoch 384, batch     8] loss: 2.44723\n",
      "[epoch 384, batch     9] loss: 2.99230\n",
      "[epoch 384, batch    10] loss: 2.97120\n",
      "[epoch 384, batch    11] loss: 3.20211\n",
      "[epoch 384, batch    12] loss: 3.52613\n",
      "[epoch 384, batch    13] loss: 2.21786\n",
      "[epoch 384, batch    14] loss: 2.76859\n",
      "[epoch 384, batch    15] loss: 3.19815\n",
      "[epoch 384, batch    16] loss: 2.66250\n",
      "[epoch 384, batch    17] loss: 2.50158\n",
      "[epoch 384, batch    18] loss: 2.08783\n",
      "[epoch 384, batch    19] loss: 3.19211\n",
      "[epoch 384, batch    20] loss: 3.00381\n",
      "[epoch 384, batch    21] loss: 3.71362\n",
      "[epoch 384, batch    22] loss: 3.14600\n",
      "[epoch 384, batch    23] loss: 3.76469\n",
      "[epoch 384, batch    24] loss: 2.84021\n",
      "[epoch 384, batch    25] loss: 3.25703\n",
      "[epoch 384, batch    26] loss: 3.54633\n",
      "[epoch 384, batch    27] loss: 3.43194\n",
      "[epoch 384, batch    28] loss: 3.55240\n",
      "[epoch 384, batch    29] loss: 3.07957\n",
      "[epoch 384, batch    30] loss: 2.57943\n",
      "[epoch 384, batch    31] loss: 2.00100\n",
      "[epoch 384, batch    32] loss: 3.38520\n",
      "[epoch 385, batch     1] loss: 3.01238\n",
      "[epoch 385, batch     2] loss: 3.03131\n",
      "[epoch 385, batch     3] loss: 2.84298\n",
      "[epoch 385, batch     4] loss: 3.61444\n",
      "[epoch 385, batch     5] loss: 2.95352\n",
      "[epoch 385, batch     6] loss: 2.61818\n",
      "[epoch 385, batch     7] loss: 2.60456\n",
      "[epoch 385, batch     8] loss: 2.88377\n",
      "[epoch 385, batch     9] loss: 2.39549\n",
      "[epoch 385, batch    10] loss: 3.14754\n",
      "[epoch 385, batch    11] loss: 3.42703\n",
      "[epoch 385, batch    12] loss: 2.38525\n",
      "[epoch 385, batch    13] loss: 2.76289\n",
      "[epoch 385, batch    14] loss: 3.88748\n",
      "[epoch 385, batch    15] loss: 3.69355\n",
      "[epoch 385, batch    16] loss: 3.52952\n",
      "[epoch 385, batch    17] loss: 3.18973\n",
      "[epoch 385, batch    18] loss: 3.65382\n",
      "[epoch 385, batch    19] loss: 3.07028\n",
      "[epoch 385, batch    20] loss: 3.32023\n",
      "[epoch 385, batch    21] loss: 3.15674\n",
      "[epoch 385, batch    22] loss: 3.30126\n",
      "[epoch 385, batch    23] loss: 2.75220\n",
      "[epoch 385, batch    24] loss: 3.01109\n",
      "[epoch 385, batch    25] loss: 2.95229\n",
      "[epoch 385, batch    26] loss: 3.01828\n",
      "[epoch 385, batch    27] loss: 2.84389\n",
      "[epoch 385, batch    28] loss: 3.13953\n",
      "[epoch 385, batch    29] loss: 2.92513\n",
      "[epoch 385, batch    30] loss: 2.75109\n",
      "[epoch 385, batch    31] loss: 2.45396\n",
      "[epoch 385, batch    32] loss: 2.70193\n",
      "[epoch 386, batch     1] loss: 3.96831\n",
      "[epoch 386, batch     2] loss: 2.95055\n",
      "[epoch 386, batch     3] loss: 2.94048\n",
      "[epoch 386, batch     4] loss: 2.67890\n",
      "[epoch 386, batch     5] loss: 2.13457\n",
      "[epoch 386, batch     6] loss: 3.31943\n",
      "[epoch 386, batch     7] loss: 3.28735\n",
      "[epoch 386, batch     8] loss: 1.97234\n",
      "[epoch 386, batch     9] loss: 2.71288\n",
      "[epoch 386, batch    10] loss: 2.73781\n",
      "[epoch 386, batch    11] loss: 2.58248\n",
      "[epoch 386, batch    12] loss: 2.71143\n",
      "[epoch 386, batch    13] loss: 2.94900\n",
      "[epoch 386, batch    14] loss: 2.85001\n",
      "[epoch 386, batch    15] loss: 2.26221\n",
      "[epoch 386, batch    16] loss: 3.21962\n",
      "[epoch 386, batch    17] loss: 3.05994\n",
      "[epoch 386, batch    18] loss: 2.51561\n",
      "[epoch 386, batch    19] loss: 3.22114\n",
      "[epoch 386, batch    20] loss: 3.11667\n",
      "[epoch 386, batch    21] loss: 2.90365\n",
      "[epoch 386, batch    22] loss: 2.81168\n",
      "[epoch 386, batch    23] loss: 3.38247\n",
      "[epoch 386, batch    24] loss: 4.00425\n",
      "[epoch 386, batch    25] loss: 2.46051\n",
      "[epoch 386, batch    26] loss: 3.73500\n",
      "[epoch 386, batch    27] loss: 3.81288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 386, batch    28] loss: 2.07908\n",
      "[epoch 386, batch    29] loss: 3.61155\n",
      "[epoch 386, batch    30] loss: 3.39666\n",
      "[epoch 386, batch    31] loss: 4.09335\n",
      "[epoch 386, batch    32] loss: 3.74354\n",
      "[epoch 387, batch     1] loss: 2.93307\n",
      "[epoch 387, batch     2] loss: 3.41795\n",
      "[epoch 387, batch     3] loss: 3.30121\n",
      "[epoch 387, batch     4] loss: 2.27154\n",
      "[epoch 387, batch     5] loss: 2.65786\n",
      "[epoch 387, batch     6] loss: 2.58287\n",
      "[epoch 387, batch     7] loss: 2.87438\n",
      "[epoch 387, batch     8] loss: 3.04963\n",
      "[epoch 387, batch     9] loss: 4.08989\n",
      "[epoch 387, batch    10] loss: 3.44810\n",
      "[epoch 387, batch    11] loss: 3.47090\n",
      "[epoch 387, batch    12] loss: 3.13331\n",
      "[epoch 387, batch    13] loss: 3.36449\n",
      "[epoch 387, batch    14] loss: 3.41979\n",
      "[epoch 387, batch    15] loss: 2.88967\n",
      "[epoch 387, batch    16] loss: 2.54057\n",
      "[epoch 387, batch    17] loss: 2.63510\n",
      "[epoch 387, batch    18] loss: 3.07658\n",
      "[epoch 387, batch    19] loss: 2.95538\n",
      "[epoch 387, batch    20] loss: 3.10671\n",
      "[epoch 387, batch    21] loss: 3.33232\n",
      "[epoch 387, batch    22] loss: 3.18179\n",
      "[epoch 387, batch    23] loss: 2.88664\n",
      "[epoch 387, batch    24] loss: 2.24984\n",
      "[epoch 387, batch    25] loss: 2.79658\n",
      "[epoch 387, batch    26] loss: 3.12150\n",
      "[epoch 387, batch    27] loss: 3.56678\n",
      "[epoch 387, batch    28] loss: 2.44448\n",
      "[epoch 387, batch    29] loss: 3.23052\n",
      "[epoch 387, batch    30] loss: 2.73231\n",
      "[epoch 387, batch    31] loss: 3.73011\n",
      "[epoch 387, batch    32] loss: 1.98900\n",
      "[epoch 388, batch     1] loss: 2.62892\n",
      "[epoch 388, batch     2] loss: 3.49597\n",
      "[epoch 388, batch     3] loss: 2.82325\n",
      "[epoch 388, batch     4] loss: 3.25050\n",
      "[epoch 388, batch     5] loss: 3.70137\n",
      "[epoch 388, batch     6] loss: 2.78008\n",
      "[epoch 388, batch     7] loss: 2.54735\n",
      "[epoch 388, batch     8] loss: 3.05027\n",
      "[epoch 388, batch     9] loss: 2.34447\n",
      "[epoch 388, batch    10] loss: 3.62314\n",
      "[epoch 388, batch    11] loss: 2.29864\n",
      "[epoch 388, batch    12] loss: 2.98551\n",
      "[epoch 388, batch    13] loss: 2.93532\n",
      "[epoch 388, batch    14] loss: 2.53931\n",
      "[epoch 388, batch    15] loss: 3.17887\n",
      "[epoch 388, batch    16] loss: 2.62374\n",
      "[epoch 388, batch    17] loss: 2.62750\n",
      "[epoch 388, batch    18] loss: 3.41432\n",
      "[epoch 388, batch    19] loss: 3.87500\n",
      "[epoch 388, batch    20] loss: 4.33889\n",
      "[epoch 388, batch    21] loss: 2.94096\n",
      "[epoch 388, batch    22] loss: 2.91337\n",
      "[epoch 388, batch    23] loss: 3.38193\n",
      "[epoch 388, batch    24] loss: 2.77510\n",
      "[epoch 388, batch    25] loss: 2.49922\n",
      "[epoch 388, batch    26] loss: 3.65254\n",
      "[epoch 388, batch    27] loss: 3.84383\n",
      "[epoch 388, batch    28] loss: 2.86283\n",
      "[epoch 388, batch    29] loss: 2.90221\n",
      "[epoch 388, batch    30] loss: 2.26630\n",
      "[epoch 388, batch    31] loss: 2.97421\n",
      "[epoch 388, batch    32] loss: 3.33290\n",
      "[epoch 389, batch     1] loss: 3.25862\n",
      "[epoch 389, batch     2] loss: 2.98797\n",
      "[epoch 389, batch     3] loss: 3.20623\n",
      "[epoch 389, batch     4] loss: 2.28707\n",
      "[epoch 389, batch     5] loss: 3.43989\n",
      "[epoch 389, batch     6] loss: 3.55243\n",
      "[epoch 389, batch     7] loss: 2.44557\n",
      "[epoch 389, batch     8] loss: 3.40688\n",
      "[epoch 389, batch     9] loss: 2.71844\n",
      "[epoch 389, batch    10] loss: 3.16844\n",
      "[epoch 389, batch    11] loss: 3.04250\n",
      "[epoch 389, batch    12] loss: 2.43596\n",
      "[epoch 389, batch    13] loss: 2.87340\n",
      "[epoch 389, batch    14] loss: 3.41414\n",
      "[epoch 389, batch    15] loss: 2.55850\n",
      "[epoch 389, batch    16] loss: 2.48463\n",
      "[epoch 389, batch    17] loss: 3.42759\n",
      "[epoch 389, batch    18] loss: 2.75368\n",
      "[epoch 389, batch    19] loss: 3.29720\n",
      "[epoch 389, batch    20] loss: 2.73031\n",
      "[epoch 389, batch    21] loss: 3.27922\n",
      "[epoch 389, batch    22] loss: 2.99000\n",
      "[epoch 389, batch    23] loss: 3.18317\n",
      "[epoch 389, batch    24] loss: 3.12860\n",
      "[epoch 389, batch    25] loss: 2.53553\n",
      "[epoch 389, batch    26] loss: 2.98300\n",
      "[epoch 389, batch    27] loss: 2.89946\n",
      "[epoch 389, batch    28] loss: 3.03298\n",
      "[epoch 389, batch    29] loss: 3.24238\n",
      "[epoch 389, batch    30] loss: 3.81329\n",
      "[epoch 389, batch    31] loss: 3.39344\n",
      "[epoch 389, batch    32] loss: 4.77759\n",
      "[epoch 390, batch     1] loss: 3.94676\n",
      "[epoch 390, batch     2] loss: 2.99769\n",
      "[epoch 390, batch     3] loss: 3.27712\n",
      "[epoch 390, batch     4] loss: 3.45128\n",
      "[epoch 390, batch     5] loss: 3.08644\n",
      "[epoch 390, batch     6] loss: 2.94129\n",
      "[epoch 390, batch     7] loss: 3.17831\n",
      "[epoch 390, batch     8] loss: 2.74510\n",
      "[epoch 390, batch     9] loss: 3.23396\n",
      "[epoch 390, batch    10] loss: 3.04714\n",
      "[epoch 390, batch    11] loss: 2.84630\n",
      "[epoch 390, batch    12] loss: 2.77089\n",
      "[epoch 390, batch    13] loss: 3.02224\n",
      "[epoch 390, batch    14] loss: 2.89142\n",
      "[epoch 390, batch    15] loss: 3.16480\n",
      "[epoch 390, batch    16] loss: 2.81454\n",
      "[epoch 390, batch    17] loss: 2.73371\n",
      "[epoch 390, batch    18] loss: 3.08642\n",
      "[epoch 390, batch    19] loss: 2.88866\n",
      "[epoch 390, batch    20] loss: 3.19868\n",
      "[epoch 390, batch    21] loss: 3.40390\n",
      "[epoch 390, batch    22] loss: 3.31287\n",
      "[epoch 390, batch    23] loss: 3.28806\n",
      "[epoch 390, batch    24] loss: 2.59084\n",
      "[epoch 390, batch    25] loss: 2.65376\n",
      "[epoch 390, batch    26] loss: 2.83115\n",
      "[epoch 390, batch    27] loss: 2.47571\n",
      "[epoch 390, batch    28] loss: 2.88824\n",
      "[epoch 390, batch    29] loss: 3.09931\n",
      "[epoch 390, batch    30] loss: 3.38016\n",
      "[epoch 390, batch    31] loss: 2.88457\n",
      "[epoch 390, batch    32] loss: 2.75165\n",
      "[epoch 391, batch     1] loss: 3.94016\n",
      "[epoch 391, batch     2] loss: 2.92414\n",
      "[epoch 391, batch     3] loss: 2.28742\n",
      "[epoch 391, batch     4] loss: 3.87203\n",
      "[epoch 391, batch     5] loss: 3.25031\n",
      "[epoch 391, batch     6] loss: 2.86931\n",
      "[epoch 391, batch     7] loss: 2.46342\n",
      "[epoch 391, batch     8] loss: 3.17613\n",
      "[epoch 391, batch     9] loss: 3.08506\n",
      "[epoch 391, batch    10] loss: 2.37728\n",
      "[epoch 391, batch    11] loss: 3.12446\n",
      "[epoch 391, batch    12] loss: 3.24150\n",
      "[epoch 391, batch    13] loss: 3.06161\n",
      "[epoch 391, batch    14] loss: 2.60650\n",
      "[epoch 391, batch    15] loss: 3.03021\n",
      "[epoch 391, batch    16] loss: 2.20049\n",
      "[epoch 391, batch    17] loss: 3.87654\n",
      "[epoch 391, batch    18] loss: 3.33146\n",
      "[epoch 391, batch    19] loss: 2.69218\n",
      "[epoch 391, batch    20] loss: 4.00378\n",
      "[epoch 391, batch    21] loss: 2.55252\n",
      "[epoch 391, batch    22] loss: 2.66770\n",
      "[epoch 391, batch    23] loss: 2.83068\n",
      "[epoch 391, batch    24] loss: 2.87393\n",
      "[epoch 391, batch    25] loss: 3.31657\n",
      "[epoch 391, batch    26] loss: 2.25328\n",
      "[epoch 391, batch    27] loss: 3.02025\n",
      "[epoch 391, batch    28] loss: 3.77283\n",
      "[epoch 391, batch    29] loss: 2.67598\n",
      "[epoch 391, batch    30] loss: 3.18434\n",
      "[epoch 391, batch    31] loss: 3.36637\n",
      "[epoch 391, batch    32] loss: 3.94489\n",
      "[epoch 392, batch     1] loss: 2.96220\n",
      "[epoch 392, batch     2] loss: 3.01909\n",
      "[epoch 392, batch     3] loss: 4.00100\n",
      "[epoch 392, batch     4] loss: 4.18270\n",
      "[epoch 392, batch     5] loss: 3.17545\n",
      "[epoch 392, batch     6] loss: 2.33335\n",
      "[epoch 392, batch     7] loss: 3.82489\n",
      "[epoch 392, batch     8] loss: 2.69092\n",
      "[epoch 392, batch     9] loss: 2.36941\n",
      "[epoch 392, batch    10] loss: 2.71791\n",
      "[epoch 392, batch    11] loss: 3.36402\n",
      "[epoch 392, batch    12] loss: 4.01388\n",
      "[epoch 392, batch    13] loss: 2.46865\n",
      "[epoch 392, batch    14] loss: 3.77768\n",
      "[epoch 392, batch    15] loss: 2.33914\n",
      "[epoch 392, batch    16] loss: 2.48211\n",
      "[epoch 392, batch    17] loss: 3.15657\n",
      "[epoch 392, batch    18] loss: 3.03432\n",
      "[epoch 392, batch    19] loss: 2.88280\n",
      "[epoch 392, batch    20] loss: 2.21328\n",
      "[epoch 392, batch    21] loss: 4.07396\n",
      "[epoch 392, batch    22] loss: 2.38129\n",
      "[epoch 392, batch    23] loss: 2.30705\n",
      "[epoch 392, batch    24] loss: 2.10758\n",
      "[epoch 392, batch    25] loss: 3.34203\n",
      "[epoch 392, batch    26] loss: 3.23203\n",
      "[epoch 392, batch    27] loss: 3.14566\n",
      "[epoch 392, batch    28] loss: 2.86023\n",
      "[epoch 392, batch    29] loss: 2.76395\n",
      "[epoch 392, batch    30] loss: 3.40022\n",
      "[epoch 392, batch    31] loss: 3.56271\n",
      "[epoch 392, batch    32] loss: 2.88783\n",
      "[epoch 393, batch     1] loss: 3.63924\n",
      "[epoch 393, batch     2] loss: 2.35191\n",
      "[epoch 393, batch     3] loss: 2.93759\n",
      "[epoch 393, batch     4] loss: 3.29073\n",
      "[epoch 393, batch     5] loss: 3.07339\n",
      "[epoch 393, batch     6] loss: 2.43171\n",
      "[epoch 393, batch     7] loss: 3.66582\n",
      "[epoch 393, batch     8] loss: 2.67043\n",
      "[epoch 393, batch     9] loss: 2.77028\n",
      "[epoch 393, batch    10] loss: 2.71877\n",
      "[epoch 393, batch    11] loss: 2.99301\n",
      "[epoch 393, batch    12] loss: 3.03166\n",
      "[epoch 393, batch    13] loss: 3.28452\n",
      "[epoch 393, batch    14] loss: 2.93447\n",
      "[epoch 393, batch    15] loss: 3.36817\n",
      "[epoch 393, batch    16] loss: 3.26811\n",
      "[epoch 393, batch    17] loss: 2.64320\n",
      "[epoch 393, batch    18] loss: 2.67784\n",
      "[epoch 393, batch    19] loss: 2.39104\n",
      "[epoch 393, batch    20] loss: 2.48309\n",
      "[epoch 393, batch    21] loss: 2.54263\n",
      "[epoch 393, batch    22] loss: 3.91061\n",
      "[epoch 393, batch    23] loss: 2.93206\n",
      "[epoch 393, batch    24] loss: 2.95853\n",
      "[epoch 393, batch    25] loss: 3.40279\n",
      "[epoch 393, batch    26] loss: 2.87605\n",
      "[epoch 393, batch    27] loss: 2.57658\n",
      "[epoch 393, batch    28] loss: 3.05974\n",
      "[epoch 393, batch    29] loss: 4.30788\n",
      "[epoch 393, batch    30] loss: 3.47445\n",
      "[epoch 393, batch    31] loss: 3.34281\n",
      "[epoch 393, batch    32] loss: 3.02637\n",
      "[epoch 394, batch     1] loss: 2.12318\n",
      "[epoch 394, batch     2] loss: 3.14547\n",
      "[epoch 394, batch     3] loss: 2.60903\n",
      "[epoch 394, batch     4] loss: 2.99428\n",
      "[epoch 394, batch     5] loss: 3.14044\n",
      "[epoch 394, batch     6] loss: 3.67109\n",
      "[epoch 394, batch     7] loss: 2.88488\n",
      "[epoch 394, batch     8] loss: 2.88003\n",
      "[epoch 394, batch     9] loss: 3.25812\n",
      "[epoch 394, batch    10] loss: 3.09503\n",
      "[epoch 394, batch    11] loss: 2.67843\n",
      "[epoch 394, batch    12] loss: 3.52296\n",
      "[epoch 394, batch    13] loss: 2.34423\n",
      "[epoch 394, batch    14] loss: 3.42667\n",
      "[epoch 394, batch    15] loss: 2.84983\n",
      "[epoch 394, batch    16] loss: 2.34239\n",
      "[epoch 394, batch    17] loss: 2.88333\n",
      "[epoch 394, batch    18] loss: 3.51075\n",
      "[epoch 394, batch    19] loss: 3.48753\n",
      "[epoch 394, batch    20] loss: 3.10238\n",
      "[epoch 394, batch    21] loss: 3.34641\n",
      "[epoch 394, batch    22] loss: 3.31887\n",
      "[epoch 394, batch    23] loss: 2.98191\n",
      "[epoch 394, batch    24] loss: 3.13952\n",
      "[epoch 394, batch    25] loss: 2.38693\n",
      "[epoch 394, batch    26] loss: 2.23636\n",
      "[epoch 394, batch    27] loss: 2.92130\n",
      "[epoch 394, batch    28] loss: 2.82459\n",
      "[epoch 394, batch    29] loss: 3.59875\n",
      "[epoch 394, batch    30] loss: 3.67493\n",
      "[epoch 394, batch    31] loss: 3.16156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 394, batch    32] loss: 5.24499\n",
      "[epoch 395, batch     1] loss: 2.78577\n",
      "[epoch 395, batch     2] loss: 3.80697\n",
      "[epoch 395, batch     3] loss: 2.75318\n",
      "[epoch 395, batch     4] loss: 3.47679\n",
      "[epoch 395, batch     5] loss: 2.34950\n",
      "[epoch 395, batch     6] loss: 2.46039\n",
      "[epoch 395, batch     7] loss: 2.08363\n",
      "[epoch 395, batch     8] loss: 2.43549\n",
      "[epoch 395, batch     9] loss: 3.38715\n",
      "[epoch 395, batch    10] loss: 3.79534\n",
      "[epoch 395, batch    11] loss: 2.82587\n",
      "[epoch 395, batch    12] loss: 2.37541\n",
      "[epoch 395, batch    13] loss: 3.37009\n",
      "[epoch 395, batch    14] loss: 2.59728\n",
      "[epoch 395, batch    15] loss: 2.78354\n",
      "[epoch 395, batch    16] loss: 3.19902\n",
      "[epoch 395, batch    17] loss: 1.91936\n",
      "[epoch 395, batch    18] loss: 2.51421\n",
      "[epoch 395, batch    19] loss: 2.32363\n",
      "[epoch 395, batch    20] loss: 4.14647\n",
      "[epoch 395, batch    21] loss: 3.96097\n",
      "[epoch 395, batch    22] loss: 2.47456\n",
      "[epoch 395, batch    23] loss: 3.50382\n",
      "[epoch 395, batch    24] loss: 3.59198\n",
      "[epoch 395, batch    25] loss: 3.70689\n",
      "[epoch 395, batch    26] loss: 3.11588\n",
      "[epoch 395, batch    27] loss: 3.26891\n",
      "[epoch 395, batch    28] loss: 3.44142\n",
      "[epoch 395, batch    29] loss: 2.76214\n",
      "[epoch 395, batch    30] loss: 3.04238\n",
      "[epoch 395, batch    31] loss: 4.08381\n",
      "[epoch 395, batch    32] loss: 3.53669\n",
      "[epoch 396, batch     1] loss: 3.88470\n",
      "[epoch 396, batch     2] loss: 2.18382\n",
      "[epoch 396, batch     3] loss: 3.55814\n",
      "[epoch 396, batch     4] loss: 2.85848\n",
      "[epoch 396, batch     5] loss: 2.34838\n",
      "[epoch 396, batch     6] loss: 2.34220\n",
      "[epoch 396, batch     7] loss: 2.81779\n",
      "[epoch 396, batch     8] loss: 2.96767\n",
      "[epoch 396, batch     9] loss: 3.30640\n",
      "[epoch 396, batch    10] loss: 3.05177\n",
      "[epoch 396, batch    11] loss: 3.09507\n",
      "[epoch 396, batch    12] loss: 2.81469\n",
      "[epoch 396, batch    13] loss: 3.20409\n",
      "[epoch 396, batch    14] loss: 3.27369\n",
      "[epoch 396, batch    15] loss: 3.04310\n",
      "[epoch 396, batch    16] loss: 2.97245\n",
      "[epoch 396, batch    17] loss: 4.00444\n",
      "[epoch 396, batch    18] loss: 2.92194\n",
      "[epoch 396, batch    19] loss: 3.28792\n",
      "[epoch 396, batch    20] loss: 3.40818\n",
      "[epoch 396, batch    21] loss: 3.94617\n",
      "[epoch 396, batch    22] loss: 3.42998\n",
      "[epoch 396, batch    23] loss: 3.17346\n",
      "[epoch 396, batch    24] loss: 3.64567\n",
      "[epoch 396, batch    25] loss: 1.85977\n",
      "[epoch 396, batch    26] loss: 2.89425\n",
      "[epoch 396, batch    27] loss: 2.72487\n",
      "[epoch 396, batch    28] loss: 3.45174\n",
      "[epoch 396, batch    29] loss: 1.96380\n",
      "[epoch 396, batch    30] loss: 3.21624\n",
      "[epoch 396, batch    31] loss: 2.41613\n",
      "[epoch 396, batch    32] loss: 2.88302\n",
      "[epoch 397, batch     1] loss: 3.00712\n",
      "[epoch 397, batch     2] loss: 4.10793\n",
      "[epoch 397, batch     3] loss: 2.75433\n",
      "[epoch 397, batch     4] loss: 2.98165\n",
      "[epoch 397, batch     5] loss: 2.29690\n",
      "[epoch 397, batch     6] loss: 2.52201\n",
      "[epoch 397, batch     7] loss: 2.48343\n",
      "[epoch 397, batch     8] loss: 2.10047\n",
      "[epoch 397, batch     9] loss: 3.71171\n",
      "[epoch 397, batch    10] loss: 3.47161\n",
      "[epoch 397, batch    11] loss: 3.31202\n",
      "[epoch 397, batch    12] loss: 2.54075\n",
      "[epoch 397, batch    13] loss: 2.48716\n",
      "[epoch 397, batch    14] loss: 3.23706\n",
      "[epoch 397, batch    15] loss: 3.26514\n",
      "[epoch 397, batch    16] loss: 3.17085\n",
      "[epoch 397, batch    17] loss: 2.62648\n",
      "[epoch 397, batch    18] loss: 3.06385\n",
      "[epoch 397, batch    19] loss: 3.60923\n",
      "[epoch 397, batch    20] loss: 2.67413\n",
      "[epoch 397, batch    21] loss: 2.68277\n",
      "[epoch 397, batch    22] loss: 3.45706\n",
      "[epoch 397, batch    23] loss: 2.27414\n",
      "[epoch 397, batch    24] loss: 3.58465\n",
      "[epoch 397, batch    25] loss: 3.03792\n",
      "[epoch 397, batch    26] loss: 3.97637\n",
      "[epoch 397, batch    27] loss: 3.63633\n",
      "[epoch 397, batch    28] loss: 2.71532\n",
      "[epoch 397, batch    29] loss: 3.04792\n",
      "[epoch 397, batch    30] loss: 2.99779\n",
      "[epoch 397, batch    31] loss: 3.08358\n",
      "[epoch 397, batch    32] loss: 4.20299\n",
      "[epoch 398, batch     1] loss: 2.63149\n",
      "[epoch 398, batch     2] loss: 2.26308\n",
      "[epoch 398, batch     3] loss: 2.71767\n",
      "[epoch 398, batch     4] loss: 3.08446\n",
      "[epoch 398, batch     5] loss: 3.22479\n",
      "[epoch 398, batch     6] loss: 2.80289\n",
      "[epoch 398, batch     7] loss: 2.95854\n",
      "[epoch 398, batch     8] loss: 3.22752\n",
      "[epoch 398, batch     9] loss: 3.04841\n",
      "[epoch 398, batch    10] loss: 3.03224\n",
      "[epoch 398, batch    11] loss: 3.60995\n",
      "[epoch 398, batch    12] loss: 3.51768\n",
      "[epoch 398, batch    13] loss: 3.26824\n",
      "[epoch 398, batch    14] loss: 3.02813\n",
      "[epoch 398, batch    15] loss: 3.31137\n",
      "[epoch 398, batch    16] loss: 3.11326\n",
      "[epoch 398, batch    17] loss: 2.45824\n",
      "[epoch 398, batch    18] loss: 3.91048\n",
      "[epoch 398, batch    19] loss: 2.59048\n",
      "[epoch 398, batch    20] loss: 3.34773\n",
      "[epoch 398, batch    21] loss: 2.94535\n",
      "[epoch 398, batch    22] loss: 3.12032\n",
      "[epoch 398, batch    23] loss: 2.16854\n",
      "[epoch 398, batch    24] loss: 3.04896\n",
      "[epoch 398, batch    25] loss: 2.95558\n",
      "[epoch 398, batch    26] loss: 3.04146\n",
      "[epoch 398, batch    27] loss: 3.07267\n",
      "[epoch 398, batch    28] loss: 3.53262\n",
      "[epoch 398, batch    29] loss: 2.65884\n",
      "[epoch 398, batch    30] loss: 2.65437\n",
      "[epoch 398, batch    31] loss: 3.54468\n",
      "[epoch 398, batch    32] loss: 2.41110\n",
      "[epoch 399, batch     1] loss: 3.03423\n",
      "[epoch 399, batch     2] loss: 2.92361\n",
      "[epoch 399, batch     3] loss: 3.18838\n",
      "[epoch 399, batch     4] loss: 2.55974\n",
      "[epoch 399, batch     5] loss: 3.07249\n",
      "[epoch 399, batch     6] loss: 2.84131\n",
      "[epoch 399, batch     7] loss: 2.61622\n",
      "[epoch 399, batch     8] loss: 2.57953\n",
      "[epoch 399, batch     9] loss: 2.69174\n",
      "[epoch 399, batch    10] loss: 3.14558\n",
      "[epoch 399, batch    11] loss: 2.76375\n",
      "[epoch 399, batch    12] loss: 2.76659\n",
      "[epoch 399, batch    13] loss: 2.95172\n",
      "[epoch 399, batch    14] loss: 3.03355\n",
      "[epoch 399, batch    15] loss: 3.35942\n",
      "[epoch 399, batch    16] loss: 3.59681\n",
      "[epoch 399, batch    17] loss: 3.86178\n",
      "[epoch 399, batch    18] loss: 2.66141\n",
      "[epoch 399, batch    19] loss: 3.09708\n",
      "[epoch 399, batch    20] loss: 2.71774\n",
      "[epoch 399, batch    21] loss: 2.35489\n",
      "[epoch 399, batch    22] loss: 2.86086\n",
      "[epoch 399, batch    23] loss: 2.84377\n",
      "[epoch 399, batch    24] loss: 3.62955\n",
      "[epoch 399, batch    25] loss: 2.75936\n",
      "[epoch 399, batch    26] loss: 3.38248\n",
      "[epoch 399, batch    27] loss: 3.10658\n",
      "[epoch 399, batch    28] loss: 3.07004\n",
      "[epoch 399, batch    29] loss: 4.15750\n",
      "[epoch 399, batch    30] loss: 3.12236\n",
      "[epoch 399, batch    31] loss: 3.90531\n",
      "[epoch 399, batch    32] loss: 2.16643\n",
      "[epoch 400, batch     1] loss: 3.58708\n",
      "[epoch 400, batch     2] loss: 2.53804\n",
      "[epoch 400, batch     3] loss: 2.48152\n",
      "[epoch 400, batch     4] loss: 2.77292\n",
      "[epoch 400, batch     5] loss: 3.18665\n",
      "[epoch 400, batch     6] loss: 2.98289\n",
      "[epoch 400, batch     7] loss: 3.34009\n",
      "[epoch 400, batch     8] loss: 2.78553\n",
      "[epoch 400, batch     9] loss: 2.76968\n",
      "[epoch 400, batch    10] loss: 2.87644\n",
      "[epoch 400, batch    11] loss: 2.59471\n",
      "[epoch 400, batch    12] loss: 2.58393\n",
      "[epoch 400, batch    13] loss: 3.02632\n",
      "[epoch 400, batch    14] loss: 3.18872\n",
      "[epoch 400, batch    15] loss: 3.31646\n",
      "[epoch 400, batch    16] loss: 2.89183\n",
      "[epoch 400, batch    17] loss: 2.84128\n",
      "[epoch 400, batch    18] loss: 3.37656\n",
      "[epoch 400, batch    19] loss: 2.89122\n",
      "[epoch 400, batch    20] loss: 3.27619\n",
      "[epoch 400, batch    21] loss: 3.18383\n",
      "[epoch 400, batch    22] loss: 2.44764\n",
      "[epoch 400, batch    23] loss: 3.22647\n",
      "[epoch 400, batch    24] loss: 3.11770\n",
      "[epoch 400, batch    25] loss: 2.83792\n",
      "[epoch 400, batch    26] loss: 3.11616\n",
      "[epoch 400, batch    27] loss: 3.37798\n",
      "[epoch 400, batch    28] loss: 3.53087\n",
      "[epoch 400, batch    29] loss: 3.30454\n",
      "[epoch 400, batch    30] loss: 2.67714\n",
      "[epoch 400, batch    31] loss: 4.05676\n",
      "[epoch 400, batch    32] loss: 3.18844\n",
      "[epoch 401, batch     1] loss: 3.25516\n",
      "[epoch 401, batch     2] loss: 2.96620\n",
      "[epoch 401, batch     3] loss: 2.42204\n",
      "[epoch 401, batch     4] loss: 2.28360\n",
      "[epoch 401, batch     5] loss: 3.09676\n",
      "[epoch 401, batch     6] loss: 2.49527\n",
      "[epoch 401, batch     7] loss: 3.32516\n",
      "[epoch 401, batch     8] loss: 3.06606\n",
      "[epoch 401, batch     9] loss: 3.35472\n",
      "[epoch 401, batch    10] loss: 3.21815\n",
      "[epoch 401, batch    11] loss: 3.87054\n",
      "[epoch 401, batch    12] loss: 3.08162\n",
      "[epoch 401, batch    13] loss: 3.29493\n",
      "[epoch 401, batch    14] loss: 3.88833\n",
      "[epoch 401, batch    15] loss: 2.64169\n",
      "[epoch 401, batch    16] loss: 2.77737\n",
      "[epoch 401, batch    17] loss: 2.28327\n",
      "[epoch 401, batch    18] loss: 2.81723\n",
      "[epoch 401, batch    19] loss: 3.27569\n",
      "[epoch 401, batch    20] loss: 3.59677\n",
      "[epoch 401, batch    21] loss: 3.69980\n",
      "[epoch 401, batch    22] loss: 2.40260\n",
      "[epoch 401, batch    23] loss: 2.86747\n",
      "[epoch 401, batch    24] loss: 2.55649\n",
      "[epoch 401, batch    25] loss: 2.43540\n",
      "[epoch 401, batch    26] loss: 2.85595\n",
      "[epoch 401, batch    27] loss: 3.63047\n",
      "[epoch 401, batch    28] loss: 3.63761\n",
      "[epoch 401, batch    29] loss: 3.17386\n",
      "[epoch 401, batch    30] loss: 2.21861\n",
      "[epoch 401, batch    31] loss: 3.42841\n",
      "[epoch 401, batch    32] loss: 3.71916\n",
      "[epoch 402, batch     1] loss: 2.33495\n",
      "[epoch 402, batch     2] loss: 3.39850\n",
      "[epoch 402, batch     3] loss: 3.43862\n",
      "[epoch 402, batch     4] loss: 2.46682\n",
      "[epoch 402, batch     5] loss: 3.07769\n",
      "[epoch 402, batch     6] loss: 3.39761\n",
      "[epoch 402, batch     7] loss: 3.00620\n",
      "[epoch 402, batch     8] loss: 3.60698\n",
      "[epoch 402, batch     9] loss: 2.63841\n",
      "[epoch 402, batch    10] loss: 2.81412\n",
      "[epoch 402, batch    11] loss: 2.15028\n",
      "[epoch 402, batch    12] loss: 2.41722\n",
      "[epoch 402, batch    13] loss: 2.60251\n",
      "[epoch 402, batch    14] loss: 2.86159\n",
      "[epoch 402, batch    15] loss: 2.94967\n",
      "[epoch 402, batch    16] loss: 5.13480\n",
      "[epoch 402, batch    17] loss: 2.30425\n",
      "[epoch 402, batch    18] loss: 2.50951\n",
      "[epoch 402, batch    19] loss: 2.95717\n",
      "[epoch 402, batch    20] loss: 3.15893\n",
      "[epoch 402, batch    21] loss: 2.52528\n",
      "[epoch 402, batch    22] loss: 3.47290\n",
      "[epoch 402, batch    23] loss: 3.27961\n",
      "[epoch 402, batch    24] loss: 3.08145\n",
      "[epoch 402, batch    25] loss: 3.64222\n",
      "[epoch 402, batch    26] loss: 3.24566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 402, batch    27] loss: 3.59421\n",
      "[epoch 402, batch    28] loss: 3.27695\n",
      "[epoch 402, batch    29] loss: 2.75893\n",
      "[epoch 402, batch    30] loss: 3.63445\n",
      "[epoch 402, batch    31] loss: 2.99101\n",
      "[epoch 402, batch    32] loss: 1.41196\n",
      "[epoch 403, batch     1] loss: 4.03902\n",
      "[epoch 403, batch     2] loss: 2.36936\n",
      "[epoch 403, batch     3] loss: 3.54200\n",
      "[epoch 403, batch     4] loss: 3.34870\n",
      "[epoch 403, batch     5] loss: 3.29964\n",
      "[epoch 403, batch     6] loss: 3.03284\n",
      "[epoch 403, batch     7] loss: 2.81728\n",
      "[epoch 403, batch     8] loss: 3.28208\n",
      "[epoch 403, batch     9] loss: 2.64340\n",
      "[epoch 403, batch    10] loss: 4.08317\n",
      "[epoch 403, batch    11] loss: 2.84952\n",
      "[epoch 403, batch    12] loss: 2.91189\n",
      "[epoch 403, batch    13] loss: 3.28719\n",
      "[epoch 403, batch    14] loss: 3.08721\n",
      "[epoch 403, batch    15] loss: 3.61168\n",
      "[epoch 403, batch    16] loss: 2.99406\n",
      "[epoch 403, batch    17] loss: 3.15673\n",
      "[epoch 403, batch    18] loss: 2.72625\n",
      "[epoch 403, batch    19] loss: 3.28642\n",
      "[epoch 403, batch    20] loss: 3.12292\n",
      "[epoch 403, batch    21] loss: 3.28221\n",
      "[epoch 403, batch    22] loss: 2.91287\n",
      "[epoch 403, batch    23] loss: 2.34715\n",
      "[epoch 403, batch    24] loss: 3.28785\n",
      "[epoch 403, batch    25] loss: 2.05375\n",
      "[epoch 403, batch    26] loss: 3.20276\n",
      "[epoch 403, batch    27] loss: 2.69075\n",
      "[epoch 403, batch    28] loss: 3.48236\n",
      "[epoch 403, batch    29] loss: 2.79835\n",
      "[epoch 403, batch    30] loss: 2.20477\n",
      "[epoch 403, batch    31] loss: 2.79295\n",
      "[epoch 403, batch    32] loss: 2.31010\n",
      "[epoch 404, batch     1] loss: 2.90171\n",
      "[epoch 404, batch     2] loss: 2.57020\n",
      "[epoch 404, batch     3] loss: 2.83693\n",
      "[epoch 404, batch     4] loss: 3.03350\n",
      "[epoch 404, batch     5] loss: 2.70245\n",
      "[epoch 404, batch     6] loss: 3.08732\n",
      "[epoch 404, batch     7] loss: 2.89828\n",
      "[epoch 404, batch     8] loss: 3.72250\n",
      "[epoch 404, batch     9] loss: 2.57373\n",
      "[epoch 404, batch    10] loss: 2.66464\n",
      "[epoch 404, batch    11] loss: 3.36342\n",
      "[epoch 404, batch    12] loss: 3.61539\n",
      "[epoch 404, batch    13] loss: 2.14813\n",
      "[epoch 404, batch    14] loss: 3.40686\n",
      "[epoch 404, batch    15] loss: 3.21649\n",
      "[epoch 404, batch    16] loss: 4.70753\n",
      "[epoch 404, batch    17] loss: 3.15234\n",
      "[epoch 404, batch    18] loss: 3.42815\n",
      "[epoch 404, batch    19] loss: 2.42217\n",
      "[epoch 404, batch    20] loss: 2.99546\n",
      "[epoch 404, batch    21] loss: 2.87082\n",
      "[epoch 404, batch    22] loss: 3.00988\n",
      "[epoch 404, batch    23] loss: 3.27723\n",
      "[epoch 404, batch    24] loss: 3.13053\n",
      "[epoch 404, batch    25] loss: 2.70951\n",
      "[epoch 404, batch    26] loss: 2.58156\n",
      "[epoch 404, batch    27] loss: 3.11891\n",
      "[epoch 404, batch    28] loss: 3.46601\n",
      "[epoch 404, batch    29] loss: 3.01276\n",
      "[epoch 404, batch    30] loss: 3.11834\n",
      "[epoch 404, batch    31] loss: 2.72066\n",
      "[epoch 404, batch    32] loss: 1.90786\n",
      "[epoch 405, batch     1] loss: 2.87564\n",
      "[epoch 405, batch     2] loss: 2.37759\n",
      "[epoch 405, batch     3] loss: 2.50324\n",
      "[epoch 405, batch     4] loss: 3.52179\n",
      "[epoch 405, batch     5] loss: 2.81335\n",
      "[epoch 405, batch     6] loss: 2.72974\n",
      "[epoch 405, batch     7] loss: 3.68939\n",
      "[epoch 405, batch     8] loss: 3.52202\n",
      "[epoch 405, batch     9] loss: 3.37288\n",
      "[epoch 405, batch    10] loss: 3.02553\n",
      "[epoch 405, batch    11] loss: 2.88441\n",
      "[epoch 405, batch    12] loss: 2.84930\n",
      "[epoch 405, batch    13] loss: 3.64589\n",
      "[epoch 405, batch    14] loss: 2.94217\n",
      "[epoch 405, batch    15] loss: 3.12442\n",
      "[epoch 405, batch    16] loss: 2.40417\n",
      "[epoch 405, batch    17] loss: 3.75653\n",
      "[epoch 405, batch    18] loss: 2.98921\n",
      "[epoch 405, batch    19] loss: 2.18511\n",
      "[epoch 405, batch    20] loss: 3.35052\n",
      "[epoch 405, batch    21] loss: 3.98799\n",
      "[epoch 405, batch    22] loss: 2.33807\n",
      "[epoch 405, batch    23] loss: 3.73220\n",
      "[epoch 405, batch    24] loss: 3.67181\n",
      "[epoch 405, batch    25] loss: 2.28603\n",
      "[epoch 405, batch    26] loss: 2.58516\n",
      "[epoch 405, batch    27] loss: 3.92042\n",
      "[epoch 405, batch    28] loss: 2.69926\n",
      "[epoch 405, batch    29] loss: 3.30238\n",
      "[epoch 405, batch    30] loss: 2.71033\n",
      "[epoch 405, batch    31] loss: 2.62448\n",
      "[epoch 405, batch    32] loss: 2.59362\n",
      "[epoch 406, batch     1] loss: 2.77882\n",
      "[epoch 406, batch     2] loss: 2.26994\n",
      "[epoch 406, batch     3] loss: 4.21925\n",
      "[epoch 406, batch     4] loss: 3.31142\n",
      "[epoch 406, batch     5] loss: 3.01203\n",
      "[epoch 406, batch     6] loss: 2.76282\n",
      "[epoch 406, batch     7] loss: 3.77852\n",
      "[epoch 406, batch     8] loss: 3.10235\n",
      "[epoch 406, batch     9] loss: 2.38321\n",
      "[epoch 406, batch    10] loss: 3.44768\n",
      "[epoch 406, batch    11] loss: 3.02579\n",
      "[epoch 406, batch    12] loss: 3.15220\n",
      "[epoch 406, batch    13] loss: 3.08303\n",
      "[epoch 406, batch    14] loss: 3.25214\n",
      "[epoch 406, batch    15] loss: 3.21301\n",
      "[epoch 406, batch    16] loss: 3.54789\n",
      "[epoch 406, batch    17] loss: 3.41279\n",
      "[epoch 406, batch    18] loss: 3.26638\n",
      "[epoch 406, batch    19] loss: 2.48156\n",
      "[epoch 406, batch    20] loss: 2.62211\n",
      "[epoch 406, batch    21] loss: 3.15876\n",
      "[epoch 406, batch    22] loss: 2.71489\n",
      "[epoch 406, batch    23] loss: 2.01031\n",
      "[epoch 406, batch    24] loss: 3.83199\n",
      "[epoch 406, batch    25] loss: 2.60997\n",
      "[epoch 406, batch    26] loss: 3.37322\n",
      "[epoch 406, batch    27] loss: 2.33494\n",
      "[epoch 406, batch    28] loss: 2.84936\n",
      "[epoch 406, batch    29] loss: 2.96768\n",
      "[epoch 406, batch    30] loss: 3.66509\n",
      "[epoch 406, batch    31] loss: 2.76302\n",
      "[epoch 406, batch    32] loss: 2.69964\n",
      "[epoch 407, batch     1] loss: 2.87615\n",
      "[epoch 407, batch     2] loss: 2.92871\n",
      "[epoch 407, batch     3] loss: 2.89922\n",
      "[epoch 407, batch     4] loss: 2.68699\n",
      "[epoch 407, batch     5] loss: 2.91742\n",
      "[epoch 407, batch     6] loss: 2.99685\n",
      "[epoch 407, batch     7] loss: 3.61276\n",
      "[epoch 407, batch     8] loss: 4.12774\n",
      "[epoch 407, batch     9] loss: 3.08526\n",
      "[epoch 407, batch    10] loss: 3.09685\n",
      "[epoch 407, batch    11] loss: 2.44422\n",
      "[epoch 407, batch    12] loss: 2.38160\n",
      "[epoch 407, batch    13] loss: 2.80846\n",
      "[epoch 407, batch    14] loss: 3.13245\n",
      "[epoch 407, batch    15] loss: 2.83835\n",
      "[epoch 407, batch    16] loss: 3.60515\n",
      "[epoch 407, batch    17] loss: 2.94091\n",
      "[epoch 407, batch    18] loss: 2.92082\n",
      "[epoch 407, batch    19] loss: 2.81937\n",
      "[epoch 407, batch    20] loss: 3.71227\n",
      "[epoch 407, batch    21] loss: 3.31758\n",
      "[epoch 407, batch    22] loss: 2.29999\n",
      "[epoch 407, batch    23] loss: 3.13375\n",
      "[epoch 407, batch    24] loss: 3.09361\n",
      "[epoch 407, batch    25] loss: 2.53150\n",
      "[epoch 407, batch    26] loss: 3.21494\n",
      "[epoch 407, batch    27] loss: 3.75740\n",
      "[epoch 407, batch    28] loss: 2.96689\n",
      "[epoch 407, batch    29] loss: 3.51891\n",
      "[epoch 407, batch    30] loss: 2.74005\n",
      "[epoch 407, batch    31] loss: 3.28185\n",
      "[epoch 407, batch    32] loss: 3.30071\n",
      "[epoch 408, batch     1] loss: 2.12683\n",
      "[epoch 408, batch     2] loss: 3.22122\n",
      "[epoch 408, batch     3] loss: 2.79879\n",
      "[epoch 408, batch     4] loss: 2.02454\n",
      "[epoch 408, batch     5] loss: 2.46987\n",
      "[epoch 408, batch     6] loss: 3.79053\n",
      "[epoch 408, batch     7] loss: 2.78577\n",
      "[epoch 408, batch     8] loss: 2.81764\n",
      "[epoch 408, batch     9] loss: 3.45102\n",
      "[epoch 408, batch    10] loss: 3.58389\n",
      "[epoch 408, batch    11] loss: 3.31114\n",
      "[epoch 408, batch    12] loss: 2.63153\n",
      "[epoch 408, batch    13] loss: 2.69837\n",
      "[epoch 408, batch    14] loss: 2.52248\n",
      "[epoch 408, batch    15] loss: 3.12817\n",
      "[epoch 408, batch    16] loss: 3.44175\n",
      "[epoch 408, batch    17] loss: 3.98708\n",
      "[epoch 408, batch    18] loss: 3.12187\n",
      "[epoch 408, batch    19] loss: 3.91592\n",
      "[epoch 408, batch    20] loss: 2.54120\n",
      "[epoch 408, batch    21] loss: 3.61229\n",
      "[epoch 408, batch    22] loss: 3.22628\n",
      "[epoch 408, batch    23] loss: 4.39015\n",
      "[epoch 408, batch    24] loss: 3.01732\n",
      "[epoch 408, batch    25] loss: 2.27393\n",
      "[epoch 408, batch    26] loss: 2.50979\n",
      "[epoch 408, batch    27] loss: 2.05484\n",
      "[epoch 408, batch    28] loss: 3.64006\n",
      "[epoch 408, batch    29] loss: 3.03029\n",
      "[epoch 408, batch    30] loss: 3.08060\n",
      "[epoch 408, batch    31] loss: 2.95074\n",
      "[epoch 408, batch    32] loss: 2.76114\n",
      "[epoch 409, batch     1] loss: 3.86195\n",
      "[epoch 409, batch     2] loss: 2.29640\n",
      "[epoch 409, batch     3] loss: 2.54715\n",
      "[epoch 409, batch     4] loss: 2.83889\n",
      "[epoch 409, batch     5] loss: 2.42771\n",
      "[epoch 409, batch     6] loss: 3.74263\n",
      "[epoch 409, batch     7] loss: 2.78228\n",
      "[epoch 409, batch     8] loss: 2.82274\n",
      "[epoch 409, batch     9] loss: 3.74879\n",
      "[epoch 409, batch    10] loss: 2.20032\n",
      "[epoch 409, batch    11] loss: 2.80805\n",
      "[epoch 409, batch    12] loss: 3.27600\n",
      "[epoch 409, batch    13] loss: 2.98386\n",
      "[epoch 409, batch    14] loss: 3.01209\n",
      "[epoch 409, batch    15] loss: 3.78864\n",
      "[epoch 409, batch    16] loss: 3.31793\n",
      "[epoch 409, batch    17] loss: 4.00793\n",
      "[epoch 409, batch    18] loss: 3.63145\n",
      "[epoch 409, batch    19] loss: 2.32973\n",
      "[epoch 409, batch    20] loss: 3.95998\n",
      "[epoch 409, batch    21] loss: 2.64676\n",
      "[epoch 409, batch    22] loss: 2.63385\n",
      "[epoch 409, batch    23] loss: 2.77186\n",
      "[epoch 409, batch    24] loss: 2.69742\n",
      "[epoch 409, batch    25] loss: 3.29178\n",
      "[epoch 409, batch    26] loss: 3.14197\n",
      "[epoch 409, batch    27] loss: 3.63982\n",
      "[epoch 409, batch    28] loss: 2.78582\n",
      "[epoch 409, batch    29] loss: 2.72525\n",
      "[epoch 409, batch    30] loss: 3.21537\n",
      "[epoch 409, batch    31] loss: 2.46023\n",
      "[epoch 409, batch    32] loss: 1.82193\n",
      "[epoch 410, batch     1] loss: 2.48800\n",
      "[epoch 410, batch     2] loss: 3.20620\n",
      "[epoch 410, batch     3] loss: 3.06459\n",
      "[epoch 410, batch     4] loss: 2.90642\n",
      "[epoch 410, batch     5] loss: 3.38655\n",
      "[epoch 410, batch     6] loss: 2.80558\n",
      "[epoch 410, batch     7] loss: 2.77066\n",
      "[epoch 410, batch     8] loss: 3.01285\n",
      "[epoch 410, batch     9] loss: 3.26042\n",
      "[epoch 410, batch    10] loss: 1.83686\n",
      "[epoch 410, batch    11] loss: 2.65836\n",
      "[epoch 410, batch    12] loss: 3.03125\n",
      "[epoch 410, batch    13] loss: 3.17255\n",
      "[epoch 410, batch    14] loss: 3.72174\n",
      "[epoch 410, batch    15] loss: 2.28501\n",
      "[epoch 410, batch    16] loss: 3.22334\n",
      "[epoch 410, batch    17] loss: 3.74140\n",
      "[epoch 410, batch    18] loss: 3.31625\n",
      "[epoch 410, batch    19] loss: 2.54351\n",
      "[epoch 410, batch    20] loss: 3.36613\n",
      "[epoch 410, batch    21] loss: 3.86733\n",
      "[epoch 410, batch    22] loss: 2.86083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 410, batch    23] loss: 3.43926\n",
      "[epoch 410, batch    24] loss: 2.75430\n",
      "[epoch 410, batch    25] loss: 3.08704\n",
      "[epoch 410, batch    26] loss: 2.83832\n",
      "[epoch 410, batch    27] loss: 3.25162\n",
      "[epoch 410, batch    28] loss: 3.29434\n",
      "[epoch 410, batch    29] loss: 2.26408\n",
      "[epoch 410, batch    30] loss: 3.28150\n",
      "[epoch 410, batch    31] loss: 2.84432\n",
      "[epoch 410, batch    32] loss: 7.37149\n",
      "[epoch 411, batch     1] loss: 2.54547\n",
      "[epoch 411, batch     2] loss: 2.43526\n",
      "[epoch 411, batch     3] loss: 2.93041\n",
      "[epoch 411, batch     4] loss: 2.93046\n",
      "[epoch 411, batch     5] loss: 2.58239\n",
      "[epoch 411, batch     6] loss: 3.19417\n",
      "[epoch 411, batch     7] loss: 2.91077\n",
      "[epoch 411, batch     8] loss: 3.04121\n",
      "[epoch 411, batch     9] loss: 3.46310\n",
      "[epoch 411, batch    10] loss: 4.42125\n",
      "[epoch 411, batch    11] loss: 3.41921\n",
      "[epoch 411, batch    12] loss: 4.16458\n",
      "[epoch 411, batch    13] loss: 4.05080\n",
      "[epoch 411, batch    14] loss: 2.86868\n",
      "[epoch 411, batch    15] loss: 3.47298\n",
      "[epoch 411, batch    16] loss: 3.73938\n",
      "[epoch 411, batch    17] loss: 2.73294\n",
      "[epoch 411, batch    18] loss: 2.29442\n",
      "[epoch 411, batch    19] loss: 3.76939\n",
      "[epoch 411, batch    20] loss: 2.66856\n",
      "[epoch 411, batch    21] loss: 2.80379\n",
      "[epoch 411, batch    22] loss: 2.24408\n",
      "[epoch 411, batch    23] loss: 3.33968\n",
      "[epoch 411, batch    24] loss: 2.54336\n",
      "[epoch 411, batch    25] loss: 3.25092\n",
      "[epoch 411, batch    26] loss: 2.63053\n",
      "[epoch 411, batch    27] loss: 2.27617\n",
      "[epoch 411, batch    28] loss: 2.31691\n",
      "[epoch 411, batch    29] loss: 2.94064\n",
      "[epoch 411, batch    30] loss: 2.72883\n",
      "[epoch 411, batch    31] loss: 3.31244\n",
      "[epoch 411, batch    32] loss: 4.79790\n",
      "[epoch 412, batch     1] loss: 2.98519\n",
      "[epoch 412, batch     2] loss: 3.97164\n",
      "[epoch 412, batch     3] loss: 3.48609\n",
      "[epoch 412, batch     4] loss: 2.86245\n",
      "[epoch 412, batch     5] loss: 2.33934\n",
      "[epoch 412, batch     6] loss: 2.32510\n",
      "[epoch 412, batch     7] loss: 2.67581\n",
      "[epoch 412, batch     8] loss: 3.64996\n",
      "[epoch 412, batch     9] loss: 2.66224\n",
      "[epoch 412, batch    10] loss: 3.69143\n",
      "[epoch 412, batch    11] loss: 2.95323\n",
      "[epoch 412, batch    12] loss: 3.40992\n",
      "[epoch 412, batch    13] loss: 2.44261\n",
      "[epoch 412, batch    14] loss: 2.90588\n",
      "[epoch 412, batch    15] loss: 3.03636\n",
      "[epoch 412, batch    16] loss: 2.53766\n",
      "[epoch 412, batch    17] loss: 3.36889\n",
      "[epoch 412, batch    18] loss: 3.45226\n",
      "[epoch 412, batch    19] loss: 2.94047\n",
      "[epoch 412, batch    20] loss: 3.22266\n",
      "[epoch 412, batch    21] loss: 2.91501\n",
      "[epoch 412, batch    22] loss: 2.50420\n",
      "[epoch 412, batch    23] loss: 2.75019\n",
      "[epoch 412, batch    24] loss: 3.48490\n",
      "[epoch 412, batch    25] loss: 2.45567\n",
      "[epoch 412, batch    26] loss: 2.93061\n",
      "[epoch 412, batch    27] loss: 3.25762\n",
      "[epoch 412, batch    28] loss: 2.83597\n",
      "[epoch 412, batch    29] loss: 3.77995\n",
      "[epoch 412, batch    30] loss: 3.32328\n",
      "[epoch 412, batch    31] loss: 2.74320\n",
      "[epoch 412, batch    32] loss: 2.42614\n",
      "[epoch 413, batch     1] loss: 3.56377\n",
      "[epoch 413, batch     2] loss: 2.83128\n",
      "[epoch 413, batch     3] loss: 2.61412\n",
      "[epoch 413, batch     4] loss: 3.92119\n",
      "[epoch 413, batch     5] loss: 3.38644\n",
      "[epoch 413, batch     6] loss: 2.65951\n",
      "[epoch 413, batch     7] loss: 3.40851\n",
      "[epoch 413, batch     8] loss: 2.81752\n",
      "[epoch 413, batch     9] loss: 3.37552\n",
      "[epoch 413, batch    10] loss: 3.47118\n",
      "[epoch 413, batch    11] loss: 3.57376\n",
      "[epoch 413, batch    12] loss: 2.60659\n",
      "[epoch 413, batch    13] loss: 2.85791\n",
      "[epoch 413, batch    14] loss: 2.90295\n",
      "[epoch 413, batch    15] loss: 3.23891\n",
      "[epoch 413, batch    16] loss: 2.66634\n",
      "[epoch 413, batch    17] loss: 2.33908\n",
      "[epoch 413, batch    18] loss: 3.07627\n",
      "[epoch 413, batch    19] loss: 2.61881\n",
      "[epoch 413, batch    20] loss: 3.53030\n",
      "[epoch 413, batch    21] loss: 3.26739\n",
      "[epoch 413, batch    22] loss: 3.51661\n",
      "[epoch 413, batch    23] loss: 2.57776\n",
      "[epoch 413, batch    24] loss: 2.40055\n",
      "[epoch 413, batch    25] loss: 3.50433\n",
      "[epoch 413, batch    26] loss: 3.93321\n",
      "[epoch 413, batch    27] loss: 2.52006\n",
      "[epoch 413, batch    28] loss: 3.04359\n",
      "[epoch 413, batch    29] loss: 2.42794\n",
      "[epoch 413, batch    30] loss: 2.25050\n",
      "[epoch 413, batch    31] loss: 2.97402\n",
      "[epoch 413, batch    32] loss: 4.58637\n",
      "[epoch 414, batch     1] loss: 2.40689\n",
      "[epoch 414, batch     2] loss: 3.86043\n",
      "[epoch 414, batch     3] loss: 3.14665\n",
      "[epoch 414, batch     4] loss: 2.17341\n",
      "[epoch 414, batch     5] loss: 2.44916\n",
      "[epoch 414, batch     6] loss: 3.77289\n",
      "[epoch 414, batch     7] loss: 2.56280\n",
      "[epoch 414, batch     8] loss: 2.89689\n",
      "[epoch 414, batch     9] loss: 3.05528\n",
      "[epoch 414, batch    10] loss: 2.96585\n",
      "[epoch 414, batch    11] loss: 3.10739\n",
      "[epoch 414, batch    12] loss: 2.88133\n",
      "[epoch 414, batch    13] loss: 3.48436\n",
      "[epoch 414, batch    14] loss: 2.89932\n",
      "[epoch 414, batch    15] loss: 3.37485\n",
      "[epoch 414, batch    16] loss: 3.48797\n",
      "[epoch 414, batch    17] loss: 3.34451\n",
      "[epoch 414, batch    18] loss: 3.86739\n",
      "[epoch 414, batch    19] loss: 2.51473\n",
      "[epoch 414, batch    20] loss: 2.36669\n",
      "[epoch 414, batch    21] loss: 3.23890\n",
      "[epoch 414, batch    22] loss: 2.88492\n",
      "[epoch 414, batch    23] loss: 3.17086\n",
      "[epoch 414, batch    24] loss: 3.31881\n",
      "[epoch 414, batch    25] loss: 2.94800\n",
      "[epoch 414, batch    26] loss: 3.30429\n",
      "[epoch 414, batch    27] loss: 3.10317\n",
      "[epoch 414, batch    28] loss: 3.04291\n",
      "[epoch 414, batch    29] loss: 2.72125\n",
      "[epoch 414, batch    30] loss: 3.18376\n",
      "[epoch 414, batch    31] loss: 2.90357\n",
      "[epoch 414, batch    32] loss: 3.37475\n",
      "[epoch 415, batch     1] loss: 2.72314\n",
      "[epoch 415, batch     2] loss: 3.39427\n",
      "[epoch 415, batch     3] loss: 2.93066\n",
      "[epoch 415, batch     4] loss: 3.29003\n",
      "[epoch 415, batch     5] loss: 2.99272\n",
      "[epoch 415, batch     6] loss: 3.21288\n",
      "[epoch 415, batch     7] loss: 4.16712\n",
      "[epoch 415, batch     8] loss: 2.59044\n",
      "[epoch 415, batch     9] loss: 2.98909\n",
      "[epoch 415, batch    10] loss: 2.41127\n",
      "[epoch 415, batch    11] loss: 2.98672\n",
      "[epoch 415, batch    12] loss: 2.90676\n",
      "[epoch 415, batch    13] loss: 3.45507\n",
      "[epoch 415, batch    14] loss: 2.94122\n",
      "[epoch 415, batch    15] loss: 3.03477\n",
      "[epoch 415, batch    16] loss: 2.40563\n",
      "[epoch 415, batch    17] loss: 2.08022\n",
      "[epoch 415, batch    18] loss: 3.69164\n",
      "[epoch 415, batch    19] loss: 3.31138\n",
      "[epoch 415, batch    20] loss: 2.80021\n",
      "[epoch 415, batch    21] loss: 2.27111\n",
      "[epoch 415, batch    22] loss: 2.37282\n",
      "[epoch 415, batch    23] loss: 3.20396\n",
      "[epoch 415, batch    24] loss: 2.91463\n",
      "[epoch 415, batch    25] loss: 3.46498\n",
      "[epoch 415, batch    26] loss: 3.20381\n",
      "[epoch 415, batch    27] loss: 2.86290\n",
      "[epoch 415, batch    28] loss: 3.92190\n",
      "[epoch 415, batch    29] loss: 3.79044\n",
      "[epoch 415, batch    30] loss: 2.50653\n",
      "[epoch 415, batch    31] loss: 3.04883\n",
      "[epoch 415, batch    32] loss: 4.32871\n",
      "[epoch 416, batch     1] loss: 2.58652\n",
      "[epoch 416, batch     2] loss: 2.66502\n",
      "[epoch 416, batch     3] loss: 3.53217\n",
      "[epoch 416, batch     4] loss: 3.22388\n",
      "[epoch 416, batch     5] loss: 3.63244\n",
      "[epoch 416, batch     6] loss: 3.02418\n",
      "[epoch 416, batch     7] loss: 2.88234\n",
      "[epoch 416, batch     8] loss: 2.65888\n",
      "[epoch 416, batch     9] loss: 2.54199\n",
      "[epoch 416, batch    10] loss: 4.14104\n",
      "[epoch 416, batch    11] loss: 3.82171\n",
      "[epoch 416, batch    12] loss: 2.07977\n",
      "[epoch 416, batch    13] loss: 2.73306\n",
      "[epoch 416, batch    14] loss: 3.94759\n",
      "[epoch 416, batch    15] loss: 2.69719\n",
      "[epoch 416, batch    16] loss: 2.68995\n",
      "[epoch 416, batch    17] loss: 3.16333\n",
      "[epoch 416, batch    18] loss: 2.57978\n",
      "[epoch 416, batch    19] loss: 3.52881\n",
      "[epoch 416, batch    20] loss: 3.24881\n",
      "[epoch 416, batch    21] loss: 2.76549\n",
      "[epoch 416, batch    22] loss: 2.84067\n",
      "[epoch 416, batch    23] loss: 2.94582\n",
      "[epoch 416, batch    24] loss: 3.12304\n",
      "[epoch 416, batch    25] loss: 3.24136\n",
      "[epoch 416, batch    26] loss: 3.77277\n",
      "[epoch 416, batch    27] loss: 2.85958\n",
      "[epoch 416, batch    28] loss: 3.24503\n",
      "[epoch 416, batch    29] loss: 2.47681\n",
      "[epoch 416, batch    30] loss: 2.93912\n",
      "[epoch 416, batch    31] loss: 2.88372\n",
      "[epoch 416, batch    32] loss: 2.53290\n",
      "[epoch 417, batch     1] loss: 3.26860\n",
      "[epoch 417, batch     2] loss: 2.93279\n",
      "[epoch 417, batch     3] loss: 2.68571\n",
      "[epoch 417, batch     4] loss: 3.48089\n",
      "[epoch 417, batch     5] loss: 3.07562\n",
      "[epoch 417, batch     6] loss: 2.89594\n",
      "[epoch 417, batch     7] loss: 3.75850\n",
      "[epoch 417, batch     8] loss: 2.77045\n",
      "[epoch 417, batch     9] loss: 3.17992\n",
      "[epoch 417, batch    10] loss: 2.76405\n",
      "[epoch 417, batch    11] loss: 3.63952\n",
      "[epoch 417, batch    12] loss: 2.80714\n",
      "[epoch 417, batch    13] loss: 2.22979\n",
      "[epoch 417, batch    14] loss: 2.44732\n",
      "[epoch 417, batch    15] loss: 3.25336\n",
      "[epoch 417, batch    16] loss: 2.18648\n",
      "[epoch 417, batch    17] loss: 3.10226\n",
      "[epoch 417, batch    18] loss: 2.73913\n",
      "[epoch 417, batch    19] loss: 2.78735\n",
      "[epoch 417, batch    20] loss: 3.07718\n",
      "[epoch 417, batch    21] loss: 2.63721\n",
      "[epoch 417, batch    22] loss: 2.85051\n",
      "[epoch 417, batch    23] loss: 2.85113\n",
      "[epoch 417, batch    24] loss: 3.80780\n",
      "[epoch 417, batch    25] loss: 2.88752\n",
      "[epoch 417, batch    26] loss: 3.42274\n",
      "[epoch 417, batch    27] loss: 2.22114\n",
      "[epoch 417, batch    28] loss: 3.39766\n",
      "[epoch 417, batch    29] loss: 4.34959\n",
      "[epoch 417, batch    30] loss: 3.33355\n",
      "[epoch 417, batch    31] loss: 3.55389\n",
      "[epoch 417, batch    32] loss: 2.78493\n",
      "[epoch 418, batch     1] loss: 3.53364\n",
      "[epoch 418, batch     2] loss: 3.86922\n",
      "[epoch 418, batch     3] loss: 3.44041\n",
      "[epoch 418, batch     4] loss: 3.04149\n",
      "[epoch 418, batch     5] loss: 2.78276\n",
      "[epoch 418, batch     6] loss: 2.87576\n",
      "[epoch 418, batch     7] loss: 2.90795\n",
      "[epoch 418, batch     8] loss: 2.84469\n",
      "[epoch 418, batch     9] loss: 3.12554\n",
      "[epoch 418, batch    10] loss: 2.92409\n",
      "[epoch 418, batch    11] loss: 2.85362\n",
      "[epoch 418, batch    12] loss: 3.42917\n",
      "[epoch 418, batch    13] loss: 2.64420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 418, batch    14] loss: 2.98295\n",
      "[epoch 418, batch    15] loss: 2.80685\n",
      "[epoch 418, batch    16] loss: 3.04114\n",
      "[epoch 418, batch    17] loss: 1.87467\n",
      "[epoch 418, batch    18] loss: 2.84651\n",
      "[epoch 418, batch    19] loss: 2.63609\n",
      "[epoch 418, batch    20] loss: 3.27649\n",
      "[epoch 418, batch    21] loss: 3.74276\n",
      "[epoch 418, batch    22] loss: 2.96667\n",
      "[epoch 418, batch    23] loss: 3.89391\n",
      "[epoch 418, batch    24] loss: 3.56387\n",
      "[epoch 418, batch    25] loss: 2.74139\n",
      "[epoch 418, batch    26] loss: 2.78909\n",
      "[epoch 418, batch    27] loss: 3.27646\n",
      "[epoch 418, batch    28] loss: 2.94205\n",
      "[epoch 418, batch    29] loss: 2.82984\n",
      "[epoch 418, batch    30] loss: 2.47798\n",
      "[epoch 418, batch    31] loss: 3.53832\n",
      "[epoch 418, batch    32] loss: 2.90425\n",
      "[epoch 419, batch     1] loss: 2.56695\n",
      "[epoch 419, batch     2] loss: 3.31180\n",
      "[epoch 419, batch     3] loss: 3.43506\n",
      "[epoch 419, batch     4] loss: 2.18611\n",
      "[epoch 419, batch     5] loss: 3.59306\n",
      "[epoch 419, batch     6] loss: 3.24845\n",
      "[epoch 419, batch     7] loss: 3.52441\n",
      "[epoch 419, batch     8] loss: 3.19237\n",
      "[epoch 419, batch     9] loss: 2.97666\n",
      "[epoch 419, batch    10] loss: 3.02374\n",
      "[epoch 419, batch    11] loss: 2.89247\n",
      "[epoch 419, batch    12] loss: 2.34577\n",
      "[epoch 419, batch    13] loss: 2.86887\n",
      "[epoch 419, batch    14] loss: 3.17609\n",
      "[epoch 419, batch    15] loss: 3.16513\n",
      "[epoch 419, batch    16] loss: 2.34755\n",
      "[epoch 419, batch    17] loss: 3.33451\n",
      "[epoch 419, batch    18] loss: 3.00265\n",
      "[epoch 419, batch    19] loss: 3.36520\n",
      "[epoch 419, batch    20] loss: 3.02516\n",
      "[epoch 419, batch    21] loss: 3.10212\n",
      "[epoch 419, batch    22] loss: 2.88916\n",
      "[epoch 419, batch    23] loss: 2.75321\n",
      "[epoch 419, batch    24] loss: 3.90542\n",
      "[epoch 419, batch    25] loss: 3.52511\n",
      "[epoch 419, batch    26] loss: 3.50486\n",
      "[epoch 419, batch    27] loss: 2.72030\n",
      "[epoch 419, batch    28] loss: 2.40212\n",
      "[epoch 419, batch    29] loss: 2.90267\n",
      "[epoch 419, batch    30] loss: 3.06492\n",
      "[epoch 419, batch    31] loss: 3.40148\n",
      "[epoch 419, batch    32] loss: 3.15905\n",
      "[epoch 420, batch     1] loss: 3.04530\n",
      "[epoch 420, batch     2] loss: 2.46249\n",
      "[epoch 420, batch     3] loss: 3.08193\n",
      "[epoch 420, batch     4] loss: 4.17664\n",
      "[epoch 420, batch     5] loss: 2.90995\n",
      "[epoch 420, batch     6] loss: 3.06473\n",
      "[epoch 420, batch     7] loss: 3.42310\n",
      "[epoch 420, batch     8] loss: 3.97644\n",
      "[epoch 420, batch     9] loss: 3.00720\n",
      "[epoch 420, batch    10] loss: 4.24823\n",
      "[epoch 420, batch    11] loss: 2.95750\n",
      "[epoch 420, batch    12] loss: 3.37786\n",
      "[epoch 420, batch    13] loss: 2.05211\n",
      "[epoch 420, batch    14] loss: 2.72369\n",
      "[epoch 420, batch    15] loss: 2.77689\n",
      "[epoch 420, batch    16] loss: 2.66304\n",
      "[epoch 420, batch    17] loss: 2.42099\n",
      "[epoch 420, batch    18] loss: 1.99640\n",
      "[epoch 420, batch    19] loss: 2.69504\n",
      "[epoch 420, batch    20] loss: 2.71585\n",
      "[epoch 420, batch    21] loss: 2.16238\n",
      "[epoch 420, batch    22] loss: 3.04172\n",
      "[epoch 420, batch    23] loss: 3.20008\n",
      "[epoch 420, batch    24] loss: 2.91642\n",
      "[epoch 420, batch    25] loss: 2.89946\n",
      "[epoch 420, batch    26] loss: 3.12231\n",
      "[epoch 420, batch    27] loss: 2.95585\n",
      "[epoch 420, batch    28] loss: 3.78715\n",
      "[epoch 420, batch    29] loss: 3.43424\n",
      "[epoch 420, batch    30] loss: 3.69878\n",
      "[epoch 420, batch    31] loss: 3.33096\n",
      "[epoch 420, batch    32] loss: 3.62893\n",
      "[epoch 421, batch     1] loss: 2.83423\n",
      "[epoch 421, batch     2] loss: 2.76110\n",
      "[epoch 421, batch     3] loss: 2.93165\n",
      "[epoch 421, batch     4] loss: 3.47813\n",
      "[epoch 421, batch     5] loss: 3.03558\n",
      "[epoch 421, batch     6] loss: 3.28503\n",
      "[epoch 421, batch     7] loss: 2.89854\n",
      "[epoch 421, batch     8] loss: 3.16865\n",
      "[epoch 421, batch     9] loss: 2.86185\n",
      "[epoch 421, batch    10] loss: 2.92268\n",
      "[epoch 421, batch    11] loss: 3.21244\n",
      "[epoch 421, batch    12] loss: 2.48704\n",
      "[epoch 421, batch    13] loss: 3.57051\n",
      "[epoch 421, batch    14] loss: 2.78132\n",
      "[epoch 421, batch    15] loss: 3.20258\n",
      "[epoch 421, batch    16] loss: 3.00523\n",
      "[epoch 421, batch    17] loss: 3.87734\n",
      "[epoch 421, batch    18] loss: 2.87323\n",
      "[epoch 421, batch    19] loss: 3.18540\n",
      "[epoch 421, batch    20] loss: 3.13779\n",
      "[epoch 421, batch    21] loss: 3.09254\n",
      "[epoch 421, batch    22] loss: 3.55305\n",
      "[epoch 421, batch    23] loss: 2.66065\n",
      "[epoch 421, batch    24] loss: 3.02752\n",
      "[epoch 421, batch    25] loss: 2.89111\n",
      "[epoch 421, batch    26] loss: 3.70446\n",
      "[epoch 421, batch    27] loss: 2.52975\n",
      "[epoch 421, batch    28] loss: 3.29025\n",
      "[epoch 421, batch    29] loss: 2.30317\n",
      "[epoch 421, batch    30] loss: 3.48136\n",
      "[epoch 421, batch    31] loss: 2.00293\n",
      "[epoch 421, batch    32] loss: 3.55972\n",
      "[epoch 422, batch     1] loss: 3.46304\n",
      "[epoch 422, batch     2] loss: 2.65312\n",
      "[epoch 422, batch     3] loss: 2.75528\n",
      "[epoch 422, batch     4] loss: 2.89936\n",
      "[epoch 422, batch     5] loss: 3.27177\n",
      "[epoch 422, batch     6] loss: 3.06361\n",
      "[epoch 422, batch     7] loss: 2.52211\n",
      "[epoch 422, batch     8] loss: 2.93386\n",
      "[epoch 422, batch     9] loss: 2.47109\n",
      "[epoch 422, batch    10] loss: 3.36881\n",
      "[epoch 422, batch    11] loss: 3.53869\n",
      "[epoch 422, batch    12] loss: 3.04765\n",
      "[epoch 422, batch    13] loss: 3.06412\n",
      "[epoch 422, batch    14] loss: 2.69893\n",
      "[epoch 422, batch    15] loss: 3.14471\n",
      "[epoch 422, batch    16] loss: 2.18923\n",
      "[epoch 422, batch    17] loss: 2.94983\n",
      "[epoch 422, batch    18] loss: 3.06652\n",
      "[epoch 422, batch    19] loss: 3.12074\n",
      "[epoch 422, batch    20] loss: 3.44032\n",
      "[epoch 422, batch    21] loss: 3.22035\n",
      "[epoch 422, batch    22] loss: 2.74461\n",
      "[epoch 422, batch    23] loss: 2.96068\n",
      "[epoch 422, batch    24] loss: 2.95211\n",
      "[epoch 422, batch    25] loss: 2.54949\n",
      "[epoch 422, batch    26] loss: 3.32377\n",
      "[epoch 422, batch    27] loss: 4.20699\n",
      "[epoch 422, batch    28] loss: 3.30543\n",
      "[epoch 422, batch    29] loss: 3.10967\n",
      "[epoch 422, batch    30] loss: 3.02169\n",
      "[epoch 422, batch    31] loss: 2.98647\n",
      "[epoch 422, batch    32] loss: 5.05413\n",
      "[epoch 423, batch     1] loss: 3.06918\n",
      "[epoch 423, batch     2] loss: 3.70150\n",
      "[epoch 423, batch     3] loss: 2.57456\n",
      "[epoch 423, batch     4] loss: 2.67185\n",
      "[epoch 423, batch     5] loss: 3.88991\n",
      "[epoch 423, batch     6] loss: 2.94053\n",
      "[epoch 423, batch     7] loss: 2.87225\n",
      "[epoch 423, batch     8] loss: 3.69057\n",
      "[epoch 423, batch     9] loss: 3.16125\n",
      "[epoch 423, batch    10] loss: 2.63902\n",
      "[epoch 423, batch    11] loss: 2.83626\n",
      "[epoch 423, batch    12] loss: 2.73596\n",
      "[epoch 423, batch    13] loss: 3.05501\n",
      "[epoch 423, batch    14] loss: 2.64734\n",
      "[epoch 423, batch    15] loss: 2.89125\n",
      "[epoch 423, batch    16] loss: 3.41573\n",
      "[epoch 423, batch    17] loss: 3.23409\n",
      "[epoch 423, batch    18] loss: 2.92243\n",
      "[epoch 423, batch    19] loss: 2.72173\n",
      "[epoch 423, batch    20] loss: 2.57084\n",
      "[epoch 423, batch    21] loss: 3.17074\n",
      "[epoch 423, batch    22] loss: 2.53613\n",
      "[epoch 423, batch    23] loss: 2.71002\n",
      "[epoch 423, batch    24] loss: 3.00143\n",
      "[epoch 423, batch    25] loss: 2.38376\n",
      "[epoch 423, batch    26] loss: 2.48772\n",
      "[epoch 423, batch    27] loss: 3.43304\n",
      "[epoch 423, batch    28] loss: 3.36658\n",
      "[epoch 423, batch    29] loss: 5.82722\n",
      "[epoch 423, batch    30] loss: 2.51529\n",
      "[epoch 423, batch    31] loss: 2.58095\n",
      "[epoch 423, batch    32] loss: 2.44055\n",
      "[epoch 424, batch     1] loss: 3.05935\n",
      "[epoch 424, batch     2] loss: 3.60967\n",
      "[epoch 424, batch     3] loss: 2.45803\n",
      "[epoch 424, batch     4] loss: 3.42178\n",
      "[epoch 424, batch     5] loss: 3.69495\n",
      "[epoch 424, batch     6] loss: 2.09545\n",
      "[epoch 424, batch     7] loss: 2.74566\n",
      "[epoch 424, batch     8] loss: 3.19410\n",
      "[epoch 424, batch     9] loss: 2.89825\n",
      "[epoch 424, batch    10] loss: 3.41439\n",
      "[epoch 424, batch    11] loss: 2.46085\n",
      "[epoch 424, batch    12] loss: 2.77775\n",
      "[epoch 424, batch    13] loss: 3.24280\n",
      "[epoch 424, batch    14] loss: 2.84996\n",
      "[epoch 424, batch    15] loss: 2.99895\n",
      "[epoch 424, batch    16] loss: 3.23262\n",
      "[epoch 424, batch    17] loss: 2.64075\n",
      "[epoch 424, batch    18] loss: 3.23172\n",
      "[epoch 424, batch    19] loss: 1.92652\n",
      "[epoch 424, batch    20] loss: 2.24183\n",
      "[epoch 424, batch    21] loss: 2.94968\n",
      "[epoch 424, batch    22] loss: 4.00733\n",
      "[epoch 424, batch    23] loss: 3.24674\n",
      "[epoch 424, batch    24] loss: 4.36751\n",
      "[epoch 424, batch    25] loss: 3.18590\n",
      "[epoch 424, batch    26] loss: 2.68919\n",
      "[epoch 424, batch    27] loss: 2.75105\n",
      "[epoch 424, batch    28] loss: 3.91946\n",
      "[epoch 424, batch    29] loss: 3.08193\n",
      "[epoch 424, batch    30] loss: 2.96691\n",
      "[epoch 424, batch    31] loss: 2.84784\n",
      "[epoch 424, batch    32] loss: 4.60209\n",
      "[epoch 425, batch     1] loss: 3.30193\n",
      "[epoch 425, batch     2] loss: 3.77122\n",
      "[epoch 425, batch     3] loss: 3.25971\n",
      "[epoch 425, batch     4] loss: 3.03056\n",
      "[epoch 425, batch     5] loss: 2.18882\n",
      "[epoch 425, batch     6] loss: 2.94609\n",
      "[epoch 425, batch     7] loss: 2.84867\n",
      "[epoch 425, batch     8] loss: 2.70914\n",
      "[epoch 425, batch     9] loss: 3.15239\n",
      "[epoch 425, batch    10] loss: 2.68277\n",
      "[epoch 425, batch    11] loss: 4.33519\n",
      "[epoch 425, batch    12] loss: 3.91669\n",
      "[epoch 425, batch    13] loss: 3.07606\n",
      "[epoch 425, batch    14] loss: 2.08157\n",
      "[epoch 425, batch    15] loss: 3.38869\n",
      "[epoch 425, batch    16] loss: 3.78212\n",
      "[epoch 425, batch    17] loss: 2.97347\n",
      "[epoch 425, batch    18] loss: 2.55833\n",
      "[epoch 425, batch    19] loss: 3.21687\n",
      "[epoch 425, batch    20] loss: 3.15179\n",
      "[epoch 425, batch    21] loss: 2.82328\n",
      "[epoch 425, batch    22] loss: 2.62763\n",
      "[epoch 425, batch    23] loss: 2.38695\n",
      "[epoch 425, batch    24] loss: 3.06343\n",
      "[epoch 425, batch    25] loss: 3.26767\n",
      "[epoch 425, batch    26] loss: 3.05143\n",
      "[epoch 425, batch    27] loss: 2.39118\n",
      "[epoch 425, batch    28] loss: 3.52111\n",
      "[epoch 425, batch    29] loss: 3.21682\n",
      "[epoch 425, batch    30] loss: 3.02861\n",
      "[epoch 425, batch    31] loss: 2.66122\n",
      "[epoch 425, batch    32] loss: 2.03190\n",
      "[epoch 426, batch     1] loss: 2.89658\n",
      "[epoch 426, batch     2] loss: 3.16266\n",
      "[epoch 426, batch     3] loss: 3.45944\n",
      "[epoch 426, batch     4] loss: 2.61868\n",
      "[epoch 426, batch     5] loss: 2.94643\n",
      "[epoch 426, batch     6] loss: 2.78755\n",
      "[epoch 426, batch     7] loss: 2.39013\n",
      "[epoch 426, batch     8] loss: 2.86233\n",
      "[epoch 426, batch     9] loss: 3.83673\n",
      "[epoch 426, batch    10] loss: 3.50259\n",
      "[epoch 426, batch    11] loss: 2.66969\n",
      "[epoch 426, batch    12] loss: 3.01803\n",
      "[epoch 426, batch    13] loss: 2.96950\n",
      "[epoch 426, batch    14] loss: 3.25638\n",
      "[epoch 426, batch    15] loss: 2.81656\n",
      "[epoch 426, batch    16] loss: 2.92206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 426, batch    17] loss: 2.64414\n",
      "[epoch 426, batch    18] loss: 4.35059\n",
      "[epoch 426, batch    19] loss: 3.92541\n",
      "[epoch 426, batch    20] loss: 3.02692\n",
      "[epoch 426, batch    21] loss: 3.33086\n",
      "[epoch 426, batch    22] loss: 3.63364\n",
      "[epoch 426, batch    23] loss: 2.39062\n",
      "[epoch 426, batch    24] loss: 3.45455\n",
      "[epoch 426, batch    25] loss: 2.18377\n",
      "[epoch 426, batch    26] loss: 4.01816\n",
      "[epoch 426, batch    27] loss: 2.23232\n",
      "[epoch 426, batch    28] loss: 3.76710\n",
      "[epoch 426, batch    29] loss: 2.49113\n",
      "[epoch 426, batch    30] loss: 2.44296\n",
      "[epoch 426, batch    31] loss: 2.54010\n",
      "[epoch 426, batch    32] loss: 1.76567\n",
      "[epoch 427, batch     1] loss: 2.88115\n",
      "[epoch 427, batch     2] loss: 3.36423\n",
      "[epoch 427, batch     3] loss: 3.74525\n",
      "[epoch 427, batch     4] loss: 2.10973\n",
      "[epoch 427, batch     5] loss: 2.94905\n",
      "[epoch 427, batch     6] loss: 3.13442\n",
      "[epoch 427, batch     7] loss: 2.65165\n",
      "[epoch 427, batch     8] loss: 3.46473\n",
      "[epoch 427, batch     9] loss: 2.70588\n",
      "[epoch 427, batch    10] loss: 2.34870\n",
      "[epoch 427, batch    11] loss: 2.99416\n",
      "[epoch 427, batch    12] loss: 2.64668\n",
      "[epoch 427, batch    13] loss: 3.40319\n",
      "[epoch 427, batch    14] loss: 2.27503\n",
      "[epoch 427, batch    15] loss: 3.72739\n",
      "[epoch 427, batch    16] loss: 3.36382\n",
      "[epoch 427, batch    17] loss: 2.97996\n",
      "[epoch 427, batch    18] loss: 2.24858\n",
      "[epoch 427, batch    19] loss: 3.35164\n",
      "[epoch 427, batch    20] loss: 2.80532\n",
      "[epoch 427, batch    21] loss: 2.71952\n",
      "[epoch 427, batch    22] loss: 3.05375\n",
      "[epoch 427, batch    23] loss: 3.51341\n",
      "[epoch 427, batch    24] loss: 3.31051\n",
      "[epoch 427, batch    25] loss: 2.68842\n",
      "[epoch 427, batch    26] loss: 3.12547\n",
      "[epoch 427, batch    27] loss: 3.64627\n",
      "[epoch 427, batch    28] loss: 2.98087\n",
      "[epoch 427, batch    29] loss: 3.41870\n",
      "[epoch 427, batch    30] loss: 3.53444\n",
      "[epoch 427, batch    31] loss: 2.98455\n",
      "[epoch 427, batch    32] loss: 2.58223\n",
      "[epoch 428, batch     1] loss: 2.68905\n",
      "[epoch 428, batch     2] loss: 2.93319\n",
      "[epoch 428, batch     3] loss: 2.02618\n",
      "[epoch 428, batch     4] loss: 2.52701\n",
      "[epoch 428, batch     5] loss: 2.42543\n",
      "[epoch 428, batch     6] loss: 4.10956\n",
      "[epoch 428, batch     7] loss: 3.65123\n",
      "[epoch 428, batch     8] loss: 3.74071\n",
      "[epoch 428, batch     9] loss: 2.92239\n",
      "[epoch 428, batch    10] loss: 3.20764\n",
      "[epoch 428, batch    11] loss: 3.90349\n",
      "[epoch 428, batch    12] loss: 2.84438\n",
      "[epoch 428, batch    13] loss: 3.35138\n",
      "[epoch 428, batch    14] loss: 3.15517\n",
      "[epoch 428, batch    15] loss: 2.38597\n",
      "[epoch 428, batch    16] loss: 3.29374\n",
      "[epoch 428, batch    17] loss: 3.19679\n",
      "[epoch 428, batch    18] loss: 2.71608\n",
      "[epoch 428, batch    19] loss: 2.41162\n",
      "[epoch 428, batch    20] loss: 2.60153\n",
      "[epoch 428, batch    21] loss: 3.72595\n",
      "[epoch 428, batch    22] loss: 2.81331\n",
      "[epoch 428, batch    23] loss: 2.98540\n",
      "[epoch 428, batch    24] loss: 3.66889\n",
      "[epoch 428, batch    25] loss: 2.33322\n",
      "[epoch 428, batch    26] loss: 2.38725\n",
      "[epoch 428, batch    27] loss: 3.14713\n",
      "[epoch 428, batch    28] loss: 2.97393\n",
      "[epoch 428, batch    29] loss: 3.31895\n",
      "[epoch 428, batch    30] loss: 3.12393\n",
      "[epoch 428, batch    31] loss: 3.24620\n",
      "[epoch 428, batch    32] loss: 2.96189\n",
      "[epoch 429, batch     1] loss: 3.39545\n",
      "[epoch 429, batch     2] loss: 3.49656\n",
      "[epoch 429, batch     3] loss: 2.51863\n",
      "[epoch 429, batch     4] loss: 3.04078\n",
      "[epoch 429, batch     5] loss: 2.67514\n",
      "[epoch 429, batch     6] loss: 3.51911\n",
      "[epoch 429, batch     7] loss: 1.90733\n",
      "[epoch 429, batch     8] loss: 2.75636\n",
      "[epoch 429, batch     9] loss: 3.52903\n",
      "[epoch 429, batch    10] loss: 2.91984\n",
      "[epoch 429, batch    11] loss: 3.50241\n",
      "[epoch 429, batch    12] loss: 2.50888\n",
      "[epoch 429, batch    13] loss: 3.40563\n",
      "[epoch 429, batch    14] loss: 3.16462\n",
      "[epoch 429, batch    15] loss: 2.90809\n",
      "[epoch 429, batch    16] loss: 2.87648\n",
      "[epoch 429, batch    17] loss: 2.87094\n",
      "[epoch 429, batch    18] loss: 2.87809\n",
      "[epoch 429, batch    19] loss: 3.07003\n",
      "[epoch 429, batch    20] loss: 2.91245\n",
      "[epoch 429, batch    21] loss: 2.51784\n",
      "[epoch 429, batch    22] loss: 3.12981\n",
      "[epoch 429, batch    23] loss: 2.86515\n",
      "[epoch 429, batch    24] loss: 3.16460\n",
      "[epoch 429, batch    25] loss: 3.23657\n",
      "[epoch 429, batch    26] loss: 2.91741\n",
      "[epoch 429, batch    27] loss: 2.84019\n",
      "[epoch 429, batch    28] loss: 3.09990\n",
      "[epoch 429, batch    29] loss: 2.95120\n",
      "[epoch 429, batch    30] loss: 3.61608\n",
      "[epoch 429, batch    31] loss: 3.65537\n",
      "[epoch 429, batch    32] loss: 4.24498\n",
      "[epoch 430, batch     1] loss: 2.57399\n",
      "[epoch 430, batch     2] loss: 3.53432\n",
      "[epoch 430, batch     3] loss: 3.28525\n",
      "[epoch 430, batch     4] loss: 2.56537\n",
      "[epoch 430, batch     5] loss: 3.56789\n",
      "[epoch 430, batch     6] loss: 2.52868\n",
      "[epoch 430, batch     7] loss: 2.89743\n",
      "[epoch 430, batch     8] loss: 3.38212\n",
      "[epoch 430, batch     9] loss: 3.04876\n",
      "[epoch 430, batch    10] loss: 4.33980\n",
      "[epoch 430, batch    11] loss: 2.99456\n",
      "[epoch 430, batch    12] loss: 3.17387\n",
      "[epoch 430, batch    13] loss: 2.58034\n",
      "[epoch 430, batch    14] loss: 2.89867\n",
      "[epoch 430, batch    15] loss: 3.31189\n",
      "[epoch 430, batch    16] loss: 2.29982\n",
      "[epoch 430, batch    17] loss: 2.56357\n",
      "[epoch 430, batch    18] loss: 2.51163\n",
      "[epoch 430, batch    19] loss: 2.54314\n",
      "[epoch 430, batch    20] loss: 2.90333\n",
      "[epoch 430, batch    21] loss: 2.84543\n",
      "[epoch 430, batch    22] loss: 2.89149\n",
      "[epoch 430, batch    23] loss: 3.30940\n",
      "[epoch 430, batch    24] loss: 2.64455\n",
      "[epoch 430, batch    25] loss: 3.31957\n",
      "[epoch 430, batch    26] loss: 3.54931\n",
      "[epoch 430, batch    27] loss: 2.72021\n",
      "[epoch 430, batch    28] loss: 3.06153\n",
      "[epoch 430, batch    29] loss: 3.14434\n",
      "[epoch 430, batch    30] loss: 4.16506\n",
      "[epoch 430, batch    31] loss: 2.72896\n",
      "[epoch 430, batch    32] loss: 2.08477\n",
      "[epoch 431, batch     1] loss: 3.20898\n",
      "[epoch 431, batch     2] loss: 3.20364\n",
      "[epoch 431, batch     3] loss: 3.17104\n",
      "[epoch 431, batch     4] loss: 2.38160\n",
      "[epoch 431, batch     5] loss: 3.01840\n",
      "[epoch 431, batch     6] loss: 3.57690\n",
      "[epoch 431, batch     7] loss: 2.39764\n",
      "[epoch 431, batch     8] loss: 3.46521\n",
      "[epoch 431, batch     9] loss: 3.47559\n",
      "[epoch 431, batch    10] loss: 2.78909\n",
      "[epoch 431, batch    11] loss: 3.21352\n",
      "[epoch 431, batch    12] loss: 3.47573\n",
      "[epoch 431, batch    13] loss: 2.82580\n",
      "[epoch 431, batch    14] loss: 2.91992\n",
      "[epoch 431, batch    15] loss: 2.85524\n",
      "[epoch 431, batch    16] loss: 2.70674\n",
      "[epoch 431, batch    17] loss: 2.26334\n",
      "[epoch 431, batch    18] loss: 2.88174\n",
      "[epoch 431, batch    19] loss: 3.16925\n",
      "[epoch 431, batch    20] loss: 3.54869\n",
      "[epoch 431, batch    21] loss: 3.14787\n",
      "[epoch 431, batch    22] loss: 2.70354\n",
      "[epoch 431, batch    23] loss: 3.69254\n",
      "[epoch 431, batch    24] loss: 2.79592\n",
      "[epoch 431, batch    25] loss: 2.32586\n",
      "[epoch 431, batch    26] loss: 3.31698\n",
      "[epoch 431, batch    27] loss: 3.22000\n",
      "[epoch 431, batch    28] loss: 2.80714\n",
      "[epoch 431, batch    29] loss: 3.20630\n",
      "[epoch 431, batch    30] loss: 2.87166\n",
      "[epoch 431, batch    31] loss: 2.66548\n",
      "[epoch 431, batch    32] loss: 5.36342\n",
      "[epoch 432, batch     1] loss: 2.32353\n",
      "[epoch 432, batch     2] loss: 4.19749\n",
      "[epoch 432, batch     3] loss: 2.64776\n",
      "[epoch 432, batch     4] loss: 2.61541\n",
      "[epoch 432, batch     5] loss: 2.40615\n",
      "[epoch 432, batch     6] loss: 3.01603\n",
      "[epoch 432, batch     7] loss: 2.92020\n",
      "[epoch 432, batch     8] loss: 2.80652\n",
      "[epoch 432, batch     9] loss: 3.17836\n",
      "[epoch 432, batch    10] loss: 3.44980\n",
      "[epoch 432, batch    11] loss: 3.49120\n",
      "[epoch 432, batch    12] loss: 3.90691\n",
      "[epoch 432, batch    13] loss: 3.45962\n",
      "[epoch 432, batch    14] loss: 3.01312\n",
      "[epoch 432, batch    15] loss: 2.78014\n",
      "[epoch 432, batch    16] loss: 2.93009\n",
      "[epoch 432, batch    17] loss: 2.07230\n",
      "[epoch 432, batch    18] loss: 3.11340\n",
      "[epoch 432, batch    19] loss: 3.63338\n",
      "[epoch 432, batch    20] loss: 3.63854\n",
      "[epoch 432, batch    21] loss: 3.38102\n",
      "[epoch 432, batch    22] loss: 2.20222\n",
      "[epoch 432, batch    23] loss: 2.57735\n",
      "[epoch 432, batch    24] loss: 3.19197\n",
      "[epoch 432, batch    25] loss: 2.84781\n",
      "[epoch 432, batch    26] loss: 2.64199\n",
      "[epoch 432, batch    27] loss: 2.97005\n",
      "[epoch 432, batch    28] loss: 3.10657\n",
      "[epoch 432, batch    29] loss: 2.29653\n",
      "[epoch 432, batch    30] loss: 2.92203\n",
      "[epoch 432, batch    31] loss: 3.70322\n",
      "[epoch 432, batch    32] loss: 5.04097\n",
      "[epoch 433, batch     1] loss: 3.27036\n",
      "[epoch 433, batch     2] loss: 3.47731\n",
      "[epoch 433, batch     3] loss: 2.31896\n",
      "[epoch 433, batch     4] loss: 2.96357\n",
      "[epoch 433, batch     5] loss: 3.08571\n",
      "[epoch 433, batch     6] loss: 2.53082\n",
      "[epoch 433, batch     7] loss: 3.52100\n",
      "[epoch 433, batch     8] loss: 3.55489\n",
      "[epoch 433, batch     9] loss: 3.60748\n",
      "[epoch 433, batch    10] loss: 2.84315\n",
      "[epoch 433, batch    11] loss: 3.51526\n",
      "[epoch 433, batch    12] loss: 3.34920\n",
      "[epoch 433, batch    13] loss: 2.35213\n",
      "[epoch 433, batch    14] loss: 3.82590\n",
      "[epoch 433, batch    15] loss: 2.45565\n",
      "[epoch 433, batch    16] loss: 2.17234\n",
      "[epoch 433, batch    17] loss: 2.09628\n",
      "[epoch 433, batch    18] loss: 3.20499\n",
      "[epoch 433, batch    19] loss: 3.08016\n",
      "[epoch 433, batch    20] loss: 3.01376\n",
      "[epoch 433, batch    21] loss: 2.79639\n",
      "[epoch 433, batch    22] loss: 3.39177\n",
      "[epoch 433, batch    23] loss: 4.07076\n",
      "[epoch 433, batch    24] loss: 2.21527\n",
      "[epoch 433, batch    25] loss: 2.42662\n",
      "[epoch 433, batch    26] loss: 3.28214\n",
      "[epoch 433, batch    27] loss: 3.89973\n",
      "[epoch 433, batch    28] loss: 3.43088\n",
      "[epoch 433, batch    29] loss: 2.93196\n",
      "[epoch 433, batch    30] loss: 3.11878\n",
      "[epoch 433, batch    31] loss: 2.99078\n",
      "[epoch 433, batch    32] loss: 1.65124\n",
      "[epoch 434, batch     1] loss: 2.58586\n",
      "[epoch 434, batch     2] loss: 3.02946\n",
      "[epoch 434, batch     3] loss: 3.09132\n",
      "[epoch 434, batch     4] loss: 3.17882\n",
      "[epoch 434, batch     5] loss: 2.74933\n",
      "[epoch 434, batch     6] loss: 2.89950\n",
      "[epoch 434, batch     7] loss: 3.29409\n",
      "[epoch 434, batch     8] loss: 3.58624\n",
      "[epoch 434, batch     9] loss: 3.10427\n",
      "[epoch 434, batch    10] loss: 3.00920\n",
      "[epoch 434, batch    11] loss: 2.58304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 434, batch    12] loss: 2.83762\n",
      "[epoch 434, batch    13] loss: 2.81099\n",
      "[epoch 434, batch    14] loss: 3.39151\n",
      "[epoch 434, batch    15] loss: 2.30567\n",
      "[epoch 434, batch    16] loss: 2.93745\n",
      "[epoch 434, batch    17] loss: 2.74248\n",
      "[epoch 434, batch    18] loss: 3.19002\n",
      "[epoch 434, batch    19] loss: 2.54335\n",
      "[epoch 434, batch    20] loss: 2.74950\n",
      "[epoch 434, batch    21] loss: 3.57762\n",
      "[epoch 434, batch    22] loss: 4.21305\n",
      "[epoch 434, batch    23] loss: 2.88083\n",
      "[epoch 434, batch    24] loss: 2.79461\n",
      "[epoch 434, batch    25] loss: 3.70528\n",
      "[epoch 434, batch    26] loss: 2.81345\n",
      "[epoch 434, batch    27] loss: 3.25660\n",
      "[epoch 434, batch    28] loss: 3.14186\n",
      "[epoch 434, batch    29] loss: 3.34176\n",
      "[epoch 434, batch    30] loss: 2.88523\n",
      "[epoch 434, batch    31] loss: 2.65444\n",
      "[epoch 434, batch    32] loss: 2.51678\n",
      "[epoch 435, batch     1] loss: 2.47697\n",
      "[epoch 435, batch     2] loss: 3.24056\n",
      "[epoch 435, batch     3] loss: 3.38613\n",
      "[epoch 435, batch     4] loss: 2.69235\n",
      "[epoch 435, batch     5] loss: 3.39327\n",
      "[epoch 435, batch     6] loss: 2.58739\n",
      "[epoch 435, batch     7] loss: 3.00039\n",
      "[epoch 435, batch     8] loss: 3.28954\n",
      "[epoch 435, batch     9] loss: 2.83989\n",
      "[epoch 435, batch    10] loss: 2.60744\n",
      "[epoch 435, batch    11] loss: 3.19896\n",
      "[epoch 435, batch    12] loss: 2.05312\n",
      "[epoch 435, batch    13] loss: 2.54538\n",
      "[epoch 435, batch    14] loss: 4.00244\n",
      "[epoch 435, batch    15] loss: 4.12494\n",
      "[epoch 435, batch    16] loss: 3.46296\n",
      "[epoch 435, batch    17] loss: 2.89742\n",
      "[epoch 435, batch    18] loss: 3.11020\n",
      "[epoch 435, batch    19] loss: 3.91208\n",
      "[epoch 435, batch    20] loss: 3.63181\n",
      "[epoch 435, batch    21] loss: 2.46086\n",
      "[epoch 435, batch    22] loss: 3.00011\n",
      "[epoch 435, batch    23] loss: 3.15346\n",
      "[epoch 435, batch    24] loss: 2.57545\n",
      "[epoch 435, batch    25] loss: 3.21498\n",
      "[epoch 435, batch    26] loss: 3.21569\n",
      "[epoch 435, batch    27] loss: 3.74627\n",
      "[epoch 435, batch    28] loss: 2.38580\n",
      "[epoch 435, batch    29] loss: 2.67987\n",
      "[epoch 435, batch    30] loss: 2.63991\n",
      "[epoch 435, batch    31] loss: 2.34533\n",
      "[epoch 435, batch    32] loss: 4.21302\n",
      "[epoch 436, batch     1] loss: 3.68080\n",
      "[epoch 436, batch     2] loss: 3.38331\n",
      "[epoch 436, batch     3] loss: 3.75425\n",
      "[epoch 436, batch     4] loss: 3.03898\n",
      "[epoch 436, batch     5] loss: 2.87109\n",
      "[epoch 436, batch     6] loss: 2.48305\n",
      "[epoch 436, batch     7] loss: 2.37513\n",
      "[epoch 436, batch     8] loss: 3.64361\n",
      "[epoch 436, batch     9] loss: 3.71123\n",
      "[epoch 436, batch    10] loss: 4.46445\n",
      "[epoch 436, batch    11] loss: 2.76095\n",
      "[epoch 436, batch    12] loss: 2.76136\n",
      "[epoch 436, batch    13] loss: 2.78252\n",
      "[epoch 436, batch    14] loss: 4.03541\n",
      "[epoch 436, batch    15] loss: 2.68998\n",
      "[epoch 436, batch    16] loss: 3.30222\n",
      "[epoch 436, batch    17] loss: 2.34461\n",
      "[epoch 436, batch    18] loss: 2.68484\n",
      "[epoch 436, batch    19] loss: 2.83754\n",
      "[epoch 436, batch    20] loss: 2.43638\n",
      "[epoch 436, batch    21] loss: 3.57090\n",
      "[epoch 436, batch    22] loss: 2.23575\n",
      "[epoch 436, batch    23] loss: 1.65463\n",
      "[epoch 436, batch    24] loss: 3.85630\n",
      "[epoch 436, batch    25] loss: 2.61484\n",
      "[epoch 436, batch    26] loss: 2.84703\n",
      "[epoch 436, batch    27] loss: 2.75330\n",
      "[epoch 436, batch    28] loss: 2.41766\n",
      "[epoch 436, batch    29] loss: 4.01992\n",
      "[epoch 436, batch    30] loss: 2.20690\n",
      "[epoch 436, batch    31] loss: 2.98637\n",
      "[epoch 436, batch    32] loss: 4.91230\n",
      "[epoch 437, batch     1] loss: 2.82605\n",
      "[epoch 437, batch     2] loss: 2.75684\n",
      "[epoch 437, batch     3] loss: 2.61027\n",
      "[epoch 437, batch     4] loss: 3.56561\n",
      "[epoch 437, batch     5] loss: 3.13341\n",
      "[epoch 437, batch     6] loss: 2.22816\n",
      "[epoch 437, batch     7] loss: 3.90688\n",
      "[epoch 437, batch     8] loss: 3.33384\n",
      "[epoch 437, batch     9] loss: 2.31868\n",
      "[epoch 437, batch    10] loss: 2.63008\n",
      "[epoch 437, batch    11] loss: 3.64152\n",
      "[epoch 437, batch    12] loss: 2.55941\n",
      "[epoch 437, batch    13] loss: 3.00959\n",
      "[epoch 437, batch    14] loss: 3.93061\n",
      "[epoch 437, batch    15] loss: 3.02730\n",
      "[epoch 437, batch    16] loss: 3.10452\n",
      "[epoch 437, batch    17] loss: 2.93423\n",
      "[epoch 437, batch    18] loss: 3.21695\n",
      "[epoch 437, batch    19] loss: 1.86591\n",
      "[epoch 437, batch    20] loss: 3.05619\n",
      "[epoch 437, batch    21] loss: 2.38296\n",
      "[epoch 437, batch    22] loss: 2.20663\n",
      "[epoch 437, batch    23] loss: 2.82919\n",
      "[epoch 437, batch    24] loss: 3.28948\n",
      "[epoch 437, batch    25] loss: 3.85212\n",
      "[epoch 437, batch    26] loss: 3.13961\n",
      "[epoch 437, batch    27] loss: 3.05394\n",
      "[epoch 437, batch    28] loss: 2.96043\n",
      "[epoch 437, batch    29] loss: 3.09997\n",
      "[epoch 437, batch    30] loss: 3.66333\n",
      "[epoch 437, batch    31] loss: 3.74270\n",
      "[epoch 437, batch    32] loss: 1.86488\n",
      "[epoch 438, batch     1] loss: 2.64022\n",
      "[epoch 438, batch     2] loss: 3.60773\n",
      "[epoch 438, batch     3] loss: 2.93099\n",
      "[epoch 438, batch     4] loss: 3.74562\n",
      "[epoch 438, batch     5] loss: 3.14844\n",
      "[epoch 438, batch     6] loss: 3.62080\n",
      "[epoch 438, batch     7] loss: 3.12276\n",
      "[epoch 438, batch     8] loss: 3.17587\n",
      "[epoch 438, batch     9] loss: 2.48173\n",
      "[epoch 438, batch    10] loss: 3.94303\n",
      "[epoch 438, batch    11] loss: 2.22166\n",
      "[epoch 438, batch    12] loss: 3.18771\n",
      "[epoch 438, batch    13] loss: 2.59457\n",
      "[epoch 438, batch    14] loss: 3.39467\n",
      "[epoch 438, batch    15] loss: 3.66127\n",
      "[epoch 438, batch    16] loss: 2.74022\n",
      "[epoch 438, batch    17] loss: 2.50923\n",
      "[epoch 438, batch    18] loss: 2.49866\n",
      "[epoch 438, batch    19] loss: 3.61097\n",
      "[epoch 438, batch    20] loss: 2.93503\n",
      "[epoch 438, batch    21] loss: 2.44026\n",
      "[epoch 438, batch    22] loss: 2.87158\n",
      "[epoch 438, batch    23] loss: 2.51049\n",
      "[epoch 438, batch    24] loss: 2.48621\n",
      "[epoch 438, batch    25] loss: 3.37025\n",
      "[epoch 438, batch    26] loss: 3.51590\n",
      "[epoch 438, batch    27] loss: 2.48213\n",
      "[epoch 438, batch    28] loss: 2.66941\n",
      "[epoch 438, batch    29] loss: 3.39540\n",
      "[epoch 438, batch    30] loss: 3.54285\n",
      "[epoch 438, batch    31] loss: 3.53040\n",
      "[epoch 438, batch    32] loss: 3.38194\n",
      "[epoch 439, batch     1] loss: 2.54578\n",
      "[epoch 439, batch     2] loss: 2.79021\n",
      "[epoch 439, batch     3] loss: 3.55621\n",
      "[epoch 439, batch     4] loss: 3.25831\n",
      "[epoch 439, batch     5] loss: 3.10287\n",
      "[epoch 439, batch     6] loss: 3.87237\n",
      "[epoch 439, batch     7] loss: 2.76513\n",
      "[epoch 439, batch     8] loss: 3.32766\n",
      "[epoch 439, batch     9] loss: 2.44359\n",
      "[epoch 439, batch    10] loss: 2.52108\n",
      "[epoch 439, batch    11] loss: 3.37845\n",
      "[epoch 439, batch    12] loss: 3.24956\n",
      "[epoch 439, batch    13] loss: 2.91412\n",
      "[epoch 439, batch    14] loss: 2.84175\n",
      "[epoch 439, batch    15] loss: 3.91277\n",
      "[epoch 439, batch    16] loss: 3.10930\n",
      "[epoch 439, batch    17] loss: 2.80423\n",
      "[epoch 439, batch    18] loss: 2.88694\n",
      "[epoch 439, batch    19] loss: 3.16251\n",
      "[epoch 439, batch    20] loss: 2.77927\n",
      "[epoch 439, batch    21] loss: 3.15198\n",
      "[epoch 439, batch    22] loss: 2.56640\n",
      "[epoch 439, batch    23] loss: 2.68401\n",
      "[epoch 439, batch    24] loss: 2.53074\n",
      "[epoch 439, batch    25] loss: 2.67222\n",
      "[epoch 439, batch    26] loss: 3.14938\n",
      "[epoch 439, batch    27] loss: 3.15180\n",
      "[epoch 439, batch    28] loss: 2.68441\n",
      "[epoch 439, batch    29] loss: 2.46442\n",
      "[epoch 439, batch    30] loss: 3.84597\n",
      "[epoch 439, batch    31] loss: 3.21690\n",
      "[epoch 439, batch    32] loss: 4.92517\n",
      "[epoch 440, batch     1] loss: 3.04213\n",
      "[epoch 440, batch     2] loss: 3.61105\n",
      "[epoch 440, batch     3] loss: 3.09054\n",
      "[epoch 440, batch     4] loss: 3.77433\n",
      "[epoch 440, batch     5] loss: 1.99804\n",
      "[epoch 440, batch     6] loss: 3.72800\n",
      "[epoch 440, batch     7] loss: 3.44408\n",
      "[epoch 440, batch     8] loss: 4.28488\n",
      "[epoch 440, batch     9] loss: 3.66172\n",
      "[epoch 440, batch    10] loss: 2.23861\n",
      "[epoch 440, batch    11] loss: 2.82530\n",
      "[epoch 440, batch    12] loss: 2.42667\n",
      "[epoch 440, batch    13] loss: 2.86007\n",
      "[epoch 440, batch    14] loss: 2.66889\n",
      "[epoch 440, batch    15] loss: 3.01413\n",
      "[epoch 440, batch    16] loss: 3.13051\n",
      "[epoch 440, batch    17] loss: 3.00828\n",
      "[epoch 440, batch    18] loss: 2.86225\n",
      "[epoch 440, batch    19] loss: 2.86766\n",
      "[epoch 440, batch    20] loss: 3.25810\n",
      "[epoch 440, batch    21] loss: 3.10607\n",
      "[epoch 440, batch    22] loss: 2.54396\n",
      "[epoch 440, batch    23] loss: 3.33671\n",
      "[epoch 440, batch    24] loss: 2.97622\n",
      "[epoch 440, batch    25] loss: 3.17481\n",
      "[epoch 440, batch    26] loss: 3.23351\n",
      "[epoch 440, batch    27] loss: 2.69797\n",
      "[epoch 440, batch    28] loss: 3.11204\n",
      "[epoch 440, batch    29] loss: 2.34192\n",
      "[epoch 440, batch    30] loss: 2.43089\n",
      "[epoch 440, batch    31] loss: 3.39277\n",
      "[epoch 440, batch    32] loss: 4.05277\n",
      "[epoch 441, batch     1] loss: 2.95025\n",
      "[epoch 441, batch     2] loss: 2.76993\n",
      "[epoch 441, batch     3] loss: 3.32567\n",
      "[epoch 441, batch     4] loss: 2.45288\n",
      "[epoch 441, batch     5] loss: 3.37623\n",
      "[epoch 441, batch     6] loss: 3.17168\n",
      "[epoch 441, batch     7] loss: 3.37737\n",
      "[epoch 441, batch     8] loss: 1.85910\n",
      "[epoch 441, batch     9] loss: 3.04081\n",
      "[epoch 441, batch    10] loss: 3.25397\n",
      "[epoch 441, batch    11] loss: 3.40922\n",
      "[epoch 441, batch    12] loss: 3.53045\n",
      "[epoch 441, batch    13] loss: 3.03629\n",
      "[epoch 441, batch    14] loss: 3.13693\n",
      "[epoch 441, batch    15] loss: 2.77844\n",
      "[epoch 441, batch    16] loss: 2.73788\n",
      "[epoch 441, batch    17] loss: 3.68531\n",
      "[epoch 441, batch    18] loss: 2.76573\n",
      "[epoch 441, batch    19] loss: 2.14314\n",
      "[epoch 441, batch    20] loss: 3.33606\n",
      "[epoch 441, batch    21] loss: 2.67101\n",
      "[epoch 441, batch    22] loss: 4.00794\n",
      "[epoch 441, batch    23] loss: 3.11876\n",
      "[epoch 441, batch    24] loss: 2.45411\n",
      "[epoch 441, batch    25] loss: 3.07975\n",
      "[epoch 441, batch    26] loss: 3.94184\n",
      "[epoch 441, batch    27] loss: 2.69175\n",
      "[epoch 441, batch    28] loss: 2.32144\n",
      "[epoch 441, batch    29] loss: 3.24372\n",
      "[epoch 441, batch    30] loss: 3.02236\n",
      "[epoch 441, batch    31] loss: 3.78329\n",
      "[epoch 441, batch    32] loss: 2.58446\n",
      "[epoch 442, batch     1] loss: 3.61348\n",
      "[epoch 442, batch     2] loss: 2.41147\n",
      "[epoch 442, batch     3] loss: 2.71568\n",
      "[epoch 442, batch     4] loss: 3.29794\n",
      "[epoch 442, batch     5] loss: 3.61834\n",
      "[epoch 442, batch     6] loss: 2.74877\n",
      "[epoch 442, batch     7] loss: 1.86490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 442, batch     8] loss: 3.78435\n",
      "[epoch 442, batch     9] loss: 2.68407\n",
      "[epoch 442, batch    10] loss: 2.95319\n",
      "[epoch 442, batch    11] loss: 3.50318\n",
      "[epoch 442, batch    12] loss: 2.95980\n",
      "[epoch 442, batch    13] loss: 3.72707\n",
      "[epoch 442, batch    14] loss: 2.34991\n",
      "[epoch 442, batch    15] loss: 3.26954\n",
      "[epoch 442, batch    16] loss: 2.59094\n",
      "[epoch 442, batch    17] loss: 2.55567\n",
      "[epoch 442, batch    18] loss: 2.80143\n",
      "[epoch 442, batch    19] loss: 3.15337\n",
      "[epoch 442, batch    20] loss: 3.02289\n",
      "[epoch 442, batch    21] loss: 3.11480\n",
      "[epoch 442, batch    22] loss: 2.47399\n",
      "[epoch 442, batch    23] loss: 3.15840\n",
      "[epoch 442, batch    24] loss: 3.20790\n",
      "[epoch 442, batch    25] loss: 2.24054\n",
      "[epoch 442, batch    26] loss: 2.76913\n",
      "[epoch 442, batch    27] loss: 3.39672\n",
      "[epoch 442, batch    28] loss: 3.25764\n",
      "[epoch 442, batch    29] loss: 3.56120\n",
      "[epoch 442, batch    30] loss: 4.09890\n",
      "[epoch 442, batch    31] loss: 3.27055\n",
      "[epoch 442, batch    32] loss: 2.42882\n",
      "[epoch 443, batch     1] loss: 2.36093\n",
      "[epoch 443, batch     2] loss: 2.99521\n",
      "[epoch 443, batch     3] loss: 3.00908\n",
      "[epoch 443, batch     4] loss: 3.85977\n",
      "[epoch 443, batch     5] loss: 2.31923\n",
      "[epoch 443, batch     6] loss: 3.18495\n",
      "[epoch 443, batch     7] loss: 3.24562\n",
      "[epoch 443, batch     8] loss: 3.09592\n",
      "[epoch 443, batch     9] loss: 2.98876\n",
      "[epoch 443, batch    10] loss: 3.26223\n",
      "[epoch 443, batch    11] loss: 3.01637\n",
      "[epoch 443, batch    12] loss: 3.15969\n",
      "[epoch 443, batch    13] loss: 2.86190\n",
      "[epoch 443, batch    14] loss: 3.06614\n",
      "[epoch 443, batch    15] loss: 2.89411\n",
      "[epoch 443, batch    16] loss: 3.47375\n",
      "[epoch 443, batch    17] loss: 3.24761\n",
      "[epoch 443, batch    18] loss: 2.43911\n",
      "[epoch 443, batch    19] loss: 3.07328\n",
      "[epoch 443, batch    20] loss: 3.59067\n",
      "[epoch 443, batch    21] loss: 3.50762\n",
      "[epoch 443, batch    22] loss: 3.02260\n",
      "[epoch 443, batch    23] loss: 2.57882\n",
      "[epoch 443, batch    24] loss: 3.53124\n",
      "[epoch 443, batch    25] loss: 3.62617\n",
      "[epoch 443, batch    26] loss: 2.45950\n",
      "[epoch 443, batch    27] loss: 2.62249\n",
      "[epoch 443, batch    28] loss: 2.93802\n",
      "[epoch 443, batch    29] loss: 2.73145\n",
      "[epoch 443, batch    30] loss: 2.92717\n",
      "[epoch 443, batch    31] loss: 3.23507\n",
      "[epoch 443, batch    32] loss: 3.31593\n",
      "[epoch 444, batch     1] loss: 3.22298\n",
      "[epoch 444, batch     2] loss: 2.93704\n",
      "[epoch 444, batch     3] loss: 3.89188\n",
      "[epoch 444, batch     4] loss: 3.03498\n",
      "[epoch 444, batch     5] loss: 3.04776\n",
      "[epoch 444, batch     6] loss: 3.39702\n",
      "[epoch 444, batch     7] loss: 2.78191\n",
      "[epoch 444, batch     8] loss: 2.74945\n",
      "[epoch 444, batch     9] loss: 2.65927\n",
      "[epoch 444, batch    10] loss: 3.38199\n",
      "[epoch 444, batch    11] loss: 3.37575\n",
      "[epoch 444, batch    12] loss: 2.90718\n",
      "[epoch 444, batch    13] loss: 3.39965\n",
      "[epoch 444, batch    14] loss: 3.02751\n",
      "[epoch 444, batch    15] loss: 2.81465\n",
      "[epoch 444, batch    16] loss: 3.62896\n",
      "[epoch 444, batch    17] loss: 2.65437\n",
      "[epoch 444, batch    18] loss: 2.29902\n",
      "[epoch 444, batch    19] loss: 2.94792\n",
      "[epoch 444, batch    20] loss: 2.70225\n",
      "[epoch 444, batch    21] loss: 2.69108\n",
      "[epoch 444, batch    22] loss: 2.27411\n",
      "[epoch 444, batch    23] loss: 3.07976\n",
      "[epoch 444, batch    24] loss: 2.94397\n",
      "[epoch 444, batch    25] loss: 4.09345\n",
      "[epoch 444, batch    26] loss: 3.03190\n",
      "[epoch 444, batch    27] loss: 3.09388\n",
      "[epoch 444, batch    28] loss: 2.62750\n",
      "[epoch 444, batch    29] loss: 3.27692\n",
      "[epoch 444, batch    30] loss: 3.38023\n",
      "[epoch 444, batch    31] loss: 2.70597\n",
      "[epoch 444, batch    32] loss: 3.60765\n",
      "[epoch 445, batch     1] loss: 2.97549\n",
      "[epoch 445, batch     2] loss: 2.91686\n",
      "[epoch 445, batch     3] loss: 4.12490\n",
      "[epoch 445, batch     4] loss: 3.08372\n",
      "[epoch 445, batch     5] loss: 2.77753\n",
      "[epoch 445, batch     6] loss: 3.48824\n",
      "[epoch 445, batch     7] loss: 3.53565\n",
      "[epoch 445, batch     8] loss: 3.58962\n",
      "[epoch 445, batch     9] loss: 2.24883\n",
      "[epoch 445, batch    10] loss: 2.78585\n",
      "[epoch 445, batch    11] loss: 3.30005\n",
      "[epoch 445, batch    12] loss: 3.72254\n",
      "[epoch 445, batch    13] loss: 2.66303\n",
      "[epoch 445, batch    14] loss: 1.52748\n",
      "[epoch 445, batch    15] loss: 2.81449\n",
      "[epoch 445, batch    16] loss: 2.46715\n",
      "[epoch 445, batch    17] loss: 2.94397\n",
      "[epoch 445, batch    18] loss: 3.34206\n",
      "[epoch 445, batch    19] loss: 3.53219\n",
      "[epoch 445, batch    20] loss: 2.49757\n",
      "[epoch 445, batch    21] loss: 1.90710\n",
      "[epoch 445, batch    22] loss: 3.62336\n",
      "[epoch 445, batch    23] loss: 3.90568\n",
      "[epoch 445, batch    24] loss: 2.77031\n",
      "[epoch 445, batch    25] loss: 2.64223\n",
      "[epoch 445, batch    26] loss: 2.75176\n",
      "[epoch 445, batch    27] loss: 3.24913\n",
      "[epoch 445, batch    28] loss: 3.29384\n",
      "[epoch 445, batch    29] loss: 3.67808\n",
      "[epoch 445, batch    30] loss: 3.00030\n",
      "[epoch 445, batch    31] loss: 2.93854\n",
      "[epoch 445, batch    32] loss: 3.35655\n",
      "[epoch 446, batch     1] loss: 2.86416\n",
      "[epoch 446, batch     2] loss: 3.85310\n",
      "[epoch 446, batch     3] loss: 2.91665\n",
      "[epoch 446, batch     4] loss: 3.00968\n",
      "[epoch 446, batch     5] loss: 2.62526\n",
      "[epoch 446, batch     6] loss: 3.14046\n",
      "[epoch 446, batch     7] loss: 3.07730\n",
      "[epoch 446, batch     8] loss: 3.29580\n",
      "[epoch 446, batch     9] loss: 3.19877\n",
      "[epoch 446, batch    10] loss: 1.97956\n",
      "[epoch 446, batch    11] loss: 3.48228\n",
      "[epoch 446, batch    12] loss: 3.80754\n",
      "[epoch 446, batch    13] loss: 2.64849\n",
      "[epoch 446, batch    14] loss: 2.77064\n",
      "[epoch 446, batch    15] loss: 2.90449\n",
      "[epoch 446, batch    16] loss: 3.28024\n",
      "[epoch 446, batch    17] loss: 2.64261\n",
      "[epoch 446, batch    18] loss: 2.89337\n",
      "[epoch 446, batch    19] loss: 3.52688\n",
      "[epoch 446, batch    20] loss: 3.13471\n",
      "[epoch 446, batch    21] loss: 2.98793\n",
      "[epoch 446, batch    22] loss: 2.92611\n",
      "[epoch 446, batch    23] loss: 2.61054\n",
      "[epoch 446, batch    24] loss: 3.81266\n",
      "[epoch 446, batch    25] loss: 3.27028\n",
      "[epoch 446, batch    26] loss: 3.74540\n",
      "[epoch 446, batch    27] loss: 2.31075\n",
      "[epoch 446, batch    28] loss: 3.32622\n",
      "[epoch 446, batch    29] loss: 2.92503\n",
      "[epoch 446, batch    30] loss: 2.93538\n",
      "[epoch 446, batch    31] loss: 2.51868\n",
      "[epoch 446, batch    32] loss: 1.78854\n",
      "[epoch 447, batch     1] loss: 3.53001\n",
      "[epoch 447, batch     2] loss: 3.35828\n",
      "[epoch 447, batch     3] loss: 2.21231\n",
      "[epoch 447, batch     4] loss: 3.13292\n",
      "[epoch 447, batch     5] loss: 3.34733\n",
      "[epoch 447, batch     6] loss: 3.15247\n",
      "[epoch 447, batch     7] loss: 3.23525\n",
      "[epoch 447, batch     8] loss: 3.00404\n",
      "[epoch 447, batch     9] loss: 2.74322\n",
      "[epoch 447, batch    10] loss: 2.87042\n",
      "[epoch 447, batch    11] loss: 3.52766\n",
      "[epoch 447, batch    12] loss: 2.65326\n",
      "[epoch 447, batch    13] loss: 3.58534\n",
      "[epoch 447, batch    14] loss: 2.76770\n",
      "[epoch 447, batch    15] loss: 3.44065\n",
      "[epoch 447, batch    16] loss: 3.15992\n",
      "[epoch 447, batch    17] loss: 2.93771\n",
      "[epoch 447, batch    18] loss: 2.71972\n",
      "[epoch 447, batch    19] loss: 2.76748\n",
      "[epoch 447, batch    20] loss: 3.09977\n",
      "[epoch 447, batch    21] loss: 3.40350\n",
      "[epoch 447, batch    22] loss: 2.79638\n",
      "[epoch 447, batch    23] loss: 3.13661\n",
      "[epoch 447, batch    24] loss: 3.37630\n",
      "[epoch 447, batch    25] loss: 2.96139\n",
      "[epoch 447, batch    26] loss: 2.75628\n",
      "[epoch 447, batch    27] loss: 2.97297\n",
      "[epoch 447, batch    28] loss: 3.73627\n",
      "[epoch 447, batch    29] loss: 2.84505\n",
      "[epoch 447, batch    30] loss: 2.85077\n",
      "[epoch 447, batch    31] loss: 2.28913\n",
      "[epoch 447, batch    32] loss: 1.66993\n",
      "[epoch 448, batch     1] loss: 3.07795\n",
      "[epoch 448, batch     2] loss: 3.62392\n",
      "[epoch 448, batch     3] loss: 3.17407\n",
      "[epoch 448, batch     4] loss: 3.40156\n",
      "[epoch 448, batch     5] loss: 3.13628\n",
      "[epoch 448, batch     6] loss: 2.76580\n",
      "[epoch 448, batch     7] loss: 2.68189\n",
      "[epoch 448, batch     8] loss: 4.21273\n",
      "[epoch 448, batch     9] loss: 2.69786\n",
      "[epoch 448, batch    10] loss: 2.81279\n",
      "[epoch 448, batch    11] loss: 3.84055\n",
      "[epoch 448, batch    12] loss: 2.46168\n",
      "[epoch 448, batch    13] loss: 2.58246\n",
      "[epoch 448, batch    14] loss: 3.29480\n",
      "[epoch 448, batch    15] loss: 3.32725\n",
      "[epoch 448, batch    16] loss: 2.74683\n",
      "[epoch 448, batch    17] loss: 3.55667\n",
      "[epoch 448, batch    18] loss: 2.47379\n",
      "[epoch 448, batch    19] loss: 3.46146\n",
      "[epoch 448, batch    20] loss: 2.29302\n",
      "[epoch 448, batch    21] loss: 3.43618\n",
      "[epoch 448, batch    22] loss: 2.86004\n",
      "[epoch 448, batch    23] loss: 2.33301\n",
      "[epoch 448, batch    24] loss: 3.42371\n",
      "[epoch 448, batch    25] loss: 2.41170\n",
      "[epoch 448, batch    26] loss: 3.27879\n",
      "[epoch 448, batch    27] loss: 3.61401\n",
      "[epoch 448, batch    28] loss: 2.94432\n",
      "[epoch 448, batch    29] loss: 2.69155\n",
      "[epoch 448, batch    30] loss: 2.82191\n",
      "[epoch 448, batch    31] loss: 2.39932\n",
      "[epoch 448, batch    32] loss: 5.44830\n",
      "[epoch 449, batch     1] loss: 3.81193\n",
      "[epoch 449, batch     2] loss: 3.12137\n",
      "[epoch 449, batch     3] loss: 2.76174\n",
      "[epoch 449, batch     4] loss: 2.93325\n",
      "[epoch 449, batch     5] loss: 3.12323\n",
      "[epoch 449, batch     6] loss: 2.89286\n",
      "[epoch 449, batch     7] loss: 2.77968\n",
      "[epoch 449, batch     8] loss: 2.93829\n",
      "[epoch 449, batch     9] loss: 2.45015\n",
      "[epoch 449, batch    10] loss: 3.11285\n",
      "[epoch 449, batch    11] loss: 3.48445\n",
      "[epoch 449, batch    12] loss: 2.97488\n",
      "[epoch 449, batch    13] loss: 2.34320\n",
      "[epoch 449, batch    14] loss: 3.23761\n",
      "[epoch 449, batch    15] loss: 2.61170\n",
      "[epoch 449, batch    16] loss: 3.84400\n",
      "[epoch 449, batch    17] loss: 3.11918\n",
      "[epoch 449, batch    18] loss: 3.56923\n",
      "[epoch 449, batch    19] loss: 2.59575\n",
      "[epoch 449, batch    20] loss: 3.08661\n",
      "[epoch 449, batch    21] loss: 2.87151\n",
      "[epoch 449, batch    22] loss: 3.78395\n",
      "[epoch 449, batch    23] loss: 3.14358\n",
      "[epoch 449, batch    24] loss: 2.51460\n",
      "[epoch 449, batch    25] loss: 2.72243\n",
      "[epoch 449, batch    26] loss: 2.89732\n",
      "[epoch 449, batch    27] loss: 3.39148\n",
      "[epoch 449, batch    28] loss: 2.15251\n",
      "[epoch 449, batch    29] loss: 3.38268\n",
      "[epoch 449, batch    30] loss: 3.30470\n",
      "[epoch 449, batch    31] loss: 3.66687\n",
      "[epoch 449, batch    32] loss: 3.55255\n",
      "[epoch 450, batch     1] loss: 2.60149\n",
      "[epoch 450, batch     2] loss: 2.81942\n",
      "[epoch 450, batch     3] loss: 2.83715\n",
      "[epoch 450, batch     4] loss: 2.72381\n",
      "[epoch 450, batch     5] loss: 2.89551\n",
      "[epoch 450, batch     6] loss: 3.38248\n",
      "[epoch 450, batch     7] loss: 3.32464\n",
      "[epoch 450, batch     8] loss: 3.05954\n",
      "[epoch 450, batch     9] loss: 3.27393\n",
      "[epoch 450, batch    10] loss: 2.60062\n",
      "[epoch 450, batch    11] loss: 2.61149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 450, batch    12] loss: 2.64550\n",
      "[epoch 450, batch    13] loss: 3.04840\n",
      "[epoch 450, batch    14] loss: 3.45185\n",
      "[epoch 450, batch    15] loss: 3.35238\n",
      "[epoch 450, batch    16] loss: 2.26765\n",
      "[epoch 450, batch    17] loss: 3.03233\n",
      "[epoch 450, batch    18] loss: 2.48566\n",
      "[epoch 450, batch    19] loss: 3.25094\n",
      "[epoch 450, batch    20] loss: 3.83641\n",
      "[epoch 450, batch    21] loss: 3.41055\n",
      "[epoch 450, batch    22] loss: 3.04248\n",
      "[epoch 450, batch    23] loss: 3.82049\n",
      "[epoch 450, batch    24] loss: 3.62940\n",
      "[epoch 450, batch    25] loss: 3.21790\n",
      "[epoch 450, batch    26] loss: 2.90460\n",
      "[epoch 450, batch    27] loss: 2.75064\n",
      "[epoch 450, batch    28] loss: 3.61375\n",
      "[epoch 450, batch    29] loss: 2.31760\n",
      "[epoch 450, batch    30] loss: 2.47271\n",
      "[epoch 450, batch    31] loss: 3.08910\n",
      "[epoch 450, batch    32] loss: 3.51108\n",
      "[epoch 451, batch     1] loss: 2.53262\n",
      "[epoch 451, batch     2] loss: 3.04184\n",
      "[epoch 451, batch     3] loss: 2.91237\n",
      "[epoch 451, batch     4] loss: 3.03903\n",
      "[epoch 451, batch     5] loss: 2.61546\n",
      "[epoch 451, batch     6] loss: 2.43524\n",
      "[epoch 451, batch     7] loss: 2.69882\n",
      "[epoch 451, batch     8] loss: 3.07674\n",
      "[epoch 451, batch     9] loss: 2.80509\n",
      "[epoch 451, batch    10] loss: 3.43300\n",
      "[epoch 451, batch    11] loss: 3.08554\n",
      "[epoch 451, batch    12] loss: 2.99991\n",
      "[epoch 451, batch    13] loss: 3.50795\n",
      "[epoch 451, batch    14] loss: 2.98888\n",
      "[epoch 451, batch    15] loss: 3.31079\n",
      "[epoch 451, batch    16] loss: 2.58771\n",
      "[epoch 451, batch    17] loss: 3.80585\n",
      "[epoch 451, batch    18] loss: 3.34179\n",
      "[epoch 451, batch    19] loss: 3.42608\n",
      "[epoch 451, batch    20] loss: 3.51673\n",
      "[epoch 451, batch    21] loss: 2.24675\n",
      "[epoch 451, batch    22] loss: 2.70340\n",
      "[epoch 451, batch    23] loss: 3.35094\n",
      "[epoch 451, batch    24] loss: 3.06387\n",
      "[epoch 451, batch    25] loss: 2.91508\n",
      "[epoch 451, batch    26] loss: 3.15482\n",
      "[epoch 451, batch    27] loss: 3.46372\n",
      "[epoch 451, batch    28] loss: 3.12258\n",
      "[epoch 451, batch    29] loss: 3.41481\n",
      "[epoch 451, batch    30] loss: 2.73315\n",
      "[epoch 451, batch    31] loss: 2.57109\n",
      "[epoch 451, batch    32] loss: 3.65668\n",
      "[epoch 452, batch     1] loss: 3.16364\n",
      "[epoch 452, batch     2] loss: 2.86766\n",
      "[epoch 452, batch     3] loss: 3.07282\n",
      "[epoch 452, batch     4] loss: 3.33657\n",
      "[epoch 452, batch     5] loss: 3.38927\n",
      "[epoch 452, batch     6] loss: 3.31608\n",
      "[epoch 452, batch     7] loss: 2.65081\n",
      "[epoch 452, batch     8] loss: 2.44219\n",
      "[epoch 452, batch     9] loss: 3.02921\n",
      "[epoch 452, batch    10] loss: 3.48016\n",
      "[epoch 452, batch    11] loss: 2.70438\n",
      "[epoch 452, batch    12] loss: 3.01965\n",
      "[epoch 452, batch    13] loss: 3.02562\n",
      "[epoch 452, batch    14] loss: 3.72384\n",
      "[epoch 452, batch    15] loss: 3.12205\n",
      "[epoch 452, batch    16] loss: 2.40148\n",
      "[epoch 452, batch    17] loss: 2.80814\n",
      "[epoch 452, batch    18] loss: 3.01649\n",
      "[epoch 452, batch    19] loss: 2.73836\n",
      "[epoch 452, batch    20] loss: 3.27448\n",
      "[epoch 452, batch    21] loss: 3.00596\n",
      "[epoch 452, batch    22] loss: 3.56351\n",
      "[epoch 452, batch    23] loss: 2.97504\n",
      "[epoch 452, batch    24] loss: 3.15937\n",
      "[epoch 452, batch    25] loss: 3.09379\n",
      "[epoch 452, batch    26] loss: 2.53765\n",
      "[epoch 452, batch    27] loss: 3.37219\n",
      "[epoch 452, batch    28] loss: 3.32194\n",
      "[epoch 452, batch    29] loss: 3.00341\n",
      "[epoch 452, batch    30] loss: 2.96768\n",
      "[epoch 452, batch    31] loss: 2.61415\n",
      "[epoch 452, batch    32] loss: 1.50971\n",
      "[epoch 453, batch     1] loss: 2.85232\n",
      "[epoch 453, batch     2] loss: 3.97251\n",
      "[epoch 453, batch     3] loss: 2.86946\n",
      "[epoch 453, batch     4] loss: 3.22410\n",
      "[epoch 453, batch     5] loss: 3.11960\n",
      "[epoch 453, batch     6] loss: 2.52486\n",
      "[epoch 453, batch     7] loss: 2.92875\n",
      "[epoch 453, batch     8] loss: 2.21311\n",
      "[epoch 453, batch     9] loss: 2.29074\n",
      "[epoch 453, batch    10] loss: 2.68290\n",
      "[epoch 453, batch    11] loss: 3.01754\n",
      "[epoch 453, batch    12] loss: 2.63654\n",
      "[epoch 453, batch    13] loss: 2.50318\n",
      "[epoch 453, batch    14] loss: 3.76813\n",
      "[epoch 453, batch    15] loss: 3.50661\n",
      "[epoch 453, batch    16] loss: 3.88726\n",
      "[epoch 453, batch    17] loss: 3.10912\n",
      "[epoch 453, batch    18] loss: 3.09584\n",
      "[epoch 453, batch    19] loss: 2.60701\n",
      "[epoch 453, batch    20] loss: 3.64103\n",
      "[epoch 453, batch    21] loss: 3.33840\n",
      "[epoch 453, batch    22] loss: 3.03939\n",
      "[epoch 453, batch    23] loss: 2.79319\n",
      "[epoch 453, batch    24] loss: 3.33587\n",
      "[epoch 453, batch    25] loss: 3.22362\n",
      "[epoch 453, batch    26] loss: 3.40799\n",
      "[epoch 453, batch    27] loss: 2.32384\n",
      "[epoch 453, batch    28] loss: 2.77233\n",
      "[epoch 453, batch    29] loss: 3.04107\n",
      "[epoch 453, batch    30] loss: 3.31168\n",
      "[epoch 453, batch    31] loss: 3.18154\n",
      "[epoch 453, batch    32] loss: 3.30832\n",
      "[epoch 454, batch     1] loss: 2.70475\n",
      "[epoch 454, batch     2] loss: 3.01595\n",
      "[epoch 454, batch     3] loss: 3.21814\n",
      "[epoch 454, batch     4] loss: 3.41220\n",
      "[epoch 454, batch     5] loss: 3.10119\n",
      "[epoch 454, batch     6] loss: 3.78052\n",
      "[epoch 454, batch     7] loss: 2.83049\n",
      "[epoch 454, batch     8] loss: 2.60977\n",
      "[epoch 454, batch     9] loss: 3.01789\n",
      "[epoch 454, batch    10] loss: 3.25150\n",
      "[epoch 454, batch    11] loss: 4.06488\n",
      "[epoch 454, batch    12] loss: 2.78935\n",
      "[epoch 454, batch    13] loss: 2.79647\n",
      "[epoch 454, batch    14] loss: 3.19122\n",
      "[epoch 454, batch    15] loss: 2.38372\n",
      "[epoch 454, batch    16] loss: 3.40130\n",
      "[epoch 454, batch    17] loss: 2.18817\n",
      "[epoch 454, batch    18] loss: 2.84607\n",
      "[epoch 454, batch    19] loss: 2.70245\n",
      "[epoch 454, batch    20] loss: 3.24187\n",
      "[epoch 454, batch    21] loss: 3.05163\n",
      "[epoch 454, batch    22] loss: 2.43653\n",
      "[epoch 454, batch    23] loss: 3.00507\n",
      "[epoch 454, batch    24] loss: 3.73719\n",
      "[epoch 454, batch    25] loss: 3.15038\n",
      "[epoch 454, batch    26] loss: 2.96045\n",
      "[epoch 454, batch    27] loss: 3.09457\n",
      "[epoch 454, batch    28] loss: 3.34879\n",
      "[epoch 454, batch    29] loss: 3.40614\n",
      "[epoch 454, batch    30] loss: 2.78070\n",
      "[epoch 454, batch    31] loss: 2.60644\n",
      "[epoch 454, batch    32] loss: 3.27428\n",
      "[epoch 455, batch     1] loss: 3.97293\n",
      "[epoch 455, batch     2] loss: 2.44809\n",
      "[epoch 455, batch     3] loss: 3.74963\n",
      "[epoch 455, batch     4] loss: 2.43102\n",
      "[epoch 455, batch     5] loss: 3.77229\n",
      "[epoch 455, batch     6] loss: 3.33452\n",
      "[epoch 455, batch     7] loss: 2.75959\n",
      "[epoch 455, batch     8] loss: 4.14330\n",
      "[epoch 455, batch     9] loss: 2.69763\n",
      "[epoch 455, batch    10] loss: 2.74270\n",
      "[epoch 455, batch    11] loss: 3.09184\n",
      "[epoch 455, batch    12] loss: 3.78086\n",
      "[epoch 455, batch    13] loss: 2.61358\n",
      "[epoch 455, batch    14] loss: 2.81474\n",
      "[epoch 455, batch    15] loss: 2.86053\n",
      "[epoch 455, batch    16] loss: 2.39177\n",
      "[epoch 455, batch    17] loss: 2.53283\n",
      "[epoch 455, batch    18] loss: 2.32791\n",
      "[epoch 455, batch    19] loss: 2.90279\n",
      "[epoch 455, batch    20] loss: 2.89956\n",
      "[epoch 455, batch    21] loss: 3.59903\n",
      "[epoch 455, batch    22] loss: 3.39879\n",
      "[epoch 455, batch    23] loss: 3.14341\n",
      "[epoch 455, batch    24] loss: 3.79406\n",
      "[epoch 455, batch    25] loss: 2.82558\n",
      "[epoch 455, batch    26] loss: 3.20314\n",
      "[epoch 455, batch    27] loss: 2.81394\n",
      "[epoch 455, batch    28] loss: 2.06984\n",
      "[epoch 455, batch    29] loss: 2.99277\n",
      "[epoch 455, batch    30] loss: 3.72586\n",
      "[epoch 455, batch    31] loss: 2.71558\n",
      "[epoch 455, batch    32] loss: 2.66249\n",
      "[epoch 456, batch     1] loss: 4.23721\n",
      "[epoch 456, batch     2] loss: 3.06591\n",
      "[epoch 456, batch     3] loss: 3.75094\n",
      "[epoch 456, batch     4] loss: 3.50981\n",
      "[epoch 456, batch     5] loss: 4.27168\n",
      "[epoch 456, batch     6] loss: 2.55224\n",
      "[epoch 456, batch     7] loss: 3.03798\n",
      "[epoch 456, batch     8] loss: 3.30930\n",
      "[epoch 456, batch     9] loss: 3.27542\n",
      "[epoch 456, batch    10] loss: 3.16766\n",
      "[epoch 456, batch    11] loss: 2.94078\n",
      "[epoch 456, batch    12] loss: 3.07849\n",
      "[epoch 456, batch    13] loss: 2.98075\n",
      "[epoch 456, batch    14] loss: 3.50497\n",
      "[epoch 456, batch    15] loss: 2.78784\n",
      "[epoch 456, batch    16] loss: 3.09431\n",
      "[epoch 456, batch    17] loss: 1.48566\n",
      "[epoch 456, batch    18] loss: 2.63522\n",
      "[epoch 456, batch    19] loss: 3.10578\n",
      "[epoch 456, batch    20] loss: 2.51457\n",
      "[epoch 456, batch    21] loss: 2.76274\n",
      "[epoch 456, batch    22] loss: 3.22499\n",
      "[epoch 456, batch    23] loss: 2.57368\n",
      "[epoch 456, batch    24] loss: 3.12448\n",
      "[epoch 456, batch    25] loss: 3.08037\n",
      "[epoch 456, batch    26] loss: 2.59240\n",
      "[epoch 456, batch    27] loss: 3.26024\n",
      "[epoch 456, batch    28] loss: 3.28098\n",
      "[epoch 456, batch    29] loss: 2.72837\n",
      "[epoch 456, batch    30] loss: 2.35770\n",
      "[epoch 456, batch    31] loss: 3.27128\n",
      "[epoch 456, batch    32] loss: 1.68128\n",
      "[epoch 457, batch     1] loss: 2.03576\n",
      "[epoch 457, batch     2] loss: 3.15735\n",
      "[epoch 457, batch     3] loss: 2.78963\n",
      "[epoch 457, batch     4] loss: 3.57144\n",
      "[epoch 457, batch     5] loss: 2.70193\n",
      "[epoch 457, batch     6] loss: 3.79475\n",
      "[epoch 457, batch     7] loss: 2.47062\n",
      "[epoch 457, batch     8] loss: 2.65182\n",
      "[epoch 457, batch     9] loss: 3.73971\n",
      "[epoch 457, batch    10] loss: 2.88631\n",
      "[epoch 457, batch    11] loss: 2.87448\n",
      "[epoch 457, batch    12] loss: 2.84849\n",
      "[epoch 457, batch    13] loss: 2.38243\n",
      "[epoch 457, batch    14] loss: 4.20403\n",
      "[epoch 457, batch    15] loss: 2.54244\n",
      "[epoch 457, batch    16] loss: 2.97609\n",
      "[epoch 457, batch    17] loss: 3.11889\n",
      "[epoch 457, batch    18] loss: 2.44408\n",
      "[epoch 457, batch    19] loss: 3.71163\n",
      "[epoch 457, batch    20] loss: 2.81710\n",
      "[epoch 457, batch    21] loss: 3.55247\n",
      "[epoch 457, batch    22] loss: 3.16594\n",
      "[epoch 457, batch    23] loss: 2.53535\n",
      "[epoch 457, batch    24] loss: 3.00741\n",
      "[epoch 457, batch    25] loss: 3.15826\n",
      "[epoch 457, batch    26] loss: 2.46677\n",
      "[epoch 457, batch    27] loss: 3.60512\n",
      "[epoch 457, batch    28] loss: 2.68323\n",
      "[epoch 457, batch    29] loss: 4.14104\n",
      "[epoch 457, batch    30] loss: 2.61485\n",
      "[epoch 457, batch    31] loss: 2.93943\n",
      "[epoch 457, batch    32] loss: 4.37021\n",
      "[epoch 458, batch     1] loss: 3.30721\n",
      "[epoch 458, batch     2] loss: 2.86115\n",
      "[epoch 458, batch     3] loss: 3.51531\n",
      "[epoch 458, batch     4] loss: 3.44539\n",
      "[epoch 458, batch     5] loss: 3.46181\n",
      "[epoch 458, batch     6] loss: 3.84993\n",
      "[epoch 458, batch     7] loss: 2.97865\n",
      "[epoch 458, batch     8] loss: 2.59228\n",
      "[epoch 458, batch     9] loss: 3.51138\n",
      "[epoch 458, batch    10] loss: 3.70715\n",
      "[epoch 458, batch    11] loss: 1.89769\n",
      "[epoch 458, batch    12] loss: 3.63110\n",
      "[epoch 458, batch    13] loss: 2.95535\n",
      "[epoch 458, batch    14] loss: 2.77331\n",
      "[epoch 458, batch    15] loss: 3.27551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 458, batch    16] loss: 3.08325\n",
      "[epoch 458, batch    17] loss: 2.86090\n",
      "[epoch 458, batch    18] loss: 2.89396\n",
      "[epoch 458, batch    19] loss: 3.22258\n",
      "[epoch 458, batch    20] loss: 3.30653\n",
      "[epoch 458, batch    21] loss: 3.00773\n",
      "[epoch 458, batch    22] loss: 2.82753\n",
      "[epoch 458, batch    23] loss: 2.06934\n",
      "[epoch 458, batch    24] loss: 2.31729\n",
      "[epoch 458, batch    25] loss: 2.72329\n",
      "[epoch 458, batch    26] loss: 2.91648\n",
      "[epoch 458, batch    27] loss: 2.37566\n",
      "[epoch 458, batch    28] loss: 3.64262\n",
      "[epoch 458, batch    29] loss: 3.59436\n",
      "[epoch 458, batch    30] loss: 3.58225\n",
      "[epoch 458, batch    31] loss: 2.59449\n",
      "[epoch 458, batch    32] loss: 2.17799\n",
      "[epoch 459, batch     1] loss: 3.18817\n",
      "[epoch 459, batch     2] loss: 3.51225\n",
      "[epoch 459, batch     3] loss: 2.77979\n",
      "[epoch 459, batch     4] loss: 3.21148\n",
      "[epoch 459, batch     5] loss: 3.27593\n",
      "[epoch 459, batch     6] loss: 3.27842\n",
      "[epoch 459, batch     7] loss: 2.56845\n",
      "[epoch 459, batch     8] loss: 2.42463\n",
      "[epoch 459, batch     9] loss: 2.97914\n",
      "[epoch 459, batch    10] loss: 2.66475\n",
      "[epoch 459, batch    11] loss: 3.07657\n",
      "[epoch 459, batch    12] loss: 3.06738\n",
      "[epoch 459, batch    13] loss: 2.83847\n",
      "[epoch 459, batch    14] loss: 3.21366\n",
      "[epoch 459, batch    15] loss: 3.60069\n",
      "[epoch 459, batch    16] loss: 2.92826\n",
      "[epoch 459, batch    17] loss: 3.24718\n",
      "[epoch 459, batch    18] loss: 2.90703\n",
      "[epoch 459, batch    19] loss: 3.36710\n",
      "[epoch 459, batch    20] loss: 2.92428\n",
      "[epoch 459, batch    21] loss: 3.86466\n",
      "[epoch 459, batch    22] loss: 2.31966\n",
      "[epoch 459, batch    23] loss: 2.69736\n",
      "[epoch 459, batch    24] loss: 3.43996\n",
      "[epoch 459, batch    25] loss: 2.53654\n",
      "[epoch 459, batch    26] loss: 3.06017\n",
      "[epoch 459, batch    27] loss: 4.12981\n",
      "[epoch 459, batch    28] loss: 2.48643\n",
      "[epoch 459, batch    29] loss: 3.62424\n",
      "[epoch 459, batch    30] loss: 2.64646\n",
      "[epoch 459, batch    31] loss: 2.21777\n",
      "[epoch 459, batch    32] loss: 3.35396\n",
      "[epoch 460, batch     1] loss: 3.75232\n",
      "[epoch 460, batch     2] loss: 3.08595\n",
      "[epoch 460, batch     3] loss: 2.68142\n",
      "[epoch 460, batch     4] loss: 3.37889\n",
      "[epoch 460, batch     5] loss: 3.47891\n",
      "[epoch 460, batch     6] loss: 2.49590\n",
      "[epoch 460, batch     7] loss: 2.15004\n",
      "[epoch 460, batch     8] loss: 2.77504\n",
      "[epoch 460, batch     9] loss: 3.40746\n",
      "[epoch 460, batch    10] loss: 3.37591\n",
      "[epoch 460, batch    11] loss: 2.22223\n",
      "[epoch 460, batch    12] loss: 3.03597\n",
      "[epoch 460, batch    13] loss: 2.48222\n",
      "[epoch 460, batch    14] loss: 2.71673\n",
      "[epoch 460, batch    15] loss: 3.54825\n",
      "[epoch 460, batch    16] loss: 3.40885\n",
      "[epoch 460, batch    17] loss: 2.96507\n",
      "[epoch 460, batch    18] loss: 2.32174\n",
      "[epoch 460, batch    19] loss: 3.12982\n",
      "[epoch 460, batch    20] loss: 2.74624\n",
      "[epoch 460, batch    21] loss: 3.34837\n",
      "[epoch 460, batch    22] loss: 3.34405\n",
      "[epoch 460, batch    23] loss: 3.54659\n",
      "[epoch 460, batch    24] loss: 3.34261\n",
      "[epoch 460, batch    25] loss: 3.09323\n",
      "[epoch 460, batch    26] loss: 3.00207\n",
      "[epoch 460, batch    27] loss: 3.31299\n",
      "[epoch 460, batch    28] loss: 3.01909\n",
      "[epoch 460, batch    29] loss: 2.86101\n",
      "[epoch 460, batch    30] loss: 3.15752\n",
      "[epoch 460, batch    31] loss: 3.13593\n",
      "[epoch 460, batch    32] loss: 3.38110\n",
      "[epoch 461, batch     1] loss: 3.19507\n",
      "[epoch 461, batch     2] loss: 3.27929\n",
      "[epoch 461, batch     3] loss: 3.81368\n",
      "[epoch 461, batch     4] loss: 3.66914\n",
      "[epoch 461, batch     5] loss: 3.52436\n",
      "[epoch 461, batch     6] loss: 2.31706\n",
      "[epoch 461, batch     7] loss: 3.33278\n",
      "[epoch 461, batch     8] loss: 3.35951\n",
      "[epoch 461, batch     9] loss: 2.95781\n",
      "[epoch 461, batch    10] loss: 2.31372\n",
      "[epoch 461, batch    11] loss: 3.01970\n",
      "[epoch 461, batch    12] loss: 2.85799\n",
      "[epoch 461, batch    13] loss: 3.32619\n",
      "[epoch 461, batch    14] loss: 2.87586\n",
      "[epoch 461, batch    15] loss: 3.10583\n",
      "[epoch 461, batch    16] loss: 2.73290\n",
      "[epoch 461, batch    17] loss: 2.95515\n",
      "[epoch 461, batch    18] loss: 3.09494\n",
      "[epoch 461, batch    19] loss: 2.31433\n",
      "[epoch 461, batch    20] loss: 3.23863\n",
      "[epoch 461, batch    21] loss: 2.39687\n",
      "[epoch 461, batch    22] loss: 3.36839\n",
      "[epoch 461, batch    23] loss: 2.70922\n",
      "[epoch 461, batch    24] loss: 3.19519\n",
      "[epoch 461, batch    25] loss: 2.72321\n",
      "[epoch 461, batch    26] loss: 3.66535\n",
      "[epoch 461, batch    27] loss: 3.57652\n",
      "[epoch 461, batch    28] loss: 2.26496\n",
      "[epoch 461, batch    29] loss: 2.17452\n",
      "[epoch 461, batch    30] loss: 3.83128\n",
      "[epoch 461, batch    31] loss: 3.07863\n",
      "[epoch 461, batch    32] loss: 4.14266\n",
      "[epoch 462, batch     1] loss: 3.09824\n",
      "[epoch 462, batch     2] loss: 3.05709\n",
      "[epoch 462, batch     3] loss: 2.30966\n",
      "[epoch 462, batch     4] loss: 3.57059\n",
      "[epoch 462, batch     5] loss: 2.53247\n",
      "[epoch 462, batch     6] loss: 3.13251\n",
      "[epoch 462, batch     7] loss: 3.14027\n",
      "[epoch 462, batch     8] loss: 2.41992\n",
      "[epoch 462, batch     9] loss: 3.81696\n",
      "[epoch 462, batch    10] loss: 2.90124\n",
      "[epoch 462, batch    11] loss: 3.64637\n",
      "[epoch 462, batch    12] loss: 2.91061\n",
      "[epoch 462, batch    13] loss: 2.69512\n",
      "[epoch 462, batch    14] loss: 3.36063\n",
      "[epoch 462, batch    15] loss: 3.22769\n",
      "[epoch 462, batch    16] loss: 2.47670\n",
      "[epoch 462, batch    17] loss: 2.87369\n",
      "[epoch 462, batch    18] loss: 3.50981\n",
      "[epoch 462, batch    19] loss: 3.24493\n",
      "[epoch 462, batch    20] loss: 3.48437\n",
      "[epoch 462, batch    21] loss: 2.43880\n",
      "[epoch 462, batch    22] loss: 2.90774\n",
      "[epoch 462, batch    23] loss: 2.98841\n",
      "[epoch 462, batch    24] loss: 2.59045\n",
      "[epoch 462, batch    25] loss: 3.14183\n",
      "[epoch 462, batch    26] loss: 3.33497\n",
      "[epoch 462, batch    27] loss: 2.98747\n",
      "[epoch 462, batch    28] loss: 3.39884\n",
      "[epoch 462, batch    29] loss: 2.63241\n",
      "[epoch 462, batch    30] loss: 3.19969\n",
      "[epoch 462, batch    31] loss: 3.03454\n",
      "[epoch 462, batch    32] loss: 3.73693\n",
      "[epoch 463, batch     1] loss: 3.37807\n",
      "[epoch 463, batch     2] loss: 3.66428\n",
      "[epoch 463, batch     3] loss: 3.09739\n",
      "[epoch 463, batch     4] loss: 3.28966\n",
      "[epoch 463, batch     5] loss: 2.51441\n",
      "[epoch 463, batch     6] loss: 3.09852\n",
      "[epoch 463, batch     7] loss: 2.99732\n",
      "[epoch 463, batch     8] loss: 3.34267\n",
      "[epoch 463, batch     9] loss: 2.57458\n",
      "[epoch 463, batch    10] loss: 3.42042\n",
      "[epoch 463, batch    11] loss: 2.82205\n",
      "[epoch 463, batch    12] loss: 2.62700\n",
      "[epoch 463, batch    13] loss: 2.47885\n",
      "[epoch 463, batch    14] loss: 2.69700\n",
      "[epoch 463, batch    15] loss: 3.25188\n",
      "[epoch 463, batch    16] loss: 2.40483\n",
      "[epoch 463, batch    17] loss: 4.15604\n",
      "[epoch 463, batch    18] loss: 2.96482\n",
      "[epoch 463, batch    19] loss: 2.73611\n",
      "[epoch 463, batch    20] loss: 3.27037\n",
      "[epoch 463, batch    21] loss: 2.46143\n",
      "[epoch 463, batch    22] loss: 3.44509\n",
      "[epoch 463, batch    23] loss: 2.81083\n",
      "[epoch 463, batch    24] loss: 3.02388\n",
      "[epoch 463, batch    25] loss: 2.77891\n",
      "[epoch 463, batch    26] loss: 2.62582\n",
      "[epoch 463, batch    27] loss: 3.34441\n",
      "[epoch 463, batch    28] loss: 2.73321\n",
      "[epoch 463, batch    29] loss: 3.23109\n",
      "[epoch 463, batch    30] loss: 3.43100\n",
      "[epoch 463, batch    31] loss: 3.58371\n",
      "[epoch 463, batch    32] loss: 3.72240\n",
      "[epoch 464, batch     1] loss: 2.63438\n",
      "[epoch 464, batch     2] loss: 4.52258\n",
      "[epoch 464, batch     3] loss: 3.42880\n",
      "[epoch 464, batch     4] loss: 2.66514\n",
      "[epoch 464, batch     5] loss: 3.97412\n",
      "[epoch 464, batch     6] loss: 3.24887\n",
      "[epoch 464, batch     7] loss: 2.90593\n",
      "[epoch 464, batch     8] loss: 3.09371\n",
      "[epoch 464, batch     9] loss: 3.14098\n",
      "[epoch 464, batch    10] loss: 3.68029\n",
      "[epoch 464, batch    11] loss: 2.46952\n",
      "[epoch 464, batch    12] loss: 3.34939\n",
      "[epoch 464, batch    13] loss: 3.16536\n",
      "[epoch 464, batch    14] loss: 2.70024\n",
      "[epoch 464, batch    15] loss: 2.96012\n",
      "[epoch 464, batch    16] loss: 2.92115\n",
      "[epoch 464, batch    17] loss: 3.13073\n",
      "[epoch 464, batch    18] loss: 2.83198\n",
      "[epoch 464, batch    19] loss: 3.25165\n",
      "[epoch 464, batch    20] loss: 2.76844\n",
      "[epoch 464, batch    21] loss: 3.20623\n",
      "[epoch 464, batch    22] loss: 2.90356\n",
      "[epoch 464, batch    23] loss: 3.03300\n",
      "[epoch 464, batch    24] loss: 2.55467\n",
      "[epoch 464, batch    25] loss: 3.16189\n",
      "[epoch 464, batch    26] loss: 2.61780\n",
      "[epoch 464, batch    27] loss: 2.86473\n",
      "[epoch 464, batch    28] loss: 2.09900\n",
      "[epoch 464, batch    29] loss: 2.13040\n",
      "[epoch 464, batch    30] loss: 3.18053\n",
      "[epoch 464, batch    31] loss: 2.86086\n",
      "[epoch 464, batch    32] loss: 4.12382\n",
      "[epoch 465, batch     1] loss: 3.74800\n",
      "[epoch 465, batch     2] loss: 2.60105\n",
      "[epoch 465, batch     3] loss: 3.56121\n",
      "[epoch 465, batch     4] loss: 3.80350\n",
      "[epoch 465, batch     5] loss: 2.75618\n",
      "[epoch 465, batch     6] loss: 2.61075\n",
      "[epoch 465, batch     7] loss: 2.43746\n",
      "[epoch 465, batch     8] loss: 3.56836\n",
      "[epoch 465, batch     9] loss: 2.76234\n",
      "[epoch 465, batch    10] loss: 2.89505\n",
      "[epoch 465, batch    11] loss: 3.40207\n",
      "[epoch 465, batch    12] loss: 3.22948\n",
      "[epoch 465, batch    13] loss: 2.65288\n",
      "[epoch 465, batch    14] loss: 3.02986\n",
      "[epoch 465, batch    15] loss: 3.40685\n",
      "[epoch 465, batch    16] loss: 3.30558\n",
      "[epoch 465, batch    17] loss: 2.44476\n",
      "[epoch 465, batch    18] loss: 2.38519\n",
      "[epoch 465, batch    19] loss: 2.41086\n",
      "[epoch 465, batch    20] loss: 3.64419\n",
      "[epoch 465, batch    21] loss: 3.03257\n",
      "[epoch 465, batch    22] loss: 3.51122\n",
      "[epoch 465, batch    23] loss: 3.63360\n",
      "[epoch 465, batch    24] loss: 2.63115\n",
      "[epoch 465, batch    25] loss: 2.65723\n",
      "[epoch 465, batch    26] loss: 2.81828\n",
      "[epoch 465, batch    27] loss: 2.87214\n",
      "[epoch 465, batch    28] loss: 3.05898\n",
      "[epoch 465, batch    29] loss: 3.30638\n",
      "[epoch 465, batch    30] loss: 3.22270\n",
      "[epoch 465, batch    31] loss: 2.90635\n",
      "[epoch 465, batch    32] loss: 3.54843\n",
      "[epoch 466, batch     1] loss: 3.63909\n",
      "[epoch 466, batch     2] loss: 3.32702\n",
      "[epoch 466, batch     3] loss: 3.12328\n",
      "[epoch 466, batch     4] loss: 2.76153\n",
      "[epoch 466, batch     5] loss: 2.43538\n",
      "[epoch 466, batch     6] loss: 2.92697\n",
      "[epoch 466, batch     7] loss: 3.15105\n",
      "[epoch 466, batch     8] loss: 2.73768\n",
      "[epoch 466, batch     9] loss: 3.16259\n",
      "[epoch 466, batch    10] loss: 2.98977\n",
      "[epoch 466, batch    11] loss: 2.05649\n",
      "[epoch 466, batch    12] loss: 3.44899\n",
      "[epoch 466, batch    13] loss: 3.26682\n",
      "[epoch 466, batch    14] loss: 3.45819\n",
      "[epoch 466, batch    15] loss: 3.49169\n",
      "[epoch 466, batch    16] loss: 2.90727\n",
      "[epoch 466, batch    17] loss: 3.26318\n",
      "[epoch 466, batch    18] loss: 2.92286\n",
      "[epoch 466, batch    19] loss: 3.40968\n",
      "[epoch 466, batch    20] loss: 3.39961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 466, batch    21] loss: 3.10057\n",
      "[epoch 466, batch    22] loss: 2.50514\n",
      "[epoch 466, batch    23] loss: 3.46786\n",
      "[epoch 466, batch    24] loss: 2.81139\n",
      "[epoch 466, batch    25] loss: 2.96417\n",
      "[epoch 466, batch    26] loss: 2.42031\n",
      "[epoch 466, batch    27] loss: 3.09653\n",
      "[epoch 466, batch    28] loss: 2.69548\n",
      "[epoch 466, batch    29] loss: 2.01194\n",
      "[epoch 466, batch    30] loss: 3.44365\n",
      "[epoch 466, batch    31] loss: 3.47820\n",
      "[epoch 466, batch    32] loss: 3.49497\n",
      "[epoch 467, batch     1] loss: 2.63225\n",
      "[epoch 467, batch     2] loss: 3.11493\n",
      "[epoch 467, batch     3] loss: 3.12653\n",
      "[epoch 467, batch     4] loss: 3.39229\n",
      "[epoch 467, batch     5] loss: 2.45427\n",
      "[epoch 467, batch     6] loss: 3.05264\n",
      "[epoch 467, batch     7] loss: 3.06020\n",
      "[epoch 467, batch     8] loss: 3.20098\n",
      "[epoch 467, batch     9] loss: 3.59905\n",
      "[epoch 467, batch    10] loss: 3.94039\n",
      "[epoch 467, batch    11] loss: 3.16044\n",
      "[epoch 467, batch    12] loss: 3.01239\n",
      "[epoch 467, batch    13] loss: 2.58304\n",
      "[epoch 467, batch    14] loss: 2.78559\n",
      "[epoch 467, batch    15] loss: 2.21063\n",
      "[epoch 467, batch    16] loss: 2.86652\n",
      "[epoch 467, batch    17] loss: 3.15057\n",
      "[epoch 467, batch    18] loss: 2.75095\n",
      "[epoch 467, batch    19] loss: 3.81987\n",
      "[epoch 467, batch    20] loss: 2.32136\n",
      "[epoch 467, batch    21] loss: 2.90667\n",
      "[epoch 467, batch    22] loss: 3.42788\n",
      "[epoch 467, batch    23] loss: 2.62932\n",
      "[epoch 467, batch    24] loss: 2.72778\n",
      "[epoch 467, batch    25] loss: 3.87274\n",
      "[epoch 467, batch    26] loss: 2.72289\n",
      "[epoch 467, batch    27] loss: 3.62874\n",
      "[epoch 467, batch    28] loss: 2.77305\n",
      "[epoch 467, batch    29] loss: 3.31811\n",
      "[epoch 467, batch    30] loss: 3.11065\n",
      "[epoch 467, batch    31] loss: 3.18240\n",
      "[epoch 467, batch    32] loss: 3.86671\n",
      "[epoch 468, batch     1] loss: 3.67331\n",
      "[epoch 468, batch     2] loss: 2.84236\n",
      "[epoch 468, batch     3] loss: 1.89169\n",
      "[epoch 468, batch     4] loss: 3.11016\n",
      "[epoch 468, batch     5] loss: 2.06370\n",
      "[epoch 468, batch     6] loss: 2.96053\n",
      "[epoch 468, batch     7] loss: 3.27698\n",
      "[epoch 468, batch     8] loss: 2.99747\n",
      "[epoch 468, batch     9] loss: 2.53753\n",
      "[epoch 468, batch    10] loss: 3.08075\n",
      "[epoch 468, batch    11] loss: 2.70005\n",
      "[epoch 468, batch    12] loss: 2.18386\n",
      "[epoch 468, batch    13] loss: 2.70549\n",
      "[epoch 468, batch    14] loss: 3.87712\n",
      "[epoch 468, batch    15] loss: 3.47769\n",
      "[epoch 468, batch    16] loss: 3.47385\n",
      "[epoch 468, batch    17] loss: 3.37440\n",
      "[epoch 468, batch    18] loss: 2.40821\n",
      "[epoch 468, batch    19] loss: 3.35104\n",
      "[epoch 468, batch    20] loss: 3.48367\n",
      "[epoch 468, batch    21] loss: 2.95398\n",
      "[epoch 468, batch    22] loss: 2.87891\n",
      "[epoch 468, batch    23] loss: 2.59231\n",
      "[epoch 468, batch    24] loss: 3.63066\n",
      "[epoch 468, batch    25] loss: 3.48603\n",
      "[epoch 468, batch    26] loss: 3.33805\n",
      "[epoch 468, batch    27] loss: 3.34992\n",
      "[epoch 468, batch    28] loss: 4.26456\n",
      "[epoch 468, batch    29] loss: 3.47934\n",
      "[epoch 468, batch    30] loss: 1.71402\n",
      "[epoch 468, batch    31] loss: 3.25183\n",
      "[epoch 468, batch    32] loss: 2.04491\n",
      "[epoch 469, batch     1] loss: 3.19419\n",
      "[epoch 469, batch     2] loss: 2.49260\n",
      "[epoch 469, batch     3] loss: 3.25591\n",
      "[epoch 469, batch     4] loss: 3.47923\n",
      "[epoch 469, batch     5] loss: 3.07194\n",
      "[epoch 469, batch     6] loss: 3.01558\n",
      "[epoch 469, batch     7] loss: 2.14156\n",
      "[epoch 469, batch     8] loss: 2.96726\n",
      "[epoch 469, batch     9] loss: 2.75675\n",
      "[epoch 469, batch    10] loss: 3.37707\n",
      "[epoch 469, batch    11] loss: 2.54080\n",
      "[epoch 469, batch    12] loss: 4.24359\n",
      "[epoch 469, batch    13] loss: 3.22556\n",
      "[epoch 469, batch    14] loss: 2.53821\n",
      "[epoch 469, batch    15] loss: 3.10764\n",
      "[epoch 469, batch    16] loss: 2.72008\n",
      "[epoch 469, batch    17] loss: 2.67086\n",
      "[epoch 469, batch    18] loss: 3.34693\n",
      "[epoch 469, batch    19] loss: 2.94373\n",
      "[epoch 469, batch    20] loss: 2.75406\n",
      "[epoch 469, batch    21] loss: 3.33600\n",
      "[epoch 469, batch    22] loss: 3.33191\n",
      "[epoch 469, batch    23] loss: 3.17594\n",
      "[epoch 469, batch    24] loss: 3.49588\n",
      "[epoch 469, batch    25] loss: 2.63870\n",
      "[epoch 469, batch    26] loss: 2.94526\n",
      "[epoch 469, batch    27] loss: 2.34173\n",
      "[epoch 469, batch    28] loss: 2.21417\n",
      "[epoch 469, batch    29] loss: 3.39434\n",
      "[epoch 469, batch    30] loss: 3.30802\n",
      "[epoch 469, batch    31] loss: 3.59388\n",
      "[epoch 469, batch    32] loss: 4.67190\n",
      "[epoch 470, batch     1] loss: 3.35146\n",
      "[epoch 470, batch     2] loss: 2.91447\n",
      "[epoch 470, batch     3] loss: 4.08071\n",
      "[epoch 470, batch     4] loss: 2.19966\n",
      "[epoch 470, batch     5] loss: 3.09984\n",
      "[epoch 470, batch     6] loss: 3.01611\n",
      "[epoch 470, batch     7] loss: 3.55901\n",
      "[epoch 470, batch     8] loss: 2.97827\n",
      "[epoch 470, batch     9] loss: 2.22135\n",
      "[epoch 470, batch    10] loss: 2.25425\n",
      "[epoch 470, batch    11] loss: 2.67790\n",
      "[epoch 470, batch    12] loss: 2.66105\n",
      "[epoch 470, batch    13] loss: 3.04267\n",
      "[epoch 470, batch    14] loss: 3.09097\n",
      "[epoch 470, batch    15] loss: 3.63122\n",
      "[epoch 470, batch    16] loss: 2.67878\n",
      "[epoch 470, batch    17] loss: 3.57079\n",
      "[epoch 470, batch    18] loss: 3.35253\n",
      "[epoch 470, batch    19] loss: 2.69751\n",
      "[epoch 470, batch    20] loss: 2.70770\n",
      "[epoch 470, batch    21] loss: 3.02401\n",
      "[epoch 470, batch    22] loss: 2.40919\n",
      "[epoch 470, batch    23] loss: 3.35512\n",
      "[epoch 470, batch    24] loss: 3.44711\n",
      "[epoch 470, batch    25] loss: 2.35180\n",
      "[epoch 470, batch    26] loss: 3.56303\n",
      "[epoch 470, batch    27] loss: 3.39855\n",
      "[epoch 470, batch    28] loss: 3.39519\n",
      "[epoch 470, batch    29] loss: 3.31604\n",
      "[epoch 470, batch    30] loss: 3.27556\n",
      "[epoch 470, batch    31] loss: 3.06430\n",
      "[epoch 470, batch    32] loss: 2.28124\n",
      "[epoch 471, batch     1] loss: 3.48362\n",
      "[epoch 471, batch     2] loss: 3.22366\n",
      "[epoch 471, batch     3] loss: 3.47622\n",
      "[epoch 471, batch     4] loss: 3.34242\n",
      "[epoch 471, batch     5] loss: 2.83341\n",
      "[epoch 471, batch     6] loss: 3.24904\n",
      "[epoch 471, batch     7] loss: 3.20380\n",
      "[epoch 471, batch     8] loss: 2.95571\n",
      "[epoch 471, batch     9] loss: 3.12445\n",
      "[epoch 471, batch    10] loss: 3.39220\n",
      "[epoch 471, batch    11] loss: 3.14898\n",
      "[epoch 471, batch    12] loss: 3.23193\n",
      "[epoch 471, batch    13] loss: 2.68272\n",
      "[epoch 471, batch    14] loss: 2.49450\n",
      "[epoch 471, batch    15] loss: 2.72165\n",
      "[epoch 471, batch    16] loss: 3.15487\n",
      "[epoch 471, batch    17] loss: 2.39313\n",
      "[epoch 471, batch    18] loss: 3.25917\n",
      "[epoch 471, batch    19] loss: 2.64880\n",
      "[epoch 471, batch    20] loss: 3.33565\n",
      "[epoch 471, batch    21] loss: 3.24866\n",
      "[epoch 471, batch    22] loss: 3.10148\n",
      "[epoch 471, batch    23] loss: 2.00839\n",
      "[epoch 471, batch    24] loss: 3.02927\n",
      "[epoch 471, batch    25] loss: 3.40669\n",
      "[epoch 471, batch    26] loss: 3.43547\n",
      "[epoch 471, batch    27] loss: 2.67805\n",
      "[epoch 471, batch    28] loss: 3.26512\n",
      "[epoch 471, batch    29] loss: 2.52136\n",
      "[epoch 471, batch    30] loss: 2.50399\n",
      "[epoch 471, batch    31] loss: 3.04662\n",
      "[epoch 471, batch    32] loss: 3.90751\n",
      "[epoch 472, batch     1] loss: 3.11420\n",
      "[epoch 472, batch     2] loss: 3.89970\n",
      "[epoch 472, batch     3] loss: 2.89119\n",
      "[epoch 472, batch     4] loss: 3.00659\n",
      "[epoch 472, batch     5] loss: 2.86914\n",
      "[epoch 472, batch     6] loss: 2.69674\n",
      "[epoch 472, batch     7] loss: 2.59933\n",
      "[epoch 472, batch     8] loss: 2.91184\n",
      "[epoch 472, batch     9] loss: 3.70108\n",
      "[epoch 472, batch    10] loss: 4.13708\n",
      "[epoch 472, batch    11] loss: 2.26211\n",
      "[epoch 472, batch    12] loss: 3.36958\n",
      "[epoch 472, batch    13] loss: 2.65274\n",
      "[epoch 472, batch    14] loss: 3.11847\n",
      "[epoch 472, batch    15] loss: 3.68526\n",
      "[epoch 472, batch    16] loss: 4.09539\n",
      "[epoch 472, batch    17] loss: 3.76906\n",
      "[epoch 472, batch    18] loss: 2.32189\n",
      "[epoch 472, batch    19] loss: 3.06992\n",
      "[epoch 472, batch    20] loss: 2.59146\n",
      "[epoch 472, batch    21] loss: 2.64130\n",
      "[epoch 472, batch    22] loss: 2.61822\n",
      "[epoch 472, batch    23] loss: 3.21027\n",
      "[epoch 472, batch    24] loss: 2.72452\n",
      "[epoch 472, batch    25] loss: 3.44023\n",
      "[epoch 472, batch    26] loss: 3.17439\n",
      "[epoch 472, batch    27] loss: 2.37865\n",
      "[epoch 472, batch    28] loss: 3.19370\n",
      "[epoch 472, batch    29] loss: 2.25561\n",
      "[epoch 472, batch    30] loss: 2.89898\n",
      "[epoch 472, batch    31] loss: 3.33684\n",
      "[epoch 472, batch    32] loss: 3.68839\n",
      "[epoch 473, batch     1] loss: 3.60866\n",
      "[epoch 473, batch     2] loss: 3.34289\n",
      "[epoch 473, batch     3] loss: 3.06157\n",
      "[epoch 473, batch     4] loss: 2.96338\n",
      "[epoch 473, batch     5] loss: 2.62290\n",
      "[epoch 473, batch     6] loss: 2.35275\n",
      "[epoch 473, batch     7] loss: 2.85128\n",
      "[epoch 473, batch     8] loss: 2.81204\n",
      "[epoch 473, batch     9] loss: 3.49458\n",
      "[epoch 473, batch    10] loss: 2.70419\n",
      "[epoch 473, batch    11] loss: 2.79110\n",
      "[epoch 473, batch    12] loss: 3.40238\n",
      "[epoch 473, batch    13] loss: 3.00613\n",
      "[epoch 473, batch    14] loss: 3.69816\n",
      "[epoch 473, batch    15] loss: 2.88338\n",
      "[epoch 473, batch    16] loss: 2.23186\n",
      "[epoch 473, batch    17] loss: 2.27202\n",
      "[epoch 473, batch    18] loss: 3.10269\n",
      "[epoch 473, batch    19] loss: 3.21673\n",
      "[epoch 473, batch    20] loss: 2.97229\n",
      "[epoch 473, batch    21] loss: 2.68359\n",
      "[epoch 473, batch    22] loss: 3.77334\n",
      "[epoch 473, batch    23] loss: 2.33389\n",
      "[epoch 473, batch    24] loss: 3.24042\n",
      "[epoch 473, batch    25] loss: 3.31245\n",
      "[epoch 473, batch    26] loss: 3.05940\n",
      "[epoch 473, batch    27] loss: 2.96019\n",
      "[epoch 473, batch    28] loss: 4.15607\n",
      "[epoch 473, batch    29] loss: 3.45450\n",
      "[epoch 473, batch    30] loss: 3.13572\n",
      "[epoch 473, batch    31] loss: 3.16648\n",
      "[epoch 473, batch    32] loss: 2.16624\n",
      "[epoch 474, batch     1] loss: 3.10334\n",
      "[epoch 474, batch     2] loss: 3.30983\n",
      "[epoch 474, batch     3] loss: 3.25650\n",
      "[epoch 474, batch     4] loss: 2.91078\n",
      "[epoch 474, batch     5] loss: 2.92649\n",
      "[epoch 474, batch     6] loss: 3.26548\n",
      "[epoch 474, batch     7] loss: 2.67711\n",
      "[epoch 474, batch     8] loss: 3.21519\n",
      "[epoch 474, batch     9] loss: 3.34599\n",
      "[epoch 474, batch    10] loss: 2.82827\n",
      "[epoch 474, batch    11] loss: 4.37607\n",
      "[epoch 474, batch    12] loss: 2.98190\n",
      "[epoch 474, batch    13] loss: 2.89604\n",
      "[epoch 474, batch    14] loss: 2.53332\n",
      "[epoch 474, batch    15] loss: 2.60059\n",
      "[epoch 474, batch    16] loss: 3.08678\n",
      "[epoch 474, batch    17] loss: 2.50885\n",
      "[epoch 474, batch    18] loss: 2.84231\n",
      "[epoch 474, batch    19] loss: 3.25348\n",
      "[epoch 474, batch    20] loss: 3.01492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 474, batch    21] loss: 2.67387\n",
      "[epoch 474, batch    22] loss: 3.14652\n",
      "[epoch 474, batch    23] loss: 2.90670\n",
      "[epoch 474, batch    24] loss: 3.62649\n",
      "[epoch 474, batch    25] loss: 2.39375\n",
      "[epoch 474, batch    26] loss: 3.13153\n",
      "[epoch 474, batch    27] loss: 2.39895\n",
      "[epoch 474, batch    28] loss: 3.88535\n",
      "[epoch 474, batch    29] loss: 3.34364\n",
      "[epoch 474, batch    30] loss: 2.75104\n",
      "[epoch 474, batch    31] loss: 3.13835\n",
      "[epoch 474, batch    32] loss: 2.25905\n",
      "[epoch 475, batch     1] loss: 2.25540\n",
      "[epoch 475, batch     2] loss: 2.93124\n",
      "[epoch 475, batch     3] loss: 2.79814\n",
      "[epoch 475, batch     4] loss: 2.14381\n",
      "[epoch 475, batch     5] loss: 3.38072\n",
      "[epoch 475, batch     6] loss: 3.62741\n",
      "[epoch 475, batch     7] loss: 3.08188\n",
      "[epoch 475, batch     8] loss: 3.47229\n",
      "[epoch 475, batch     9] loss: 2.54152\n",
      "[epoch 475, batch    10] loss: 2.98178\n",
      "[epoch 475, batch    11] loss: 2.77518\n",
      "[epoch 475, batch    12] loss: 2.72937\n",
      "[epoch 475, batch    13] loss: 3.86797\n",
      "[epoch 475, batch    14] loss: 2.61605\n",
      "[epoch 475, batch    15] loss: 2.59464\n",
      "[epoch 475, batch    16] loss: 2.70384\n",
      "[epoch 475, batch    17] loss: 3.06207\n",
      "[epoch 475, batch    18] loss: 3.71695\n",
      "[epoch 475, batch    19] loss: 3.13466\n",
      "[epoch 475, batch    20] loss: 3.21623\n",
      "[epoch 475, batch    21] loss: 4.10367\n",
      "[epoch 475, batch    22] loss: 2.69695\n",
      "[epoch 475, batch    23] loss: 2.52822\n",
      "[epoch 475, batch    24] loss: 2.95277\n",
      "[epoch 475, batch    25] loss: 2.37639\n",
      "[epoch 475, batch    26] loss: 3.96670\n",
      "[epoch 475, batch    27] loss: 3.33886\n",
      "[epoch 475, batch    28] loss: 3.39288\n",
      "[epoch 475, batch    29] loss: 3.45904\n",
      "[epoch 475, batch    30] loss: 3.09657\n",
      "[epoch 475, batch    31] loss: 2.75935\n",
      "[epoch 475, batch    32] loss: 2.58098\n",
      "[epoch 476, batch     1] loss: 3.11210\n",
      "[epoch 476, batch     2] loss: 3.31654\n",
      "[epoch 476, batch     3] loss: 3.27751\n",
      "[epoch 476, batch     4] loss: 3.19258\n",
      "[epoch 476, batch     5] loss: 3.39011\n",
      "[epoch 476, batch     6] loss: 2.46281\n",
      "[epoch 476, batch     7] loss: 2.47052\n",
      "[epoch 476, batch     8] loss: 3.31352\n",
      "[epoch 476, batch     9] loss: 3.61630\n",
      "[epoch 476, batch    10] loss: 2.50857\n",
      "[epoch 476, batch    11] loss: 2.82152\n",
      "[epoch 476, batch    12] loss: 3.39668\n",
      "[epoch 476, batch    13] loss: 2.40203\n",
      "[epoch 476, batch    14] loss: 3.21677\n",
      "[epoch 476, batch    15] loss: 4.21893\n",
      "[epoch 476, batch    16] loss: 3.18926\n",
      "[epoch 476, batch    17] loss: 3.04127\n",
      "[epoch 476, batch    18] loss: 3.14984\n",
      "[epoch 476, batch    19] loss: 2.84840\n",
      "[epoch 476, batch    20] loss: 2.86987\n",
      "[epoch 476, batch    21] loss: 2.93407\n",
      "[epoch 476, batch    22] loss: 2.68427\n",
      "[epoch 476, batch    23] loss: 2.91005\n",
      "[epoch 476, batch    24] loss: 1.79984\n",
      "[epoch 476, batch    25] loss: 3.10385\n",
      "[epoch 476, batch    26] loss: 3.44259\n",
      "[epoch 476, batch    27] loss: 3.05362\n",
      "[epoch 476, batch    28] loss: 3.17107\n",
      "[epoch 476, batch    29] loss: 2.41199\n",
      "[epoch 476, batch    30] loss: 3.55301\n",
      "[epoch 476, batch    31] loss: 3.30725\n",
      "[epoch 476, batch    32] loss: 3.03485\n",
      "[epoch 477, batch     1] loss: 3.00530\n",
      "[epoch 477, batch     2] loss: 3.43618\n",
      "[epoch 477, batch     3] loss: 2.47648\n",
      "[epoch 477, batch     4] loss: 3.07402\n",
      "[epoch 477, batch     5] loss: 2.57687\n",
      "[epoch 477, batch     6] loss: 2.98748\n",
      "[epoch 477, batch     7] loss: 3.03122\n",
      "[epoch 477, batch     8] loss: 3.75828\n",
      "[epoch 477, batch     9] loss: 4.25569\n",
      "[epoch 477, batch    10] loss: 2.45102\n",
      "[epoch 477, batch    11] loss: 3.04112\n",
      "[epoch 477, batch    12] loss: 2.87424\n",
      "[epoch 477, batch    13] loss: 3.53842\n",
      "[epoch 477, batch    14] loss: 2.58595\n",
      "[epoch 477, batch    15] loss: 3.17202\n",
      "[epoch 477, batch    16] loss: 3.25283\n",
      "[epoch 477, batch    17] loss: 3.20307\n",
      "[epoch 477, batch    18] loss: 3.47869\n",
      "[epoch 477, batch    19] loss: 3.50116\n",
      "[epoch 477, batch    20] loss: 2.36484\n",
      "[epoch 477, batch    21] loss: 2.93726\n",
      "[epoch 477, batch    22] loss: 3.00166\n",
      "[epoch 477, batch    23] loss: 2.69801\n",
      "[epoch 477, batch    24] loss: 2.27903\n",
      "[epoch 477, batch    25] loss: 3.32529\n",
      "[epoch 477, batch    26] loss: 2.74856\n",
      "[epoch 477, batch    27] loss: 3.28872\n",
      "[epoch 477, batch    28] loss: 2.59845\n",
      "[epoch 477, batch    29] loss: 2.99772\n",
      "[epoch 477, batch    30] loss: 3.00559\n",
      "[epoch 477, batch    31] loss: 3.02151\n",
      "[epoch 477, batch    32] loss: 2.62455\n",
      "[epoch 478, batch     1] loss: 2.65702\n",
      "[epoch 478, batch     2] loss: 3.07273\n",
      "[epoch 478, batch     3] loss: 3.03856\n",
      "[epoch 478, batch     4] loss: 3.13578\n",
      "[epoch 478, batch     5] loss: 2.87900\n",
      "[epoch 478, batch     6] loss: 3.22259\n",
      "[epoch 478, batch     7] loss: 3.22362\n",
      "[epoch 478, batch     8] loss: 3.52425\n",
      "[epoch 478, batch     9] loss: 3.60797\n",
      "[epoch 478, batch    10] loss: 3.04090\n",
      "[epoch 478, batch    11] loss: 2.74225\n",
      "[epoch 478, batch    12] loss: 3.20821\n",
      "[epoch 478, batch    13] loss: 3.31505\n",
      "[epoch 478, batch    14] loss: 3.18560\n",
      "[epoch 478, batch    15] loss: 2.69164\n",
      "[epoch 478, batch    16] loss: 2.87119\n",
      "[epoch 478, batch    17] loss: 3.69446\n",
      "[epoch 478, batch    18] loss: 2.52185\n",
      "[epoch 478, batch    19] loss: 3.63833\n",
      "[epoch 478, batch    20] loss: 3.01665\n",
      "[epoch 478, batch    21] loss: 1.49337\n",
      "[epoch 478, batch    22] loss: 2.75651\n",
      "[epoch 478, batch    23] loss: 2.35815\n",
      "[epoch 478, batch    24] loss: 3.85402\n",
      "[epoch 478, batch    25] loss: 3.81646\n",
      "[epoch 478, batch    26] loss: 2.52708\n",
      "[epoch 478, batch    27] loss: 2.47299\n",
      "[epoch 478, batch    28] loss: 2.98615\n",
      "[epoch 478, batch    29] loss: 3.17045\n",
      "[epoch 478, batch    30] loss: 2.74727\n",
      "[epoch 478, batch    31] loss: 3.66139\n",
      "[epoch 478, batch    32] loss: 3.81737\n",
      "[epoch 479, batch     1] loss: 2.57769\n",
      "[epoch 479, batch     2] loss: 3.17098\n",
      "[epoch 479, batch     3] loss: 3.34548\n",
      "[epoch 479, batch     4] loss: 3.16350\n",
      "[epoch 479, batch     5] loss: 3.24023\n",
      "[epoch 479, batch     6] loss: 3.07024\n",
      "[epoch 479, batch     7] loss: 3.57246\n",
      "[epoch 479, batch     8] loss: 3.38625\n",
      "[epoch 479, batch     9] loss: 2.50526\n",
      "[epoch 479, batch    10] loss: 3.40501\n",
      "[epoch 479, batch    11] loss: 2.86976\n",
      "[epoch 479, batch    12] loss: 3.33132\n",
      "[epoch 479, batch    13] loss: 2.65635\n",
      "[epoch 479, batch    14] loss: 2.09663\n",
      "[epoch 479, batch    15] loss: 3.41261\n",
      "[epoch 479, batch    16] loss: 3.46676\n",
      "[epoch 479, batch    17] loss: 3.45083\n",
      "[epoch 479, batch    18] loss: 3.21231\n",
      "[epoch 479, batch    19] loss: 3.15066\n",
      "[epoch 479, batch    20] loss: 2.28314\n",
      "[epoch 479, batch    21] loss: 2.55393\n",
      "[epoch 479, batch    22] loss: 3.13136\n",
      "[epoch 479, batch    23] loss: 2.94295\n",
      "[epoch 479, batch    24] loss: 3.35198\n",
      "[epoch 479, batch    25] loss: 2.28107\n",
      "[epoch 479, batch    26] loss: 2.97761\n",
      "[epoch 479, batch    27] loss: 2.92713\n",
      "[epoch 479, batch    28] loss: 2.90422\n",
      "[epoch 479, batch    29] loss: 2.64092\n",
      "[epoch 479, batch    30] loss: 2.83632\n",
      "[epoch 479, batch    31] loss: 4.17840\n",
      "[epoch 479, batch    32] loss: 4.19854\n",
      "[epoch 480, batch     1] loss: 2.47336\n",
      "[epoch 480, batch     2] loss: 2.69795\n",
      "[epoch 480, batch     3] loss: 3.26426\n",
      "[epoch 480, batch     4] loss: 3.47828\n",
      "[epoch 480, batch     5] loss: 3.17165\n",
      "[epoch 480, batch     6] loss: 2.46190\n",
      "[epoch 480, batch     7] loss: 2.17721\n",
      "[epoch 480, batch     8] loss: 2.69392\n",
      "[epoch 480, batch     9] loss: 2.26555\n",
      "[epoch 480, batch    10] loss: 3.35135\n",
      "[epoch 480, batch    11] loss: 3.30748\n",
      "[epoch 480, batch    12] loss: 3.34953\n",
      "[epoch 480, batch    13] loss: 2.32324\n",
      "[epoch 480, batch    14] loss: 3.82220\n",
      "[epoch 480, batch    15] loss: 2.95910\n",
      "[epoch 480, batch    16] loss: 3.23484\n",
      "[epoch 480, batch    17] loss: 3.11064\n",
      "[epoch 480, batch    18] loss: 3.54700\n",
      "[epoch 480, batch    19] loss: 3.19674\n",
      "[epoch 480, batch    20] loss: 3.55715\n",
      "[epoch 480, batch    21] loss: 2.51037\n",
      "[epoch 480, batch    22] loss: 3.00909\n",
      "[epoch 480, batch    23] loss: 2.04568\n",
      "[epoch 480, batch    24] loss: 3.51112\n",
      "[epoch 480, batch    25] loss: 2.75997\n",
      "[epoch 480, batch    26] loss: 2.90334\n",
      "[epoch 480, batch    27] loss: 3.04477\n",
      "[epoch 480, batch    28] loss: 2.32252\n",
      "[epoch 480, batch    29] loss: 3.40078\n",
      "[epoch 480, batch    30] loss: 4.42303\n",
      "[epoch 480, batch    31] loss: 3.40201\n",
      "[epoch 480, batch    32] loss: 1.27760\n",
      "[epoch 481, batch     1] loss: 3.71388\n",
      "[epoch 481, batch     2] loss: 2.83754\n",
      "[epoch 481, batch     3] loss: 2.56285\n",
      "[epoch 481, batch     4] loss: 2.62894\n",
      "[epoch 481, batch     5] loss: 3.28672\n",
      "[epoch 481, batch     6] loss: 3.76503\n",
      "[epoch 481, batch     7] loss: 3.36294\n",
      "[epoch 481, batch     8] loss: 2.41578\n",
      "[epoch 481, batch     9] loss: 2.90880\n",
      "[epoch 481, batch    10] loss: 2.72638\n",
      "[epoch 481, batch    11] loss: 2.98975\n",
      "[epoch 481, batch    12] loss: 3.40119\n",
      "[epoch 481, batch    13] loss: 2.94483\n",
      "[epoch 481, batch    14] loss: 3.03453\n",
      "[epoch 481, batch    15] loss: 2.60446\n",
      "[epoch 481, batch    16] loss: 2.99449\n",
      "[epoch 481, batch    17] loss: 2.51411\n",
      "[epoch 481, batch    18] loss: 3.05054\n",
      "[epoch 481, batch    19] loss: 3.09854\n",
      "[epoch 481, batch    20] loss: 2.53820\n",
      "[epoch 481, batch    21] loss: 3.12080\n",
      "[epoch 481, batch    22] loss: 3.65196\n",
      "[epoch 481, batch    23] loss: 2.66109\n",
      "[epoch 481, batch    24] loss: 3.30292\n",
      "[epoch 481, batch    25] loss: 4.59503\n",
      "[epoch 481, batch    26] loss: 3.94866\n",
      "[epoch 481, batch    27] loss: 2.29886\n",
      "[epoch 481, batch    28] loss: 2.90965\n",
      "[epoch 481, batch    29] loss: 2.81866\n",
      "[epoch 481, batch    30] loss: 2.73602\n",
      "[epoch 481, batch    31] loss: 2.50034\n",
      "[epoch 481, batch    32] loss: 2.95001\n",
      "[epoch 482, batch     1] loss: 2.99406\n",
      "[epoch 482, batch     2] loss: 2.35798\n",
      "[epoch 482, batch     3] loss: 3.12576\n",
      "[epoch 482, batch     4] loss: 2.47292\n",
      "[epoch 482, batch     5] loss: 3.37739\n",
      "[epoch 482, batch     6] loss: 2.97530\n",
      "[epoch 482, batch     7] loss: 3.64072\n",
      "[epoch 482, batch     8] loss: 1.88536\n",
      "[epoch 482, batch     9] loss: 3.12739\n",
      "[epoch 482, batch    10] loss: 3.39758\n",
      "[epoch 482, batch    11] loss: 2.79612\n",
      "[epoch 482, batch    12] loss: 2.72696\n",
      "[epoch 482, batch    13] loss: 2.86042\n",
      "[epoch 482, batch    14] loss: 2.74204\n",
      "[epoch 482, batch    15] loss: 2.81724\n",
      "[epoch 482, batch    16] loss: 4.01047\n",
      "[epoch 482, batch    17] loss: 3.35861\n",
      "[epoch 482, batch    18] loss: 3.42198\n",
      "[epoch 482, batch    19] loss: 3.21739\n",
      "[epoch 482, batch    20] loss: 4.00663\n",
      "[epoch 482, batch    21] loss: 2.54749\n",
      "[epoch 482, batch    22] loss: 3.14943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 482, batch    23] loss: 2.87173\n",
      "[epoch 482, batch    24] loss: 3.55242\n",
      "[epoch 482, batch    25] loss: 3.69016\n",
      "[epoch 482, batch    26] loss: 2.98592\n",
      "[epoch 482, batch    27] loss: 2.32067\n",
      "[epoch 482, batch    28] loss: 2.76716\n",
      "[epoch 482, batch    29] loss: 2.25583\n",
      "[epoch 482, batch    30] loss: 3.88457\n",
      "[epoch 482, batch    31] loss: 2.90273\n",
      "[epoch 482, batch    32] loss: 4.09122\n",
      "[epoch 483, batch     1] loss: 3.67415\n",
      "[epoch 483, batch     2] loss: 3.34296\n",
      "[epoch 483, batch     3] loss: 4.04123\n",
      "[epoch 483, batch     4] loss: 2.31398\n",
      "[epoch 483, batch     5] loss: 3.37315\n",
      "[epoch 483, batch     6] loss: 2.80866\n",
      "[epoch 483, batch     7] loss: 3.36578\n",
      "[epoch 483, batch     8] loss: 2.76569\n",
      "[epoch 483, batch     9] loss: 3.27386\n",
      "[epoch 483, batch    10] loss: 3.95905\n",
      "[epoch 483, batch    11] loss: 2.64826\n",
      "[epoch 483, batch    12] loss: 3.00543\n",
      "[epoch 483, batch    13] loss: 2.48785\n",
      "[epoch 483, batch    14] loss: 3.06550\n",
      "[epoch 483, batch    15] loss: 3.32915\n",
      "[epoch 483, batch    16] loss: 3.38470\n",
      "[epoch 483, batch    17] loss: 2.53481\n",
      "[epoch 483, batch    18] loss: 2.30272\n",
      "[epoch 483, batch    19] loss: 3.25147\n",
      "[epoch 483, batch    20] loss: 3.79084\n",
      "[epoch 483, batch    21] loss: 3.82346\n",
      "[epoch 483, batch    22] loss: 2.87210\n",
      "[epoch 483, batch    23] loss: 2.84990\n",
      "[epoch 483, batch    24] loss: 3.57795\n",
      "[epoch 483, batch    25] loss: 2.60815\n",
      "[epoch 483, batch    26] loss: 2.29072\n",
      "[epoch 483, batch    27] loss: 2.42931\n",
      "[epoch 483, batch    28] loss: 3.01600\n",
      "[epoch 483, batch    29] loss: 2.28583\n",
      "[epoch 483, batch    30] loss: 2.59561\n",
      "[epoch 483, batch    31] loss: 2.98692\n",
      "[epoch 483, batch    32] loss: 3.53876\n",
      "[epoch 484, batch     1] loss: 2.65556\n",
      "[epoch 484, batch     2] loss: 3.99188\n",
      "[epoch 484, batch     3] loss: 3.27806\n",
      "[epoch 484, batch     4] loss: 3.14957\n",
      "[epoch 484, batch     5] loss: 3.19267\n",
      "[epoch 484, batch     6] loss: 2.82055\n",
      "[epoch 484, batch     7] loss: 2.31967\n",
      "[epoch 484, batch     8] loss: 2.85422\n",
      "[epoch 484, batch     9] loss: 2.50931\n",
      "[epoch 484, batch    10] loss: 3.35141\n",
      "[epoch 484, batch    11] loss: 2.92084\n",
      "[epoch 484, batch    12] loss: 2.05558\n",
      "[epoch 484, batch    13] loss: 3.06936\n",
      "[epoch 484, batch    14] loss: 2.78973\n",
      "[epoch 484, batch    15] loss: 3.13949\n",
      "[epoch 484, batch    16] loss: 3.22567\n",
      "[epoch 484, batch    17] loss: 2.14856\n",
      "[epoch 484, batch    18] loss: 2.79369\n",
      "[epoch 484, batch    19] loss: 2.96641\n",
      "[epoch 484, batch    20] loss: 3.77134\n",
      "[epoch 484, batch    21] loss: 3.50011\n",
      "[epoch 484, batch    22] loss: 3.21243\n",
      "[epoch 484, batch    23] loss: 3.07550\n",
      "[epoch 484, batch    24] loss: 3.51622\n",
      "[epoch 484, batch    25] loss: 2.60987\n",
      "[epoch 484, batch    26] loss: 3.65799\n",
      "[epoch 484, batch    27] loss: 3.93019\n",
      "[epoch 484, batch    28] loss: 2.90481\n",
      "[epoch 484, batch    29] loss: 2.87275\n",
      "[epoch 484, batch    30] loss: 2.81422\n",
      "[epoch 484, batch    31] loss: 2.66830\n",
      "[epoch 484, batch    32] loss: 3.50359\n",
      "[epoch 485, batch     1] loss: 2.38437\n",
      "[epoch 485, batch     2] loss: 3.67781\n",
      "[epoch 485, batch     3] loss: 2.87105\n",
      "[epoch 485, batch     4] loss: 2.59993\n",
      "[epoch 485, batch     5] loss: 2.28907\n",
      "[epoch 485, batch     6] loss: 2.99741\n",
      "[epoch 485, batch     7] loss: 3.55773\n",
      "[epoch 485, batch     8] loss: 2.71679\n",
      "[epoch 485, batch     9] loss: 3.36398\n",
      "[epoch 485, batch    10] loss: 3.20777\n",
      "[epoch 485, batch    11] loss: 2.71108\n",
      "[epoch 485, batch    12] loss: 3.26379\n",
      "[epoch 485, batch    13] loss: 2.90504\n",
      "[epoch 485, batch    14] loss: 3.69729\n",
      "[epoch 485, batch    15] loss: 2.57700\n",
      "[epoch 485, batch    16] loss: 2.52958\n",
      "[epoch 485, batch    17] loss: 3.08130\n",
      "[epoch 485, batch    18] loss: 3.50451\n",
      "[epoch 485, batch    19] loss: 3.18175\n",
      "[epoch 485, batch    20] loss: 2.72125\n",
      "[epoch 485, batch    21] loss: 2.90429\n",
      "[epoch 485, batch    22] loss: 3.38503\n",
      "[epoch 485, batch    23] loss: 3.30911\n",
      "[epoch 485, batch    24] loss: 4.53097\n",
      "[epoch 485, batch    25] loss: 2.89860\n",
      "[epoch 485, batch    26] loss: 2.83692\n",
      "[epoch 485, batch    27] loss: 2.55855\n",
      "[epoch 485, batch    28] loss: 3.16010\n",
      "[epoch 485, batch    29] loss: 3.14625\n",
      "[epoch 485, batch    30] loss: 2.55752\n",
      "[epoch 485, batch    31] loss: 2.74637\n",
      "[epoch 485, batch    32] loss: 2.12946\n",
      "[epoch 486, batch     1] loss: 2.68466\n",
      "[epoch 486, batch     2] loss: 3.01605\n",
      "[epoch 486, batch     3] loss: 2.71328\n",
      "[epoch 486, batch     4] loss: 3.82859\n",
      "[epoch 486, batch     5] loss: 2.77831\n",
      "[epoch 486, batch     6] loss: 3.00706\n",
      "[epoch 486, batch     7] loss: 2.67621\n",
      "[epoch 486, batch     8] loss: 3.78303\n",
      "[epoch 486, batch     9] loss: 2.79595\n",
      "[epoch 486, batch    10] loss: 3.20776\n",
      "[epoch 486, batch    11] loss: 2.33104\n",
      "[epoch 486, batch    12] loss: 2.97851\n",
      "[epoch 486, batch    13] loss: 3.46797\n",
      "[epoch 486, batch    14] loss: 3.52210\n",
      "[epoch 486, batch    15] loss: 3.61191\n",
      "[epoch 486, batch    16] loss: 2.72610\n",
      "[epoch 486, batch    17] loss: 2.93983\n",
      "[epoch 486, batch    18] loss: 3.08922\n",
      "[epoch 486, batch    19] loss: 2.10963\n",
      "[epoch 486, batch    20] loss: 3.09488\n",
      "[epoch 486, batch    21] loss: 3.52026\n",
      "[epoch 486, batch    22] loss: 3.37417\n",
      "[epoch 486, batch    23] loss: 3.24879\n",
      "[epoch 486, batch    24] loss: 3.48633\n",
      "[epoch 486, batch    25] loss: 3.30225\n",
      "[epoch 486, batch    26] loss: 3.03901\n",
      "[epoch 486, batch    27] loss: 2.56885\n",
      "[epoch 486, batch    28] loss: 2.85869\n",
      "[epoch 486, batch    29] loss: 2.65523\n",
      "[epoch 486, batch    30] loss: 3.08084\n",
      "[epoch 486, batch    31] loss: 2.62494\n",
      "[epoch 486, batch    32] loss: 2.54425\n",
      "[epoch 487, batch     1] loss: 3.04884\n",
      "[epoch 487, batch     2] loss: 3.03211\n",
      "[epoch 487, batch     3] loss: 2.76132\n",
      "[epoch 487, batch     4] loss: 3.15915\n",
      "[epoch 487, batch     5] loss: 3.01303\n",
      "[epoch 487, batch     6] loss: 2.69640\n",
      "[epoch 487, batch     7] loss: 3.16836\n",
      "[epoch 487, batch     8] loss: 3.16588\n",
      "[epoch 487, batch     9] loss: 3.10009\n",
      "[epoch 487, batch    10] loss: 3.99079\n",
      "[epoch 487, batch    11] loss: 3.45248\n",
      "[epoch 487, batch    12] loss: 3.17634\n",
      "[epoch 487, batch    13] loss: 2.77347\n",
      "[epoch 487, batch    14] loss: 2.50568\n",
      "[epoch 487, batch    15] loss: 2.95919\n",
      "[epoch 487, batch    16] loss: 3.42700\n",
      "[epoch 487, batch    17] loss: 3.22424\n",
      "[epoch 487, batch    18] loss: 3.70413\n",
      "[epoch 487, batch    19] loss: 2.87575\n",
      "[epoch 487, batch    20] loss: 2.70851\n",
      "[epoch 487, batch    21] loss: 3.10530\n",
      "[epoch 487, batch    22] loss: 3.01730\n",
      "[epoch 487, batch    23] loss: 3.32374\n",
      "[epoch 487, batch    24] loss: 2.82276\n",
      "[epoch 487, batch    25] loss: 3.05823\n",
      "[epoch 487, batch    26] loss: 2.53780\n",
      "[epoch 487, batch    27] loss: 3.34833\n",
      "[epoch 487, batch    28] loss: 2.06447\n",
      "[epoch 487, batch    29] loss: 2.39271\n",
      "[epoch 487, batch    30] loss: 3.78987\n",
      "[epoch 487, batch    31] loss: 3.06244\n",
      "[epoch 487, batch    32] loss: 1.55496\n",
      "[epoch 488, batch     1] loss: 2.11899\n",
      "[epoch 488, batch     2] loss: 1.99432\n",
      "[epoch 488, batch     3] loss: 3.06382\n",
      "[epoch 488, batch     4] loss: 2.60701\n",
      "[epoch 488, batch     5] loss: 3.15262\n",
      "[epoch 488, batch     6] loss: 3.13732\n",
      "[epoch 488, batch     7] loss: 2.66850\n",
      "[epoch 488, batch     8] loss: 3.21831\n",
      "[epoch 488, batch     9] loss: 3.90939\n",
      "[epoch 488, batch    10] loss: 3.03719\n",
      "[epoch 488, batch    11] loss: 3.22276\n",
      "[epoch 488, batch    12] loss: 2.23028\n",
      "[epoch 488, batch    13] loss: 3.24892\n",
      "[epoch 488, batch    14] loss: 3.63718\n",
      "[epoch 488, batch    15] loss: 3.47007\n",
      "[epoch 488, batch    16] loss: 3.48938\n",
      "[epoch 488, batch    17] loss: 3.30818\n",
      "[epoch 488, batch    18] loss: 2.35378\n",
      "[epoch 488, batch    19] loss: 3.70991\n",
      "[epoch 488, batch    20] loss: 3.14946\n",
      "[epoch 488, batch    21] loss: 2.72568\n",
      "[epoch 488, batch    22] loss: 3.67794\n",
      "[epoch 488, batch    23] loss: 3.19827\n",
      "[epoch 488, batch    24] loss: 2.80257\n",
      "[epoch 488, batch    25] loss: 3.22000\n",
      "[epoch 488, batch    26] loss: 2.99295\n",
      "[epoch 488, batch    27] loss: 3.01438\n",
      "[epoch 488, batch    28] loss: 2.98049\n",
      "[epoch 488, batch    29] loss: 2.66403\n",
      "[epoch 488, batch    30] loss: 3.11560\n",
      "[epoch 488, batch    31] loss: 3.10313\n",
      "[epoch 488, batch    32] loss: 2.85690\n",
      "[epoch 489, batch     1] loss: 3.30167\n",
      "[epoch 489, batch     2] loss: 3.66000\n",
      "[epoch 489, batch     3] loss: 3.37616\n",
      "[epoch 489, batch     4] loss: 3.77884\n",
      "[epoch 489, batch     5] loss: 3.42187\n",
      "[epoch 489, batch     6] loss: 3.11198\n",
      "[epoch 489, batch     7] loss: 2.74220\n",
      "[epoch 489, batch     8] loss: 2.69480\n",
      "[epoch 489, batch     9] loss: 3.77854\n",
      "[epoch 489, batch    10] loss: 3.04688\n",
      "[epoch 489, batch    11] loss: 2.90935\n",
      "[epoch 489, batch    12] loss: 3.17304\n",
      "[epoch 489, batch    13] loss: 2.54811\n",
      "[epoch 489, batch    14] loss: 4.51987\n",
      "[epoch 489, batch    15] loss: 3.11673\n",
      "[epoch 489, batch    16] loss: 3.38812\n",
      "[epoch 489, batch    17] loss: 2.93646\n",
      "[epoch 489, batch    18] loss: 3.17068\n",
      "[epoch 489, batch    19] loss: 2.65995\n",
      "[epoch 489, batch    20] loss: 2.34339\n",
      "[epoch 489, batch    21] loss: 3.04556\n",
      "[epoch 489, batch    22] loss: 3.17029\n",
      "[epoch 489, batch    23] loss: 2.81000\n",
      "[epoch 489, batch    24] loss: 2.51316\n",
      "[epoch 489, batch    25] loss: 2.42108\n",
      "[epoch 489, batch    26] loss: 3.10923\n",
      "[epoch 489, batch    27] loss: 2.56573\n",
      "[epoch 489, batch    28] loss: 2.69246\n",
      "[epoch 489, batch    29] loss: 3.06915\n",
      "[epoch 489, batch    30] loss: 2.35642\n",
      "[epoch 489, batch    31] loss: 2.92814\n",
      "[epoch 489, batch    32] loss: 3.03570\n",
      "[epoch 490, batch     1] loss: 3.52112\n",
      "[epoch 490, batch     2] loss: 2.82391\n",
      "[epoch 490, batch     3] loss: 3.56918\n",
      "[epoch 490, batch     4] loss: 3.45376\n",
      "[epoch 490, batch     5] loss: 2.39977\n",
      "[epoch 490, batch     6] loss: 3.24855\n",
      "[epoch 490, batch     7] loss: 3.79357\n",
      "[epoch 490, batch     8] loss: 3.19022\n",
      "[epoch 490, batch     9] loss: 3.09499\n",
      "[epoch 490, batch    10] loss: 3.41852\n",
      "[epoch 490, batch    11] loss: 3.02369\n",
      "[epoch 490, batch    12] loss: 2.39121\n",
      "[epoch 490, batch    13] loss: 2.88257\n",
      "[epoch 490, batch    14] loss: 3.70153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 490, batch    15] loss: 2.93741\n",
      "[epoch 490, batch    16] loss: 2.98968\n",
      "[epoch 490, batch    17] loss: 2.55985\n",
      "[epoch 490, batch    18] loss: 2.55191\n",
      "[epoch 490, batch    19] loss: 3.00758\n",
      "[epoch 490, batch    20] loss: 2.89913\n",
      "[epoch 490, batch    21] loss: 2.41226\n",
      "[epoch 490, batch    22] loss: 2.62310\n",
      "[epoch 490, batch    23] loss: 2.63431\n",
      "[epoch 490, batch    24] loss: 3.27966\n",
      "[epoch 490, batch    25] loss: 2.59771\n",
      "[epoch 490, batch    26] loss: 3.19286\n",
      "[epoch 490, batch    27] loss: 3.80959\n",
      "[epoch 490, batch    28] loss: 3.00076\n",
      "[epoch 490, batch    29] loss: 2.64672\n",
      "[epoch 490, batch    30] loss: 3.23321\n",
      "[epoch 490, batch    31] loss: 3.11807\n",
      "[epoch 490, batch    32] loss: 4.49555\n",
      "[epoch 491, batch     1] loss: 2.61078\n",
      "[epoch 491, batch     2] loss: 3.11938\n",
      "[epoch 491, batch     3] loss: 3.42717\n",
      "[epoch 491, batch     4] loss: 3.64818\n",
      "[epoch 491, batch     5] loss: 2.91258\n",
      "[epoch 491, batch     6] loss: 2.69312\n",
      "[epoch 491, batch     7] loss: 2.94185\n",
      "[epoch 491, batch     8] loss: 3.81377\n",
      "[epoch 491, batch     9] loss: 3.44051\n",
      "[epoch 491, batch    10] loss: 3.33141\n",
      "[epoch 491, batch    11] loss: 3.25970\n",
      "[epoch 491, batch    12] loss: 2.93689\n",
      "[epoch 491, batch    13] loss: 2.88671\n",
      "[epoch 491, batch    14] loss: 3.55572\n",
      "[epoch 491, batch    15] loss: 2.94488\n",
      "[epoch 491, batch    16] loss: 2.67884\n",
      "[epoch 491, batch    17] loss: 2.92459\n",
      "[epoch 491, batch    18] loss: 3.00308\n",
      "[epoch 491, batch    19] loss: 3.12799\n",
      "[epoch 491, batch    20] loss: 1.97672\n",
      "[epoch 491, batch    21] loss: 3.21154\n",
      "[epoch 491, batch    22] loss: 2.42656\n",
      "[epoch 491, batch    23] loss: 2.22503\n",
      "[epoch 491, batch    24] loss: 4.06477\n",
      "[epoch 491, batch    25] loss: 3.80229\n",
      "[epoch 491, batch    26] loss: 2.98015\n",
      "[epoch 491, batch    27] loss: 2.79531\n",
      "[epoch 491, batch    28] loss: 2.46338\n",
      "[epoch 491, batch    29] loss: 2.61686\n",
      "[epoch 491, batch    30] loss: 3.26382\n",
      "[epoch 491, batch    31] loss: 3.15242\n",
      "[epoch 491, batch    32] loss: 1.96746\n",
      "[epoch 492, batch     1] loss: 2.72503\n",
      "[epoch 492, batch     2] loss: 3.98477\n",
      "[epoch 492, batch     3] loss: 2.20368\n",
      "[epoch 492, batch     4] loss: 2.51419\n",
      "[epoch 492, batch     5] loss: 3.50483\n",
      "[epoch 492, batch     6] loss: 3.88354\n",
      "[epoch 492, batch     7] loss: 3.36003\n",
      "[epoch 492, batch     8] loss: 2.98653\n",
      "[epoch 492, batch     9] loss: 3.11022\n",
      "[epoch 492, batch    10] loss: 2.19290\n",
      "[epoch 492, batch    11] loss: 2.96071\n",
      "[epoch 492, batch    12] loss: 2.35981\n",
      "[epoch 492, batch    13] loss: 3.19791\n",
      "[epoch 492, batch    14] loss: 4.03075\n",
      "[epoch 492, batch    15] loss: 2.60857\n",
      "[epoch 492, batch    16] loss: 2.94935\n",
      "[epoch 492, batch    17] loss: 3.44006\n",
      "[epoch 492, batch    18] loss: 2.26933\n",
      "[epoch 492, batch    19] loss: 2.89921\n",
      "[epoch 492, batch    20] loss: 1.95197\n",
      "[epoch 492, batch    21] loss: 4.31335\n",
      "[epoch 492, batch    22] loss: 2.50947\n",
      "[epoch 492, batch    23] loss: 3.07906\n",
      "[epoch 492, batch    24] loss: 2.74105\n",
      "[epoch 492, batch    25] loss: 2.94888\n",
      "[epoch 492, batch    26] loss: 3.10218\n",
      "[epoch 492, batch    27] loss: 3.29452\n",
      "[epoch 492, batch    28] loss: 3.07297\n",
      "[epoch 492, batch    29] loss: 2.83552\n",
      "[epoch 492, batch    30] loss: 3.39494\n",
      "[epoch 492, batch    31] loss: 3.48322\n",
      "[epoch 492, batch    32] loss: 4.66183\n",
      "[epoch 493, batch     1] loss: 2.79560\n",
      "[epoch 493, batch     2] loss: 3.22003\n",
      "[epoch 493, batch     3] loss: 2.75154\n",
      "[epoch 493, batch     4] loss: 2.69232\n",
      "[epoch 493, batch     5] loss: 3.07720\n",
      "[epoch 493, batch     6] loss: 3.41684\n",
      "[epoch 493, batch     7] loss: 2.78832\n",
      "[epoch 493, batch     8] loss: 3.24291\n",
      "[epoch 493, batch     9] loss: 3.27471\n",
      "[epoch 493, batch    10] loss: 3.83907\n",
      "[epoch 493, batch    11] loss: 2.76981\n",
      "[epoch 493, batch    12] loss: 2.87812\n",
      "[epoch 493, batch    13] loss: 1.90917\n",
      "[epoch 493, batch    14] loss: 2.59859\n",
      "[epoch 493, batch    15] loss: 3.14517\n",
      "[epoch 493, batch    16] loss: 2.74366\n",
      "[epoch 493, batch    17] loss: 3.15226\n",
      "[epoch 493, batch    18] loss: 3.59056\n",
      "[epoch 493, batch    19] loss: 2.46111\n",
      "[epoch 493, batch    20] loss: 3.33283\n",
      "[epoch 493, batch    21] loss: 2.31049\n",
      "[epoch 493, batch    22] loss: 3.56368\n",
      "[epoch 493, batch    23] loss: 3.59247\n",
      "[epoch 493, batch    24] loss: 3.17299\n",
      "[epoch 493, batch    25] loss: 3.26631\n",
      "[epoch 493, batch    26] loss: 2.83597\n",
      "[epoch 493, batch    27] loss: 3.29281\n",
      "[epoch 493, batch    28] loss: 3.37193\n",
      "[epoch 493, batch    29] loss: 2.68675\n",
      "[epoch 493, batch    30] loss: 3.30451\n",
      "[epoch 493, batch    31] loss: 3.10382\n",
      "[epoch 493, batch    32] loss: 5.18290\n",
      "[epoch 494, batch     1] loss: 2.89566\n",
      "[epoch 494, batch     2] loss: 2.95328\n",
      "[epoch 494, batch     3] loss: 2.88782\n",
      "[epoch 494, batch     4] loss: 4.08827\n",
      "[epoch 494, batch     5] loss: 3.63513\n",
      "[epoch 494, batch     6] loss: 3.20350\n",
      "[epoch 494, batch     7] loss: 3.11605\n",
      "[epoch 494, batch     8] loss: 2.60166\n",
      "[epoch 494, batch     9] loss: 2.65978\n",
      "[epoch 494, batch    10] loss: 3.51188\n",
      "[epoch 494, batch    11] loss: 3.35653\n",
      "[epoch 494, batch    12] loss: 2.01637\n",
      "[epoch 494, batch    13] loss: 3.02365\n",
      "[epoch 494, batch    14] loss: 4.12436\n",
      "[epoch 494, batch    15] loss: 4.06213\n",
      "[epoch 494, batch    16] loss: 2.24618\n",
      "[epoch 494, batch    17] loss: 3.16625\n",
      "[epoch 494, batch    18] loss: 2.64104\n",
      "[epoch 494, batch    19] loss: 2.10240\n",
      "[epoch 494, batch    20] loss: 3.68349\n",
      "[epoch 494, batch    21] loss: 2.52266\n",
      "[epoch 494, batch    22] loss: 3.40504\n",
      "[epoch 494, batch    23] loss: 3.17843\n",
      "[epoch 494, batch    24] loss: 2.88828\n",
      "[epoch 494, batch    25] loss: 2.51581\n",
      "[epoch 494, batch    26] loss: 2.99570\n",
      "[epoch 494, batch    27] loss: 3.22163\n",
      "[epoch 494, batch    28] loss: 3.46397\n",
      "[epoch 494, batch    29] loss: 2.91441\n",
      "[epoch 494, batch    30] loss: 3.11198\n",
      "[epoch 494, batch    31] loss: 2.52192\n",
      "[epoch 494, batch    32] loss: 2.87890\n",
      "[epoch 495, batch     1] loss: 3.04343\n",
      "[epoch 495, batch     2] loss: 3.06103\n",
      "[epoch 495, batch     3] loss: 2.53526\n",
      "[epoch 495, batch     4] loss: 3.34839\n",
      "[epoch 495, batch     5] loss: 2.68921\n",
      "[epoch 495, batch     6] loss: 3.02605\n",
      "[epoch 495, batch     7] loss: 2.86396\n",
      "[epoch 495, batch     8] loss: 3.40098\n",
      "[epoch 495, batch     9] loss: 2.56379\n",
      "[epoch 495, batch    10] loss: 3.10437\n",
      "[epoch 495, batch    11] loss: 3.74528\n",
      "[epoch 495, batch    12] loss: 2.62091\n",
      "[epoch 495, batch    13] loss: 3.51190\n",
      "[epoch 495, batch    14] loss: 2.89005\n",
      "[epoch 495, batch    15] loss: 2.16232\n",
      "[epoch 495, batch    16] loss: 3.24883\n",
      "[epoch 495, batch    17] loss: 2.63974\n",
      "[epoch 495, batch    18] loss: 3.00344\n",
      "[epoch 495, batch    19] loss: 3.08234\n",
      "[epoch 495, batch    20] loss: 2.85183\n",
      "[epoch 495, batch    21] loss: 3.80994\n",
      "[epoch 495, batch    22] loss: 3.05097\n",
      "[epoch 495, batch    23] loss: 2.46326\n",
      "[epoch 495, batch    24] loss: 3.38029\n",
      "[epoch 495, batch    25] loss: 2.45386\n",
      "[epoch 495, batch    26] loss: 3.18801\n",
      "[epoch 495, batch    27] loss: 3.07730\n",
      "[epoch 495, batch    28] loss: 3.09200\n",
      "[epoch 495, batch    29] loss: 2.94838\n",
      "[epoch 495, batch    30] loss: 3.03582\n",
      "[epoch 495, batch    31] loss: 4.21899\n",
      "[epoch 495, batch    32] loss: 2.98118\n",
      "[epoch 496, batch     1] loss: 3.30116\n",
      "[epoch 496, batch     2] loss: 2.54453\n",
      "[epoch 496, batch     3] loss: 2.87704\n",
      "[epoch 496, batch     4] loss: 3.55833\n",
      "[epoch 496, batch     5] loss: 2.99660\n",
      "[epoch 496, batch     6] loss: 2.83873\n",
      "[epoch 496, batch     7] loss: 2.45840\n",
      "[epoch 496, batch     8] loss: 3.26407\n",
      "[epoch 496, batch     9] loss: 3.81878\n",
      "[epoch 496, batch    10] loss: 3.43666\n",
      "[epoch 496, batch    11] loss: 2.62915\n",
      "[epoch 496, batch    12] loss: 2.95117\n",
      "[epoch 496, batch    13] loss: 2.63996\n",
      "[epoch 496, batch    14] loss: 2.69602\n",
      "[epoch 496, batch    15] loss: 3.08774\n",
      "[epoch 496, batch    16] loss: 2.98030\n",
      "[epoch 496, batch    17] loss: 2.49293\n",
      "[epoch 496, batch    18] loss: 3.04333\n",
      "[epoch 496, batch    19] loss: 3.03993\n",
      "[epoch 496, batch    20] loss: 3.46714\n",
      "[epoch 496, batch    21] loss: 2.56371\n",
      "[epoch 496, batch    22] loss: 2.98136\n",
      "[epoch 496, batch    23] loss: 2.97908\n",
      "[epoch 496, batch    24] loss: 3.17025\n",
      "[epoch 496, batch    25] loss: 2.83557\n",
      "[epoch 496, batch    26] loss: 3.64414\n",
      "[epoch 496, batch    27] loss: 4.05744\n",
      "[epoch 496, batch    28] loss: 3.31368\n",
      "[epoch 496, batch    29] loss: 2.57116\n",
      "[epoch 496, batch    30] loss: 2.86707\n",
      "[epoch 496, batch    31] loss: 3.31989\n",
      "[epoch 496, batch    32] loss: 3.42752\n",
      "[epoch 497, batch     1] loss: 2.73010\n",
      "[epoch 497, batch     2] loss: 4.10354\n",
      "[epoch 497, batch     3] loss: 3.17345\n",
      "[epoch 497, batch     4] loss: 3.35716\n",
      "[epoch 497, batch     5] loss: 3.41505\n",
      "[epoch 497, batch     6] loss: 3.42612\n",
      "[epoch 497, batch     7] loss: 3.19175\n",
      "[epoch 497, batch     8] loss: 3.37176\n",
      "[epoch 497, batch     9] loss: 2.70509\n",
      "[epoch 497, batch    10] loss: 2.43960\n",
      "[epoch 497, batch    11] loss: 3.48521\n",
      "[epoch 497, batch    12] loss: 2.63762\n",
      "[epoch 497, batch    13] loss: 3.21040\n",
      "[epoch 497, batch    14] loss: 2.37552\n",
      "[epoch 497, batch    15] loss: 2.33864\n",
      "[epoch 497, batch    16] loss: 3.22916\n",
      "[epoch 497, batch    17] loss: 2.39118\n",
      "[epoch 497, batch    18] loss: 3.10154\n",
      "[epoch 497, batch    19] loss: 2.65436\n",
      "[epoch 497, batch    20] loss: 2.85063\n",
      "[epoch 497, batch    21] loss: 3.77592\n",
      "[epoch 497, batch    22] loss: 3.39021\n",
      "[epoch 497, batch    23] loss: 2.62602\n",
      "[epoch 497, batch    24] loss: 2.67717\n",
      "[epoch 497, batch    25] loss: 2.75668\n",
      "[epoch 497, batch    26] loss: 3.23526\n",
      "[epoch 497, batch    27] loss: 3.11787\n",
      "[epoch 497, batch    28] loss: 3.45889\n",
      "[epoch 497, batch    29] loss: 3.01665\n",
      "[epoch 497, batch    30] loss: 2.82642\n",
      "[epoch 497, batch    31] loss: 3.30446\n",
      "[epoch 497, batch    32] loss: 1.85761\n",
      "[epoch 498, batch     1] loss: 2.82085\n",
      "[epoch 498, batch     2] loss: 2.94525\n",
      "[epoch 498, batch     3] loss: 2.80992\n",
      "[epoch 498, batch     4] loss: 3.37974\n",
      "[epoch 498, batch     5] loss: 2.88606\n",
      "[epoch 498, batch     6] loss: 3.78966\n",
      "[epoch 498, batch     7] loss: 2.78700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 498, batch     8] loss: 2.76162\n",
      "[epoch 498, batch     9] loss: 2.68581\n",
      "[epoch 498, batch    10] loss: 3.67364\n",
      "[epoch 498, batch    11] loss: 3.16363\n",
      "[epoch 498, batch    12] loss: 3.35666\n",
      "[epoch 498, batch    13] loss: 3.02523\n",
      "[epoch 498, batch    14] loss: 3.62964\n",
      "[epoch 498, batch    15] loss: 2.80438\n",
      "[epoch 498, batch    16] loss: 2.52415\n",
      "[epoch 498, batch    17] loss: 3.55538\n",
      "[epoch 498, batch    18] loss: 2.22001\n",
      "[epoch 498, batch    19] loss: 2.89608\n",
      "[epoch 498, batch    20] loss: 2.55748\n",
      "[epoch 498, batch    21] loss: 2.74555\n",
      "[epoch 498, batch    22] loss: 3.62305\n",
      "[epoch 498, batch    23] loss: 3.43042\n",
      "[epoch 498, batch    24] loss: 3.13028\n",
      "[epoch 498, batch    25] loss: 2.94148\n",
      "[epoch 498, batch    26] loss: 3.58362\n",
      "[epoch 498, batch    27] loss: 3.15206\n",
      "[epoch 498, batch    28] loss: 4.40612\n",
      "[epoch 498, batch    29] loss: 2.32002\n",
      "[epoch 498, batch    30] loss: 2.30054\n",
      "[epoch 498, batch    31] loss: 2.57443\n",
      "[epoch 498, batch    32] loss: 2.00139\n",
      "[epoch 499, batch     1] loss: 3.29149\n",
      "[epoch 499, batch     2] loss: 2.72427\n",
      "[epoch 499, batch     3] loss: 3.03698\n",
      "[epoch 499, batch     4] loss: 3.07572\n",
      "[epoch 499, batch     5] loss: 3.15998\n",
      "[epoch 499, batch     6] loss: 2.79621\n",
      "[epoch 499, batch     7] loss: 2.65081\n",
      "[epoch 499, batch     8] loss: 3.48884\n",
      "[epoch 499, batch     9] loss: 3.33370\n",
      "[epoch 499, batch    10] loss: 2.78906\n",
      "[epoch 499, batch    11] loss: 2.83518\n",
      "[epoch 499, batch    12] loss: 2.96825\n",
      "[epoch 499, batch    13] loss: 2.58730\n",
      "[epoch 499, batch    14] loss: 3.22518\n",
      "[epoch 499, batch    15] loss: 3.21366\n",
      "[epoch 499, batch    16] loss: 3.12601\n",
      "[epoch 499, batch    17] loss: 3.48605\n",
      "[epoch 499, batch    18] loss: 2.87069\n",
      "[epoch 499, batch    19] loss: 2.81665\n",
      "[epoch 499, batch    20] loss: 3.11261\n",
      "[epoch 499, batch    21] loss: 2.72777\n",
      "[epoch 499, batch    22] loss: 3.00702\n",
      "[epoch 499, batch    23] loss: 3.68765\n",
      "[epoch 499, batch    24] loss: 2.82867\n",
      "[epoch 499, batch    25] loss: 2.86032\n",
      "[epoch 499, batch    26] loss: 3.67249\n",
      "[epoch 499, batch    27] loss: 3.20628\n",
      "[epoch 499, batch    28] loss: 3.59009\n",
      "[epoch 499, batch    29] loss: 2.46759\n",
      "[epoch 499, batch    30] loss: 3.14746\n",
      "[epoch 499, batch    31] loss: 2.44473\n",
      "[epoch 499, batch    32] loss: 5.15836\n",
      "[epoch 500, batch     1] loss: 3.41152\n",
      "[epoch 500, batch     2] loss: 2.52967\n",
      "[epoch 500, batch     3] loss: 3.25937\n",
      "[epoch 500, batch     4] loss: 2.82873\n",
      "[epoch 500, batch     5] loss: 3.01424\n",
      "[epoch 500, batch     6] loss: 3.06825\n",
      "[epoch 500, batch     7] loss: 2.85252\n",
      "[epoch 500, batch     8] loss: 2.84695\n",
      "[epoch 500, batch     9] loss: 2.85042\n",
      "[epoch 500, batch    10] loss: 2.76084\n",
      "[epoch 500, batch    11] loss: 2.88070\n",
      "[epoch 500, batch    12] loss: 2.92118\n",
      "[epoch 500, batch    13] loss: 2.97116\n",
      "[epoch 500, batch    14] loss: 3.31629\n",
      "[epoch 500, batch    15] loss: 3.32628\n",
      "[epoch 500, batch    16] loss: 2.60484\n",
      "[epoch 500, batch    17] loss: 3.62922\n",
      "[epoch 500, batch    18] loss: 3.17851\n",
      "[epoch 500, batch    19] loss: 2.76967\n",
      "[epoch 500, batch    20] loss: 2.83343\n",
      "[epoch 500, batch    21] loss: 2.50439\n",
      "[epoch 500, batch    22] loss: 3.69022\n",
      "[epoch 500, batch    23] loss: 2.70791\n",
      "[epoch 500, batch    24] loss: 2.75829\n",
      "[epoch 500, batch    25] loss: 2.80697\n",
      "[epoch 500, batch    26] loss: 2.89042\n",
      "[epoch 500, batch    27] loss: 3.26436\n",
      "[epoch 500, batch    28] loss: 3.13642\n",
      "[epoch 500, batch    29] loss: 4.17984\n",
      "[epoch 500, batch    30] loss: 3.00914\n",
      "[epoch 500, batch    31] loss: 3.13193\n",
      "[epoch 500, batch    32] loss: 1.97394\n"
     ]
    }
   ],
   "source": [
    "lvm = train2(lvm, data, batch_size=64)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response_net_param weight:  Parameter containing:\n",
      "tensor([[ 0.0791],\n",
      "        [-1.0239],\n",
      "        [ 0.9633]], dtype=torch.float64, requires_grad=True)\n",
      "response_net_param bias:  Parameter containing:\n",
      "tensor([-0.1999,  1.1499,  1.0392], dtype=torch.float64, requires_grad=True)\n",
      "iv model param bias:  Parameter containing:\n",
      "tensor([-0.0572], dtype=torch.float64, requires_grad=True)\n",
      "iv model param:  Parameter containing:\n",
      "tensor([[ 0.3823, -0.1420, -0.6842, -0.6079]], dtype=torch.float64,\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print('response_net_param weight: ', lvm.response.response_net[0].weight)\n",
    "print('response_net_param bias: ', lvm.response.response_net[0].bias)\n",
    "print('iv model param bias: ', lvm.ivm.z_logscale_fc.bias)\n",
    "print('iv model param: ', lvm.ivm.z_logscale_fc.weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.3675]], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lvm.ivm.z_logscale_fc.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0716], dtype=torch.float64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(lvm.ivm.z_logscale_fc.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/yuchenzhu/miniconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m(156)\u001b[0;36mbackward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    154 \u001b[0;31m    Variable._execution_engine.run_backward(\n",
      "\u001b[0m\u001b[0;32m    155 \u001b[0;31m        \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 156 \u001b[0;31m        allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0m\u001b[0;32m    157 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    158 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> exit\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.9018, 0.5114, 2.3246],\n",
       "        [5.2017, 4.1888, 4.1847],\n",
       "        [6.0157, 8.1930, 5.6748]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_dist = torch.distributions.Normal(torch.tensor([[3.], [5.], [7.]]), torch.tensor([[1.,1.,1.]]))\n",
    "_dist.rsample()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LVM(\n",
       "  (ivm): IVModel(\n",
       "    (z_feature): Sequential(\n",
       "      (0): Linear(in_features=1, out_features=4, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (z_mean_fc): Linear(in_features=4, out_features=1, bias=True)\n",
       "    (z_logscale_fc): Linear(in_features=4, out_features=1, bias=True)\n",
       "  )\n",
       "  (ndecoder): NDecoder(\n",
       "    (n_logscale_fc): Linear(in_features=1, out_features=1, bias=True)\n",
       "  )\n",
       "  (mdecoder): MDecoder(\n",
       "    (m_logscale_fc): Linear(in_features=1, out_features=1, bias=True)\n",
       "  )\n",
       "  (encoder): Encoder(\n",
       "    (q_nonlinear): Sequential(\n",
       "      (0): Linear(in_features=3, out_features=6, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (q_mean_fc): Linear(in_features=6, out_features=1, bias=True)\n",
       "    (q_logscale_fc): Linear(in_features=6, out_features=1, bias=True)\n",
       "  )\n",
       "  (response): ResponseModel(\n",
       "    (response_net): Sequential(\n",
       "      (0): Linear(in_features=1, out_features=3, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=3, out_features=3, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=3, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lvm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuchenzhu/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "Y_pred = lvm.response(torch.tensor(data.X)).detach().numpy().flatten()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9c30281d50>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(data.M.flatten(), data.Y.flatten(), '.')\n",
    "plt.plot(data.X.flatten(), data.Y_struct.flatten(), '.')\n",
    "plt.plot(data.X.flatten(), Y_pred, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = lvm.response(torch.cat([data.X_hidden, data.covariate], axis=-1).double()).detach().numpy().flatten()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdb7e371110>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(data.M.flatten(), data.Y.flatten(), '.')\n",
    "plt.plot(data.X_hidden.flatten(), data.Y_struct.flatten(), '.')\n",
    "plt.plot(data.X_hidden.flatten(), Y_pred.flatten(), '.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdb80189750>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(data.M.flatten(), data.Y.flatten(), '.')\n",
    "plt.plot(data.X_hidden.flatten(), data.Y_struct.flatten(), '.')\n",
    "plt.plot(data.X_hidden.flatten(), Y_pred.flatten(), '.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdb80118990>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(data.M.flatten(), data.Y.flatten(), '.')\n",
    "plt.plot(data.X_hidden.flatten(), data.Y_struct.flatten(), '.')\n",
    "plt.plot(data.X_hidden.flatten(), Y_pred.flatten(), '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdb8058c3d0>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(data.M.flatten(), data.Y.flatten(), '.')\n",
    "plt.plot(data.X_hidden.flatten(), data.Y_struct.flatten(), '.')\n",
    "plt.plot(data.X_hidden.flatten(), Y_pred.flatten(), '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdb805cc6d0>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(data.M.flatten(), data.Y.flatten(), '.')\n",
    "plt.plot(data.X_hidden.flatten(), data.Y_struct.flatten(), '.')\n",
    "plt.plot(data.X_hidden.flatten(), Y_pred.flatten(), '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f94e0fc6350>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(data.M.flatten(), data.Y.flatten(), '.')\n",
    "plt.plot(data.X_hidden.flatten(), data.Y_struct.flatten(), '.')\n",
    "plt.plot(data.X_hidden.flatten(), Y_pred.flatten(), '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fadb90be190>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(data.M.flatten(), data.Y.flatten(), '.')\n",
    "plt.plot(data.X_hidden.flatten(), data.Y_struct.flatten(), '.')\n",
    "plt.plot(data.X_hidden.flatten(), Y_pred.flatten(), '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff19ebc6190>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(data.M.flatten(), data.Y.flatten(), '.')\n",
    "plt.plot(data.X_hidden.flatten(), data.Y_struct.flatten(), '.')\n",
    "plt.plot(data.X_hidden.flatten(), Y_pred.flatten(), '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
